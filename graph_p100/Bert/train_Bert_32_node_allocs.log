bert/encoder/layer_4/output/LayerNorm/beta/read
bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_2_grad/Mul_1
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
add_689
bert/encoder/layer_7/attention/self/dropout/random_uniform/RandomUniform
	24.0
Square_123
Assign_95
Square_119
bert/encoder/layer_1/attention/self/Reshape_1
bert/encoder/layer_9/attention/self/key/MatMul
	12.0
bert/encoder/layer_7/attention/self/value/bias/adam_v
Mul_871
	9.0
bert/pooler/dense/kernel/adam_v/read
gradients/cls/predictions/transform/LayerNorm/moments/SquaredDifference_grad/sub
Mul_673
	0.0029296875
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.02783203125
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
bert/encoder/layer_3/attention/output/LayerNorm/gamma/read
Mul_192
gradients/bert/encoder/layer_8/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
truediv_150
mul_375
bert/encoder/layer_3/attention/self/value/bias/adam_m
bert/encoder/layer_9/attention/self/key/kernel/adam_m/read
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
mul_795
bert/encoder/layer_0/attention/output/LayerNorm/moments/variance
	0.015625
bert/encoder/layer_5/attention/output/dense/kernel
Assign_320
Square_12
	0.0029296875
bert/encoder/layer_3/output/LayerNorm/moments/mean
	0.015625
gradients/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1
	3.0
cls/predictions/transform/dense/bias/read
bert/encoder/layer_4/attention/self/value/bias/adam_v/read
bert/encoder/layer_10/attention/output/dropout/GreaterEqual
	3.0
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v
gradients/bert/encoder/layer_9/attention/output/dense/MatMul_grad/MatMul
	12.0
cls/predictions/output_bias/adam_v
gradients/bert/encoder/layer_10/output/dense/MatMul_grad/MatMul
	51.0
add_601
add_63
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v
bert/encoder/layer_0/output/LayerNorm/beta/adam_v
global_norm/L2Loss_136
	0.000244140625
Mul_243
	0.0029296875
Mul_448
Square_46
	0.0029296875
global_step
bert/encoder/layer_10/intermediate/dense/kernel/read
gradients/bert/embeddings/LayerNorm/moments/mean_grad/Tile
	19.5
bert/encoder/layer_5/output/dense/bias/adam_m
bert/encoder/layer_8/attention/self/key/bias/adam_v
truediv_93
bert/encoder/layer_11/output/dense/kernel/adam_v/read
bert/embeddings/token_type_embeddings
mul_778
	9.0
mul_638
	2.25
gradients/bert/encoder/layer_3/output/dropout/mul_1_grad/Mul
	12.0
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m/read
Assign_374
bert/encoder/layer_5/attention/output/dense/bias/adam_v/read
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1
	12.0
sub_196
add_212
Mul_665
bert/encoder/layer_9/attention/self/transpose_2
	12.0
bert/encoder/layer_7/attention/self/query/kernel/read
bert/encoder/layer_8/intermediate/dense/kernel/adam_m/read
mul_15
Mul_898
	0.0029296875
mul_596
gradients/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1
	3.0
bert/encoder/layer_10/output/LayerNorm/beta/adam_m
bert/encoder/layer_0/attention/self/value/bias/adam_m/read
bert/encoder/layer_9/attention/output/dense/BiasAdd
mul_661
add_633
bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2
	12.0
add_173
bert/encoder/layer_8/output/LayerNorm/beta/adam_m/read
edge_1785_bert/embeddings/Reshape@@MemcpyHtoD
Sqrt_112
	0.01171875
Sqrt_80
	0.01171875
Assign_354
gradients/bert/encoder/layer_3/output/LayerNorm/moments/variance_grad/truediv
Mul_127
gradients/bert/encoder/layer_7/intermediate/dense/MatMul_grad/MatMul
	12.0
add_375
gradients/bert/encoder/layer_8/attention/output/dense/MatMul_grad/MatMul
	12.0
Assign_336
bert/encoder/layer_9/attention/output/dense/bias/adam_v
bert/pooler/dense/kernel/adam_m
gradients/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Tile
	12.0
global_norm/L2Loss_125
	0.000244140625
Assign_453
bert/encoder/layer_3/attention/output/dense/kernel/adam_v/read
bert/encoder/layer_11/output/LayerNorm/gamma/adam_v
truediv_125
Mul_293
bert/encoder/layer_1/output/LayerNorm/gamma
Mul_689
	12.0
mul_279
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2_grad/Mul
gradients/AddN_54
clip_by_global_norm/mul_157
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
Assign_449
Square_22
	0.0029296875
Assign_52
gradients/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
truediv_117
bert/encoder/layer_1/attention/self/key/kernel/adam_m
sub_127
gradients/bert/encoder/layer_1/attention/self/transpose_grad/transpose
	19.5
bert/encoder/layer_5/attention/self/query/bias/adam_v
Mul_124
	0.0029296875
bert/encoder/layer_8/attention/self/dropout/random_uniform
bert/pooler/dense/kernel/adam_m/read
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v/read
mul_891
gradients/bert/encoder/layer_3/attention/self/Softmax_grad/mul_1
	24.0
bert/encoder/layer_2/attention/self/key/kernel/adam_v
Assign_429
bert/encoder/layer_11/attention/self/Reshape_2
gradients/bert/encoder/layer_7/output/dropout/mul_1_grad/Mul
	12.0
bert/embeddings/position_embeddings
Sqrt_55
	2.25
gradients/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/cls/seq_relationship/BiasAdd_grad/BiasAddGrad
	0.000244140625
bert/encoder/layer_2/attention/self/value/MatMul
	12.0
mul_155
	2.25
add_696
bert/encoder/layer_11/attention/self/query/kernel/adam_m/read
Mul_104
gradients/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference_grad/scalar
gradients/bert/pooler/dense/MatMul_grad/MatMul_1
	2.25
global_norm/L2Loss_90
	0.000244140625
truediv_29
bert/encoder/layer_0/intermediate/dense/bias/adam_v
clip_by_global_norm/mul_113
bert/encoder/layer_2/attention/output/LayerNorm/moments/variance
	0.015625
Assign_481
Square_64
	0.01806640625
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
Mul_16
	1.5
cls/predictions/Sum
	0.00244140625
	0.000244140625
clip_by_global_norm/mul_37
bert/encoder/layer_5/intermediate/dense/add_1
	48.0
gradients/bert/embeddings/add_1_grad/Sum
	0.375
Mul_912
gradients/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv
Sqrt_78
	0.0029296875
clip_by_global_norm/mul
bert/encoder/layer_4/intermediate/dense/kernel
add_378
bert/encoder/layer_7/attention/output/dropout/GreaterEqual
	3.0
Mul_224
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul
	12.0
gradients/bert/pooler/dense/MatMul_grad/MatMul
	0.09375
Square_167
bert/encoder/layer_10/output/dense/MatMul
	12.0
gradients/bert/encoder/layer_4/intermediate/dense/mul_2_grad/Mul_1
bert/encoder/layer_3/attention/self/dropout/mul
	24.0
add_133
sub_121
gradients/bert/encoder/layer_5/output/LayerNorm/moments/variance_grad/truediv
Assign_398
add_587
global_norm/L2Loss_118
	0.000244140625
Mul_1098
	0.116455078125
bert/encoder/layer_9/output/dense/kernel/read
gradients/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_7/output/dense/kernel
bert/encoder/layer_2/intermediate/dense/bias
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
gradients/bert/pooler/Squeeze_grad/Shape
Mul_696
	0.01171875
bert/embeddings/LayerNorm/beta/adam_m
mul_633
sub_134
sub_181
Mul_611
bert/encoder/layer_10/attention/output/LayerNorm/beta/read
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2
	12.0
add_162
bert/encoder/layer_9/attention/output/dense/bias/adam_m/read
bert/encoder/layer_8/output/dense/bias/adam_m/read
Mul_314
	2.25
gradients/bert/encoder/layer_11/output/dropout/mul_1_grad/Mul
	12.0
add_581
bert/encoder/layer_4/attention/self/Mul
bert/encoder/layer_7/attention/self/key/bias/adam_v/read
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
truediv_120
edge_1712_Cast@@MemcpyDtoH
mul_639
bert/encoder/layer_11/intermediate/dense/add
truediv_162
global_norm/L2Loss_57
	0.000244140625
	0.0087890625
bert/encoder/layer_5/attention/output/dense/kernel/read
gradients/bert/encoder/layer_8/intermediate/dense/Pow_grad/Pow
	48.0
sub_137
bert/encoder/layer_7/output/dropout/Cast
	12.0
Sqrt_107
	2.25
clip_by_global_norm/mul_81
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1
	12.0
gradients/bert/encoder/layer_9/output/dropout/mul_1_grad/Mul
	12.0
bert/encoder/layer_5/intermediate/dense/kernel/adam_v
bert/encoder/layer_6/attention/self/query/bias/adam_m/read
mul_843
	2.25
gradients/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul_1
Assign_360
cls/predictions/transform/dense/add
gradients/bert/encoder/layer_1/intermediate/dense/mul_3_grad/Mul_1
	48.0
global_norm/L2Loss_1
	0.000244140625
gradients/AddN_31
bert/encoder/layer_7/attention/self/value/MatMul
	12.0
bert/encoder/layer_10/attention/output/LayerNorm/beta
bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1
	12.0
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.018310546875
Mul_277
	0.0029296875
Mul_158
Mul_309
	0.0029296875
truediv_60
bert/encoder/layer_6/attention/self/key/bias/adam_m/read
bert/encoder/layer_5/attention/self/key/kernel/adam_v
gradients/bert/encoder/layer_6/attention/self/transpose_1_grad/transpose
	12.0
add_456
bert/encoder/layer_3/intermediate/dense/add_1
	48.0
bert/encoder/layer_4/attention/output/dropout/random_uniform
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
Square_3
	0.0029296875
mul_714
sub_25
mul_414
Assign_126
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
truediv_36
bert/encoder/layer_3/intermediate/dense/mul
gradients/bert/encoder/layer_10/output/dropout/mul_grad/Mul
bert/encoder/layer_1/output/LayerNorm/beta/adam_m
bert/encoder/layer_7/attention/self/value/bias/adam_v/read
global_norm/L2Loss_98
	0.000244140625
bert/encoder/layer_8/intermediate/dense/kernel/adam_v/read
cls/predictions/one_hot
	74.5166015625
global_norm/L2Loss_64
	0.000244140625
gradients/bert/encoder/layer_9/intermediate/dense/Pow_grad/mul
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v/read
global_step/add
	0.000244140625
gradients/bert/encoder/layer_3/intermediate/dense/mul_1_grad/Mul_1
bert/encoder/layer_4/attention/output/LayerNorm/beta
bert/encoder/layer_9/output/dense/kernel/adam_m
gradients/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul
	48.0
gradients/bert/encoder/layer_2/output/LayerNorm/moments/mean_grad/Tile
	15.75
bert/encoder/layer_1/output/add
gradients/bert/encoder/layer_5/attention/self/value/MatMul_grad/MatMul
	12.0
cls/predictions/transform/dense/kernel/adam_v/read
add_687
sub_87
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
add_110
add_40
gradients/bert/encoder/layer_10/intermediate/dense/Pow_grad/Pow
	48.0
bert/encoder/layer_3/attention/self/query/kernel/adam_v/read
bert/encoder/layer_2/attention/self/key/bias
bert/encoder/layer_5/attention/self/query/kernel/adam_v/read
bert/encoder/layer_6/output/dense/kernel/read
bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1
cls/predictions/MatMul
	74.5166015625
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m/read
bert/encoder/layer_6/intermediate/dense/Pow
	48.0
bert/encoder/layer_4/attention/self/add
Mul_937
add_383
gradients/bert/encoder/layer_11/attention/self/query/MatMul_grad/MatMul_1
	3.5625
truediv_86
bert/encoder/layer_2/attention/output/dense/bias/read
add_321
truediv_100
gradients/bert/encoder/layer_4/output/LayerNorm/moments/variance_grad/truediv
bert/encoder/layer_8/output/LayerNorm/gamma/adam_m
gradients/bert/encoder/layer_7/output/LayerNorm/moments/variance_grad/truediv
bert/encoder/layer_9/attention/self/query/kernel/adam_v/read
bert/encoder/layer_7/attention/output/dense/bias/adam_m/read
Mul_206
	2.25
mul_64
Assign_531
Mul_751
bert/encoder/layer_3/intermediate/dense/Pow
	48.0
add_114
Assign_288
bert/encoder/layer_10/attention/output/dense/kernel/adam_m
Assign_464
Mul_190
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
bert/encoder/layer_6/attention/self/add
Assign_384
Assign_218
bert/encoder/layer_4/attention/self/Reshape
global_norm/L2Loss_190
	0.000244140625
sub_59
gradients/bert/encoder/layer_5/attention/self/Softmax_grad/sub
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
gradients/bert/encoder/layer_10/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_5/attention/self/dropout/GreaterEqual
	6.0
bert/encoder/layer_6/output/dropout/random_uniform/mul
gradients/bert/encoder/layer_6/attention/output/dropout/mul_1_grad/Mul
	12.0
bert/encoder/layer_2/output/dropout/random_uniform/mul
Assign_612
bert/encoder/layer_8/attention/self/query/kernel/read
Mul_142
	2.25
Mul_1006
	0.0029296875
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2
	12.0
Mul_253
	0.0029296875
global_norm/L2Loss_148
	0.000244140625
Assign_574
global_norm/L2Loss_131
	0.000244140625
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
clip_by_global_norm/mul_31
Mul_523
	0.01171875
bert/encoder/layer_2/attention/self/dropout/GreaterEqual
	6.0
gradients/bert/encoder/layer_8/output/dense/MatMul_grad/MatMul_1
	12.0
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
Mul_818
	2.25
gradients/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul
	12.0
clip_by_global_norm/mul_200
global_norm/L2Loss_25
	0.000244140625
	0.0087890625
Square_76
	0.0029296875
Mul_185
	9.0
Mul_570
	2.25
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
bert/encoder/layer_2/output/LayerNorm/moments/mean
	0.015625
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul
	12.0
add_447
sub_112
Assign_362
bert/encoder/layer_6/output/LayerNorm/beta
Sqrt_138
	0.0029296875
bert/encoder/layer_7/intermediate/dense/kernel/adam_m/read
bert/encoder/layer_3/attention/self/dropout/random_uniform/RandomUniform
	24.0
bert/encoder/layer_9/attention/output/dropout/Cast
	12.0
mul_1015
	2.25
Mul_372
truediv_175
bert/encoder/layer_10/attention/self/dropout/GreaterEqual
	6.0
mul_982
	2.25
bert/encoder/layer_1/intermediate/dense/bias/adam_v/read
gradients/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/scalar
gradients/bert/encoder/layer_9/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_4/attention/output/dense/kernel/read
bert/encoder/layer_6/output/LayerNorm/batchnorm/sub
Square_45
	0.0029296875
bert/encoder/layer_4/attention/self/query/kernel/adam_v/read
add_103
gradients/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1
	2.25
gradients/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum
	0.02490234375
gradients/bert/embeddings/Slice_grad/Pad
	1.5
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
bert/encoder/layer_8/output/dropout/mul
	12.0
gradients/bert/encoder/layer_3/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_6/intermediate/dense/MatMul_grad/MatMul
	12.0
Mul_980
	2.25
bert/encoder/layer_2/attention/self/dropout/mul
	24.0
Assign_462
add_458
Mul_555
	0.0048828125
bert/encoder/layer_6/intermediate/dense/bias
global_norm/L2Loss_205
	0.000244140625
bert/encoder/layer_9/output/LayerNorm/gamma/adam_v
clip_by_global_norm/mul_64
clip_by_global_norm/mul_2
add_586
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
Mul_857
	0.0029296875
Assign_269
gradients/bert/encoder/layer_9/intermediate/dense/Pow_grad/mul_1
bert/encoder/layer_5/attention/self/query/bias/adam_v/read
bert/encoder/layer_0/attention/self/Mul/y
global_norm/L2Loss_8
	0.000244140625
gradients/bert/encoder/layer_11/attention/self/query/MatMul_grad/MatMul
	15.75
Square_28
	0.0029296875
bert/encoder/layer_8/output/add
Mul_180
	0.01171875
Square_185
bert/encoder/layer_11/output/dropout/Cast
	12.0
bert/encoder/layer_10/attention/output/dropout/mul_1
bert/encoder/layer_11/output/LayerNorm/beta/adam_v
Assign_427
global_norm/L2Loss_75
	0.000244140625
	0.0087890625
bert/encoder/layer_8/attention/output/dropout/mul_1
add_229
bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference
	12.0
bert/encoder/layer_4/intermediate/dense/bias/adam_v/read
add_604
Assign_72
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2
	12.0
Mul_848
clip_by_global_norm/mul_152
bert/encoder/layer_4/attention/output/dense/kernel/adam_m/read
global_norm/L2Loss_146
	0.000244140625
Assign_174
bert/encoder/layer_4/attention/output/LayerNorm/moments/variance
	0.015625
bert/encoder/layer_4/attention/output/dropout/GreaterEqual
	3.0
global_norm/L2Loss_94
	0.000244140625
bert/encoder/layer_7/attention/self/transpose
	12.0
gradients/bert/encoder/layer_3/attention/self/Reshape_2_grad/Reshape
Sqrt_2
	2.25
Square_30
	0.0029296875
bert/encoder/layer_2/attention/self/query/kernel
truediv_192
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v/read
add_227
Assign_548
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
truediv_153
add_596
bert/encoder/layer_3/attention/output/dense/kernel/read
gradients/bert/encoder/layer_8/intermediate/dense/mul_1_grad/Mul_1
global_step/cond/Switch_1
bert/encoder/layer_6/attention/self/value/kernel/adam_m
Assign_122
sub_113
Square_62
	0.0029296875
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
gradients/cls/predictions/transform/dense/mul_1_grad/Mul_1
Assign_455
Assign_37
Assign_514
bert/encoder/layer_11/intermediate/dense/mul_1
add_123
gradients/bert/encoder/layer_11/intermediate/dense/Pow_grad/Pow
	48.0
Cast_1
	0.000244140625
bert/encoder/layer_6/output/LayerNorm/gamma
Mul_769
	0.0029296875
bert/encoder/layer_8/attention/output/dense/kernel/adam_v/read
Assign_287
bert/encoder/layer_5/output/dropout/random_uniform/RandomUniform
	12.0
bert/encoder/layer_9/intermediate/dense/kernel
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference
	12.0
truediv_44
add_55
Mul_694
	0.0166015625
bert/encoder/layer_5/attention/self/query/kernel/adam_m/read
add_304
bert/encoder/layer_0/output/LayerNorm/gamma/adam_v/read
Square_10
	0.0029296875
sub_28
gradients/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference_grad/Mul
add_13
bert/encoder/layer_6/intermediate/dense/bias/adam_v
add_310
Square_192
Assign_340
Mul_292
	2.25
bert/encoder/layer_7/attention/self/value/kernel/adam_v/read
bert/encoder/layer_4/attention/output/dense/bias/adam_m/read
bert/embeddings/Reshape_1/shape
cls/predictions/transform/dense/bias/adam_v
Mul_582
	3.0
clip_by_global_norm/mul_77
bert/encoder/layer_0/attention/self/transpose_2
	12.0
clip_by_global_norm/mul_87
bert/encoder/layer_2/attention/self/query/bias
Assign_144
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v/read
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2_grad/Reshape
Mul_458
Assign_22
Sqrt_102
	0.0029296875
sub_117
bert/encoder/layer_2/output/LayerNorm/gamma/adam_v/read
gradients/bert/encoder/layer_6/output/LayerNorm/moments/mean_grad/Tile
	12.0
gradients/bert/encoder/layer_4/attention/self/transpose_1_grad/transpose
	12.0
Assign_404
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
gradients/cls/predictions/transform/LayerNorm/moments/mean_grad/truediv
Square_44
	0.0029296875
clip_by_global_norm/mul_123
Mul_653
	0.0029296875
bert/encoder/layer_6/attention/output/LayerNorm/moments/mean
	0.015625
clip_by_global_norm/mul_198
Mul_207
Sqrt_70
	0.0029296875
add_20
bert/encoder/layer_2/attention/output/dropout/mul
	12.0
Mul_421
cls/seq_relationship/output_weights/adam_v/read
bert/encoder/layer_0/attention/self/key/bias/adam_v
Mul_362
Mul_1099
bert/encoder/layer_10/output/dense/BiasAdd
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v
truediv_140
bert/encoder/layer_5/output/LayerNorm/batchnorm/add
bert/encoder/layer_3/attention/self/key/BiasAdd
bert/encoder/layer_8/attention/output/dense/kernel
bert/encoder/layer_11/attention/self/key/bias/read
Assign_492
bert/encoder/layer_10/attention/output/dense/kernel/read
Mul_167
	0.0029296875
bert/encoder/layer_1/output/dense/bias/adam_m/read
bert/embeddings/position_embeddings/adam_v
truediv_101
sub_48
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul
	12.0
gradients/bert/encoder/layer_8/attention/self/Mul_grad/Mul
gradients/bert/encoder/layer_10/attention/self/MatMul_grad/MatMul_1
	15.169921875
	0.0029296875
	0.0029296875
	0.004638671875
bert/encoder/Reshape_1
gradients/bert/encoder/layer_7/output/LayerNorm/moments/mean_grad/Tile
	12.0
gradients/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul_1
gradients/bert/encoder/layer_2/attention/output/dense/MatMul_grad/MatMul
	12.0
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2_grad/Mul
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
bert/encoder/layer_11/attention/output/dropout/random_uniform/mul
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
gradients/bert/encoder/layer_3/output/dense/MatMul_grad/MatMul
	48.0
Assign_361
bert/encoder/layer_5/output/dropout/random_uniform/mul
gradients/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape
Assign_192
Mul_536
bert/encoder/layer_2/output/dense/kernel/adam_v/read
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m
bert/encoder/layer_1/attention/output/dense/kernel/read
Mul_485
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m/read
sub_202
bert/encoder/layer_4/attention/self/query/BiasAdd
bert/encoder/layer_4/attention/self/value/bias/read
add_651
Mul_1078
bert/encoder/layer_6/attention/self/value/kernel/adam_v/read
Mul_514
bert/encoder/layer_6/attention/self/value/kernel/adam_v
gradients/bert/encoder/layer_5/output/dropout/mul_1_grad/Mul
	12.0
truediv_79
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
clip_by_global_norm/mul_117
bert/encoder/layer_5/attention/self/query/bias
mul_69
	2.25
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2_grad/Reshape
bert/encoder/layer_4/output/LayerNorm/beta/adam_v/read
bert/encoder/layer_1/intermediate/dense/kernel
Sqrt_191
	9.0
add_120
Mul_1082
Mul_108
	0.0029296875
bert/encoder/layer_1/attention/output/dense/bias/adam_v/read
bert/encoder/layer_1/output/dense/bias/read
Mul_1102
	0.005859375
bert/encoder/layer_3/intermediate/dense/Tanh
gradients/AddN_37
bert/encoder/layer_3/intermediate/dense/MatMul
	48.0
bert/encoder/layer_3/attention/self/query/bias/read
Mul_84
bert/encoder/layer_8/output/dense/MatMul
	12.0
add_649
Assign_501
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
bert/encoder/layer_2/attention/self/Reshape_3
Mul_152
mul_397
add_186
bert/encoder/layer_11/attention/output/dense/kernel/adam_v
Assign_489
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m/read
bert/encoder/layer_10/intermediate/dense/bias/adam_m/read
add_433
bert/encoder/layer_3/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_9/output/LayerNorm/moments/mean_grad/truediv
bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2
	12.0
bert/encoder/layer_0/attention/self/dropout/random_uniform/mul
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.00390625
Mul_415
	0.0029296875
gradients/bert/encoder/layer_8/intermediate/dense/MatMul_grad/MatMul_1
	12.0
mul_876
gradients/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_7/intermediate/dense/Tanh
Mul_608
	0.01171875
truediv_33
Square_7
	2.25
add_347
add_645
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape
Assign_204
Square_188
gradients/bert/encoder/layer_8/output/dropout/mul_1_grad/Mul
	12.0
bert/encoder/layer_1/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_7/attention/self/query/bias/adam_v/read
clip_by_global_norm/mul_110
gradients/bert/encoder/layer_4/attention/self/key/MatMul_grad/MatMul
	15.75
bert/encoder/layer_5/attention/self/value/BiasAdd
bert/encoder/layer_6/attention/self/transpose_1
	12.0
add_665
bert/encoder/layer_5/attention/output/dense/MatMul
	12.0
gradients/bert/encoder/layer_5/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_4/intermediate/dense/Tanh
bert/embeddings/LayerNorm/batchnorm/add
bert/encoder/layer_6/output/LayerNorm/beta/adam_v
bert/encoder/layer_5/attention/self/query/bias/adam_m/read
gradients/bert/encoder/layer_11/intermediate/dense/Tanh_grad/TanhGrad
bert/encoder/layer_7/output/LayerNorm/batchnorm/sub
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m/read
cls/seq_relationship/BiasAdd
gradients/bert/encoder/layer_0/attention/self/Softmax_grad/mul
bert/encoder/layer_6/output/LayerNorm/gamma/adam_m
Assign_296
bert/encoder/layer_1/attention/output/dropout/GreaterEqual
	3.0
Assign_544
add_276
bert/encoder/layer_4/attention/output/dropout/mul_1
bert/encoder/layer_11/output/dropout/GreaterEqual
	3.0
bert/encoder/layer_10/attention/self/key/kernel/adam_m
gradients/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/sub
Assign_286
Assign_102
bert/encoder/layer_2/attention/self/value/kernel/adam_v
add_583
cls/predictions/transform/LayerNorm/batchnorm/add_1
bert/encoder/layer_11/intermediate/dense/bias/adam_v
gradients/AddN_22
Sqrt_89
	2.25
bert/encoder/layer_5/attention/self/Softmax
	24.0
	24.0
PolynomialDecay
mul_881
add_324
Mul_470
	0.0029296875
Sqrt_45
	0.0029296875
bert/encoder/layer_1/attention/self/Mul
gradients/bert/encoder/layer_7/attention/self/Softmax_grad/mul
Mul_276
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v/read
bert/encoder/layer_1/output/dense/bias/adam_m
Assign_275
global_norm/L2Loss_160
	0.000244140625
global_norm/L2Loss_201
	0.000244140625
clip_by_global_norm/mul_59
add_460
bert/encoder/layer_2/attention/self/key/kernel/adam_m
clip_by_global_norm/mul_169
Mul_265
cls/predictions/transform/LayerNorm/moments/mean
	0.00244140625
gradients/bert/encoder/layer_6/attention/self/dropout/mul_1_grad/Mul
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Mul_1
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
Mul_291
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
bert/encoder/layer_11/intermediate/dense/BiasAdd
bert/encoder/layer_6/attention/output/LayerNorm/beta/read
global_norm/L2Loss_176
	0.000244140625
bert/encoder/layer_10/intermediate/dense/bias/read
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
mul_773
mul_757
	2.25
gradients/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference_grad/mul_1
bert/encoder/layer_5/output/LayerNorm/gamma/adam_m
Mul_443
	9.0
bert/encoder/layer_2/attention/self/dropout/Cast
	24.0
Assign_109
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub
bert/encoder/layer_6/attention/self/dropout/mul
	24.0
bert/encoder/layer_11/attention/output/dense/kernel/read
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
mul_945
Assign_186
bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1
mul_80
gradients/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape
clip_by_global_norm/mul_197
bert/encoder/layer_7/attention/self/Reshape_1
sub_65
gradients/bert/encoder/layer_9/attention/self/dropout/mul_grad/Mul
Assign_250
gradients/bert/encoder/layer_10/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.012451171875
Assign_578
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/mean_grad/truediv
Assign_314
Assign_380
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
gradients/cls/predictions/MatMul_grad/MatMul
	1.875
bert/encoder/layer_7/attention/self/query/MatMul
	12.0
bert/encoder/layer_6/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_6/attention/self/query/kernel/read
sub_111
gradients/AddN_8
Sqrt_194
	0.0029296875
Assign_289
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
truediv_99
bert/encoder/layer_2/output/dense/BiasAdd
gradients/bert/encoder/layer_10/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
sub_2
bert/encoder/layer_6/output/LayerNorm/gamma/read
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
truediv_17
add_473
bert/encoder/layer_11/intermediate/dense/kernel/read
truediv_114
Mul_909
	0.0029296875
Assign_565
Sqrt_20
	0.0029296875
Mul_172
	9.0
mul_784
add_10
Mul_717
	0.0029296875
Mul_254
global_norm/L2Loss_126
	0.000244140625
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Mul
	1.875
bert/encoder/layer_3/attention/self/key/kernel/adam_m/read
bert/encoder/layer_8/output/LayerNorm/beta/adam_m
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
Sqrt_131
	0.0029296875
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2_grad/Mul
add_251
Mul_976
Square_150
sub_7
Assign_368
gradients/bert/encoder/layer_6/attention/output/dense/MatMul_grad/MatMul
	12.0
add_107
clip_by_global_norm/mul_126
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1
bert/encoder/layer_0/attention/self/query/bias/adam_v
bert/encoder/layer_3/attention/self/key/kernel/adam_v
Assign_231
clip_by_global_norm/mul_204
Mul_462
	2.25
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
gradients/cls/predictions/transform/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
add_527
Assign_199
bert/embeddings/one_hot/off_value
bert/encoder/layer_11/attention/output/dense/BiasAdd
Assign_386
cls/predictions/transform/dense/bias/adam_v/read
bert/encoder/layer_4/attention/self/dropout/Cast
	27.0
Mul_1030
mul_606
	9.0
gradients/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Tile
	15.75
Mul_1091
	0.0029296875
Mul_748
	0.0029296875
add
global_norm/L2Loss_143
	0.000244140625
	0.0087890625
add_333
bert/encoder/layer_0/attention/self/dropout/mul_1
gradients/bert/encoder/layer_3/intermediate/dense/mul_3_grad/Mul
add_468
bert/encoder/layer_11/attention/output/dense/bias
bert/encoder/layer_3/output/dropout/mul
	12.0
truediv_178
sub_56
add_639
gradients/bert/encoder/layer_5/attention/self/dropout/mul_1_grad/Mul
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
bert/encoder/layer_10/attention/self/dropout/mul_1
gradients/bert/encoder/layer_3/attention/self/transpose_3_grad/transpose
	12.0
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
add_559
bert/encoder/layer_4/intermediate/dense/add_1
	48.0
Assign_595
Assign_112
bert/encoder/layer_1/attention/self/query/kernel/adam_v/read
Assign_486
bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2
	12.0
bert/encoder/layer_5/intermediate/dense/mul
bert/encoder/layer_11/attention/output/LayerNorm/moments/variance
	0.015625
bert/encoder/layer_4/output/dropout/mul_1
bert/encoder/layer_11/attention/output/dense/MatMul
	12.0
Sqrt_132
	0.0029296875
bert/encoder/layer_10/output/LayerNorm/gamma/read
bert/encoder/layer_11/output/dropout/random_uniform/RandomUniform
	12.0
add_575
bert/encoder/layer_4/output/LayerNorm/moments/variance
	0.015625
Sqrt_196
	0.0029296875
Assign_155
bert/encoder/layer_4/attention/self/value/kernel/adam_v
global_norm/L2Loss_78
	0.000244140625
mul_908
Assign_431
Assign_23
global_norm/L2Loss_41
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_5/attention/self/key/MatMul_grad/MatMul_1
	2.25
Mul_637
Square_125
Mul_28
gradients/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
mul_1058
Mul_1062
bert/encoder/layer_2/intermediate/dense/kernel/read
gradients/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference_grad/sub
bert/encoder/layer_1/intermediate/dense/bias/adam_m
truediv_73
Assign_132
clip_by_global_norm/mul_8
bert/encoder/layer_10/attention/output/dense/MatMul
	12.0
bert/encoder/layer_1/attention/self/key/bias/read
bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference
	12.0
gradients/bert/encoder/layer_2/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_7/attention/self/query/kernel/adam_m
Mul_1023
	0.0029296875
gradients/bert/encoder/layer_5/attention/self/Reshape_1_grad/Reshape
edge_3486_Reshape_1@@MemcpyHtoD
gradients/bert/encoder/layer_8/attention/self/transpose_grad/transpose
	12.0
gradients/bert/encoder/layer_6/intermediate/dense/Pow_grad/Pow
	48.0
bert/encoder/layer_5/intermediate/dense/mul_2
Assign_451
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
clip_by_global_norm/mul_122
add_622
truediv_134
Sqrt_16
	0.01171875
global_norm/L2Loss_10
	0.000244140625
Sqrt_171
	2.25
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
bert/encoder/layer_0/intermediate/dense/Pow/y
gradients/bert/encoder/layer_6/output/LayerNorm/moments/variance_grad/Tile
	12.0
bert/encoder/layer_5/intermediate/dense/kernel/adam_m
mul_1010
add_247
bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference
	12.0
add_668
bert/encoder/layer_9/attention/self/key/kernel
bert/encoder/mul
	2.25
sub_128
Assign_408
add_37
bert/encoder/layer_9/attention/self/transpose_3
	12.0
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	15.169921875
bert/encoder/layer_8/intermediate/dense/bias/adam_m/read
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
add_158
bert/encoder/layer_10/intermediate/dense/bias
Mul_503
	0.0029296875
gradients/bert/encoder/layer_5/output/LayerNorm/moments/mean_grad/truediv
bert/embeddings/Reshape_4/shape
bert/encoder/layer_4/attention/self/key/bias/adam_v
gradients/bert/encoder/layer_2/intermediate/dense/Pow_grad/mul
clip_by_global_norm/mul_30
bert/encoder/layer_7/attention/output/dense/bias/adam_v
gradients/bert/encoder/layer_11/attention/self/value/MatMul_grad/MatMul
	12.0
Mul_917
bert/encoder/layer_5/intermediate/dense/bias/adam_v
bert/embeddings/one_hot/depth
gradients/bert/encoder/layer_4/intermediate/dense/MatMul_grad/MatMul
	12.0
bert/encoder/layer_2/output/LayerNorm/batchnorm/add
Mul_495
	2.25
Assign_61
Mul_29
	0.0029296875
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
Square_124
Assign_116
gradients/bert/encoder/layer_3/attention/output/dropout/mul_1_grad/Mul
	12.0
Assign_397
gradients/AddN_2
add_266
bert/encoder/layer_11/output/LayerNorm/gamma/read
Assign_351
gradients/bert/encoder/layer_3/attention/self/MatMul_grad/MatMul_1
	15.75
	0.0029296875
	0.0029296875
	0.0029296875
Cast_3
	0.000244140625
Assign_90
gradients/bert/pooler/dense/Tanh_grad/TanhGrad
bert/encoder/layer_4/attention/self/Reshape_3
sub_91
Assign_179
clip_by_global_norm/mul_170
add_223
Sqrt_146
	0.0029296875
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
Mul_676
Mul_824
	0.0029296875
bert/encoder/layer_6/attention/output/dense/kernel/read
bert/encoder/layer_3/attention/self/query/MatMul
	12.0
gradients/bert/encoder/layer_0/output/dropout/mul_grad/Mul
Mul_753
	2.25
truediv_39
Mul_1049
	0.0029296875
Assign_251
Square_79
	9.0
gradients/bert/encoder/layer_3/attention/output/dropout/mul_grad/Mul
Mul_484
	2.25
bert/encoder/layer_6/intermediate/dense/bias/adam_m
gradients/bert/encoder/layer_7/attention/self/Reshape_3_grad/Reshape
bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt
bert/encoder/layer_11/attention/output/dense/bias/read
Sqrt_21
	2.25
truediv_197
bert/pooler/dense/MatMul
	0.09375
bert/encoder/layer_0/attention/self/Reshape_2
Square_161
Sqrt_115
	0.0029296875
bert/pooler/strided_slice/stack_1
add_393
bert/embeddings/Reshape_1
bert/encoder/layer_3/attention/self/key/bias/adam_m
Square_108
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m
Mul_76
	0.0029296875
cls/predictions/Neg
add_648
add_364
Mul_487
bert/encoder/layer_2/attention/self/query/bias/adam_v/read
gradients/bert/encoder/layer_10/attention/self/Reshape_1_grad/Reshape
Mul_229
Mul_141
bert/encoder/layer_2/attention/output/dense/bias/adam_m/read
gradients/AddN_53
bert/encoder/layer_9/attention/output/dropout/mul_1
global_norm/L2Loss_155
	0.000244140625
	0.0087890625
Square_121
bert/encoder/layer_10/attention/self/query/bias/adam_v
Sqrt_145
	9.0
clip_by_global_norm/IsFinite
	0.000244140625
mul_348
	9.0
bert/encoder/layer_8/intermediate/dense/bias/adam_v
sub_86
mul_822
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
bert/encoder/layer_0/attention/self/value/MatMul
	12.0
bert/encoder/layer_0/output/LayerNorm/beta/adam_v/read
add_64
truediv_66
gradients/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
clip_by_global_norm/mul_22
bert/encoder/layer_4/attention/output/dropout/mul
	12.0
Mul_1087
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1
	12.0
add_611
gradients/cls/seq_relationship/MatMul_grad/MatMul_1
	0.005859375
bert/encoder/layer_0/attention/self/dropout/random_uniform
mul_961
	9.0
add_561
bert/encoder/layer_1/output/dense/kernel/adam_m
bert/encoder/layer_0/attention/self/key/bias/adam_v/read
truediv_38
truediv_49
gradients/bert/encoder/layer_10/attention/self/transpose_2_grad/transpose
	12.0
Sqrt_50
	0.0029296875
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
Sqrt_159
	9.0
Sqrt_122
	0.0029296875
mul_306
global_norm/L2Loss_89
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_11/output/LayerNorm/moments/variance_grad/Tile
	12.0
Sqrt_34
	0.0029296875
sub_35
gradients/bert/encoder/layer_4/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v
add_86
bert/encoder/layer_8/attention/output/dropout/GreaterEqual
	3.0
add_322
cls/seq_relationship/MatMul
	0.000244140625
bert/encoder/layer_8/attention/output/dense/BiasAdd
bert/encoder/layer_3/attention/self/value/kernel/adam_v
bert/encoder/layer_0/attention/self/value/BiasAdd
gradients/bert/encoder/layer_5/attention/output/dropout/mul_grad/Mul
add_16
add_481
gradients/bert/encoder/layer_7/output/dense/MatMul_grad/MatMul
	51.0
Assign_545
Square_61
	0.0029296875
bert/encoder/layer_9/attention/self/value/bias/adam_m
Square_11
	2.25
Mul_588
	0.0029296875
global_norm/L2Loss_129
	0.000244140625
	0.0087890625
Assign_491
bert/encoder/layer_5/attention/self/value/bias/adam_v/read
bert/encoder/layer_4/output/dropout/random_uniform/RandomUniform
	12.0
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt
bert/encoder/layer_5/output/LayerNorm/gamma/read
add_621
Mul_57
Square_131
Mul_191
	0.0029296875
mul_112
bert/encoder/layer_5/output/LayerNorm/gamma
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
truediv_34
clip_by_global_norm/mul_161
bert/encoder/layer_10/attention/output/dense/kernel/adam_m/read
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.02783203125
Sqrt_151
	3.75
Mul_103
	0.0029296875
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.02783203125
bert/encoder/layer_2/attention/self/value/bias/read
bert/encoder/layer_3/output/LayerNorm/batchnorm/sub
add_236
gradients/bert/encoder/layer_1/attention/self/transpose_3_grad/transpose
	12.0
Mul_710
	0.0029296875
bert/encoder/layer_1/attention/output/dropout/mul_1
add_532
cls/predictions/output_bias/adam_m/read
Mul_1089
Mul_371
	0.0029296875
add_100
Square_152
gradients/bert/encoder/layer_8/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
Mul_33
bert/encoder/layer_7/output/LayerNorm/moments/mean
	0.015625
add_184
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	15.75
Square_86
	0.0029296875
sub_54
gradients/bert/encoder/layer_11/attention/self/MatMul_grad/MatMul
	15.75
	0.0029296875
	0.0029296875
	0.00390625
gradients/bert/encoder/layer_10/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_11/output/LayerNorm/moments/variance
	0.015625
gradients/AddN_83
bert/encoder/layer_7/attention/output/dense/kernel/read
global_norm/L2Loss_99
	0.000244140625
Square_175
	9.0
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
mul_564
Mul_981
gradients/bert/encoder/layer_11/attention/self/transpose_3_grad/transpose
	12.0
bert/encoder/layer_5/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1
add_300
Assign_375
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.027587890625
bert/embeddings/word_embeddings/read
add_61
gradients/cls/predictions/transform/LayerNorm/batchnorm/sub_grad/Neg
	1.875
bert/encoder/layer_9/attention/output/dense/kernel
bert/encoder/layer_5/attention/self/Reshape_3
Assign_477
gradients/bert/encoder/layer_7/attention/self/Softmax_grad/mul_1
	24.0
gradients/AddN_4
mul_918
	2.25
Mul_482
Mul_5
bert/encoder/layer_8/attention/self/key/kernel/adam_v/read
bert/encoder/layer_6/attention/self/dropout/random_uniform/RandomUniform
	24.0
add_323
clip_by_global_norm/mul_151
add_270
bert/encoder/layer_7/attention/self/value/kernel/adam_m/read
bert/encoder/layer_6/output/add
Sqrt_204
	0.005859375
bert/encoder/layer_8/attention/self/dropout/random_uniform/mul
gradients/AddN_66
bert/encoder/layer_5/attention/output/LayerNorm/gamma/read
add_327
bert/encoder/layer_6/attention/self/Mul
Sqrt_158
	0.0029296875
gradients/bert/encoder/layer_10/attention/self/dropout/mul_grad/Mul
Sqrt_172
	0.0029296875
ConstantFolding/gradients/cls/predictions/transform/LayerNorm/moments/variance_grad/truediv_recip
gradients/bert/encoder/layer_6/output/dropout/mul_grad/Mul
bert/encoder/layer_2/attention/self/value/kernel/adam_m
Mul_460
add_337
add_285
Assign_187
clip_by_global_norm/mul_178
Mul_825
	0.0029296875
Mul_732
	2.25
gradients/bert/encoder/layer_0/intermediate/dense/Pow_grad/mul
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
Assign_241
Mul_731
	2.25
global_norm/L2Loss_184
	0.000244140625
gradients/bert/encoder/layer_3/attention/self/key/MatMul_grad/MatMul
	17.25
mul_983
Assign_473
Assign_440
Mul_351
Mul_691
bert/encoder/layer_11/attention/self/value/bias/adam_v/read
bert/encoder/layer_7/output/dense/bias/adam_v/read
Mul_270
gradients/bert/encoder/layer_1/attention/self/Softmax_grad/mul
bert/encoder/layer_4/output/LayerNorm/beta
add_434
add_209
bert/encoder/layer_8/attention/output/add
gradients/bert/encoder/layer_7/attention/self/key/MatMul_grad/MatMul_1
	2.25
clip_by_global_norm/mul_100
Assign_357
add_147
bert/encoder/layer_10/output/LayerNorm/gamma/adam_m
bert/embeddings/word_embeddings/adam_v
gradients/bert/encoder/layer_7/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/bert/encoder/layer_0/attention/self/Softmax_grad/sub
mul_897
global_norm/L2Loss_149
	0.000244140625
	0.0087890625
bert/encoder/layer_4/attention/self/key/bias/adam_m/read
Assign_142
truediv_200
add_624
add_535
add_315
clip_by_global_norm/mul_171
Assign_60
bert/encoder/layer_10/attention/self/key/MatMul
	12.0
Sqrt_105
	2.25
sub_183
mul_703
	9.0
global_norm/L2Loss_11
	0.000244140625
	0.01220703125
gradients/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul
bert/pooler/dense/bias/adam_v/read
Mul_10
	0.005859375
Mul_1076
bert/encoder/layer_9/attention/output/LayerNorm/beta/read
Mul_88
	9.0
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m/read
bert/encoder/Reshape_13
add_97
add_135
add_507
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
add_536
Assign_124
sub_79
bert/encoder/layer_4/output/LayerNorm/moments/mean
	0.015625
bert/encoder/layer_11/intermediate/dense/mul_3
global_norm/L2Loss_80
	0.000244140625
bert/encoder/layer_7/intermediate/dense/MatMul
	48.0
Mul_299
Square_24
	0.00439453125
bert/encoder/layer_10/output/LayerNorm/gamma/adam_v/read
clip_by_global_norm/mul_15
gradients/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul
mul_768
gradients/bert/encoder/layer_6/attention/self/Softmax_grad/mul
bert/embeddings/Reshape_2
add_680
bert/encoder/layer_9/attention/self/value/bias/read
bert/encoder/layer_4/output/LayerNorm/gamma
Square_103
Mul_885
bert/encoder/layer_6/attention/self/key/kernel/adam_v/read
mul_1100
gradients/AddN_43
clip_by_global_norm/mul_119
sub_103
bert/encoder/layer_5/output/dense/bias/adam_v/read
Assign_21
gradients/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul
	12.0
bert/encoder/layer_4/attention/self/value/bias
add_584
sub_203
global_norm/L2Loss_137
	0.000244140625
	0.0087890625
bert/encoder/layer_10/attention/self/key/bias
Mul_788
gradients/bert/encoder/layer_5/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/bert/encoder/layer_0/intermediate/dense/Pow_grad/mul_1
Assign_367
cls/predictions/transform/LayerNorm/batchnorm/mul_1
	1.875
clip_by_global_norm/mul_183
Square_170
	0.0029296875
clip_by_global_norm/mul_144
clip_by_global_norm/mul_75
Mul_941
	0.0029296875
bert/encoder/layer_4/output/dense/MatMul
	12.0
Mul_93
mul_586
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m
Mul_283
gradients/bert/encoder/layer_9/attention/self/Reshape_1_grad/Reshape
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul
	12.0
mul_176
	9.0
mul_483
gradients/cls/predictions/Neg_grad/Neg
mul_14
	0.005859375
bert/encoder/layer_9/intermediate/dense/add_1
	48.0
gradients/AddN_26
bert/encoder/layer_6/attention/self/value/bias/adam_m/read
bert/encoder/layer_11/attention/self/value/bias/adam_m/read
add_619
Sqrt_182
	0.0029296875
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
gradients/bert/encoder/layer_9/attention/output/dropout/mul_grad/Mul
bert/encoder/layer_8/attention/output/LayerNorm/moments/variance
	0.015625
Assign_128
mul_214
Assign_556
bert/encoder/layer_4/attention/self/key/bias/read
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
Sqrt_63
	11.25
Sqrt_152
	0.0029296875
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul
	12.0
gradients/bert/encoder/layer_5/attention/output/dense/MatMul_grad/MatMul
	12.0
Assign_255
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
bert/encoder/layer_3/output/dense/bias/adam_m/read
Sqrt_88
	0.0029296875
truediv_189
add_245
bert/encoder/layer_5/attention/self/key/kernel/read
gradients/AddN_25
global_norm/L2Loss_173
	0.000244140625
add_89
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt
mul_569
global_norm/L2Loss_79
	0.000244140625
	0.013671875
bert/encoder/layer_5/output/LayerNorm/gamma/adam_m/read
Mul_201
	0.0029296875
add_533
Square_153
bert/encoder/layer_10/attention/output/dropout/random_uniform/RandomUniform
	12.0
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
global_norm/L2Loss_154
	0.000244140625
global_norm/L2Loss_165
	0.000244140625
	0.0087890625
add_127
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
gradients/bert/encoder/layer_10/attention/output/dense/MatMul_grad/MatMul
	12.0
bert/encoder/layer_0/attention/output/LayerNorm/gamma
add_606
Mul_656
	2.25
add_244
mul_327
	2.25
gradients/bert/encoder/layer_3/attention/self/Softmax_grad/sub
bert/encoder/layer_8/attention/self/key/bias/adam_m/read
Mul_798
	0.0029296875
bert/encoder/layer_4/attention/self/Softmax
	24.0
	24.0
add_546
bert/encoder/layer_10/intermediate/dense/mul
gradients/bert/encoder/layer_8/attention/self/transpose_3_grad/transpose
	12.0
bert/encoder/layer_10/attention/self/value/bias/adam_m/read
Square_16
	0.01171875
gradients/bert/encoder/layer_1/intermediate/dense/Pow_grad/mul
add_334
gradients/bert/encoder/layer_9/output/dropout/mul_grad/Mul
gradients/AddN_44
Mul_727
	0.0029296875
truediv_148
gradients/cls/predictions/mul_1_grad/Mul_1
Mul_140
	2.25
global_norm/L2Loss_48
	0.000244140625
gradients/bert/encoder/layer_11/output/LayerNorm/moments/mean_grad/Tile
	12.0
mul_865
Mul_385
bert/encoder/layer_2/output/LayerNorm/beta/adam_m
Mul_186
clip_by_global_norm/mul_116
global_norm/L2Loss_103
	0.000244140625
	0.0146484375
Mul_272
bert/embeddings/LayerNorm/moments/mean
	0.015625
clip_by_global_norm/mul_115
gradients/bert/encoder/layer_11/intermediate/dense/mul_3_grad/Mul
Mul_13
mul_123
gradients/AddN_50
Assign_163
bert/encoder/layer_6/output/dense/kernel
Assign_276
bert/encoder/layer_1/intermediate/dense/add_1
	48.0
Assign_576
Square_18
	0.0029296875
bert/encoder/layer_9/attention/output/dense/kernel/adam_v/read
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
Assign_277
bert/encoder/layer_5/intermediate/dense/MatMul
	48.0
Assign_239
bert/encoder/layer_5/attention/self/Reshape_2
bert/encoder/layer_9/attention/output/dropout/random_uniform
Mul_99
	9.0
bert/pooler/dense/kernel
add_572
Assign_540
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
gradients/bert/encoder/layer_5/attention/self/transpose_1_grad/transpose
	12.0
Sqrt_35
	0.0029296875
bert/encoder/layer_3/output/LayerNorm/beta/adam_m/read
clip_by_global_norm/mul_79
sub_97
bert/encoder/layer_5/attention/self/value/kernel/adam_m/read
bert/encoder/layer_4/attention/self/query/kernel
gradients/bert/encoder/layer_8/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
sub_115
bert/encoder/layer_8/intermediate/dense/kernel/adam_m
bert/encoder/layer_10/attention/self/key/kernel/read
gradients/bert/encoder/layer_2/intermediate/dense/mul_3_grad/Mul_1
	48.0
bert/encoder/layer_8/output/dropout/random_uniform/mul
Mul_319
bert/encoder/layer_7/attention/output/dropout/random_uniform/RandomUniform
	12.0
mul_42
bert/encoder/layer_2/attention/self/value/kernel/read
Sqrt_101
	2.25
clip_by_global_norm/mul_201
bert/encoder/layer_5/intermediate/dense/mul_3
Square_107
gradients/bert/encoder/layer_10/output/dropout/mul_1_grad/Mul
	12.0
bert/encoder/layer_7/attention/self/query/kernel/adam_v/read
bert/encoder/layer_2/output/dense/kernel/adam_m
global_norm/L2Loss_69
	0.000244140625
	0.0087890625
sub_171
bert/encoder/layer_3/attention/self/value/bias/adam_v/read
sub_29
sub_110
bert/encoder/layer_1/output/dense/kernel/adam_v/read
truediv_65
add_690
gradients/cls/seq_relationship/mul_grad/Mul_1
	0.000244140625
bert/encoder/layer_11/output/dense/kernel/adam_m/read
bert/encoder/layer_3/attention/output/dropout/mul_1
bert/encoder/layer_7/attention/self/transpose_2
	12.0
Sqrt_52
	0.0029296875
add_354
Mul_125
bert/embeddings/LayerNorm/batchnorm/mul_1
	12.0
add_91
sub_195
Assign_536
add_429
cls/predictions/transform/LayerNorm/beta
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
gradients/AddN_86
truediv_116
bert/encoder/layer_3/output/dense/bias/adam_v/read
bert/encoder/layer_9/attention/output/dense/kernel/adam_v
bert/encoder/layer_7/attention/self/value/bias/read
gradients/AddN_80
Square_58
	0.0029296875
add_1
clip_by_global_norm/mul_53
Mul_616
bert/encoder/layer_6/attention/self/value/kernel/adam_m/read
bert/encoder/layer_1/output/LayerNorm/moments/mean
	0.028564453125
Mul_331
	0.0029296875
bert/encoder/layer_11/output/LayerNorm/moments/mean
	0.015625
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
global_step/VarIsInitializedOp
sub_150
gradients/bert/encoder/layer_8/attention/output/dropout/mul_1_grad/Mul
	12.0
bert/encoder/layer_3/attention/output/dropout/mul
	12.0
Mul_903
	2.25
gradients/bert/encoder/layer_10/attention/self/key/MatMul_grad/MatMul
	15.75
Mul_303
	2.25
bert/encoder/layer_5/attention/output/add
Square_73
	2.25
Sqrt_22
	0.0029296875
gradients/bert/encoder/layer_7/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/embeddings/LayerNorm/gamma
Sqrt_76
	0.0029296875
Mul_855
	0.0029296875
sub_155
Mul_89
Mul_62
	0.0029296875
gradients/bert/encoder/layer_3/attention/self/dropout/mul_1_grad/Mul
Mul_356
cls/predictions/transform/LayerNorm/moments/variance
	0.00244140625
gradients/bert/encoder/layer_1/attention/output/dropout/mul_1_grad/Mul
	12.0
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Mul
mul_735
	2.25
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
cls/predictions/transform/dense/BiasAdd
add_122
bert/encoder/layer_9/attention/output/dropout/random_uniform/mul
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v
Mul_539
Mul_599
	0.0029296875
clip_by_global_norm/mul_147
add_279
bert/encoder/layer_4/output/dense/bias/adam_v
bert/encoder/layer_9/output/LayerNorm/beta/adam_m/read
global_norm/L2Loss_101
	0.000244140625
	0.01513671875
gradients/bert/encoder/layer_9/attention/self/transpose_1_grad/transpose
	12.0
bert/encoder/layer_1/attention/output/dropout/random_uniform/mul
global_norm/L2Loss_151
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_11/output/dropout/mul_grad/Mul
bert/encoder/layer_10/attention/self/dropout/random_uniform
bert/encoder/layer_10/attention/self/value/MatMul
	12.0
Assign_147
mul_800
bert/encoder/layer_6/attention/output/dense/kernel/adam_m
add_75
Mul_455
gradients/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
mul_864
	9.0
mul_1106
Mul_965
	0.0029296875
add_12
truediv_74
Mul_342
Mul_953
bert/encoder/layer_0/attention/output/dropout/Cast
	12.0
bert/encoder/layer_2/intermediate/dense/mul_2
Assign_54
bert/encoder/layer_10/output/LayerNorm/gamma
gradients/bert/encoder/layer_6/intermediate/dense/mul_2_grad/Mul_1
Mul_1041
add_384
truediv_16
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul
gradients/bert/encoder/layer_2/output/LayerNorm/moments/mean_grad/truediv
add_328
bert/embeddings/LayerNorm/batchnorm/mul
	12.0
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul
bert/encoder/layer_3/attention/self/dropout/Cast
	24.0
bert/encoder/layer_7/output/LayerNorm/gamma/adam_v
Sqrt_33
	9.0
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt
bert/embeddings/GatherV2/axis
Assign_524
mul_515
bert/encoder/layer_4/attention/self/Reshape_1
bert/encoder/layer_0/attention/self/value/kernel/adam_v/read
bert/encoder/layer_6/attention/output/LayerNorm/moments/variance
	0.015625
global_norm/L2Loss_140
	0.000244140625
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add
Reshape_1
mul_311
add_27
Mul_801
	0.0029296875
bert/encoder/layer_0/attention/self/Reshape_1
Mul_223
	0.0029296875
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Reshape
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
add_580
global_norm/L2Loss_56
	0.000244140625
bert/encoder/layer_4/intermediate/dense/bias/adam_m/read
Mul_858
gradients/bert/encoder/layer_3/attention/self/transpose_2_grad/transpose
	12.0
bert/embeddings/assert_less_equal/Assert/Assert
add_62
Mul_872
	9.0
edge_1728_cls/predictions/Reshape@@MemcpyHtoD
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add
bert/encoder/layer_5/output/LayerNorm/beta/adam_m
bert/encoder/layer_3/attention/output/dense/kernel/adam_v
add_306
Mul_389
	2.25
Mul_632
Mul_1033
	9.0
gradients/bert/encoder/layer_5/intermediate/dense/mul_1_grad/Mul_1
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.0283203125
Mul_1083
	0.0029296875
mul_333
Mul_684
	0.0029296875
Square_21
	2.25
bert/encoder/layer_8/attention/self/query/kernel/adam_v/read
mul_763
truediv_177
bert/encoder/layer_0/attention/self/query/BiasAdd
Mul_782
	0.01171875
Mul_433
Sqrt_49
	9.0
bert/encoder/layer_11/attention/output/dense/bias/adam_v/read
bert/encoder/layer_7/attention/self/query/kernel/adam_m/read
mul_962
mul_617
	9.0
add_599
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v/read
bert/encoder/layer_9/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
Mul_783
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
Sqrt_188
	0.0029296875
global_norm/L2Loss_110
	0.000244140625
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m/read
bert/encoder/layer_2/attention/self/key/kernel
Assign_393
clip_by_global_norm/mul_88
add_506
clip_by_global_norm/mul_156
bert/embeddings/dropout/mul_1
Mul_614
	9.0
add_225
global_step/cond/Merge
bert/encoder/layer_4/attention/self/value/bias/adam_m/read
mul_607
add_608
truediv_31
gradients/bert/encoder/layer_1/attention/self/transpose_1_grad/transpose
	12.0
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
gradients/bert/encoder/layer_1/intermediate/dense/Tanh_grad/TanhGrad
bert/encoder/layer_1/intermediate/dense/bias/adam_v
Mul_678
	0.0029296875
Mul_823
	0.0029296875
bert/encoder/layer_5/attention/output/LayerNorm/moments/variance
	0.015625
gradients/AddN_75
truediv_158
clip_by_global_norm/mul_27
bert/encoder/Cast
	0.015625
Assign_146
bert/encoder/layer_4/output/add
bert/encoder/layer_4/output/dropout/random_uniform
sub_199
bert/encoder/layer_3/output/dropout/random_uniform/mul
Mul_578
	0.0029296875
bert/encoder/layer_2/attention/output/dropout/random_uniform/mul
Sqrt_116
	0.0029296875
Square_37
	2.25
bert/encoder/layer_0/output/dense/kernel/adam_m
add_475
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
global_norm/L2Loss_30
	0.000244140625
truediv_84
add_598
truediv_77
bert/encoder/layer_1/output/LayerNorm/beta
sub_50
Assign_213
global_norm/L2Loss_53
	0.000244140625
	0.014404296875
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
add_544
gradients/bert/encoder/layer_6/attention/self/query/MatMul_grad/MatMul_1
	2.25
gradients/bert/encoder/layer_7/attention/output/dropout/mul_grad/Mul
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
bert/embeddings/LayerNorm/gamma/read
bert/encoder/layer_0/attention/self/value/kernel/adam_m
bert/encoder/layer_1/intermediate/dense/bias/read
bert/encoder/layer_0/attention/output/dropout/GreaterEqual
	3.0
Mul_905
	2.25
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m
truediv_188
sub_149
add_365
bert/encoder/layer_8/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/embeddings/dropout/Cast
	12.0
add_180
gradients/bert/encoder/layer_5/intermediate/dense/MatMul_grad/MatMul
	12.0
mul_1069
bert/encoder/layer_6/attention/self/value/bias/adam_m
Square_20
	0.0029296875
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
bert/encoder/layer_1/attention/self/value/bias/read
gradients/bert/encoder/layer_8/attention/self/Softmax_grad/Sum
	0.1875
bert/encoder/layer_6/attention/output/dropout/GreaterEqual
	3.0
gradients/bert/encoder/layer_11/intermediate/dense/MatMul_grad/MatMul
	12.0
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/mean_grad/truediv
Mul_740
truediv_174
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
bert/encoder/layer_7/attention/output/dense/kernel/adam_v
bert/encoder/layer_1/intermediate/dense/bias/adam_m/read
Mul_320
	0.0029296875
gradients/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul_1
sub_42
Mul_594
	0.0029296875
bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference
	12.0
bert/encoder/layer_4/attention/self/dropout/random_uniform/mul
add_464
gradients/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_8/output/dense/kernel/read
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
Square_183
	2.25
bert/encoder/layer_9/output/LayerNorm/batchnorm/sub
bert/encoder/layer_10/attention/output/add
bert/encoder/layer_6/attention/self/query/kernel
global_norm/L2Loss_161
	0.000244140625
	0.0087890625
global_norm/L2Loss_62
	0.000244140625
bert/encoder/layer_6/attention/output/dense/kernel/adam_v
gradients/cls/predictions/transform/LayerNorm/moments/variance_grad/Tile
	1.875
global_norm/L2Loss_144
	0.000244140625
Square_122
bert/encoder/layer_11/attention/self/key/bias/adam_v/read
add_412
bert/encoder/layer_4/output/LayerNorm/beta/adam_m/read
add_172
mul_219
	2.25
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_5/attention/self/value/bias/adam_v
bert/encoder/layer_8/attention/output/dense/kernel/adam_m
gradients/bert/encoder/layer_11/attention/self/Reshape_3_grad/Reshape
Mul_199
	0.0029296875
gradients/bert/encoder/layer_4/attention/self/Mul_grad/Mul
mul_1068
	2.25
bert/encoder/layer_1/attention/self/value/BiasAdd
bert/encoder/layer_9/output/dense/kernel/adam_v/read
Assign_316
bert/encoder/layer_11/attention/output/dropout/random_uniform
bert/encoder/layer_9/attention/self/key/kernel/adam_v/read
sub_191
Sqrt_135
	2.25
add_60
mul_709
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
gradients/bert/encoder/layer_4/attention/self/dropout/mul_grad/Mul
global_norm/L2Loss_21
	0.000244140625
	0.012451171875
gradients/bert/encoder/layer_6/output/LayerNorm/moments/mean_grad/truediv
Square_27
	2.25
global_norm/L2Loss_164
	0.000244140625
sub_205
cls/predictions/LogSoftmax
	74.5166015625
	74.5166015625
	0.000244140625
	0.000244140625
bert/encoder/layer_3/attention/self/dropout/random_uniform/mul
Sqrt_205
	0.000244140625
bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1
	12.0
add_25
Assign_58
gradients/bert/encoder/layer_4/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.00439453125
	0.0029296875
	0.0029296875
Sqrt_32
	0.01171875
truediv_168
Mul_78
	0.0029296875
bert/encoder/layer_6/output/dense/BiasAdd
bert/encoder/layer_8/attention/self/Reshape
add_330
add_5
Mul_38
	0.0029296875
bert/encoder/layer_7/attention/output/dropout/Cast
	12.0
Square_49
	9.0
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/truediv
bert/encoder/layer_4/output/dense/bias/adam_m/read
Mul_447
	0.0029296875
Mul_647
	2.25
bert/encoder/layer_5/output/dense/kernel/adam_m
gradients/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1
	2.25
Mul_352
	0.01171875
gradients/bert/encoder/layer_5/intermediate/dense/Tanh_grad/TanhGrad
Sqrt_9
	2.25
add_455
Mul_946
	9.0
cls/seq_relationship/LogSoftmax
	0.000244140625
	0.000244140625
bert/encoder/layer_6/attention/output/dense/kernel/adam_m/read
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
bert/encoder/layer_4/attention/self/key/bias
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v/read
gradients/bert/encoder/layer_7/attention/self/dropout/mul_grad/Mul
Assign_414
add_483
add_145
bert/encoder/layer_10/intermediate/dense/mul_3
bert/encoder/layer_3/attention/self/query/BiasAdd
Assign_399
add_499
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
add_627
mul_263
add_518
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.027587890625
bert/encoder/layer_5/attention/output/dropout/GreaterEqual
	3.0
bert/encoder/layer_1/attention/self/key/kernel/read
bert/encoder/layer_2/output/LayerNorm/batchnorm/mul
	12.0
Square_114
clip_by_global_norm/mul_89
bert/encoder/layer_8/output/dense/BiasAdd
bert/encoder/layer_8/intermediate/dense/mul
bert/encoder/layer_7/intermediate/dense/kernel
gradients/AddN_18
bert/encoder/layer_5/attention/self/value/bias/read
bert/encoder/layer_7/attention/self/value/bias
sub_197
bert/encoder/layer_2/attention/output/dense/bias/adam_v
bert/encoder/layer_10/attention/self/query/kernel/adam_m
gradients/bert/encoder/layer_6/attention/self/MatMul_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
add_498
bert/encoder/layer_9/attention/self/query/kernel
bert/encoder/layer_1/intermediate/dense/kernel/adam_m/read
Mul_379
global_norm/L2Loss_71
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_5/attention/self/Mul_grad/Mul
gradients/AddN_56
Assign_55
gradients/bert/encoder/layer_10/attention/output/dropout/mul_1_grad/Mul
	12.0
gradients/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_5/output/add
bert/encoder/layer_7/output/LayerNorm/gamma/adam_m/read
bert/encoder/layer_7/output/dense/kernel/adam_v
add_54
mul_268
bert/encoder/layer_0/attention/output/dense/BiasAdd
add_607
bert/encoder/layer_0/attention/output/LayerNorm/beta/read
Mul_1043
	9.0
add_629
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Reshape
add_282
bert/encoder/layer_9/attention/output/dense/bias/adam_m
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v
bert/encoder/layer_4/attention/output/LayerNorm/gamma/read
bert/encoder/layer_0/intermediate/dense/bias/adam_m
Assign_346
bert/encoder/layer_3/attention/self/transpose
	12.0
Mul_986
	0.0029296875
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add
Mul_428
Assign_140
bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2
	12.0
clip_by_global_norm/mul_40
Assign_36
mul_951
Assign_245
gradients/bert/encoder/layer_8/attention/self/value/MatMul_grad/MatMul_1
	3.0
Mul_310
add_68
sub_108
add_640
gradients/bert/encoder/layer_4/output/dense/MatMul_grad/MatMul_1
	12.0
Mul_966
bert/encoder/layer_3/output/add
Sqrt_10
	0.0029296875
bert/encoder/layer_9/attention/self/dropout/random_uniform/RandomUniform
	24.0
bert/encoder/layer_0/output/dropout/mul_1
bert/encoder/layer_7/output/LayerNorm/beta/adam_v
mul_257
add_585
bert/encoder/layer_1/attention/self/Reshape_2
Mul_880
bert/encoder/layer_0/attention/self/Softmax
	24.0
	24.0
add_348
gradients/bert/encoder/layer_2/attention/self/query/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_8/attention/self/query/bias/adam_m
bert/encoder/layer_9/attention/self/query/kernel/adam_m/read
gradients/bert/encoder/layer_7/output/dense/MatMul_grad/MatMul_1
	10.669921875
Assign_190
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
gradients/bert/encoder/layer_7/output/LayerNorm/moments/variance_grad/Tile
	12.0
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Reshape
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
add_11
Assign_104
gradients/AddN_84
add_609
gradients/bert/encoder/layer_9/attention/self/Softmax_grad/mul_1
	24.0
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.0283203125
gradients/bert/encoder/layer_11/intermediate/dense/mul_1_grad/Mul_1
gradients/bert/encoder/layer_7/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.01171875
add_34
add_238
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt
Assign_549
add_503
bert/encoder/layer_4/attention/self/query/bias
gradients/bert/encoder/layer_9/output/dense/MatMul_grad/MatMul_1
	12.0
bert/embeddings/Slice/size
Assign_198
add_582
add_693
Assign_75
add_292
clip_by_global_norm/mul_20
sub_43
bert/encoder/layer_0/attention/self/query/kernel/read
Mul_321
sub_156
bert/encoder/layer_0/attention/output/dropout/random_uniform/RandomUniform
	12.0
bert/encoder/layer_8/intermediate/dense/kernel/read
Mul_948
	9.0
bert/encoder/layer_6/output/LayerNorm/batchnorm/add
bert/encoder/layer_6/attention/self/query/bias
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_1_grad/Mul_1
	1.875
global_norm/L2Loss_104
	0.000244140625
Assign_206
Assign_528
bert/encoder/layer_10/output/LayerNorm/beta/adam_v/read
bert/encoder/layer_0/attention/self/dropout/random_uniform/RandomUniform
	24.0
gradients/bert/encoder/layer_5/attention/self/transpose_3_grad/transpose
	12.0
Assign_79
gradients/AddN_79
Sqrt_127
	9.0
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/mean_grad/truediv
mul_816
Assign_283
gradients/bert/encoder/layer_11/attention/self/value/MatMul_grad/MatMul_1
	2.25
Assign_290
Assign_465
Assign_78
Square_159
Mul_159
	0.0029296875
bert/encoder/layer_3/intermediate/dense/kernel/adam_m/read
Assign_328
gradients/bert/encoder/layer_6/attention/self/value/MatMul_grad/MatMul_1
	2.25
clip_by_global_norm/mul_184
Assign_20
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2_grad/Reshape
Mul_922
	0.0029296875
bert/encoder/layer_11/intermediate/dense/bias
bert/encoder/layer_0/attention/self/key/bias
add_416
gradients/bert/encoder/layer_9/intermediate/dense/mul_1_grad/Mul_1
clip_by_global_norm/mul_158
bert/encoder/layer_1/attention/output/dense/kernel/adam_m
bert/encoder/layer_1/attention/self/dropout/mul_1
bert/encoder/layer_2/attention/self/value/bias
Assign_402
Mul_926
bert/encoder/layer_10/attention/self/value/kernel/adam_m
global_norm/L2Loss_36
	0.000244140625
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
add_441
bert/encoder/layer_2/output/dense/kernel
Sqrt_197
	2.25
cls/seq_relationship/output_bias/adam_m/read
bert/encoder/layer_9/intermediate/dense/bias/adam_m
Mul_1027
	0.0029296875
gradients/bert/encoder/layer_8/output/LayerNorm/moments/variance_grad/Tile
	12.0
global_norm/L2Loss_194
	0.000244140625
Mul_567
	0.0029296875
add_426
cls/predictions/transform/dense/bias/adam_m/read
bert/encoder/layer_0/attention/self/Mul
Sqrt_128
	0.01171875
Assign_121
truediv_76
bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1
	12.0
add_48
bert/encoder/layer_9/attention/self/Reshape
bert/encoder/layer_11/attention/self/value/kernel/adam_m
add_558
bert/encoder/layer_11/attention/self/Reshape
bert/encoder/layer_0/intermediate/dense/kernel/adam_v
gradients/bert/encoder/layer_6/attention/self/Reshape_3_grad/Reshape
Mul_815
Assign_30
Mul_1108
bert/embeddings/position_embeddings/adam_m
gradients/bert/encoder/layer_9/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_4/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
truediv_166
clip_by_global_norm/mul_166
add_420
bert/encoder/layer_11/attention/self/Mul
add_490
gradients/bert/encoder/layer_3/attention/self/dropout/mul_grad/Mul
Assign_410
Square_146
bert/embeddings/LayerNorm/beta/adam_m/read
Mul_1072
	0.0029296875
sub_63
sub_61
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m
Assign_17
clip_by_global_norm/mul_109
clip_by_global_norm/mul_137
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v/read
Mul_286
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
truediv_3
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
mul_805
Mul_772
mul_1063
bert/encoder/layer_8/attention/output/dense/kernel/adam_m/read
Mul_911
	0.0029296875
mul_1004
	2.25
add_685
Square_166
bert/encoder/layer_9/output/dense/kernel/adam_m/read
Square_165
bert/encoder/layer_4/attention/self/value/kernel/adam_m
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/sub_grad/Sum
	0.00390625
Assign_4
bert/encoder/layer_0/attention/self/value/kernel/adam_v
sub_146
bert/encoder/layer_9/attention/self/key/kernel/adam_v
bert/encoder/layer_9/intermediate/dense/mul_1
gradients/bert/encoder/layer_6/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_5/intermediate/dense/kernel/read
Assign_205
bert/encoder/layer_8/attention/self/key/bias
sub_198
sub_84
truediv_82
clip_by_global_norm/mul_18
sub_130
Assign_184
bert/encoder/layer_0/attention/self/Reshape
gradients/AddN_21
add_454
bert/encoder/layer_8/output/LayerNorm/gamma/adam_v
add_577
Assign_530
Mul_71
	0.0029296875
Assign_448
bert/encoder/layer_5/output/LayerNorm/beta/adam_v/read
Mul_603
	9.0
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.022705078125
bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt
add_57
gradients/bert/encoder/layer_7/attention/self/Reshape_2_grad/Reshape
bert/encoder/layer_7/intermediate/dense/mul_1
gradients/bert/encoder/layer_2/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
add_263
mul_166
Assign_24
add_616
Mul_840
	2.25
Mul_589
	0.0029296875
Square_127
bert/encoder/layer_10/output/LayerNorm/gamma/adam_v
bert/encoder/layer_5/attention/self/key/kernel/adam_v/read
clip_by_global_norm/mul_177
Mul_1081
	0.0029296875
sub_141
add_76
clip_by_global_norm/mul_14
bert/encoder/layer_7/intermediate/dense/bias/read
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_11/attention/self/query/MatMul
	12.0
sub_10
Assign_498
global_norm/L2Loss_192
	0.000244140625
Mul_996
bert/embeddings/token_type_embeddings/read
sub_165
sub_23
bert/embeddings/Reshape
Square_85
	2.25
add_694
bert/encoder/layer_0/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
add_211
Mul_713
bert/encoder/layer_4/attention/output/dense/kernel
bert/encoder/layer_7/intermediate/dense/add_1
	48.0
add_676
Square_101
gradients/bert/encoder/layer_11/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_2/attention/self/Reshape
bert/encoder/layer_3/intermediate/dense/bias/read
bert/embeddings/word_embeddings/adam_v/read
Mul_508
	0.0029296875
Mul_98
truediv_25
gradients/bert/encoder/layer_5/attention/self/Reshape_2_grad/Reshape
add_289
sub_159
bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1
	12.0
add_271
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
global_step/Initializer/zeros
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
bert/encoder/layer_9/attention/self/Reshape_2
Mul_41
bert/encoder/layer_8/attention/output/dense/kernel/adam_v
Assign_443
mul_628
bert/encoder/layer_6/output/dense/bias/adam_v
sub_17
global_norm/L2Loss_68
	0.000244140625
global_norm/L2Loss_174
	0.000244140625
bert/encoder/layer_7/intermediate/dense/kernel/adam_m
add_129
gradients/bert/encoder/layer_5/output/dense/MatMul_grad/MatMul_1
	12.0
add_548
bert/encoder/layer_3/attention/output/dense/bias/adam_v/read
Assign_232
mul_434
	9.0
Assign_191
bert/encoder/layer_0/intermediate/dense/add
add_436
gradients/AddN_61
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Reshape
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2_grad/Reshape
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul
	12.0
gradients/bert/encoder/layer_0/intermediate/dense/Tanh_grad/TanhGrad
bert/encoder/layer_7/attention/self/value/bias/adam_m/read
Mul_600
bert/encoder/layer_1/attention/output/dense/kernel/adam_v
add_380
clip_by_global_norm/mul_62
bert/encoder/layer_9/output/dense/bias
bert/encoder/layer_0/attention/output/dense/bias/adam_v
bert/encoder/layer_0/attention/output/LayerNorm/gamma/read
sub_11
sub_188
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v/read
gradients/bert/encoder/layer_3/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
cls/predictions/transform/LayerNorm/batchnorm/Rsqrt
bert/encoder/layer_5/output/LayerNorm/gamma/adam_v/read
gradients/bert/encoder/layer_7/attention/self/value/MatMul_grad/MatMul
	12.0
Assign_183
bert/encoder/layer_0/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
global_norm/L2Loss_169
	0.000244140625
	0.010498046875
Mul_266
	0.01171875
Sqrt_14
	0.0029296875
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
Assign_511
Mul_1011
	2.25
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v/read
bert/encoder/layer_10/attention/self/Reshape_1
Square_17
	9.0
Mul_920
	0.0029296875
Mul_572
	2.25
Square_191
gradients/bert/encoder/layer_8/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.013427734375
bert/encoder/layer_9/attention/output/dense/kernel/adam_m
Square_95
sub_169
bert/encoder/layer_9/output/LayerNorm/beta/read
Assign_590
bert/pooler/dense/bias/adam_m
sub_125
gradients/bert/encoder/layer_11/attention/self/Reshape_1_grad/Reshape
Mul_329
	0.0029296875
bert/encoder/layer_1/intermediate/dense/kernel/adam_m
bert/encoder/layer_4/attention/output/dense/MatMul
	12.0
gradients/Reshape_2_grad/Reshape/tensor
	12.0
Mul_130
Mul_627
Square_88
	0.0029296875
bert/encoder/layer_0/attention/self/add
Assign_546
clip_by_global_norm/mul_120
bert/encoder/layer_5/attention/output/dense/bias/read
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Reshape
Assign_315
bert/encoder/layer_4/attention/self/dropout/random_uniform/RandomUniform
	24.0
bert/encoder/layer_2/output/LayerNorm/batchnorm/sub
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.025634765625
gradients/AddN_27
sub_94
add_400
bert/encoder/layer_3/output/dense/bias/read
add_511
Mul_914
	2.25
gradients/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape
Square_43
	2.25
bert/encoder/layer_6/attention/self/value/kernel/read
bert/encoder/layer_2/attention/output/dropout/random_uniform/RandomUniform
	12.0
add_551
gradients/bert/encoder/layer_9/attention/self/Softmax_grad/mul
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/sub_grad/Sum
	0.00341796875
gradients/bert/encoder/layer_1/intermediate/dense/Pow_grad/Pow
	48.0
bert/encoder/layer_1/attention/self/value/bias/adam_v
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
Square_8
	0.0029296875
add_171
clip_by_global_norm/mul_154
add_46
gradients/bert/encoder/layer_6/attention/self/transpose_3_grad/transpose
	12.0
clip_by_global_norm/mul_85
global_norm/L2Loss_6
	0.000244140625
mul_472
bert/encoder/layer_11/output/dropout/mul
	12.0
add_391
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
Assign_168
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
bert/encoder/layer_5/output/LayerNorm/beta/adam_m/read
Assign_479
gradients/AddN_10
bert/encoder/layer_3/intermediate/dense/kernel/adam_v/read
Assign_274
bert/encoder/layer_1/output/dropout/GreaterEqual
	3.0
add_28
mul_48
clip_by_global_norm/mul_58
global_norm/L2Loss_52
	0.000244140625
bert/encoder/layer_1/attention/output/dense/kernel
Mul_681
gradients/bert/encoder/layer_7/attention/self/transpose_grad/transpose
	12.0
Assign_541
Sqrt_201
	0.0029296875
Assign_264
gradients/AddN_59
Mul_791
	0.0029296875
Assign_141
bert/encoder/layer_7/output/dense/BiasAdd
bert/encoder/layer_5/attention/self/value/kernel/adam_m
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
gradients/bert/encoder/layer_8/attention/self/Reshape_1_grad/Reshape
bert/encoder/layer_5/attention/output/dense/bias/adam_m/read
bert/pooler/strided_slice
	0.09375
Mul_699
	9.0
Square_97
	9.0
clip_by_global_norm/mul_1
Assign_575
gradients/bert/encoder/layer_5/intermediate/dense/MatMul_grad/MatMul_1
	12.0
Square_98
	0.0029296875
add_692
gradients/bert/encoder/layer_3/attention/self/Softmax_grad/Sum
	0.1875
mul_1080
gradients/bert/encoder/layer_4/attention/self/Softmax_grad/Sum
	0.1875
bert/encoder/layer_4/attention/self/dropout/GreaterEqual
	6.0
Assign_50
add_160
mul_187
	9.0
bert/encoder/layer_0/attention/self/mul_1/y
bert/encoder/layer_5/attention/self/transpose_2
	12.0
Assign_180
Mul_450
Assign_170
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m
Assign_83
add_451
edge_1780_Less@@MemcpyHtoD
gradients/bert/encoder/layer_3/attention/self/Reshape_3_grad/Reshape
global_norm/L2Loss_188
	0.000244140625
Assign_196
Assign_347
gradients/AddN_15
truediv_30
Assign_100
bert/encoder/layer_0/attention/self/query/bias
Mul_820
Mul_715
	0.0029296875
bert/encoder/layer_2/output/LayerNorm/gamma/adam_v
add_169
Mul_734
Mul_545/x
gradients/bert/encoder/layer_9/output/LayerNorm/moments/variance_grad/truediv
bert/encoder/layer_11/attention/output/LayerNorm/beta
Assign_46
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.028076171875
bert/encoder/layer_9/attention/output/dropout/random_uniform/RandomUniform
	12.0
Mul_551
Mul_66
global_norm/L2Loss_179
	0.000244140625
add_255
Sqrt_126
	0.0029296875
mul_262
	9.0
Square_39
	2.25
truediv_13
bert/encoder/layer_1/output/dropout/random_uniform
add_657
Assign_516
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
bert/encoder/layer_3/attention/self/Reshape_1
bert/encoder/layer_2/attention/self/value/kernel/adam_v/read
sub_144
Mul_910
add_228
Assign_371
cls/seq_relationship/output_bias
clip_by_global_norm/Minimum
add_419
edge_1721_bert/embeddings/Reshape_2@@MemcpyHtoD
Assign_557
gradients/bert/encoder/layer_4/attention/output/dense/MatMul_grad/MatMul_1
	3.0
bert/encoder/layer_9/attention/self/value/bias/adam_v
bert/encoder/layer_2/attention/self/value/BiasAdd
Mul_24
	0.0029296875
gradients/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape
bert/encoder/layer_8/attention/self/key/bias/read
add_128
Assign_613
Mul_302
Sqrt_69
	2.25
Square_23
	2.25
Assign_608
gradients/bert/encoder/Reshape_1_grad/Reshape
bert/encoder/layer_0/output/LayerNorm/gamma/adam_m
bert/encoder/layer_8/output/dense/kernel/adam_m
Assign_444
Mul_129
	2.25
bert/encoder/layer_8/intermediate/dense/bias
Mul_1070
	0.0029296875
Mul_862
	9.0
bert/encoder/layer_11/output/dense/bias/adam_v
Mul_366
	0.0029296875
clip_by_global_norm/mul_50
bert/encoder/layer_8/attention/self/dropout/mul
	24.0
global_norm/L2Loss_166
	0.000244140625
Assign_329
Mul_651
	0.0029296875
sub_138
Square_160
clip_by_global_norm/mul_51
bert/encoder/layer_8/attention/output/dropout/random_uniform
add_453
truediv_24
add_33
Sqrt_82
	0.0029296875
bert/embeddings/Reshape_4
bert/encoder/layer_8/output/dense/bias
sub_32
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
cls/predictions/transform/dense/bias/adam_m
add_200
Mul_232
	0.0029296875
gradients/bert/encoder/layer_9/attention/self/dropout/mul_1_grad/Mul
bert/encoder/layer_7/attention/self/query/bias
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
Assign_306
Sqrt_15
	12.0
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/variance_grad/truediv
add_189
cls/predictions/output_bias
gradients/bert/encoder/layer_5/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_11/output/dense/bias/adam_m
gradients/AddN_74
gradients/bert/encoder/layer_2/attention/self/Softmax_grad/mul_1
	24.0
truediv_75
sub_16
truediv_139
add_517
Mul_449
	0.0029296875
bert/encoder/layer_10/intermediate/dense/kernel/adam_m
Assign_460
bert/encoder/layer_0/output/add
Square_151
add_343
gradients/bert/encoder/layer_2/output/LayerNorm/moments/variance_grad/truediv
Assign_325
clip_by_global_norm/mul_191
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
gradients/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad
	0.005615234375
bert/encoder/layer_9/attention/self/key/kernel/read
Square_41
	3.75
Square_136
Sqrt_192
	0.01171875
add_472
bert/encoder/layer_6/intermediate/dense/mul
bert/encoder/layer_3/attention/output/dense/kernel/adam_m/read
Assign_110
Square_2
	1.5
bert/encoder/layer_6/attention/self/key/kernel/read
clip_by_global_norm/mul_66
bert/encoder/layer_10/attention/self/dropout/random_uniform/RandomUniform
	24.0
bert/encoder/layer_9/attention/self/value/kernel
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub
add_359
add_695
Assign_363
bert/encoder/layer_6/attention/self/query/bias/adam_v/read
Mul_367
bert/encoder/layer_9/attention/self/dropout/mul_1
Assign_456
bert/encoder/layer_6/attention/output/dropout/mul_1
bert/encoder/layer_9/intermediate/dense/BiasAdd
bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt
bert/encoder/layer_11/attention/output/dropout/mul_1
bert/encoder/layer_10/attention/self/dropout/mul
	24.0
bert/encoder/layer_9/intermediate/dense/Tanh
Assign_6
bert/encoder/layer_2/attention/self/query/kernel/adam_m
bert/encoder/layer_4/intermediate/dense/mul_3
bert/encoder/layer_5/attention/self/value/bias/adam_m
mul_429
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/sub_grad/Sum
	0.003662109375
Mul_540
	0.0029296875
Mul_868
	0.01171875
bert/encoder/layer_1/attention/self/key/MatMul
	12.0
truediv_154
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2
	12.0
bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1
truediv_130
Mul_1093
	0.0029296875
bert/encoder/layer_11/attention/output/dense/bias/adam_v
Assign_212
Mul_30
add_496
bert/encoder/layer_1/attention/self/query/kernel/adam_v
bert/encoder/layer_9/attention/output/dense/MatMul
	12.0
sub_26
clip_by_global_norm/mul_44
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
add_29
bert/encoder/layer_11/attention/self/query/kernel/adam_v/read
global_norm/L2Loss_35
	0.000244140625
Mul_196
	0.0029296875
mul_360
Mul_839
	2.25
Mul_355
	9.0
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
add_438
bert/encoder/layer_6/output/LayerNorm/gamma/adam_v
Mul_425
	0.0029296875
bert/encoder/layer_2/output/LayerNorm/beta/adam_v/read
add_515
Mul_882
	0.0029296875
clip_by_global_norm/mul_185
clip_by_global_norm/mul_57
bert/encoder/layer_3/attention/self/Mul
bert/encoder/layer_10/attention/self/key/kernel/adam_m/read
gradients/bert/encoder/layer_11/output/LayerNorm/moments/variance_grad/truediv
bert/encoder/layer_1/output/dense/bias/adam_v/read
gradients/bert/encoder/layer_4/attention/self/dropout/mul_1_grad/Mul
gradients/bert/encoder/layer_0/intermediate/dense/mul_3_grad/Mul
Assign_93
bert/encoder/layer_8/attention/self/Mul
Mul_353
Assign_301
bert/encoder/layer_0/attention/self/value/kernel/adam_m/read
Mul_1107
	0.000244140625
add_1/_2558
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.00439453125
truediv_138
bert/encoder/layer_9/attention/self/add
bert/encoder/layer_9/attention/self/transpose
	12.0
Mul_959
	9.0
truediv_180
Mul_454
	0.0029296875
global_norm/L2Loss_117
	0.000244140625
	0.0087890625
Mul_43
	2.25
Assign_525
bert/encoder/layer_10/output/add
add_677
bert/encoder/layer_11/attention/output/dense/kernel/adam_m/read
clip_by_global_norm/mul_173
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
gradients/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
bert/encoder/layer_11/attention/output/LayerNorm/beta/read
bert/encoder/layer_3/intermediate/dense/mul_2
bert/embeddings/dropout/truediv
bert/encoder/layer_0/attention/self/value/kernel
gradients/bert/encoder/layer_8/attention/output/dense/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_3/attention/self/value/kernel/adam_m/read
add_157
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
bert/encoder/layer_6/output/dropout/Cast
	12.0
Assign_256
bert/encoder/layer_8/output/dense/kernel/adam_v/read
gradients/bert/encoder/layer_2/attention/output/dropout/mul_grad/Mul
bert/encoder/layer_2/output/dropout/mul_1
bert/encoder/layer_10/attention/output/dense/bias/read
gradients/bert/encoder/layer_0/output/dropout/mul_1_grad/Mul
	12.0
clip_by_global_norm/mul_188
bert/encoder/layer_2/attention/self/dropout/random_uniform/RandomUniform
	24.0
bert/encoder/layer_8/intermediate/dense/kernel
gradients/bert/encoder/layer_5/attention/self/Softmax_grad/mul
bert/encoder/layer_2/output/LayerNorm/beta/adam_m/read
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m/read
bert/encoder/layer_11/output/dense/kernel
add_70
bert/pooler/dense/kernel/adam_v
bert/encoder/layer_6/attention/self/key/bias/adam_m
gradients/cls/predictions/Sum_grad/Reshape
truediv_63
bert/encoder/layer_0/attention/self/ExpandDims
Mul_511
	0.0029296875
gradients/bert/encoder/layer_2/attention/self/transpose_grad/transpose
	19.5
bert/encoder/layer_9/attention/self/query/MatMul
	12.0
global_norm/L2Loss_133
	0.000244140625
	0.0146484375
Square_158
bert/encoder/layer_9/output/dropout/mul
	12.0
global_norm/L2Loss_86
	0.000244140625
gradients/bert/encoder/layer_5/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
cls/predictions/transform/LayerNorm/batchnorm/mul_2
	1.875
bert/encoder/layer_1/attention/self/dropout/random_uniform/mul
Assign_339
sub_116
bert/encoder/layer_5/output/dense/kernel/adam_v
bert/embeddings/token_type_embeddings/adam_m/read
Mul_761
	0.0029296875
bert/encoder/layer_3/output/dense/kernel/adam_m
truediv_199
Mul_1009
Square_69
	2.25
add_305
Sqrt_5
	2.25
mul_838
Mul_248
	0.0029296875
Assign_18
Mul_463
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m/read
mul_96
Mul_1054
	0.0029296875
Assign_517
add_410
mul_1
mul_128
mul_650
bert/encoder/layer_1/attention/output/dropout/random_uniform
Mul_423
bert/encoder/layer_5/attention/self/query/MatMul
	12.0
add_116
mul_3
bert/encoder/layer_1/output/dense/bias/adam_v
Mul_938
	0.0029296875
Assign_438
Assign_252
Sqrt_149
	2.25
truediv_23
bert/embeddings/LayerNorm/batchnorm/add/y
Square_26
	0.0029296875
Square_179
	0.0029296875
truediv_83
bert/encoder/layer_0/attention/output/dense/kernel/adam_v/read
global_norm/L2Loss_123
	0.000244140625
	0.01220703125
Sqrt_19
	0.0029296875
gradients/AddN_34
add_560
gradients/AddN_90/inputs_1
	122.5166015625
bert/encoder/layer_1/output/LayerNorm/gamma/adam_v
add_204
add_402
mul_730
Assign_89
sub_179
add_673
add_41
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/sub_grad/Neg
	15.169921875
bert/encoder/layer_2/output/dropout/mul
	12.0
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
gradients/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference_grad/Mul
add_597
Assign_265
Assign_240
add_291
Mul_546
cls/seq_relationship/Reshape
mul_655
bert/encoder/layer_1/attention/output/LayerNorm/beta
Sqrt_179
	0.0029296875
Assign_601
bert/encoder/layer_5/attention/self/add
mul_649
	2.25
Mul_147
bert/encoder/layer_7/output/LayerNorm/gamma/read
bert/encoder/layer_8/intermediate/dense/add
bert/encoder/layer_0/attention/self/transpose_1
	12.0
clip_by_global_norm/mul_182
bert/encoder/layer_0/output/dense/kernel
global_norm/L2Loss_58
	0.000244140625
clip_by_global_norm/mul_149
mul_402
	2.25
bert/encoder/layer_1/intermediate/dense/kernel/read
sub_73
Mul_111
Mul_573
bert/encoder/layer_2/attention/self/Softmax
	24.0
	24.0
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
gradients/bert/encoder/layer_1/attention/self/transpose_2_grad/transpose
	12.0
Mul_4
	89.419921875
Mul_989
	2.25
add_655
Mul_181
gradients/bert/encoder/layer_9/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1
	12.0
Mul_95
sub_71
Sqrt_60
	0.0029296875
bert/encoder/layer_6/intermediate/dense/add_1
	48.0
bert/encoder/layer_4/attention/output/dropout/random_uniform/RandomUniform
	12.0
cls/predictions/Const
bert/encoder/layer_8/output/dense/kernel/adam_v
mul_20
	1.5
add_125
Mul_197
mul_47
	2.25
Sqrt_177
	9.0
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape
Assign_81
Mul_492
	0.0029296875
gradients/bert/encoder/layer_4/attention/self/transpose_2_grad/transpose
	12.0
sub_158
global_norm/L2Loss_141
	0.000244140625
bert/encoder/layer_1/output/dense/BiasAdd
Assign_247
mul_833
Mul_1029
	0.0029296875
global_norm/L2Loss_9
	0.000244140625
	0.0087890625
bert/encoder/layer_8/output/dense/bias/adam_m
add_628
bert/encoder/layer_7/attention/self/key/MatMul
	12.0
Assign_87
gradients/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul
	48.0
gradients/bert/encoder/layer_7/output/LayerNorm/moments/mean_grad/truediv
bert/encoder/layer_8/attention/self/add
gradients/bert/encoder/layer_2/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
add_461
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
bert/encoder/layer_1/attention/self/key/bias
bert/embeddings/LayerNorm/batchnorm/Rsqrt
Assign_182
global_norm/L2Loss_127
	0.000244140625
	0.0087890625
bert/encoder/layer_4/attention/self/query/kernel/adam_m
bert/encoder/layer_3/attention/output/LayerNorm/gamma
Mul_973
	0.0029296875
bert/encoder/layer_9/attention/output/LayerNorm/moments/variance
	0.015625
Mul_281
bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt
Mul_444
Mul_393
	0.0029296875
gradients/bert/encoder/layer_4/attention/self/query/MatMul_grad/MatMul_1
	2.25
Square_199
	2.25
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/variance_grad/truediv
sub_120
add_505
bert/encoder/layer_8/attention/output/dropout/Cast
	12.0
Mul_137
	0.0029296875
bert/encoder/layer_0/output/dropout/Cast
	12.0
sub_166
gradients/AddN_58
add_17
bert/encoder/layer_2/attention/output/dense/BiasAdd
gradients/bert/encoder/layer_8/attention/self/query/MatMul_grad/MatMul_1
	2.25
Assign_49
Square_40
	0.0029296875
bert/encoder/layer_2/attention/self/query/BiasAdd
bert/encoder/layer_7/attention/output/dense/bias
Square_68
	0.0029296875
gradients/bert/encoder/layer_11/output/LayerNorm/moments/mean_grad/truediv
mul_1036
	9.0
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_1_grad/Mul
	1.875
bert/encoder/layer_5/attention/self/dropout/mul
	24.0
bert/encoder/layer_1/intermediate/dense/add
bert/embeddings/dropout/random_uniform
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m/read
add_43
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/variance_grad/truediv
sub_64
bert/encoder/layer_0/output/dense/bias/adam_m
Assign_459
add_425
bert/encoder/layer_11/attention/self/dropout/random_uniform/mul
Mul_410
sub_66
add_361
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
gradients/bert/encoder/layer_7/intermediate/dense/Pow_grad/Pow
	48.0
bert/encoder/layer_8/attention/output/dense/bias/adam_m/read
bert/encoder/layer_9/attention/self/query/bias/adam_m
add_610
truediv_204
bert/encoder/layer_0/attention/self/query/bias/adam_v/read
bert/encoder/layer_9/attention/self/key/BiasAdd
bert/encoder/layer_3/output/dropout/Cast
	12.0
bert/encoder/layer_2/attention/output/dropout/random_uniform
Mul_863
add_295
bert/encoder/layer_11/output/dense/kernel/adam_m
Mul_1075
	2.25
Mul_921
sub_151
mul_380
	2.25
bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference
	12.0
sub_123
Square_19
	0.0029296875
bert/encoder/layer_0/attention/self/key/bias/read
bert/encoder/layer_0/attention/output/dense/kernel/adam_m
bert/encoder/layer_0/attention/output/dense/kernel
Assign_257
Assign_278
sub_167
Assign_65
Mul_364
global_norm/L2Loss_7
	0.000244140625
	0.0087890625
add_84
mul_552
	2.25
bert/encoder/layer_5/attention/output/dense/kernel/adam_m
Assign_589
add_522
bert/encoder/layer_9/intermediate/dense/kernel/read
mul_967
Assign_273
bert/encoder/layer_0/intermediate/dense/MatMul
	48.0
gradients/bert/encoder/layer_8/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
add_124
bert/encoder/layer_9/attention/output/LayerNorm/gamma
bert/encoder/layer_1/attention/self/Reshape
add_66
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
truediv_170
truediv_62
sub_83
Assign_403
global_norm/L2Loss_108
	0.000244140625
mul_542
gradients/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/scalar
Mul_261
Mul_808
	2.25
gradients/bert/encoder/layer_9/attention/self/Softmax_grad/Sum
	0.1875
gradients/bert/encoder/layer_2/output/dropout/mul_grad/Mul
Assign_349
sub_92
Mul_205
bert/encoder/layer_2/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
Sqrt_119
	2.25
gradients/Reshape_2_grad/Reshape
Mul_813
	0.003173828125
sub_1
gradients/bert/encoder/layer_10/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.004638671875
bert/encoder/layer_9/attention/self/key/bias/adam_m/read
bert/encoder/layer_11/attention/self/Reshape_1
bert/encoder/layer_0/intermediate/dense/kernel/adam_m
bert/encoder/layer_7/attention/self/key/kernel
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
Mul_465
global_norm/L2Loss_112
	0.000244140625
clip_by_global_norm/mul_163
bert/encoder/layer_1/attention/self/key/kernel
Mul_663
	0.0029296875
truediv_108
bert/encoder/layer_8/attention/self/key/kernel
Mul_86
	9.0
sub_160
gradients/bert/encoder/layer_4/attention/self/value/MatMul_grad/MatMul_1
	2.25
Assign_282
gradients/bert/encoder/layer_2/intermediate/dense/Pow_grad/Pow
	48.0
bert/encoder/layer_11/attention/self/transpose_1
	12.0
Assign_342
Assign_507
Mul_1103
	0.005859375
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add
Mul_888
	0.0029296875
Assign_432
bert/encoder/layer_2/intermediate/dense/kernel/adam_m/read
Assign_570
bert/encoder/layer_5/attention/self/value/bias
clip_by_global_norm/mul_134
bert/encoder/layer_1/output/LayerNorm/beta/adam_v/read
Assign_123
Assign_611
Square_141
Assign_76
bert/encoder/layer_2/intermediate/dense/BiasAdd
global_norm/L2Loss_109
	0.000244140625
bert/encoder/layer_3/attention/self/query/kernel/read
bert/encoder/layer_3/attention/self/query/bias/adam_v/read
bert/encoder/layer_0/attention/self/query/bias/adam_m/read
bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt
bert/encoder/layer_4/attention/self/dropout/mul
	24.0
Assign_171
bert/encoder/layer_8/attention/self/value/bias/adam_m/read
gradients/bert/encoder/layer_6/attention/self/transpose_2_grad/transpose
	12.0
truediv_92
Mul_835
	0.0029296875
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v
truediv_89
Assign_332
bert/encoder/layer_1/attention/output/LayerNorm/gamma
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_2/attention/self/value/kernel/adam_m/read
add_392
cls/predictions/transform/dense/kernel/adam_m/read
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1
mul_977
bert/encoder/layer_7/attention/output/dropout/random_uniform/mul
Assign_521
truediv_11
Mul_34
	2.25
Mul_942
bert/encoder/layer_6/output/dropout/mul
	12.0
sub_90
gradients/bert/encoder/layer_11/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
Sqrt_85
	2.25
Sqrt_139
	2.25
Assign_579
Assign_279
bert/encoder/layer_3/attention/output/LayerNorm/moments/variance
	0.015625
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
Assign_470
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
bert/encoder/layer_7/output/dropout/GreaterEqual
	3.0
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
Mul_11
add_618
gradients/AddN_23
Sqrt_123
	2.25
Square_117
gradients/cls/seq_relationship/LogSoftmax_grad/Exp
	0.000244140625
mul_359
	9.0
sub_154
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/sub_grad/Neg
	15.75
Sqrt_180
	0.0029296875
Mul_346
	9.0
Sqrt_124
	0.0029296875
add_146
Mul_737
	0.0029296875
Assign_496
mul_467
bert/embeddings/position_embeddings/read
AssignVariableOp
Square_115
bert/encoder/layer_8/attention/self/value/kernel
truediv_9
bert/encoder/layer_5/attention/self/value/bias/adam_m/read
gradients/bert/encoder/layer_2/attention/self/dropout/mul_grad/Mul
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
clip_by_global_norm/mul_175
Mul_189
	0.0029296875
add_547
Assign_463
add_77
bert/encoder/layer_8/output/LayerNorm/gamma/adam_v/read
Mul_237
	2.25
add_439
add_565
Assign_207
sub_114
gradients/bert/embeddings/LayerNorm/batchnorm/sub_grad/Neg
	12.0
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_9/output/dense/bias/adam_m/read
gradients/bert/encoder/layer_8/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/bert/encoder/layer_3/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
Assign_117
truediv_164
Mul_625
	0.003173828125
add_267
bert/encoder/layer_4/attention/output/dense/BiasAdd
Mul_469
Sqrt_186
	0.0029296875
gradients/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul
Assign_533
add_540
add_379
Mul_418
mul_58
	2.25
gradients/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference_grad/scalar
clip_by_global_norm/mul_121
bert/encoder/layer_5/attention/output/dense/kernel/adam_m/read
Mul_168
bert/encoder/layer_7/intermediate/dense/Pow
	48.0
bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1
	12.0
bert/embeddings/LayerNorm/moments/variance
	0.015625
bert/encoder/layer_11/attention/self/dropout/Cast
	24.0
add_389
Sqrt_183
	2.25
bert/encoder/layer_10/attention/self/key/bias/adam_v
clip_by_global_norm/mul_26
Assign_44
Square_135
Mul_527
	9.0
Mul_626
	0.0029296875
add_574
mul_242
bert/encoder/layer_2/output/dropout/random_uniform/RandomUniform
	12.0
truediv_40
bert/encoder/layer_10/attention/self/value/bias/read
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.003662109375
sub_41
bert/encoder/layer_10/attention/output/LayerNorm/gamma
bert/encoder/layer_10/output/dense/kernel/read
mul_343
clip_by_global_norm/mul_95
gradients/bert/encoder/layer_6/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_4/attention/self/value/bias/adam_m
gradients/bert/encoder/layer_2/attention/self/transpose_2_grad/transpose
	12.0
Square_32
	0.01171875
Square_105
add_108
gradients/bert/encoder/layer_8/attention/self/key/MatMul_grad/MatMul_1
	2.25
add_602
bert/embeddings/token_type_embeddings/adam_v/read
bert/encoder/layer_0/attention/output/dense/bias/adam_v/read
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
Const_2
add_388
sub_49
mul_526
gradients/bert/encoder/layer_7/attention/self/Softmax_grad/sub
add_571
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
gradients/bert/encoder/layer_3/attention/self/query/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_2/attention/self/dropout/random_uniform
gradients/AddN_63
gradients/cls/predictions/transform/dense/Pow_grad/Pow
	1.875
gradients/cls/seq_relationship/Sum_grad/Tile
add_257
Assign_359
add_480
bert/encoder/layer_5/attention/self/dropout/mul_1
Assign_523
cls/seq_relationship/output_weights/read
mul_1105
	0.005859375
Assign_369
gradients/bert/encoder/layer_8/attention/self/Softmax_grad/mul
Mul_121
bert/encoder/layer_7/attention/output/LayerNorm/gamma
gradients/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference_grad/Mul
bert/encoder/layer_6/attention/self/key/bias
bert/encoder/layer_3/output/LayerNorm/batchnorm/add
Sqrt_96
	0.01171875
Assign_532
bert/encoder/layer_3/attention/self/value/bias
bert/encoder/layer_0/output/LayerNorm/batchnorm/sub
bert/encoder/layer_0/attention/self/transpose_3
	12.0
Square_149
bert/encoder/layer_3/intermediate/dense/kernel/read
gradients/bert/encoder/layer_9/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.01171875
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Mul_1
truediv_110
Mul_1007/x
bert/encoder/layer_4/output/LayerNorm/gamma/adam_v/read
gradients/bert/encoder/layer_11/attention/output/dense/MatMul_grad/MatMul
	12.0
gradients/bert/encoder/layer_6/attention/self/Softmax_grad/Sum
	0.1875
bert/encoder/layer_5/attention/self/dropout/Cast
	24.0
bert/encoder/layer_10/attention/self/value/kernel/adam_v
bert/encoder/layer_6/attention/self/value/bias/read
bert/encoder/layer_0/intermediate/dense/bias/read
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
bert/encoder/layer_9/attention/output/dense/bias/adam_v/read
Mul_1088
	0.0029296875
bert/encoder/layer_4/output/LayerNorm/gamma/adam_m/read
Square_205
	0.000244140625
bert/encoder/layer_5/attention/output/dropout/Cast
	12.0
Mul_535
	0.0029296875
Mul_358
bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1
	12.0
bert/encoder/layer_5/output/LayerNorm/beta/adam_v
gradients/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference_grad/mul_1
Sqrt_93
	0.0029296875
mul_698
add_563
add_637
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m/read
truediv_64
truediv_143
Mul_643
bert/encoder/layer_9/output/dense/kernel
bert/encoder/layer_8/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_9/output/LayerNorm/moments/variance_grad/Tile
	12.0
bert/encoder/layer_2/output/LayerNorm/moments/variance
	0.015625
truediv_128
truediv_191
gradients/AddN_36
mul_322
bert/encoder/layer_3/attention/self/query/bias/adam_m/read
add_117
bert/embeddings/LayerNorm/batchnorm/sub
bert/encoder/layer_1/attention/self/value/MatMul
	12.0
gradients/bert/encoder/layer_3/output/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_7/intermediate/dense/mul_3
Mul_195
mul_230
	2.25
Sqrt_190
	0.0029296875
Mul_132
gradients/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/truediv
bert/encoder/layer_8/attention/self/transpose_2
	12.0
add_234
bert/encoder/layer_3/output/dense/bias/adam_v
gradients/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_11/attention/output/LayerNorm/gamma/read
bert/encoder/layer_3/attention/self/key/kernel/adam_m
cls/predictions/Reshape
Mul_968
	0.0029296875
truediv_123
mul_101
	9.0
Assign_592
Sqrt_111
	9.0
mul_1085
bert/encoder/layer_2/output/dense/MatMul
	12.0
bert/encoder/layer_5/attention/self/value/kernel/read
Assign_189
bert/encoder/layer_11/intermediate/dense/Tanh
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
sub_51
gradients/bert/encoder/layer_1/attention/self/Reshape_3_grad/Reshape
gradients/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference_grad/sub
mul_419
bert/encoder/layer_0/attention/output/dropout/mul_1
truediv_91
Assign_422
gradients/bert/encoder/layer_2/attention/self/dropout/mul_1_grad/Mul
add_360
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
gradients/bert/encoder/layer_4/output/LayerNorm/moments/mean_grad/Tile
	12.0
Mul_729
bert/encoder/layer_10/output/dense/kernel/adam_m
gradients/bert/encoder/layer_2/attention/output/dropout/mul_1_grad/Mul
	12.0
bert/encoder/layer_10/output/dropout/random_uniform
bert/encoder/layer_11/output/LayerNorm/gamma/adam_m
Sqrt_198
	0.0029296875
bert/encoder/layer_0/attention/output/dense/bias
bert/encoder/layer_9/attention/self/query/BiasAdd
gradients/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference_grad/Mul
Mul_326
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
Reshape
Assign_571
global_norm/L2Loss_20
	0.000244140625
truediv_59
bert/encoder/layer_8/attention/self/query/bias/adam_v
add_625
Sqrt_38
	0.0029296875
bert/encoder/layer_9/attention/output/LayerNorm/moments/mean
	0.015625
Mul_533
	0.0029296875
add_78
bert/encoder/layer_8/output/LayerNorm/batchnorm/sub
add_646
bert/encoder/layer_7/intermediate/dense/kernel/adam_v
Assign_96
bert/encoder/layer_6/attention/self/query/MatMul
	12.0
Square_171
	2.25
sub_46
Assign_194
bert/encoder/layer_8/attention/self/Reshape_1
Mul_52
Mul_640
	0.0029296875
bert/encoder/layer_0/output/dropout/random_uniform/RandomUniform
	12.0
bert/encoder/layer_5/attention/self/key/bias/adam_v/read
global_norm/stack
	0.0009765625
	0.001708984375
bert/encoder/layer_6/attention/output/dense/bias/adam_m
Mul_796
	0.0029296875
Mul_491
gradients/bert/encoder/layer_2/attention/output/dense/MatMul_grad/MatMul_1
	2.25
truediv_161
gradients/AddN_68
Square_94
Mul_1019
	0.0029296875
gradients/bert/encoder/layer_9/attention/self/key/MatMul_grad/MatMul
	15.169921875
Assign_143
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
add_528
add_18
bert/encoder/layer_5/intermediate/dense/bias/read
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1
bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1
bert/encoder/layer_11/attention/self/transpose
	12.0
gradients/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference_grad/sub
bert/encoder/layer_4/intermediate/dense/kernel/adam_v
add_65
clip_by_global_norm/mul_80
Sqrt_118
	0.0029296875
gradients/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/truediv
global_norm/L2Loss_175
	0.000244140625
	0.0087890625
sub_145
add_484
bert/pooler/dense/bias
bert/encoder/layer_0/attention/self/query/kernel/adam_m/read
add_414
bert/encoder/layer_5/attention/output/dropout/mul_1
Square_162
Mul_245
	0.0029296875
gradients/bert/encoder/layer_0/attention/self/Softmax_grad/Sum
	0.1875
mul_198
bert/encoder/layer_9/attention/self/dropout/mul
	24.0
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
gradients/bert/encoder/layer_11/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_8/attention/self/dropout/mul_1_grad/Mul
Assign_312
Square_38
	0.0029296875
Sqrt_113
	9.0
Assign_215
Assign_593
bert/encoder/layer_6/attention/self/value/kernel
bert/encoder/layer_11/attention/self/value/MatMul
	12.0
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
Assign_167
sub_182
sub_12
bert/encoder/layer_3/attention/self/key/kernel
Sqrt_108
	0.0029296875
Sqrt_129
	9.0
Mul_290
	2.25
add_504
bert/encoder/layer_4/output/dropout/random_uniform/mul
global_norm/L2Loss_72
	0.000244140625
bert/encoder/layer_11/attention/output/LayerNorm/gamma
bert/encoder/layer_6/output/dense/kernel/adam_m
mul_1095
bert/encoder/layer_3/output/LayerNorm/beta/read
bert/encoder/layer_9/output/LayerNorm/beta/adam_v/read
Mul_383
bert/encoder/layer_6/output/LayerNorm/beta/adam_m/read
Mul_374
Mul_22
	0.0029296875
bert/encoder/layer_2/output/dense/bias/adam_v
gradients/bert/encoder/layer_6/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
Mul_481
	0.0029296875
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/mean_grad/truediv
Mul_543
	0.0029296875
bert/encoder/layer_9/attention/self/Softmax
	24.0
	24.0
truediv_133
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m
gradients/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference_grad/sub
Mul_63
Square_87
	2.25
add_467
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2
	12.0
Mul_581
	2.25
bert/encoder/layer_3/attention/output/LayerNorm/beta/read
clip_by_global_norm/mul_19
Mul_887
	0.0029296875
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
truediv_121
clip_by_global_norm/mul_6
Sqrt_61
	0.003173828125
Square_198
gradients/bert/encoder/layer_7/output/dropout/mul_grad/Mul
bert/encoder/layer_10/intermediate/dense/kernel/adam_v/read
bert/encoder/layer_10/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_11/attention/output/LayerNorm/moments/mean
	0.015625
bert/encoder/layer_8/attention/output/LayerNorm/beta
Assign_504
bert/encoder/layer_2/output/dense/kernel/adam_m/read
Mul_169
	0.0029296875
bert/encoder/layer_3/attention/self/value/bias/read
Mul_211
gradients/bert/encoder/layer_9/attention/self/key/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_7/attention/self/key/kernel/adam_m/read
Mul_590
add_372
bert/encoder/layer_6/attention/self/query/kernel/adam_m/read
bert/embeddings/LayerNorm/beta/read
bert/encoder/layer_7/output/dense/bias/adam_v
Mul_775
	9.75
gradients/bert/encoder/layer_3/intermediate/dense/Pow_grad/mul
add_593
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m
bert/encoder/layer_10/output/dense/kernel/adam_m/read
bert/embeddings/word_embeddings/adam_m
bert/encoder/layer_8/intermediate/dense/Pow
	48.0
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	15.75
global_norm/L2Loss_142
	0.000244140625
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
Mul_1092
Mul_767
add_131
Mul_271
	9.0
bert/encoder/layer_4/attention/self/transpose_1
	12.0
bert/encoder/layer_9/attention/self/key/bias/read
add_531
gradients/cls/predictions/Sum_1_grad/Reshape
clip_by_global_norm/mul_148
bert/encoder/layer_10/attention/self/query/bias/adam_v/read
Mul_235
bert/encoder/layer_0/intermediate/dense/bias
bert/encoder/layer_3/intermediate/dense/kernel
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m
Assign_209
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
Mul_502
Mul_170
bert/encoder/layer_1/output/LayerNorm/batchnorm/sub
gradients/bert/embeddings/LayerNorm/moments/variance_grad/Tile
	12.0
Mul_804
Assign_433
global_norm/L2Loss_45
	0.000244140625
bert/encoder/layer_2/attention/self/value/bias/adam_m
Assign_160
truediv_109
gradients/AddN_65
global_norm/L2Loss_49
	0.000244140625
	0.0087890625
bert/encoder/layer_6/attention/output/dense/bias/read
truediv_165
bert/encoder/layer_2/attention/output/dense/kernel/adam_m/read
global_norm/L2Loss_14
	0.000244140625
bert/encoder/layer_3/intermediate/dense/bias/adam_v/read
Assign_616
Assign_581
Assign_610
Assign_604
clip_by_global_norm/mul_92
add_591
mul_208
	2.25
bert/encoder/layer_3/attention/self/query/bias
Square_102
gradients/AddN_14
bert/encoder/layer_3/attention/self/dropout/mul_1
sub_192
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt
bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference
	12.0
Sqrt_175
	9.0
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1
clip_by_global_norm/mul_21
global_step/cond/Read/ReadVariableOp
Assign_164
Mul_105
	0.0029296875
truediv_187
global_norm/L2Loss_28
	0.000244140625
Assign_157
Square_109
bert/encoder/layer_8/attention/self/key/kernel/adam_m/read
mul_408
add_299
bert/encoder/layer_5/attention/self/transpose_1
	12.0
Mul_341
	0.0029296875
clip_by_global_norm/mul_24
add_457
mul_294
	2.25
add_523
Sqrt_46
	0.0029296875
bert/encoder/layer_6/attention/output/dense/MatMul
	12.0
truediv_10
sub_6
gradients/bert/encoder/layer_10/intermediate/dense/MatMul_grad/MatMul
	12.0
Sqrt_48
	0.01171875
gradients/cls/predictions/transform/dense/mul_3_grad/Mul
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m/read
Square_174
	0.0029296875
add_174
Assign_91
gradients/AddN_28
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt
Mul_1094
bert/encoder/layer_10/output/LayerNorm/gamma/adam_m/read
add_206
Assign_490
gradients/bert/encoder/layer_5/attention/self/transpose_grad/transpose
	12.0
bert/encoder/layer_5/intermediate/dense/kernel/adam_v/read
gradients/AddN_35
cls/seq_relationship/output_weights/adam_m
Assign_321
Square_187
gradients/AddN_82
sub_148
bert/encoder/layer_5/intermediate/dense/bias/adam_m
Sqrt_104
	0.0029296875
gradients/AddN_1
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub
bert/encoder/layer_9/attention/self/dropout/GreaterEqual
	6.0
sub_136
Mul_497
	2.25
gradients/bert/encoder/layer_11/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
Sqrt_167
	2.25
gradients/bert/encoder/layer_9/attention/self/Mul_grad/Mul
add_368
Mul_72
truediv_72
bert/encoder/layer_2/output/LayerNorm/gamma/adam_m/read
sub_80
gradients/bert/encoder/layer_6/attention/output/dense/MatMul_grad/MatMul_1
	3.0
bert/encoder/layer_2/attention/self/value/bias/adam_m/read
Mul_771
	0.0029296875
truediv_135
global_norm/L2Loss_195
	0.000244140625
Assign_445
bert/encoder/layer_9/attention/output/dense/bias/read
mul_1090
bert/encoder/layer_6/output/dense/bias
add_442
add_261
gradients/bert/encoder/layer_4/attention/self/Reshape_3_grad/Reshape
Assign_338
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
add_630
Assign_35
gradients/bert/encoder/layer_3/intermediate/dense/mul_3_grad/Mul_1
	48.0
Mul_501
	0.0029296875
add_398
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
Mul_604
	9.0
truediv_190
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m/read
global_norm/L2Loss_39
	0.000244140625
	0.0087890625
bert/encoder/layer_11/attention/self/key/bias/adam_v
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1
	12.0
clip_by_global_norm/mul_172
bert/encoder/layer_9/attention/self/key/bias
global_norm/L2Loss_91
	0.000244140625
	0.01220703125
bert/encoder/layer_6/attention/self/value/bias/adam_v/read
Assign
bert/encoder/layer_5/attention/self/transpose_3
	12.0
gradients/bert/encoder/layer_8/output/dense/MatMul_grad/MatMul
	51.0
clip_by_global_norm/mul_5
mul_682
bert/encoder/layer_11/attention/output/dropout/Cast
	12.0
Assign_400
add_405
Mul_106
sub_109
add_139
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
Assign_389
add_179
bert/encoder/layer_1/attention/self/key/bias/adam_m
clip_by_global_norm/mul_129
Mul_939
add_142
Assign_80
bert/encoder/layer_2/output/LayerNorm/beta/read
Assign_249
mul_247
mul_558
gradients/bert/encoder/layer_6/attention/output/dropout/mul_grad/Mul
bert/encoder/layer_0/attention/self/key/kernel/adam_m
Mul_528
sub_168
Mul_164
	0.0029296875
clip_by_global_norm/mul_140
bert/encoder/layer_5/output/dense/bias/adam_v
Assign_417
bert/encoder/layer_2/attention/self/value/bias/adam_v/read
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Reshape
bert/encoder/layer_2/intermediate/dense/mul
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
gradients/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference_grad/mul_1
bert/encoder/layer_10/intermediate/dense/kernel/adam_m/read
clip_by_global_norm/mul_111
gradients/cls/predictions/transform/dense/mul_2_grad/Mul_1
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv
Sqrt_193
	9.0
clip_by_global_norm/mul_101
Mul_806
	2.25
Sqrt_99
	0.0029296875
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v
bert/encoder/layer_0/attention/self/mul_1
Assign_376
Mul_113
	0.0029296875
clip_by_global_norm/Select
add_31
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Neg
	15.75
add_603
Assign_28
sub_153
add_669
bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference
	12.0
add_614
Assign_41
global_norm/L2Loss_158
	0.000244140625
clip_by_global_norm/mul_150
Assign_482
Assign_457
Assign_395
add_268
global_norm/L2Loss_119
	0.000244140625
	0.0087890625
bert/pooler/dense/BiasAdd
Mul_297
bert/encoder/layer_7/intermediate/dense/BiasAdd
sub_206
Mul_636
	2.25
Mul_546/x
bert/encoder/layer_10/attention/self/value/BiasAdd
mul_919
bert/encoder/layer_11/attention/self/key/MatMul
	12.0
Mul_87
bert/encoder/layer_7/intermediate/dense/bias/adam_m
gradients/bert/encoder/layer_8/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_1/output/LayerNorm/beta/adam_m/read
add_253
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
gradients/bert/encoder/layer_0/attention/self/transpose_grad/transpose
	12.0
Mul_878
	0.0029296875
bert/encoder/layer_1/output/LayerNorm/beta/adam_v
add_397
Mul_382
	0.0029296875
add_199
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
bert/encoder/layer_1/output/LayerNorm/batchnorm/add
Assign_596
Assign_135
clip_by_global_norm/mul_162
bert/encoder/layer_1/attention/self/transpose
	12.0
mul_672
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add
Assign_66
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
gradients/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum/reduction_indices
global_norm/L2Loss_168
	0.000244140625
bert/pooler/dense/bias/read
Mul_720
	2.25
bert/encoder/layer_11/intermediate/dense/MatMul
	48.0
global_norm/L2Loss_82
	0.000244140625
Mul_285
	0.0029296875
Square_100
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v
Assign_558
sub_161
Assign_67
global_norm/L2Loss_105
	0.000244140625
	0.0087890625
Mul_251
add_678
bert/encoder/layer_8/output/LayerNorm/gamma
add_529
cls/seq_relationship/output_weights
mul_913
sub_78
gradients/bert/encoder/layer_9/attention/self/value/MatMul_grad/MatMul
	12.0
Square_91
	2.25
Square_143
bert/encoder/layer_8/attention/output/dense/MatMul
	12.0
bert/encoder/layer_6/output/dense/bias/adam_m/read
mul_413
	2.25
Mul_826
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
gradients/bert/encoder/layer_7/attention/output/dense/MatMul_grad/MatMul
	12.0
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2
	12.0
bert/encoder/layer_7/output/LayerNorm/gamma/adam_m
Mul_943
	0.0029296875
Assign_441
Mul_67
	2.25
bert/encoder/layer_3/output/dropout/GreaterEqual
	3.0
mul_693
bert/encoder/layer_1/intermediate/dense/mul_1
Sqrt_27
	2.25
add_278
Square_133
bert/encoder/layer_4/attention/output/dense/bias/adam_v
gradients/bert/encoder/layer_9/output/dense/MatMul_grad/MatMul
	51.0
add_4
gradients/bert/encoder/layer_4/attention/self/key/MatMul_grad/MatMul_1
	2.25
cls/predictions/Reshape_1
add_564
add_319
Assign_263
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub
bert/encoder/layer_3/output/dropout/random_uniform
Mul_705
	0.0029296875
Assign_495
add_370
add_362
add_181
bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2
	12.0
Mul_512
	0.0029296875
clip_by_global_norm/mul_56
bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt
Square_60
	0.0029296875
Assign_40
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2
	12.0
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2_grad/Mul
mul_810
	2.25
bert/encoder/layer_8/attention/output/dense/bias/read
gradients/bert/encoder/layer_7/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
Sqrt_195
	0.0029296875
bert/encoder/layer_3/output/LayerNorm/beta/adam_m
truediv_156
Mul_387
	2.25
bert/encoder/layer_10/attention/self/Mul
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1
	12.0
Square_184
	0.0029296875
mul_488
	2.25
Square_15
	16.5
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
bert/encoder/layer_3/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_11/intermediate/dense/mul
Assign_108
Assign_319
sub_163
bert/encoder/layer_10/attention/self/Reshape_3
truediv_195
add_26
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum
	0.0224609375
Mul_883
	0.0029296875
bert/encoder/layer_11/attention/self/dropout/mul
	24.0
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
Assign_522
bert/encoder/layer_7/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_9/output/dense/bias/read
Assign_569
mul_1037
mul_274
gradients/bert/encoder/layer_4/output/dropout/mul_1_grad/Mul
	12.0
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1
	12.0
gradients/bert/encoder/layer_3/attention/self/Reshape_1_grad/Reshape
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
gradients/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_8/intermediate/dense/mul_1
mul_875
	9.0
add_312
mul_827
add_632
bert/encoder/layer_6/output/LayerNorm/batchnorm/mul
	12.0
global_norm/L2Loss_26
	0.000244140625
add_259
bert/encoder/layer_3/attention/self/Reshape
Mul_777
bert/encoder/layer_9/intermediate/dense/bias/adam_m/read
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v/read
Mul_390
Assign_425
add_144
gradients/bert/encoder/layer_5/attention/self/Softmax_grad/Sum
	0.1875
bert/encoder/layer_5/output/LayerNorm/gamma/adam_v
gradients/cls/predictions/Sum_grad/Tile/multiples
gradients/bert/encoder/layer_6/attention/self/Mul_grad/Mul
clip_by_global_norm/mul_139
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.02880859375
bert/encoder/layer_8/intermediate/dense/bias/adam_m
Mul_109
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2_grad/Mul
Mul_7
gradients/bert/encoder/layer_3/output/LayerNorm/moments/mean_grad/Tile
	12.0
sub_119
bert/encoder/layer_2/output/dropout/random_uniform
bert/encoder/layer_5/output/dense/kernel/read
bert/encoder/layer_9/attention/self/dropout/Cast
	24.0
add_113
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.028076171875
sub_18
sub_31
add_80
bert/encoder/layer_2/attention/output/LayerNorm/gamma
add_358
gradients/bert/encoder/layer_4/attention/self/Reshape_grad/Reshape
bert/encoder/layer_6/attention/output/dense/bias/adam_v/read
Mul_399
Square_113
Assign_554
Mul_629
	0.0029296875
bert/encoder/layer_5/output/LayerNorm/moments/mean
	0.015625
sub_126
Assign_586
bert/encoder/layer_11/attention/output/dropout/mul
	17.419921875
truediv_119
Assign_150
Assign_487
Square_200
	0.0029296875
bert/embeddings/LayerNorm/moments/mean/reduction_indices
Assign_358
Assign_424
Assign_607
Assign_577
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v
bert/encoder/layer_9/attention/self/value/kernel/adam_v
bert/encoder/layer_4/output/LayerNorm/beta/adam_v
Mul_258
	9.0
add_626
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v/read
bert/encoder/layer_8/attention/self/query/BiasAdd
bert/encoder/layer_9/attention/output/dense/kernel/read
bert/encoder/layer_1/attention/self/key/bias/adam_v
bert/encoder/layer_0/attention/output/dense/kernel/adam_v
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Mul_1
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
Mul_750
	0.0029296875
mul_724
	2.25
Mul_395
	0.0029296875
bert/encoder/layer_9/intermediate/dense/kernel/adam_m
Mul_45
	2.25
Assign_34
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub
Mul_396
bert/encoder/layer_6/attention/self/query/BiasAdd
bert/encoder/layer_10/attention/output/dropout/random_uniform/mul
add_659
Assign_103
Mul_437
Mul_829
	2.25
clip_by_global_norm/mul_205
bert/encoder/ones/shape_as_tensor
bert/encoder/layer_9/output/LayerNorm/gamma/adam_v/read
Assign_559
bert/encoder/layer_8/output/dense/bias/read
bert/encoder/layer_0/attention/output/LayerNorm/moments/mean
	0.015625
add_417
gradients/bert/encoder/layer_6/attention/self/transpose_grad/transpose
	12.0
clip_by_global_norm/mul_13
global_norm/L2Loss_33
	0.000244140625
	0.0087890625
Assign_606
add_367
gradients/bert/encoder/layer_4/attention/self/query/MatMul_grad/MatMul
	12.0
clip_by_global_norm/mul_67
global_norm/L2Loss_60
	0.000244140625
bert/encoder/layer_11/intermediate/dense/kernel/adam_m/read
Assign_318
add_6
bert/encoder/layer_1/attention/self/transpose_1
	12.0
Square_120
gradients/bert/encoder/layer_7/attention/self/key/MatMul_grad/MatMul
	12.0
bert/encoder/layer_4/output/dense/kernel/adam_m
gradients/bert/encoder/layer_3/attention/self/transpose_1_grad/transpose
	12.0
add_519
gradients/bert/encoder/layer_8/attention/self/Reshape_3_grad/Reshape
bert/encoder/layer_0/intermediate/dense/kernel/adam_v/read
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Mul_1
Sqrt_94
	0.0029296875
Mul_702
gradients/bert/encoder/layer_10/attention/self/Reshape_2_grad/Reshape
Mul_899
	0.0029296875
Assign_383
Assign_378
Assign_488
mul_145
Mul_280
	0.0029296875
truediv_131
sub_104
truediv_19
bert/embeddings/LayerNorm/gamma/adam_m
sub_45
cls/predictions/transform/dense/Pow
	1.875
bert/encoder/layer_0/attention/self/key/bias/adam_m
bert/encoder/layer_6/attention/self/value/MatMul
	12.0
clip_by_global_norm/mul_132
Mul_1052
bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference
	12.0
Square_33
	9.0
Mul_1077
	2.25
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v
add_476
bert/encoder/layer_7/attention/self/Reshape
bert/encoder/layer_0/attention/self/sub
Square_128
global_norm/L2Loss_76
	0.000244140625
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape
clip_by_global_norm/mul_49
sub_40
add_381
cls/predictions/transform/LayerNorm/beta/adam_v
add_443
add_109
Mul_955
bert/encoder/layer_5/output/dropout/mul
	12.0
clip_by_global_norm/mul_55
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul_1
bert/encoder/layer_10/attention/self/transpose_3
	12.0
bert/encoder/layer_2/output/LayerNorm/gamma
add_351
bert/embeddings/Reshape_3
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
truediv_144
Mul_250
	0.0029296875
gradients/bert/encoder/layer_2/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
add_352
add_39
Mul_970
	0.0029296875
Assign_430
clip_by_global_norm/mul_82
cls/seq_relationship/output_bias/adam_m
clip_by_global_norm/truediv
gradients/AddN_12
Square_148
bert/encoder/layer_6/output/dense/kernel/adam_v/read
gradients/AddN_29
add_344/y
mul_435
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
cls/predictions/mul
Mul_803
	0.0029296875
sub_60
bert/encoder/layer_11/output/dense/kernel/read
add_525
gradients/cls/predictions/transform/LayerNorm/moments/variance_grad/Tile/multiples
global_step/add/_2560
truediv_160
Mul_506
	0.0029296875
Assign_311
bert/encoder/layer_6/intermediate/dense/kernel/adam_v/read
bert/encoder/layer_2/attention/output/dropout/GreaterEqual
	3.0
bert/encoder/layer_6/attention/self/dropout/random_uniform
bert/encoder/layer_9/attention/self/query/bias/adam_v/read
cls/predictions/transform/LayerNorm/batchnorm/sub
Mul_770
	0.003662109375
add_79
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
Assign_447
bert/encoder/layer_8/output/dense/bias/adam_v
truediv_169
add_214
add_530
Sqrt_168
	0.0029296875
gradients/bert/encoder/layer_4/attention/self/transpose_grad/transpose
	15.75
Assign_348
Mul_452
	0.0029296875
bert/encoder/layer_0/attention/self/Reshape/shape
cls/predictions/transform/dense/kernel/adam_v
Assign_62
add_355
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v/read
gradients/bert/encoder/layer_6/intermediate/dense/mul_3_grad/Mul
clip_by_global_norm/mul_130
global_norm/L2Loss_15
	0.000244140625
	0.0087890625
mul_391
	2.25
Assign_280
add_205
bert/encoder/layer_9/attention/self/Mul
bert/pooler/dense/bias/adam_m/read
Assign_285
truediv_21
gradients/bert/encoder/layer_5/intermediate/dense/Pow_grad/mul_1
gradients/bert/encoder/layer_7/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/AddN_73
Assign_392
mul_59
bert/encoder/layer_7/output/dense/kernel/read
bert/encoder/layer_9/attention/self/value/bias/adam_v/read
sub_88
Assign_220
Mul_126
	0.0029296875
bert/encoder/layer_11/attention/self/value/bias/read
Mul_598
	0.0029296875
Mul_1003
Mul_363
	0.0029296875
bert/encoder/layer_2/attention/output/dense/kernel/adam_v/read
bert/encoder/layer_10/attention/output/LayerNorm/moments/variance
	0.015625
bert/encoder/layer_8/attention/self/Reshape_2
Assign_494
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v/read
mul_537
Mul_992
add_14
Assign_387
Mul_394
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
Assign_435
bert/encoder/layer_7/output/dense/kernel/adam_m/read
bert/encoder/layer_5/intermediate/dense/bias/adam_v/read
bert/encoder/layer_1/attention/self/query/BiasAdd
bert/encoder/layer_6/attention/self/Reshape_2
bert/encoder/layer_3/output/LayerNorm/beta/adam_v
bert/encoder/layer_10/attention/self/query/bias
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m
clip_by_global_norm/mul_42
sub_106
bert/encoder/layer_5/attention/self/dropout/random_uniform/RandomUniform
	24.0
add_49
Assign_428
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
Assign_299
gradients/bert/encoder/layer_6/attention/self/Softmax_grad/sub
bert/encoder/layer_2/attention/output/dense/bias
Mul_802
	0.0029296875
gradients/bert/encoder/layer_9/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_10/intermediate/dense/bias/adam_v/read
gradients/bert/encoder/layer_11/attention/self/Softmax_grad/mul_1
	24.0
clip_by_global_norm/mul_74
Mul_240
mul_779
sub_82
gradients/bert/encoder/layer_8/intermediate/dense/Tanh_grad/TanhGrad
clip_by_global_norm/mul_106
Mul_246
Square_51
	0.0029296875
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m
add_421
gradients/Reshape_2_grad/Reshape/strided_slice
Mul_706
	0.0029296875
truediv_2
global_norm/L2Loss_107
	0.000244140625
	0.0087890625
Square_181
	2.25
bert/embeddings/one_hot/on_value
gradients/bert/encoder/layer_3/intermediate/dense/MatMul_grad/MatMul_1
	12.0
Assign_572
Assign_474
Mul_179
Assign_233
Mul_1097
	0.116455078125
gradients/bert/encoder/layer_4/attention/self/Reshape_2_grad/Reshape
Mul_504
add_516
gradients/bert/encoder/layer_4/attention/self/value/MatMul_grad/MatMul
	12.0
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
mul_446
bert/encoder/ones
bert/encoder/layer_5/attention/output/dropout/random_uniform/RandomUniform
	12.0
bert/encoder/layer_3/attention/self/key/MatMul
	12.0
bert/encoder/layer_6/attention/self/transpose_2
	12.0
Mul_301
	2.25
bert/encoder/layer_6/output/dropout/random_uniform
Assign_246
bert/encoder/layer_8/output/LayerNorm/beta/adam_v/read
add_52
Square_65
	12.0
bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2
	12.0
Mul_1002
	2.25
add_203
Assign_106
Sqrt_6
	0.0029296875
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v/read
gradients/bert/encoder/layer_7/attention/self/transpose_2_grad/transpose
	12.0
Square_176
	0.01171875
gradients/bert/encoder/layer_2/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_1/attention/output/dense/bias/adam_v
bert/encoder/layer_11/attention/output/dense/kernel/adam_m
gradients/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1
	2.25
truediv_205
bert/encoder/layer_8/intermediate/dense/BiasAdd
global_norm/L2Loss_63
	0.000244140625
	0.0087890625
Assign_162
sub_55
Assign_391
Assign_598
Mul_218
Assign_573
bert/encoder/layer_3/attention/output/dense/MatMul
	12.0
gradients/bert/encoder/layer_10/attention/self/value/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub
bert/encoder/layer_8/intermediate/dense/bias/read
Mul_817
	2.25
gradients/bert/encoder/layer_10/intermediate/dense/mul_3_grad/Mul
bert/encoder/layer_0/attention/output/dropout/random_uniform
clip_by_global_norm/mul_125
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/sub_grad/Neg
	15.75
mul_940
bert/encoder/layer_6/attention/output/dropout/mul
	12.0
add_508
bert/encoder/layer_9/attention/self/value/kernel/adam_m
bert/encoder/layer_5/attention/self/dropout/random_uniform
bert/encoder/layer_4/output/dense/kernel/read
mul_811
Mul_473
	2.25
Assign_262
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
Mul_1059
	0.0029296875
bert/encoder/layer_10/attention/self/query/kernel/read
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m
mul_521
clip_by_global_norm/mul_94
bert/encoder/layer_4/output/dense/kernel/adam_m/read
gradients/bert/encoder/layer_10/intermediate/dense/Pow_grad/mul
gradients/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul
	12.0
Square_66
	0.0029296875
bert/encoder/layer_2/intermediate/dense/add
add_154
gradients/bert/encoder/layer_3/attention/self/Reshape_grad/Reshape
Assign_39
global_norm/L2Loss_152
	0.000244140625
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.0283203125
sub_172
Assign_472
add_543
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_7/attention/output/LayerNorm/beta/read
mul_489
Sqrt_23
	2.25
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
bert/encoder/layer_5/attention/output/dense/bias
add_526
bert/encoder/layer_0/output/LayerNorm/gamma
gradients/AddN_32
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
gradients/bert/encoder/layer_2/attention/self/Reshape_1_grad/Reshape
Assign_467
global_norm/L2Loss_193
	0.000244140625
	0.0126953125
add_541
add_635
Sqrt_148
	0.0029296875
mul_133
	2.25
gradients/bert/encoder/layer_10/attention/self/Softmax_grad/Sum
	0.1875
bert/encoder/layer_9/output/dropout/random_uniform
bert/encoder/layer_1/attention/self/key/bias/adam_v/read
add_115
bert/encoder/layer_5/attention/output/dense/kernel/adam_v
Square_202
	0.0029296875
Assign_552
gradients/bert/encoder/layer_10/attention/self/query/MatMul_grad/MatMul
	15.169921875
Sqrt_95
	9.0
gradients/AddN_5
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1
Mul_543/x
gradients/bert/encoder/layer_4/attention/self/MatMul_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1
	12.0
Mul_568
bert/encoder/layer_5/attention/self/query/kernel/adam_m
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add
bert/encoder/layer_7/attention/self/key/bias/read
bert/encoder/layer_6/output/LayerNorm/beta/adam_m
bert/encoder/layer_0/attention/output/dense/bias/adam_m/read
Square_164
global_norm/L2Loss_128
	0.000244140625
bert/encoder/layer_3/attention/output/dropout/random_uniform
bert/encoder/layer_11/output/LayerNorm/gamma/adam_m/read
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v
PolynomialDecay/Cast_2
	0.000244140625
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2_grad/Reshape
bert/encoder/layer_0/attention/self/dropout/Shape
gradients/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul_1
add_335
gradients/AddN_71
bert/encoder/layer_8/attention/self/value/bias/read
bert/encoder/layer_10/attention/output/dropout/random_uniform
bert/encoder/layer_8/attention/self/value/bias
bert/encoder/layer_11/attention/output/dense/bias/adam_m/read
Mul_153
	2.25
cls/predictions/BiasAdd
gradients/bert/encoder/layer_0/intermediate/dense/mul_2_grad/Mul_1
bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt
Mul_990
clip_by_global_norm/mul_160
gradients/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference_grad/mul_1
Mul_1032
	9.0
truediv_71
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Sum
	0.0283203125
gradients/bert/encoder/layer_2/intermediate/dense/MatMul_grad/MatMul
	12.0
add_331
Mul_1022
	0.0029296875
gradients/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference_grad/mul_1
Mul_1086
	0.0029296875
bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference
	12.0
bert/encoder/layer_0/intermediate/dense/BiasAdd
bert/encoder/layer_7/intermediate/dense/kernel/adam_v/read
Sqrt_3
	0.0029296875
mul_725
bert/encoder/layer_0/output/dense/MatMul
	12.0
Mul_755
	2.25
Mul_25
bert/encoder/layer_1/attention/self/query/kernel/adam_m
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
gradients/AddN_40
Assign_216
gradients/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference_grad/mul_1
bert/encoder/layer_0/attention/self/dropout/Cast
	24.0
add_520
bert/encoder/layer_6/attention/self/value/bias
add_102
Mul_118
	2.25
gradients/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference_grad/sub
gradients/cls/seq_relationship/LogSoftmax_grad/sub
Mul_27
	0.0029296875
bert/encoder/layer_9/intermediate/dense/MatMul
	48.0
add_303
bert/encoder/layer_7/output/dense/bias
mul_477
	2.25
add_502
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Reshape/shape
Square_172
	0.0029296875
add_242
add_148
mul_1079
	2.25
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m/read
truediv_54
gradients/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference_grad/scalar
bert/encoder/layer_7/attention/output/dense/MatMul
	12.0
bert/encoder/layer_0/attention/output/dropout/mul
	12.0
Assign_7
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
bert/encoder/layer_8/output/LayerNorm/moments/mean
	0.015625
Square_196
Less
Assign_222
Mul_657
	2.25
global_norm/L2Loss_198
	0.000244140625
bert/encoder/layer_7/attention/self/query/BiasAdd
gradients/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape
Assign_3
gradients/bert/encoder/layer_6/output/dropout/mul_1_grad/Mul
	12.0
Square_112
Square_80
	0.02294921875
clip_by_global_norm/mul_7
Mul_474
mul_139
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum
	0.02490234375
Assign_500
add_386
bert/encoder/layer_0/attention/output/LayerNorm/beta
Mul_550
	2.25
gradients/bert/encoder/layer_4/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.01171875
truediv_132
Mul_1065
	2.25
mul_1053
Assign_137
bert/encoder/layer_0/attention/self/value/bias
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
Assign_304
bert/encoder/layer_7/attention/self/value/bias/adam_m
mul_692
	9.0
clip_by_global_norm/mul_190
Sqrt_13
	0.0029296875
truediv_12
Sqrt_43
	2.25
bert/encoder/layer_0/intermediate/dense/kernel/read
cls/predictions/add
Square_89
	2.25
bert/encoder/layer_6/attention/self/Reshape
Mul_68
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1_grad/Mul
	15.75
Assign_499
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/mean_grad/truediv
cls/predictions/transform/LayerNorm/gamma/adam_m/read
bert/encoder/layer_2/attention/self/query/bias/adam_m
Sqrt_165
	2.25
Mul_893
	2.25
Sqrt_125
	0.0029296875
mul_574
	2.25
add_22
gradients/bert/encoder/layer_10/attention/self/Mul_grad/Mul
Square_4
	0.0029296875
bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2
	12.0
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
Assign_436
gradients/bert/encoder/layer_5/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.01171875
Sqrt_30
	0.0029296875
Square_67
	0.0029296875
clip_by_global_norm/mul_181
bert/encoder/layer_3/attention/self/transpose_3
	12.0
gradients/bert/encoder/layer_1/intermediate/dense/Pow_grad/mul_1
truediv_80
Assign_200
bert/encoder/layer_11/attention/self/key/BiasAdd
gradients/bert/encoder/layer_2/attention/self/Softmax_grad/Sum
	0.1875
bert/encoder/layer_0/attention/output/dense/kernel/read
bert/encoder/layer_2/output/dropout/Cast
	12.0
add_72
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
bert/encoder/layer_6/attention/self/key/kernel/adam_m
add_32
gradients/bert/encoder/layer_9/intermediate/dense/Tanh_grad/TanhGrad
Assign_609
mul_8
	89.419921875
Assign_138
bert/embeddings/token_type_embeddings/adam_m
add_8
add_554
Mul_369
bert/encoder/layer_2/attention/self/Reshape_1
Mul_315
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/variance_grad/truediv
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt
gradients/AddN_42
bert/encoder/layer_4/attention/self/query/bias/adam_v
add_185
gradients/bert/encoder/layer_9/attention/self/Reshape_2_grad/Reshape
Mul_264
	0.01171875
bert/encoder/layer_10/intermediate/dense/kernel/adam_v
add_382
truediv_196
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m/read
Assign_512
cls/predictions/transform/dense/mul_2
Square_157
add_246
bert/encoder/layer_4/intermediate/dense/mul_1
bert/encoder/layer_1/attention/output/dense/bias/adam_m
Mul_1096
	0.116455078125
Mul_979
clip_by_global_norm/mul_32
mul_90
	9.0
gradients/AddN_70
bert/encoder/layer_4/output/LayerNorm/gamma/adam_v
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
Assign_520
gradients/bert/embeddings/MatMul_grad/MatMul_1
	0.005859375
gradients/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference_grad/scalar
gradients/bert/encoder/layer_1/output/dropout/mul_grad/Mul
truediv_126
bert/encoder/layer_9/output/dense/MatMul
	12.0
bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference
	12.0
global_norm/L2Loss_70
	0.000244140625
global_norm/L2Loss_124
	0.000244140625
bert/encoder/layer_1/attention/self/value/kernel/adam_v/read
cls/predictions/output_bias/read
bert/encoder/layer_1/attention/self/add
gradients/AddN_52
bert/encoder/layer_7/attention/output/dense/BiasAdd
Mul_686
Square_31
	11.25
gradients/bert/encoder/layer_4/intermediate/dense/mul_1_grad/Mul_1
add_674
bert/embeddings/GatherV2
	12.0
Mul_318
	0.0029296875
clip_by_global_norm/mul_141
add_636
Sqrt_200
	0.0029296875
gradients/bert/encoder/layer_0/attention/self/Mul_grad/Mul
gradients/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.01953125
add_176
Sqrt_39
	2.25
Mul_135
	0.0029296875
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
Assign_181
gradients/bert/pooler/strided_slice_grad/StridedSliceGrad
	12.0
gradients/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/sub
Square_47
	9.0
add_395
mul_424
Assign_297
clip_by_global_norm/mul_90
gradients/bert/encoder/layer_2/attention/self/query/MatMul_grad/MatMul
	15.75
Mul_991
	2.25
sub_177
Mul_426
global_norm/L2Loss_156
	0.000244140625
bert/encoder/layer_2/attention/self/query/kernel/adam_m/read
bert/encoder/layer_10/output/dense/bias/read
Sqrt_64
	0.01513671875
Mul_958
bert/encoder/layer_4/output/dense/kernel/adam_v/read
Mul_234
	0.0029296875
add_385
bert/encoder/layer_7/output/LayerNorm/beta/adam_v/read
bert/encoder/layer_4/intermediate/dense/bias/adam_v
Sqrt_142
	0.0029296875
Square_154
clip_by_global_norm/mul_176
mul_284
add_555
bert/encoder/layer_5/attention/self/query/kernel
Assign_136
add_3
bert/encoder/layer_2/attention/output/LayerNorm/beta
add_220
Mul_890
bert/encoder/layer_10/attention/self/value/kernel/adam_v/read
bert/encoder/layer_8/output/dropout/random_uniform/RandomUniform
	12.0
mul_171
gradients/bert/encoder/layer_6/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
bert/encoder/layer_4/attention/self/value/kernel/adam_v/read
bert/encoder/layer_4/attention/output/dropout/random_uniform/mul
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m
Assign_542
cls/predictions/output_bias/adam_m
bert/encoder/layer_11/attention/self/transpose_3
	12.0
Mul_645
	2.25
gradients/bert/encoder/layer_9/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
sub_69
mul_117
add_363
add_666
Mul_55
truediv_186
PolynomialDecay/truediv
add_275
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
Sqrt_72
	0.0029296875
bert/encoder/layer_5/output/dropout/random_uniform
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
gradients/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul
	12.0
clip_by_global_norm/mul_206
bert/encoder/layer_1/attention/self/dropout/Cast
	24.0
bert/encoder/layer_0/attention/self/key/kernel/adam_m/read
mul_499
	2.25
add_237
bert/encoder/layer_1/attention/self/query/bias/adam_v/read
bert/encoder/layer_4/attention/self/Reshape_2
add_281
Mul_94
	0.01171875
Mul_695
	0.01171875
mul_752
gradients/bert/encoder/layer_11/attention/self/key/MatMul_grad/MatMul_1
	2.25
add_317
gradients/bert/encoder/layer_7/attention/self/transpose_3_grad/transpose
	12.0
gradients/bert/encoder/layer_5/attention/output/dropout/mul_1_grad/Mul
	12.0
Mul_904
	2.25
sub_135
Mul_906
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
Mul_378
	2.25
add_248
global_norm/L2Loss_202
	0.000244140625
bert/encoder/layer_9/intermediate/dense/kernel/adam_m/read
Square_25
	2.25
Mul_146
	0.0029296875
gradients/bert/encoder/layer_2/intermediate/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_5/attention/self/key/bias
gradients/bert/encoder/layer_5/attention/self/Softmax_grad/mul_1
	24.0
Mul_269
	9.0
global_norm/L2Loss_34
	0.000244140625
clip_by_global_norm/mul_168
bert/encoder/layer_9/attention/self/Reshape_3
gradients/bert/encoder/layer_6/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_8/attention/self/query/kernel
Assign_16
bert/encoder/layer_1/attention/output/dense/bias/adam_m/read
bert/encoder/layer_9/attention/self/query/kernel/read
sub_47
bert/encoder/layer_9/output/dropout/Cast
	12.0
bert/encoder/layer_0/attention/self/value/bias/adam_v
clip_by_global_norm/mul_164
clip_by_global_norm/mul_142
Square_74
	0.0029296875
bert/encoder/layer_8/intermediate/dense/MatMul
	48.0
Assign_114
cls/predictions/transform/LayerNorm/gamma/adam_v
Mul_74
gradients/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv
Mul_847
	0.0029296875
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Reshape
Mul_641
	0.0029296875
bert/encoder/layer_9/output/dense/BiasAdd
Mul_685
	0.0029296875
bert/encoder/layer_2/intermediate/dense/mul_1
Mul_524
	0.01171875
global_norm/L2Loss_182
	0.000244140625
bert/encoder/layer_10/attention/output/dense/kernel/adam_v/read
bert/encoder/layer_1/attention/self/value/bias
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/mean_grad/truediv
add_656
gradients/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference_grad/Mul
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
Assign_377
bert/embeddings/ExpandDims
Mul_892
	2.25
bert/encoder/layer_7/attention/output/dropout/random_uniform
bert/encoder/layer_11/intermediate/dense/Pow
	48.0
bert/encoder/layer_11/attention/output/dropout/random_uniform/RandomUniform
	12.0
Assign_63
bert/encoder/layer_1/intermediate/dense/BiasAdd
clip_by_global_norm/mul_96
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v/read
gradients/AddN_62
bert/encoder/layer_8/output/LayerNorm/beta/read
gradients/bert/encoder/layer_10/output/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_8/attention/self/dropout/mul_1
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt
clip_by_global_norm/mul_16
Mul_60
	0.0029296875
cls/predictions/truediv
bert/encoder/layer_4/output/dropout/mul
	12.0
add_316
gradients/bert/encoder/layer_5/output/dropout/mul_grad/Mul
add_235
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub
Assign_77
bert/encoder/layer_8/output/dropout/GreaterEqual
	3.0
add_208
Sqrt_162
	0.0029296875
bert/encoder/layer_1/output/dense/kernel/read
add_118
Mul_18
	1.5
clip_by_global_norm/mul_10
Mul_287
	0.0029296875
add_549
Mul_998
bert/encoder/layer_1/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt
sub_37
global_norm/L2Loss_22
	0.000244140625
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2_grad/Reshape
mul_854
Assign_454
cls/predictions/transform/LayerNorm/moments/SquaredDifference
	1.875
gradients/bert/embeddings/dropout/mul_grad/Mul
add_45
Mul_620
	0.0029296875
bert/encoder/layer_10/attention/self/key/kernel/adam_v/read
bert/encoder/layer_9/output/add
Assign_134
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference
	12.0
add_130
Mul_330
Assign_426
bert/encoder/layer_6/attention/self/key/BiasAdd
add_219
add_566
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v/read
bert/encoder/layer_4/intermediate/dense/bias/adam_m
clip_by_global_norm/mul_84
Mul_65
	2.25
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Sum
	0.016357421875
Sqrt_160
	0.01171875
add_697
Mul_40
	0.0029296875
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
add_175
mul_316
	2.25
Assign_483
gradients/bert/encoder/layer_4/output/dense/MatMul_grad/MatMul
	48.0
Assign_119
mul_1026
add_269
Mul_613
	9.0
bert/encoder/layer_0/attention/self/query/kernel/adam_v
cls/predictions/Sum_2
	0.000244140625
Assign_118
bert/encoder/layer_3/output/LayerNorm/gamma/adam_m
clip_by_global_norm/mul_136
gradients/bert/encoder/layer_7/attention/self/transpose_1_grad/transpose
	12.0
Square_147
bert/encoder/layer_11/output/LayerNorm/beta/read
bert/encoder/layer_3/attention/self/key/kernel/adam_v/read
bert/encoder/layer_11/output/dense/bias
global_norm/L2Loss_186
	0.000244140625
bert/encoder/layer_4/attention/self/value/kernel
bert/encoder/layer_6/output/LayerNorm/beta/read
bert/encoder/layer_11/attention/self/query/bias/adam_m/read
mul_789
	9.0
bert/encoder/layer_9/output/dropout/mul_1
Mul_739
	0.0029296875
clip_by_global_norm/mul_194
gradients/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference_grad/Mul
truediv_105
gradients/bert/encoder/layer_11/intermediate/dense/mul_3_grad/Mul_1
	48.0
add_196
add_290
Assign_617
gradients/bert/encoder/layer_6/intermediate/dense/Pow_grad/mul
bert/encoder/layer_6/attention/output/dropout/random_uniform/RandomUniform
	12.0
global_norm/L2Loss_43
	0.000244140625
	0.01220703125
bert/encoder/layer_2/attention/self/transpose_3
	12.0
gradients/bert/encoder/layer_11/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/bert/encoder/layer_7/attention/self/query/MatMul_grad/MatMul
	12.0
add_243
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1
	12.0
gradients/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference_grad/mul_1
clip_by_global_norm/mul_48
bert/encoder/layer_11/attention/self/query/kernel/adam_v
global_norm/L2Loss_116
	0.000244140625
gradients/bert/encoder/layer_2/output/dense/MatMul_grad/MatMul
	48.0
bert/encoder/layer_7/attention/self/key/kernel/adam_v/read
bert/encoder/layer_3/attention/output/dropout/GreaterEqual
	3.0
bert/encoder/layer_11/attention/self/query/bias/adam_v/read
Sqrt_68
	0.0029296875
bert/encoder/layer_8/attention/self/dropout/Cast
	24.0
bert/encoder/layer_4/attention/self/query/kernel/adam_v
Mul_648
bert/encoder/layer_0/attention/self/dropout/GreaterEqual
	11.419921875
cls/seq_relationship/Mean
	0.000244140625
Mul_19
bert/encoder/layer_3/attention/output/dropout/random_uniform/RandomUniform
	12.0
Mul_165
Sqrt_166
	0.0029296875
add_462
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m/read
bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference
	12.0
bert/encoder/layer_8/attention/output/LayerNorm/gamma/read
add_691
gradients/bert/encoder/layer_10/attention/self/Softmax_grad/mul
Mul_215
	2.25
Assign_11
add_258
sub_132
Assign_450
bert/encoder/layer_9/intermediate/dense/bias/adam_v
Mul_32
	2.25
gradients/AddN_48
bert/encoder/layer_8/output/LayerNorm/gamma/read
bert/encoder/layer_11/attention/self/query/BiasAdd
add_58
bert/encoder/layer_5/output/dropout/Cast
	12.0
mul_9
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
Mul_742
	2.25
bert/encoder/layer_7/attention/self/dropout/GreaterEqual
	6.0
add_136
gradients/bert/encoder/layer_3/attention/self/Softmax_grad/mul
Mul_901
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
Mul_728
	0.0029296875
Assign_156
Cast/ReadVariableOp
bert/encoder/layer_7/attention/output/dense/kernel/adam_m/read
bert/encoder/layer_5/attention/self/key/bias/adam_v
bert/encoder/layer_7/attention/output/dense/kernel
bert/encoder/layer_9/attention/output/add
gradients/bert/encoder/layer_8/attention/self/Softmax_grad/sub
Mul_357
	9.0
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
Assign_355
Assign_505
Mul_830
	2.25
gradients/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul
	12.0
Mul_634
	2.25
gradients/bert/embeddings/LayerNorm/moments/variance_grad/truediv
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Reshape
bert/encoder/layer_0/intermediate/dense/bias/adam_m/read
bert/encoder/layer_8/output/dropout/random_uniform
bert/encoder/layer_6/output/LayerNorm/moments/variance
	0.015625
Mul_288
bert/encoder/layer_3/attention/self/add
sub_186
bert/encoder/layer_1/attention/self/query/MatMul
	12.0
Mul_278
add_15
add_254
sub_68
bert/encoder/layer_2/attention/self/query/kernel/adam_v
bert/encoder/layer_9/attention/self/value/bias
truediv_95
add_42
Square_173
	0.0029296875
bert/encoder/layer_0/attention/self/query/MatMul
	12.0
bert/encoder/layer_5/attention/self/transpose
	12.0
gradients/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_6/attention/self/dropout/mul_1
bert/encoder/layer_10/output/LayerNorm/beta/read
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
bert/encoder/layer_1/output/dropout/mul_1
Mul_308
bert/encoder/layer_8/attention/self/query/bias
bert/encoder/layer_6/output/dense/bias/adam_m
Assign_71
gradients/bert/encoder/layer_4/intermediate/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_11/output/dense/kernel/adam_v
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add
Sqrt_176
	0.0146484375
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_8/attention/output/dropout/mul
	12.0
Assign_407
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v
add_664
bert/encoder/layer_10/attention/self/transpose
	12.0
bert/encoder/layer_7/attention/output/LayerNorm/moments/mean
	0.015625
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
Mul_834
	0.0029296875
add_422
gradients/bert/encoder/layer_5/attention/self/value/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_8/output/LayerNorm/batchnorm/add
gradients/bert/encoder/layer_10/attention/self/transpose_grad/transpose
	15.75
bert/encoder/layer_0/output/dropout/random_uniform/mul
bert/encoder/layer_11/output/LayerNorm/beta/adam_m/read
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
add_340
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_4/intermediate/dense/kernel/read
gradients/AddN_90
global_norm/L2Loss_163
	0.000244140625
add_36
bert/encoder/layer_1/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
truediv_147
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m
mul_403
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/variance_grad/truediv
bert/encoder/layer_10/attention/self/value/bias/adam_m
gradients/bert/encoder/layer_10/intermediate/dense/MatMul_grad/MatMul_1
	12.0
mul_193
Assign_32
bert/encoder/layer_4/attention/output/dense/bias/adam_m
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v
gradients/bert/encoder/layer_5/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/bert/encoder/layer_2/intermediate/dense/mul_1_grad/Mul_1
bert/encoder/layer_1/attention/self/Softmax
	24.0
	24.0
bert/pooler/strided_slice/stack_2
add_512
sub_81
gradients/cls/predictions/transform/LayerNorm/moments/SquaredDifference_grad/mul_1
gradients/bert/encoder/layer_11/intermediate/dense/MatMul_grad/MatMul_1
	9.0
bert/encoder/layer_2/attention/output/dense/kernel/adam_v
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/mean_grad/truediv
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
clip_by_global_norm/mul_9
bert/encoder/layer_9/output/dense/bias/adam_m
Mul_787
	9.0
clip_by_global_norm/mul_45
Square_53
	2.25
gradients/bert/encoder/layer_2/output/LayerNorm/moments/variance_grad/Tile
	12.0
add_88
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
bert/encoder/layer_2/intermediate/dense/kernel
bert/encoder/layer_7/attention/self/key/kernel/adam_m
bert/encoder/layer_6/output/dense/bias/adam_v/read
bert/encoder/layer_1/intermediate/dense/bias
bert/encoder/layer_2/attention/output/dropout/mul_1
add_74
global_norm/L2Loss_65
	0.000244140625
	0.014892578125
Assign_597
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
Mul_174
	9.0
bert/encoder/layer_9/output/LayerNorm/gamma/read
cls/seq_relationship/Sum
	0.000244140625
clip_by_global_norm/mul_93
Square_57
	2.25
Mul_690
	9.0
bert/encoder/layer_3/attention/output/dense/bias/read
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
truediv_159
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
global_norm/L2Loss_4
	0.000244140625
truediv_52
sub_140
mul_252
bert/encoder/layer_10/output/dropout/mul_1
sub_157
Assign_253
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/mean_grad/Tile
	15.75
gradients/bert/encoder/layer_7/attention/output/dropout/mul_1_grad/Mul
	12.0
add_688
add_260
gradients/bert/encoder/layer_1/attention/self/Mul_grad/Mul
Mul_148
	0.0029296875
add_430
bert/encoder/layer_3/attention/self/query/kernel/adam_v
Square_54
	0.0029296875
Mul_401
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv
Mul_212
	0.0029296875
bert/encoder/layer_8/attention/self/value/kernel/adam_v
gradients/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1
	2.25
gradients/bert/pooler/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/bert/encoder/layer_11/intermediate/dense/Pow_grad/mul
add_569
add_573
bert/encoder/layer_1/attention/output/dropout/mul
	12.0
add_150
global_norm/L2Loss_97
	0.000244140625
	0.0087890625
bert/encoder/layer_2/attention/self/key/kernel/adam_v/read
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m/read
bert/encoder/layer_10/attention/output/dense/bias/adam_v
bert/encoder/layer_9/attention/self/query/kernel/adam_m
Square_71
	2.25
Mul_12
	0.005859375
Mul_464
	2.25
add_353
bert/encoder/layer_4/output/dense/kernel/adam_v
Mul_952
	0.01171875
ConstantFolding/PolynomialDecay/truediv_recip
Square_134
clip_by_global_norm/mul_138
ReadVariableOp
gradients/bert/encoder/layer_8/output/dropout/mul_grad/Mul
Mul_707
	0.0029296875
gradients/AddN_11
add_286
add_488
bert/encoder/layer_6/intermediate/dense/add
clip_by_global_norm/mul_34
global_norm/L2Loss_18
	0.000244140625
gradients/bert/encoder/layer_2/attention/self/Softmax_grad/sub
add_342
Assign_98
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
add_301
bert/encoder/layer_8/attention/self/query/MatMul
	12.0
bert/encoder/layer_6/intermediate/dense/mul_1
add_165
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
bert/encoder/layer_3/attention/self/value/bias/adam_v
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Mul_1
gradients/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_3/output/dropout/mul_1
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
bert/encoder/layer_1/attention/self/query/kernel
Sqrt_169
	2.25
bert/encoder/layer_11/attention/output/dropout/GreaterEqual
	3.0
Mul_344
	9.0
global_norm/L2Loss_54
	0.000244140625
cls/seq_relationship/one_hot
	0.000244140625
bert/encoder/layer_0/attention/self/value/kernel/read
gradients/bert/encoder/layer_5/attention/self/transpose_2_grad/transpose
	12.0
add_98
bert/encoder/layer_5/attention/output/dropout/random_uniform/mul
Sqrt_156
	0.0029296875
bert/encoder/layer_9/attention/self/query/kernel/adam_v
Mul_46
bert/encoder/layer_0/attention/self/dropout/mul
	24.0
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
add_82
Mul_987
clip_by_global_norm/mul_98
add_479
Mul_347
Assign_446
cls/seq_relationship/output_weights/adam_v
Assign_535
gradients/bert/encoder/layer_11/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_9/output/dense/kernel/adam_v
add_681
Sqrt_66
	0.0029296875
Mul_662
	0.0029296875
bert/encoder/layer_1/attention/self/value/kernel/adam_m/read
bert/encoder/layer_11/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
truediv_203
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1
	12.0
gradients/bert/encoder/layer_3/attention/output/dense/MatMul_grad/MatMul
	12.0
truediv_6
Sqrt_79
	9.0
gradients/bert/encoder/layer_10/attention/output/dense/MatMul_grad/MatMul_1
	2.25
Mul_175
bert/encoder/layer_5/attention/self/Reshape_1
gradients/bert/encoder/layer_4/attention/output/dense/MatMul_grad/MatMul
	12.0
Square_29
	0.0029296875
Mul_664
	0.0029296875
bert/encoder/layer_0/attention/self/value/bias/adam_m
Assign_152
Square_137
bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference
	12.0
bert/encoder/layer_1/attention/output/LayerNorm/moments/mean
	0.015625
clip_by_global_norm/mul_28
gradients/bert/encoder/layer_3/intermediate/dense/mul_2_grad/Mul_1
add_96
Mul_304
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m
gradients/bert/encoder/layer_11/attention/self/transpose_2_grad/transpose
	15.75
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul
	12.0
Mul_786
	9.0
add_686
truediv_173
sub_100
gradients/cls/predictions/transform/dense/Tanh_grad/TanhGrad
global_norm/L2Loss_31
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_4/attention/self/Softmax_grad/sub
bert/encoder/layer_11/attention/self/value/kernel/read
bert/encoder/layer_6/attention/output/dense/BiasAdd
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1
bert/encoder/layer_2/intermediate/dense/bias/adam_m
bert/encoder/layer_1/attention/self/query/bias/adam_m/read
mul_188
bert/encoder/layer_3/intermediate/dense/BiasAdd
sub_98
Mul_610
	0.01171875
Mul_335
bert/encoder/layer_7/attention/self/dropout/Cast
	45.0
Mul_852
	0.0029296875
gradients/bert/encoder/layer_4/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2
	12.0
global_norm/L2Loss_191
	0.000244140625
	0.0087890625
gradients/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/sub
bert/encoder/layer_4/output/LayerNorm/beta/adam_m
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Sum
	0.022705078125
bert/encoder/layer_8/attention/self/key/BiasAdd
Mul_700
	9.0
add_50
Assign_56
truediv_22
gradients/bert/encoder/layer_8/output/LayerNorm/moments/mean_grad/truediv
gradients/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul_1
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
gradients/bert/encoder/layer_5/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
add_170
add_357
bert/encoder/layer_7/intermediate/dense/kernel/read
add_101
bert/encoder/layer_3/attention/self/query/kernel/adam_m/read
gradients/cls/predictions/transform/LayerNorm/moments/SquaredDifference_grad/Mul
PolynomialDecay/Minimum/y
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
bert/encoder/layer_0/attention/self/key/BiasAdd
Mul_56
	2.25
add_288
Assign_13
bert/encoder/layer_8/intermediate/dense/mul_2
mul_370
gradients/AddN_6
bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference
	12.0
global_norm/L2Loss_172
	0.000244140625
sub_76
Assign_469
bert/encoder/layer_6/attention/output/dense/kernel
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
clip_by_global_norm/mul_107
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul
	12.0
truediv_141
gradients/cls/predictions/transform/dense/MatMul_grad/MatMul_1
	3.7548828125
Square_140
Assign_478
truediv_179
bert/encoder/layer_2/intermediate/dense/bias/adam_m/read
Mul_183
	9.0
cls/predictions/transform/LayerNorm/beta/adam_v/read
gradients/bert/encoder/layer_10/intermediate/dense/Pow_grad/mul_1
gradients/AddN_49
Mul_256
bert/encoder/layer_2/attention/self/transpose_1
	12.0
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/mean_grad/truediv
bert/encoder/layer_4/attention/self/query/bias/read
truediv_97
Mul_114
gradients/bert/encoder/layer_2/attention/self/value/MatMul_grad/MatMul_1
	2.25
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul
	12.0
add_44
bert/encoder/layer_5/attention/output/LayerNorm/beta/read
Mul_873
	9.0
add_56
bert/encoder/layer_8/attention/self/value/kernel/adam_m
Mul_1035
bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference
	12.0
truediv_185
Sqrt_87
	2.25
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add
gradients/bert/encoder/layer_7/intermediate/dense/mul_3_grad/Mul_1
	48.0
bert/encoder/layer_7/attention/self/Softmax
	24.0
	24.0
truediv_201
bert/encoder/layer_7/attention/self/query/bias/adam_m/read
bert/encoder/layer_6/intermediate/dense/mul_2
gradients/bert/encoder/layer_3/intermediate/dense/MatMul_grad/MatMul
	12.0
Square_104
bert/encoder/layer_10/attention/self/query/MatMul
	12.0
Assign_423
gradients/bert/encoder/layer_6/output/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m
gradients/bert/encoder/layer_8/intermediate/dense/mul_3_grad/Mul
bert/pooler/dense/kernel/read
Sqrt_37
	2.25
bert/encoder/layer_11/output/dropout/random_uniform/mul
bert/encoder/layer_11/output/dense/BiasAdd
gradients/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/embeddings/LayerNorm/batchnorm/mul_2
	12.0
bert/encoder/layer_0/output/LayerNorm/beta
bert/encoder/layer_4/attention/self/query/kernel/read
bert/encoder/layer_10/attention/self/key/BiasAdd
bert/encoder/layer_8/attention/output/dense/bias
bert/encoder/layer_6/attention/output/dropout/random_uniform/mul
gradients/bert/encoder/layer_2/output/dense/MatMul_grad/MatMul_1
	12.0
add_562
gradients/bert/encoder/layer_9/attention/output/dense/MatMul_grad/MatMul_1
	3.0
truediv_57
bert/encoder/layer_0/output/LayerNorm/beta/read
Mul_652
	0.0029296875
bert/encoder/layer_3/attention/self/Softmax
	24.0
	24.0
gradients/bert/encoder/layer_10/attention/self/Reshape_grad/Reshape
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
Sqrt_77
	0.0029296875
gradients/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul
	12.0
Square_56
	0.0029296875
Mul_812
	0.0029296875
add_652
sub_93
bert/encoder/layer_1/intermediate/dense/kernel/adam_v/read
bert/encoder/layer_1/attention/output/dense/BiasAdd
mul_338
truediv_146
Mul_856
	0.0029296875
Mul_559
	2.25
gradients/bert/encoder/layer_10/output/LayerNorm/moments/mean_grad/Tile
	15.75
bert/encoder/layer_11/attention/self/value/kernel/adam_v/read
Mul_674
	0.0029296875
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
Mul_1018
	0.0029296875
sub_77
sub_4
bert/encoder/layer_4/attention/self/query/bias/adam_v/read
mul_907
	2.25
Mul_851
	0.0029296875
bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference
	12.0
global_norm/L2Loss_180
	0.000244140625
sub_101
Square_106
bert/encoder/layer_8/attention/self/transpose_3
	12.0
Mul_530
bert/encoder/layer_5/output/dense/kernel/adam_v/read
add_187
bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1
clip_by_global_norm/mul_47
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt
Assign_303
bert/encoder/layer_1/output/dropout/mul
	12.0
add_644
bert/encoder/layer_2/intermediate/dense/kernel/adam_v
bert/encoder/layer_3/attention/output/dense/kernel
gradients/bert/embeddings/LayerNorm/moments/mean_grad/truediv
Assign_19
bert/pooler/Squeeze
truediv_61
truediv_151
bert/encoder/layer_7/attention/self/transpose_3
	12.0
add_134
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
global_norm/L2Loss_73
	0.000244140625
	0.0087890625
clip_by_global_norm/Const_1
bert/encoder/layer_5/attention/self/key/MatMul
	12.0
global_norm/L2Loss_19
	0.000244140625
Square_1
	0.005859375
bert/encoder/layer_9/output/dropout/GreaterEqual
	3.0
Assign_585
Assign_43
Assign_510
Assign_416
gradients/bert/encoder/layer_9/attention/self/Reshape_3_grad/Reshape
add_325
cls/predictions/transform/LayerNorm/gamma/adam_v/read
bert/encoder/layer_1/output/dropout/Cast
	12.0
gradients/AddN_24
bert/encoder/layer_3/attention/self/query/bias/adam_m
gradients/bert/encoder/layer_10/intermediate/dense/mul_3_grad/Mul_1
	48.0
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.0224609375
Assign_406
global_norm/L2Loss_81
	0.000244140625
	0.0087890625
gradients/AddN_39
Assign_587
bert/encoder/layer_11/attention/self/dropout/random_uniform
add_465
add_570
Assign_281
Mul_398
	2.25
gradients/bert/encoder/layer_10/attention/self/dropout/mul_1_grad/Mul
bert/encoder/layer_10/attention/self/key/kernel
cls/predictions/transform/dense/MatMul
	1.875
add_155
mul_91
truediv_103
bert/encoder/layer_2/attention/self/transpose_2
	12.0
bert/encoder/layer_8/attention/self/value/bias/adam_m
add_497
Assign_476
gradients/AddN_7
Mul_738
	0.0029296875
bert/encoder/layer_3/attention/self/key/bias
Mul_83
	0.0029296875
Mul_51
	0.0029296875
Square_163
edge_690_IteratorGetNext@@MemcpyHtoD
add_366
Mul_776
	9.0
mul_305
	2.25
sub_201
Assign_493
global_norm/L2Loss_102
	0.000244140625
bert/encoder/layer_0/attention/output/add
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
gradients/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape
truediv
bert/encoder/layer_0/output/LayerNorm/gamma/adam_m/read
Assign_568
Sqrt_53
	2.25
bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2
	12.0
add_71
Mul_545
	0.0029296875
Assign_223
bert/encoder/layer_1/attention/self/value/kernel
add_338
Mul_468
	0.0029296875
Mul_985
clip_by_global_norm/mul_76
bert/encoder/layer_10/attention/output/dense/BiasAdd
bert/encoder/layer_7/output/LayerNorm/beta/read
gradients/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
global_norm/L2Loss_178
	0.000244140625
mul_494
add_675
add_151
gradients/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
gradients/AddN_38
bert/encoder/layer_11/output/dropout/random_uniform
Mul_340
bert/encoder/layer_2/attention/output/dense/kernel/adam_m
bert/encoder/layer_3/output/dense/kernel/adam_m/read
Mul_615
	9.0
gradients/bert/encoder/layer_6/attention/self/query/MatMul_grad/MatMul
	12.0
Assign_294
bert/encoder/layer_2/attention/self/dropout/mul_1
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_2_grad/Sum
	0.00244140625
bert/encoder/layer_4/attention/output/dropout/Cast
	12.0
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.017333984375
Mul_556
	0.0029296875
Mul_716
	0.0029296875
bert/encoder/layer_10/attention/self/query/kernel
Square_180
	0.0029296875
Assign_385
add_534
bert/encoder/layer_10/output/dropout/random_uniform/RandomUniform
	12.0
bert/encoder/layer_10/intermediate/dense/mul_2
bert/encoder/layer_10/attention/self/key/bias/adam_m
sub_204
Mul_54
	2.25
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_6/attention/self/query/kernel/adam_v/read
Assign_86
mul_85
gradients/bert/encoder/layer_6/attention/self/key/MatMul_grad/MatMul
	12.0
gradients/bert/encoder/layer_4/intermediate/dense/Pow_grad/mul
bert/encoder/layer_11/attention/self/key/bias/adam_m/read
bert/encoder/layer_4/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_11/attention/self/query/bias/read
bert/encoder/layer_2/attention/self/Mul
mul_134
Mul_814
	0.0029296875
Mul_376
	2.25
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2_grad/Mul
add_119
bert/encoder/layer_10/attention/self/value/bias
add_191
Mul_688
	9.0
mul_591
Square_13
	0.0029296875
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add
sub_39
gradients/bert/encoder/layer_7/intermediate/dense/Pow_grad/mul_1
Assign_421
gradients/bert/encoder/layer_8/attention/output/dropout/mul_grad/Mul
global_norm/L2Loss_40
	0.000244140625
bert/encoder/layer_11/attention/self/value/BiasAdd
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1
	12.0
Sqrt_121
	2.25
gradients/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul_1
Assign_177
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2_grad/Mul
bert/encoder/layer_6/attention/output/dense/bias/adam_m/read
Mul_576
	0.0029296875
Assign_267
gradients/bert/encoder/layer_3/output/dropout/mul_grad/Mul
Square_5
	2.25
Assign_38
add_356
gradients/bert/encoder/layer_6/attention/self/Softmax_grad/mul_1
	24.0
mul_1047
	9.0
Sqrt_81
	9.0
bert/encoder/layer_9/attention/self/dropout/random_uniform/mul
Square_132
gradients/bert/encoder/layer_7/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
Mul_1045
	9.0
global_norm/L2Loss_106
	0.000244140625
gradients/bert/encoder/layer_0/attention/self/transpose_2_grad/transpose
	12.0
add_140
bert/encoder/layer_7/attention/self/Reshape_3
add_159
add_538
global_norm/L2Loss_130
	0.000244140625
bert/encoder/layer_11/attention/self/Softmax
	24.0
	24.0
bert/embeddings/ArithmeticOptimizer/AddOpsRewrite_add_1
Mul_496
bert/encoder/layer_2/attention/output/dense/MatMul
	12.0
Square_129
truediv_15
bert/encoder/layer_7/attention/self/query/bias/read
bert/encoder/layer_4/attention/output/dense/bias
bert/encoder/layer_7/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
truediv_50
add_293
add_213
bert/encoder/layer_9/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1
sub_38
bert/encoder/layer_3/output/dense/bias/adam_m
gradients/bert/encoder/layer_10/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/cls/predictions/MatMul_grad/MatMul_1
	89.419921875
Mul_498
Mul_405
bert/encoder/layer_11/output/dense/MatMul
	12.0
Assign_259
add_215
mul_935
global_norm/L2Loss_157
	0.000244140625
group_deps_1
add_350
Mul_984
	0.0029296875
gradients/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
add_302
mul_704
Mul_194
	0.0029296875
bert/pooler/strided_slice/stack
mul_365
bert/encoder/layer_6/attention/self/transpose
	12.0
Assign_188
sub_70
add_265
add_466
Assign_202
gradients/AddN_51
gradients/bert/encoder/layer_10/attention/self/Softmax_grad/sub
gradients/bert/encoder/layer_7/intermediate/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_2/output/dense/bias/adam_m/read
Mul_764
	0.0029296875
bert/encoder/layer_4/output/dense/bias/adam_m
bert/encoder/layer_4/attention/self/value/BiasAdd
clip_by_global_norm/mul_71
Assign_560
bert/encoder/layer_10/output/LayerNorm/moments/variance
	0.015625
gradients/bert/encoder/layer_3/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.014892578125
sub_193
Mul_222
global_norm/L2Loss_74
	0.000244140625
gradients/bert/encoder/layer_10/attention/self/key/MatMul_grad/MatMul_1
	2.25
sub_52
gradients/bert/encoder/layer_0/attention/self/transpose_1_grad/transpose
	12.0
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
mul_972
sub_5
Assign_68
gradients/bert/encoder/layer_5/attention/output/dense/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_7/output/dense/bias/adam_m/read
gradients/bert/encoder/layer_1/attention/self/Softmax_grad/sub
mul_580
sub_30
Assign_370
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
bert/encoder/layer_11/attention/self/query/kernel/adam_m
Mul_1007
	0.0029296875
bert/encoder/layer_1/output/LayerNorm/beta/read
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
bert/encoder/layer_1/attention/self/value/kernel/adam_m
add_662
sub_33
Assign_27
gradients/bert/encoder/layer_4/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.00439453125
bert/encoder/layer_5/intermediate/dense/bias
gradients/bert/encoder/layer_2/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.01171875
bert/encoder/layer_10/attention/self/value/kernel
bert/encoder/layer_7/attention/output/LayerNorm/gamma/read
Square_182
	0.0029296875
Mul_809
Mul_136
bert/encoder/layer_0/intermediate/dense/mul/x
gradients/cls/predictions/LogSoftmax_grad/mul
bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference
	12.0
Square_111
Mul_411
	2.25
cls/seq_relationship/Neg
Assign_59
gradients/bert/encoder/layer_0/attention/self/Softmax_grad/mul_1
	24.0
Assign_47
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	15.169921875
gradients/bert/encoder/layer_10/attention/self/transpose_1_grad/transpose
	12.0
bert/encoder/layer_10/attention/self/dropout/Cast
	24.0
bert/encoder/layer_4/attention/output/LayerNorm/beta/read
Mul_762
bert/encoder/layer_7/output/dropout/mul_1
bert/encoder/layer_6/attention/self/dropout/random_uniform/mul
bert/encoder/layer_2/attention/self/key/BiasAdd
bert/encoder/layer_4/attention/self/key/MatMul
	12.0
Mul_592
	0.0029296875
gradients/bert/embeddings/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_9/intermediate/dense/Pow
	48.0
bert/encoder/layer_2/attention/self/query/kernel/read
Mul_1034
	9.0
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
gradients/bert/encoder/layer_5/intermediate/dense/Pow_grad/Pow
	48.0
bert/encoder/layer_7/intermediate/dense/bias
bert/encoder/layer_7/attention/self/key/bias/adam_m
bert/encoder/layer_10/attention/self/query/kernel/adam_m/read
Mul_377
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
mul_746
	2.25
Mul_799
gradients/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1
	12.0
add_448
bert/encoder/layer_1/output/LayerNorm/moments/variance
	0.015625
gradients/bert/encoder/layer_11/attention/self/transpose_grad/transpose
	12.0
Mul_667
	2.25
bert/encoder/layer_3/attention/self/value/kernel
bert/encoder/layer_3/output/dense/kernel/adam_v
truediv_20
Square_35
	0.0029296875
bert/encoder/layer_2/attention/self/key/MatMul
	12.0
bert/encoder/layer_5/intermediate/dense/Tanh
Mul_571
	2.25
Sqrt_26
	0.0029296875
sub_21
Mul_119
bert/encoder/layer_4/output/dropout/GreaterEqual
	3.0
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul_1
bert/encoder/layer_8/output/dense/kernel
Sqrt_86
	0.0029296875
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add
truediv_48
Mul_518
	9.0
bert/encoder/layer_5/output/dense/bias
Assign_418
mul_618
sub_89
global_norm/L2Loss_200
	0.000244140625
clip_by_global_norm/mul_104
Assign_485
clip_by_global_norm/mul_70
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
bert/encoder/layer_7/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_1/attention/self/key/bias/adam_m/read
bert/encoder/layer_4/intermediate/dense/kernel/adam_m/read
mul_505
mul_300
Assign_480
global_norm/L2Loss_47
	0.000244140625
	0.0087890625
Mul_1101
	0.00732421875
bert/encoder/layer_4/attention/self/dropout/mul_1
gradients/cls/predictions/transform/LayerNorm/moments/mean_grad/Tile
	1.875
bert/encoder/layer_9/output/LayerNorm/beta/adam_v
add_440
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
bert/encoder/layer_4/attention/output/dense/bias/read
Mul_879
	0.0029296875
bert/encoder/layer_1/output/dense/kernel/adam_m/read
Mul_658
	2.25
sub_176
_SOURCE
Mul_323
	2.25
Assign_333
gradients/bert/encoder/layer_11/attention/output/dropout/mul_grad/Mul
global_norm/L2Loss_46
	0.000244140625
Mul_932
Mul_480
bert/encoder/layer_11/attention/self/value/kernel/adam_v
Sqrt_174
	0.0029296875
Mul_1038
	0.01171875
bert/encoder/layer_8/attention/self/value/bias/adam_v
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	15.169921875
Sqrt_8
	0.0029296875
bert/encoder/layer_0/intermediate/dense/Tanh
mul_75
clip_by_global_norm/mul_118
bert/encoder/layer_0/attention/self/key/kernel/read
Mul_565
	0.0029296875
add_513
Mul_659
bert/encoder/layer_9/output/LayerNorm/gamma
Mul_1084
bert/encoder/layer_3/output/dense/BiasAdd
bert/encoder/layer_9/attention/output/dropout/GreaterEqual
	3.0
bert/encoder/layer_3/output/dense/kernel
Mul_927
	2.25
gradients/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape
bert/encoder/layer_10/output/LayerNorm/beta
bert/encoder/layer_7/attention/output/add
Mul_944
bert/encoder/layer_10/output/dense/bias/adam_m/read
bert/encoder/layer_8/attention/self/transpose
	12.0
clip_by_global_norm/mul_153
gradients/AddN_81
Assign_148
gradients/bert/encoder/layer_2/attention/self/Softmax_grad/mul
bert/encoder/layer_7/intermediate/dense/mul_2
bert/encoder/layer_8/attention/self/key/bias/adam_v/read
bert/encoder/layer_6/attention/output/dense/bias/adam_v
global_norm/L2Loss_111
	0.000244140625
	0.0087890625
Assign_295
bert/encoder/layer_6/attention/self/query/bias/read
sub_9
Mul_513
	0.0029296875
add_489
gradients/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul
	12.0
sub_164
Sqrt_31
	9.0
gradients/bert/encoder/layer_11/attention/self/transpose_1_grad/transpose
	12.0
gradients/AddN_60
Sqrt_25
	2.25
gradients/AddN_76
Assign_394
Mul_1012
	2.25
gradients/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul
edge_13_bert/embeddings/assert_less_equal/All@@MemcpyDtoH
add_314
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
gradients/bert/encoder/layer_10/intermediate/dense/mul_1_grad/Mul_1
bert/encoder/layer_1/output/LayerNorm/gamma/adam_m
truediv_37
bert/encoder/layer_6/intermediate/dense/kernel/adam_m
Sqrt_110
	0.0029296875
bert/encoder/layer_11/attention/self/key/kernel/adam_m
Mul_39
bert/encoder/layer_9/attention/self/value/kernel/adam_v/read
global_norm/L2Loss_16
	0.000244140625
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Sum
	0.00244140625
bert/encoder/layer_7/output/dropout/random_uniform/RandomUniform
	12.0
gradients/bert/encoder/layer_3/intermediate/dense/Tanh_grad/TanhGrad
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
Square_194
bert/encoder/layer_1/output/dropout/random_uniform/mul
add_670
bert/encoder/layer_10/output/dense/kernel/adam_v/read
Assign_411
bert/encoder/layer_2/attention/self/key/bias/adam_v
Assign_105
global_norm/L2Loss_77
	0.000244140625
Square_96
add_612
truediv_124
gradients/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/scalar
bert/encoder/layer_1/attention/self/query/kernel/adam_m/read
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
truediv_87
gradients/bert/encoder/layer_8/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
Square_77
	0.0029296875
sub_178
Mul_312
	2.25
global_norm/L2Loss_121
	0.000244140625
	0.0087890625
Mul_587
	0.0029296875
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
mul_2
truediv_51
gradients/cls/predictions/transform/LayerNorm/moments/SquaredDifference_grad/scalar
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
bert/encoder/layer_2/attention/self/dropout/random_uniform/mul
gradients/bert/encoder/layer_9/attention/self/transpose_2_grad/transpose
	12.0
clip_by_global_norm/mul_174
add_167
bert/encoder/layer_10/intermediate/dense/add
bert/encoder/layer_9/attention/self/value/MatMul
	12.0
Assign_127
bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1
Assign_185
add_592
Mul_577
	0.0029296875
bert/encoder/layer_1/attention/output/dropout/random_uniform/RandomUniform
	12.0
Mul_915
truediv_7
bert/encoder/layer_8/attention/self/key/kernel/adam_m
Square_142
Sqrt_163
	0.0029296875
gradients/bert/encoder/layer_3/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
add_650
bert/encoder/layer_4/intermediate/dense/mul
Mul_544
	0.0029296875
gradients/bert/encoder/layer_6/output/dense/MatMul_grad/MatMul
	48.0
Assign_26
Sqrt_92
	0.0029296875
Assign_8
clip_by_global_norm/mul_65
Assign_111
bert/encoder/layer_10/attention/output/dropout/Cast
	12.0
Mul_797
	0.0029296875
add_272
Assign_88
Sqrt_114
	0.0029296875
gradients/bert/encoder/layer_4/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/bert/encoder/layer_3/attention/self/value/MatMul_grad/MatMul
	12.0
global_step/cond/Identity
mul_575
bert/embeddings/assert_less_equal/All
Sqrt_141
	0.0029296875
Mul_793
	0.0029296875
bert/encoder/layer_10/intermediate/dense/kernel
add_224
add_542
bert/encoder/layer_2/output/dropout/GreaterEqual
	3.0
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
add_298
bert/encoder/layer_8/attention/output/LayerNorm/moments/mean
	0.015625
bert/encoder/layer_0/attention/output/dense/bias/adam_m
bert/encoder/layer_1/attention/output/LayerNorm/gamma/read
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1
truediv_106
bert/embeddings/Slice
global_norm/L2Loss_115
	0.000244140625
mul_844
global_norm/L2Loss_167
	0.000244140625
	0.0087890625
truediv_85
clip_by_global_norm/mul_192
bert/encoder/layer_10/attention/self/key/kernel/adam_v
gradients/bert/encoder/layer_3/output/LayerNorm/moments/variance_grad/Tile
	12.0
bert/encoder/layer_7/attention/self/query/bias/adam_m
gradients/bert/encoder/layer_11/intermediate/dense/mul_2_grad/Mul_1
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/variance_grad/truediv
bert/encoder/layer_2/intermediate/dense/Pow
	48.0
bert/encoder/layer_10/output/LayerNorm/beta/adam_m/read
Assign_169
sub_162
add_207
Assign_154
truediv_26
bert/encoder/layer_11/attention/self/value/kernel/adam_m/read
Mul_507
	0.0029296875
mul_1111
bert/encoder/layer_7/attention/self/dropout/random_uniform/mul
Assign_70
sub_200
bert/encoder/layer_8/attention/self/key/kernel/adam_v
mul_747
bert/encoder/layer_10/intermediate/dense/bias/adam_m
bert/encoder/layer_4/attention/self/key/bias/adam_m
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
gradients/bert/pooler/Squeeze_grad/Reshape
gradients/bert/encoder/layer_10/intermediate/dense/mul_2_grad/Mul_1
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
bert/encoder/layer_5/attention/output/dropout/mul
	12.0
bert/encoder/layer_4/attention/output/dense/kernel/adam_v/read
sub_105
gradients/bert/encoder/layer_10/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1
Assign_566
bert/encoder/layer_6/attention/output/dropout/Cast
	12.0
bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference
	12.0
bert/encoder/layer_3/attention/self/dropout/random_uniform
Sqrt_84
	0.0029296875
sub_24
clip_by_global_norm/mul_203
bert/encoder/layer_11/intermediate/dense/bias/read
bert/encoder/layer_9/attention/self/value/kernel/adam_m/read
add_67
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub
bert/encoder/layer_6/attention/self/key/bias/adam_v
mul_466
	2.25
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Reshape
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
bert/encoder/layer_3/output/dense/kernel/read
mul_531
	9.0
gradients/bert/encoder/Reshape_13_grad/Reshape
bert/encoder/layer_8/attention/self/value/kernel/adam_v/read
gradients/bert/encoder/layer_7/attention/output/dense/MatMul_grad/MatMul_1
	2.25
Assign_235
add_307
bert/encoder/layer_6/intermediate/dense/Tanh
Sqrt_181
	2.25
Assign_468
bert/encoder/layer_0/intermediate/dense/kernel
Mul_486
	2.25
bert/encoder/layer_8/attention/self/query/kernel/adam_m/read
bert/encoder/layer_7/output/LayerNorm/moments/variance
	0.015625
Assign_125
Assign_266
mul_993
	2.25
global_norm/L2Loss_2
	0.000244140625
	0.009765625
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_2_grad/Mul
Assign_133
Square_82
	0.0029296875
gradients/cls/predictions/Sum_grad/Reshape/shape
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
sub_190
add_537
Mul_538
	0.0029296875
gradients/bert/encoder/layer_8/intermediate/dense/MatMul_grad/MatMul
	12.0
Sqrt_71
	2.25
gradients/bert/encoder/layer_2/output/dropout/mul_1_grad/Mul
	12.0
Assign_201
truediv_172
Sqrt_90
	0.0029296875
bert/encoder/layer_3/attention/self/value/bias/adam_m/read
gradients/bert/encoder/layer_11/intermediate/dense/Pow_grad/mul_1
gradients/cls/predictions/transform/dense/mul_3_grad/Mul_1
	1.875
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
global_norm/L2Loss_162
	0.000244140625
mul_36
	2.25
add_620
global_norm/L2Loss_29
	0.000244140625
cls/seq_relationship/output_bias/adam_v
Mul_723
bert/encoder/layer_11/output/dense/bias/adam_v/read
bert/encoder/layer_0/output/LayerNorm/batchnorm/add
sub_36
bert/encoder/layer_7/attention/output/dense/bias/adam_m
Sqrt_143
	9.0
gradients/bert/encoder/layer_8/attention/self/transpose_1_grad/transpose
	12.0
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/variance_grad/truediv
bert/encoder/layer_11/attention/output/dense/bias/adam_m
bert/encoder/layer_6/attention/output/LayerNorm/gamma/read
bert/encoder/layer_3/intermediate/dense/bias
mul_849
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
cls/predictions/one_hot/depth
Assign_300
gradients/bert/encoder/layer_3/intermediate/dense/Pow_grad/mul_1
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m/read
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2
	12.0
bert/encoder/layer_8/attention/self/query/kernel/adam_v
add_287
add_576
clip_by_global_norm/mul_43
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Neg
	15.75
bert/encoder/layer_9/intermediate/dense/bias/adam_v/read
Mul_427
	0.0029296875
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m
bert/encoder/layer_10/attention/output/dense/bias
bert/embeddings/dropout/random_uniform/RandomUniform
	12.0
Square
	89.419921875
bert/encoder/layer_11/intermediate/dense/bias/adam_m
Assign_197
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_8/attention/self/value/kernel/adam_m/read
mul_231
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
bert/encoder/layer_1/attention/self/value/kernel/read
gradients/bert/encoder/layer_2/attention/self/Reshape_grad/Reshape
Sqrt_42
	0.0029296875
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
Mul_749
	0.0029296875
Mul_866
	0.01171875
bert/encoder/layer_7/attention/self/key/bias
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Mul_1
Assign_305
bert/encoder/layer_9/attention/self/transpose_1
	12.0
gradients/bert/encoder/layer_9/intermediate/dense/MatMul_grad/MatMul_1
	12.0
gradients/bert/encoder/layer_8/attention/self/value/MatMul_grad/MatMul
	12.0
gradients/bert/encoder/layer_0/attention/output/dropout/mul_1_grad/Mul
	12.0
gradients/AddN_57
gradients/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul
	15.75
truediv_112
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2_grad/Mul
gradients/bert/encoder/layer_3/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
Mul_509
Assign_84
global_norm/L2Loss_37
	0.000244140625
	0.0087890625
truediv_45
Square_6
	0.0029296875
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt
bert/embeddings/one_hot
	0.03125
Assign_45
bert/encoder/layer_6/output/dense/MatMul
	12.0
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Sum
	0.02783203125
bert/encoder/layer_9/attention/output/dropout/mul
	12.0
Sqrt_1
	0.005859375
Square_145
clip_by_global_norm/mul_4
gradients/bert/encoder/layer_10/output/LayerNorm/moments/variance_grad/Tile
	12.0
bert/embeddings/token_type_embeddings/adam_v
cls/predictions/transform/dense/kernel/adam_m
Mul_416
Mul_668
	2.25
bert/encoder/layer_6/output/dropout/random_uniform/RandomUniform
	12.0
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_2_grad/Reshape
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
Mul_794
gradients/bert/encoder/layer_4/intermediate/dense/Tanh_grad/TanhGrad
bert/encoder/layer_9/output/LayerNorm/moments/variance
	0.015625
bert/encoder/layer_8/output/dense/bias/adam_v/read
bert/encoder/layer_7/intermediate/dense/bias/adam_v
bert/encoder/layer_9/attention/output/LayerNorm/gamma/read
gradients/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference_grad/mul_1
bert/encoder/layer_9/output/dense/bias/adam_v/read
Square_195
gradients/AddN_87
bert/encoder/layer_5/attention/self/key/bias/read
bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2
	12.0
Mul_116
gradients/bert/encoder/layer_4/intermediate/dense/Pow_grad/Pow
	48.0
add_557
bert/encoder/layer_5/intermediate/dense/mul_1
gradients/bert/encoder/layer_10/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
gradients/AddN
gradients/bert/encoder/layer_11/attention/self/dropout/mul_1_grad/Mul
add_217
bert/encoder/layer_1/output/dense/MatMul
	12.0
mul_1031
bert/encoder/layer_9/attention/output/LayerNorm/beta
bert/encoder/layer_1/attention/self/key/kernel/adam_v/read
gradients/bert/encoder/layer_4/attention/output/dropout/mul_grad/Mul
bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1
	12.0
bert/encoder/layer_11/attention/self/value/kernel
gradients/bert/encoder/layer_11/attention/output/dense/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_3/intermediate/dense/bias/adam_m/read
gradients/bert/encoder/layer_7/attention/self/query/MatMul_grad/MatMul_1
	2.25
Square_186
add_643
Mul_228
	2.25
bert/encoder/layer_7/output/dense/kernel/adam_m
Mul_457
	0.0029296875
mul_552/x
global_norm/L2Loss_50
	0.000244140625
clip_by_global_norm/mul_108
mul_671
	2.25
bert/encoder/layer_11/attention/self/key/kernel/read
Mul_785
	9.0
clip_by_global_norm/mul_193
bert/encoder/layer_2/attention/output/LayerNorm/gamma/read
Mul_525
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
bert/encoder/layer_9/attention/self/value/kernel/read
cls/predictions/transform/dense/kernel
Mul_430
	9.0
add_494
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
bert/encoder/layer_10/output/dense/bias/adam_v/read
truediv_90
Assign_193
gradients/bert/encoder/layer_2/attention/self/transpose_1_grad/transpose
	12.0
Mul_157
	0.0029296875
gradients/bert/encoder/layer_5/output/LayerNorm/moments/mean_grad/Tile
	12.0
add_427
gradients/bert/encoder/layer_5/attention/self/Reshape_3_grad/Reshape
bert/encoder/layer_10/output/dense/bias/adam_v
bert/encoder/layer_0/intermediate/dense/add_1
	48.0
Assign_161
gradients/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Tile
	12.0
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
add_450
bert/encoder/layer_8/attention/output/dropout/random_uniform/mul
global_norm/L2Loss_171
	0.000244140625
	0.013916015625
bert/encoder/layer_0/output/dropout/random_uniform
clip_by_global_norm/mul_60
bert/encoder/layer_11/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_10/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_3/output/LayerNorm/moments/variance
	0.015625
bert/encoder/layer_11/intermediate/dense/mul_2
bert/encoder/layer_11/attention/self/value/bias/adam_m
bert/encoder/layer_2/intermediate/dense/add_1
	48.0
Sqrt_83
	0.0029296875
clip_by_global_norm/mul_195
add_277
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
bert/encoder/layer_10/intermediate/dense/Pow
	48.0
Mul_718
Mul_453
gradients/bert/encoder/layer_10/attention/self/Reshape_3_grad/Reshape
Sqrt_75
	2.25
Assign_227
bert/encoder/layer_5/attention/self/Mul
bert/encoder/layer_2/output/dense/bias/adam_v/read
Mul_780
	0.01171875
Assign_210
bert/embeddings/LayerNorm/gamma/adam_v/read
clip_by_global_norm/mul_39
bert/encoder/layer_4/output/dense/bias/read
bert/encoder/layer_11/output/dropout/mul_1
bert/encoder/layer_8/attention/output/dense/kernel/read
Mul_61
bert/encoder/layer_11/output/dense/bias/read
bert/encoder/layer_2/intermediate/dense/bias/adam_v/read
Sqrt_173
	0.0029296875
global_norm/L2Loss_27
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
Square_78
	0.0029296875
bert/encoder/layer_1/output/dense/kernel
bert/encoder/layer_6/output/LayerNorm/gamma/adam_v/read
bert/encoder/layer_2/attention/self/key/kernel/adam_m/read
Mul_490
	0.0029296875
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
Assign_31
gradients/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference_grad/sub
bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt
PolynomialDecay/sub
Assign_345
bert/encoder/layer_2/attention/output/dense/bias/adam_v/read
Square_48
	0.01171875
bert/encoder/layer_8/output/dropout/mul_1
add_178
Assign_228
Mul_1040
	0.01171875
bert/encoder/layer_3/output/LayerNorm/beta
gradients/cls/predictions/transform/dense/mul_grad/Mul_1
gradients/bert/encoder/layer_5/output/LayerNorm/moments/variance_grad/Tile
	12.0
gradients/bert/encoder/layer_8/intermediate/dense/mul_3_grad/Mul_1
	48.0
Mul_1046
Mul_275
	0.0029296875
gradients/bert/encoder/layer_9/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_1/attention/self/value/bias/adam_m
Mul_711
	0.0029296875
gradients/bert/encoder/layer_4/attention/self/Softmax_grad/mul_1
	24.0
bert/encoder/layer_0/attention/self/query/bias/read
gradients/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
Assign_172
gradients/bert/encoder/layer_7/attention/self/Reshape_grad/Reshape
Mul_204
	2.25
Square_99
	0.00439453125
bert/encoder/layer_0/output/LayerNorm/beta/adam_m
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v/read
add_349
clip_by_global_norm/mul_61
gradients/cls/predictions/transform/dense/MatMul_grad/MatMul
	1.875
bert/encoder/layer_6/output/dense/bias/read
add_641
gradients/bert/encoder/layer_2/attention/self/key/MatMul_grad/MatMul_1
	2.25
Sqrt_154
	0.0029296875
gradients/bert/encoder/layer_8/attention/self/MatMul_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
global_norm/L2Loss_189
	0.000244140625
bert/encoder/layer_0/output/dense/bias/adam_v/read
GatherV2
	2.1875
Mul_1008
	0.0029296875
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Reshape
Mul_957
	9.0
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/mean_grad/truediv
global_norm/L2Loss_187
	0.000244140625
	0.0126953125
global_norm/L2Loss_61
	0.000244140625
bert/encoder/layer_11/output/LayerNorm/gamma/adam_v/read
Assign_543
bert/encoder/layer_1/attention/self/query/bias/read
bert/encoder/layer_11/attention/self/key/bias/adam_m
Mul_1014
gradients/bert/encoder/layer_2/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_1/attention/self/Softmax_grad/Sum
	0.1875
Mul_227
Mul_384
	0.0029296875
bert/encoder/layer_7/output/dropout/random_uniform
Square_203
Mul_324
Sqrt_140
	0.0029296875
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference
	12.0
bert/encoder/layer_10/attention/self/query/bias/adam_m
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub
bert/encoder/layer_6/attention/self/query/bias/adam_m
Mul_131
	2.25
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v
bert/encoder/layer_10/output/dense/kernel/adam_v
gradients/bert/encoder/layer_11/attention/self/Reshape_2_grad/Reshape
sub_107
Assign_591
bert/encoder/layer_7/output/LayerNorm/beta/adam_m
bert/encoder/layer_0/output/dense/bias/read
bert/encoder/layer_4/attention/self/value/bias/adam_v
Mul_50
truediv_184
cls/predictions/transform/dense/kernel/read
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
bert/encoder/layer_5/intermediate/dense/bias/adam_m/read
Sqrt_130
	0.0029296875
Mul_325
	2.25
gradients/bert/encoder/layer_8/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_4/intermediate/dense/mul_3_grad/Mul
mul_381
gradients/bert/encoder/layer_1/attention/self/Softmax_grad/mul_1
	24.0
Mul_233
bert/encoder/layer_0/output/dense/bias/adam_m/read
add_615
add_262
add_309
add_424
gradients/bert/encoder/layer_5/intermediate/dense/mul_3_grad/Mul
bert/encoder/layer_11/output/LayerNorm/beta/adam_v/read
bert/encoder/layer_5/attention/self/query/bias/adam_m
bert/encoder/layer_6/intermediate/dense/BiasAdd
gradients/bert/embeddings/LayerNorm/moments/variance_grad/Tile/multiples
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v
bert/encoder/layer_0/output/dense/kernel/read
global_norm/L2Loss_66
	0.000244140625
Sqrt_202
	0.0029296875
Sqrt_106
	0.0029296875
Assign_327
clip_by_global_norm/mul_187
Mul_244
Mul_971
Assign_85
gradients/bert/encoder/layer_6/attention/self/value/MatMul_grad/MatMul
	12.0
bert/pooler/dense/bias/adam_v
bert/encoder/layer_3/attention/output/dropout/random_uniform/mul
gradients/bert/encoder/layer_5/intermediate/dense/Pow_grad/mul
bert/encoder/layer_7/intermediate/dense/mul
truediv_69
add_679
gradients/AddN_72
bert/encoder/layer_1/intermediate/dense/MatMul
	48.0
bert/encoder/layer_4/intermediate/dense/kernel/adam_m
Mul_1057
bert/encoder/layer_1/attention/self/dropout/random_uniform
bert/encoder/layer_3/output/LayerNorm/gamma/adam_m/read
mul_585
	2.25
add_699
	0.000244140625
bert/encoder/layer_0/intermediate/dense/mul_1
truediv_5
Assign_260
bert/encoder/layer_5/attention/self/value/kernel/adam_v/read
mul_896
	2.25
Assign_248
truediv_127
truediv_145
gradients/bert/encoder/layer_9/attention/self/query/MatMul_grad/MatMul
	12.0
Assign_82
bert/encoder/layer_5/attention/self/query/kernel/read
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v
add_345
bert/encoder/layer_9/output/LayerNorm/moments/mean
	0.015625
Assign_64
Mul_44
Mul_754
	2.25
bert/encoder/layer_3/attention/self/key/bias/read
Mul_77
add_556
Assign_130
global_norm/L2Loss_67
	0.000244140625
clip_by_global_norm/mul_69
Assign_341
sub_124
Assign_335
gradients/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference_grad/sub
cls/predictions/mul_1
gradients/bert/encoder/layer_6/intermediate/dense/Pow_grad/mul_1
bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt
add_428
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m
add_638
bert/encoder/layer_4/attention/self/key/BiasAdd
gradients/AddN_3
gradients/bert/encoder/layer_1/intermediate/dense/mul_2_grad/Mul_1
gradients/bert/encoder/layer_3/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
gradients/bert/encoder/layer_6/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
cls/predictions/transform/dense/add_1
	1.875
cls/predictions/transform/dense/mul_3
	1.875
sub_3
Square_34
	0.0029296875
add_105
mul_821
	2.25
bert/encoder/layer_6/attention/self/key/bias/read
bert/encoder/layer_10/attention/self/transpose_2
	12.0
Assign_352
Mul_562
bert/encoder/layer_10/output/LayerNorm/batchnorm/sub
Mul_522
	0.01171875
bert/encoder/layer_5/attention/self/key/kernel/adam_m/read
bert/encoder/layer_2/attention/self/key/bias/adam_v/read
gradients/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference_grad/mul_1
clip_by_global_norm/mul_124
gradients/bert/encoder/layer_10/attention/self/query/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_7/output/dropout/mul
	12.0
bert/encoder/layer_4/attention/self/query/bias/adam_m/read
bert/encoder/layer_10/attention/self/dropout/random_uniform/mul
bert/encoder/layer_0/output/dense/bias
gradients/bert/encoder/layer_0/intermediate/dense/Pow_grad/Pow
	48.0
gradients/bert/encoder/layer_6/intermediate/dense/Tanh_grad/TanhGrad
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Reshape
Assign_605
Assign_293
bert/embeddings/word_embeddings/adam_m/read
Sqrt_103
	2.25
bert/encoder/layer_5/intermediate/dense/kernel
mul_677
bert/encoder/layer_6/attention/self/value/bias/adam_v
add_390
Mul_712
	0.0029296875
sub_174
gradients/bert/encoder/layer_6/attention/self/key/MatMul_grad/MatMul_1
	2.25
add_501
add_152
bert/encoder/layer_8/attention/self/dropout/GreaterEqual
	9.0
clip_by_global_norm/mul_135
add_121
mul_623
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
Mul_100
Mul_745
bert/encoder/layer_3/attention/self/transpose_1
	12.0
add_53
add_92
clip_by_global_norm/mul_11
bert/encoder/layer_6/output/LayerNorm/moments/mean
	0.015625
Mul_549
	3.75
Square_178
	0.0029296875
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
truediv_118
gradients/bert/encoder/layer_6/output/LayerNorm/moments/variance_grad/truediv
clip_by_global_norm/mul_199
Sqrt_134
	0.0029296875
bert/encoder/layer_7/attention/self/query/kernel/adam_v
Mul_744
	2.25
clip_by_global_norm/mul_105
Mul_884
	0.0029296875
Mul_819
	2.25
gradients/bert/encoder/layer_9/attention/self/transpose_3_grad/transpose
	12.0
Assign_214
clip_by_global_norm/mul_3
mul_317
bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference
	12.0
Mul_432
	9.0
gradients/bert/encoder/layer_4/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
global_norm/L2Loss_83
	0.000244140625
bert/encoder/layer_2/output/dense/kernel/adam_v
gradients/bert/encoder/layer_6/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_4/attention/output/LayerNorm/moments/mean
	0.015625
Assign_326
bert/encoder/layer_0/intermediate/dense/mul_2/x
clip_by_global_norm/mul_73
bert/encoder/layer_5/output/dense/bias/adam_m/read
bert/encoder/layer_7/attention/self/transpose_1
	12.0
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1
	12.0
bert/encoder/layer_8/output/LayerNorm/beta/adam_v
add_231
Mul_595
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m
bert/encoder/layer_2/attention/self/key/bias/read
bert/encoder/layer_3/attention/output/LayerNorm/beta
bert/encoder/layer_5/intermediate/dense/kernel/adam_m/read
Sqrt_147
	0.0029296875
add_153
bert/encoder/layer_2/output/LayerNorm/beta
bert/encoder/layer_3/attention/self/key/bias/adam_v
bert/encoder/layer_4/intermediate/dense/add
gradients/cls/predictions/Sum_grad/Tile
	74.5166015625
bert/encoder/layer_0/intermediate/dense/Pow
	48.0
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m
truediv_111
bert/encoder/layer_9/output/LayerNorm/batchnorm/mul
	12.0
clip_by_global_norm/mul_103
gradients/bert/encoder/layer_9/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1
	12.0
add_423
Assign_324
Mul_722
	2.25
add_493
Assign_221
bert/encoder/layer_1/attention/self/query/bias/adam_m
add_578
add_653
Mul_850
	0.0029296875
gradients/bert/encoder/layer_2/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
Sqrt_120
	0.0029296875
add_684
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Reshape
gradients/bert/encoder/layer_10/attention/self/MatMul_1_grad/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
add_264
bert/encoder/layer_3/output/LayerNorm/gamma/read
Assign_401
Mul_846
	0.0029296875
add_90
Assign_101
gradients/bert/encoder/layer_9/attention/self/Reshape_grad/Reshape
gradients/bert/encoder/layer_9/attention/output/dropout/mul_1_grad/Mul
	12.0
Mul_6
	89.419921875
gradients/bert/encoder/layer_2/intermediate/dense/mul_3_grad/Mul
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape
clip_by_global_norm/mul_41
mul_736
bert/encoder/layer_3/attention/output/dense/kernel/adam_m
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.02880859375
bert/encoder/layer_2/output/dense/bias/read
Assign_434
bert/encoder/layer_11/attention/output/dense/kernel
add_510
bert/encoder/layer_9/output/LayerNorm/beta/adam_m
Assign_219
Mul_584
mul_26
Assign_466
Assign_539
Mul_267
add_218
truediv_1
bert/encoder/layer_11/intermediate/dense/bias/adam_v/read
Mul_964
bert/encoder/layer_3/output/LayerNorm/gamma/adam_v
Assign_224
Mul_249
add_183
add_313
bert/encoder/layer_1/output/LayerNorm/gamma/adam_m/read
add_617
bert/encoder/layer_10/attention/output/dropout/mul
	12.0
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2_grad/Reshape
bert/encoder/layer_10/output/dropout/mul
	12.0
Mul_760
	0.0029296875
bert/encoder/layer_11/attention/self/key/kernel
Sqrt
	89.419921875
bert/encoder/layer_5/attention/self/key/BiasAdd
Mul_79
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m/read
bert/encoder/layer_4/attention/output/LayerNorm/gamma
mul_601
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2
	12.0
bert/encoder/layer_3/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
Square_84
	0.0029296875
sub_189
Sqrt_157
	0.0029296875
Sqrt_57
	2.25
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
mul_1016
Mul_831
gradients/bert/encoder/layer_11/attention/self/Softmax_grad/Sum
	0.1875
global_norm/L2Loss_24
	0.000244140625
add_631
Mul_1044
	9.0
Assign_51
gradients/cls/predictions/transform/LayerNorm/moments/variance_grad/truediv
Mul_1109
	0.000244140625
Mul_697
Mul_436
	0.01171875
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
mul_225
truediv_94
Assign_270
global_norm/L2Loss_87
	0.000244140625
	0.0087890625
clip_by_global_norm/mul_83
bert/encoder/layer_4/intermediate/dense/bias/read
mul_1048
Assign_166
Mul_1039
	0.01171875
Mul_282
	0.0029296875
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul
	12.0
gradients/AddN_47
Mul_842
cls/predictions/transform/dense/bias
bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt
bert/encoder/layer_0/attention/self/value/bias/adam_v/read
bert/encoder/layer_2/attention/output/dense/kernel
mul_122
	2.25
gradients/bert/encoder/layer_11/attention/self/Reshape_grad/Reshape
bert/encoder/layer_5/output/LayerNorm/beta/read
global_norm/L2Loss_147
	0.000244140625
bert/encoder/layer_9/output/dropout/random_uniform/mul
gradients/bert/encoder/layer_5/attention/self/query/MatMul_grad/MatMul_1
	2.25
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Tile
	12.0
Assign_337
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
bert/encoder/layer_7/intermediate/dense/add
truediv_46
gradients/bert/encoder/layer_11/attention/self/Softmax_grad/mul
gradients/cls/predictions/BiasAdd_grad/BiasAddGrad
	0.116455078125
bert/encoder/layer_10/intermediate/dense/add_1
	48.0
cls/predictions/transform/dense/mul_1
bert/encoder/layer_1/attention/self/key/kernel/adam_v
clip_by_global_norm/mul_23
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Mul_1
Mul_561
	2.25
bert/encoder/layer_2/output/dense/bias
sub_85
mul_956
add_470
global_norm/global_norm
gradients/bert/encoder/layer_4/attention/self/Reshape_1_grad/Reshape
bert/encoder/layer_10/attention/self/value/bias/adam_v/read
gradients/cls/predictions/transform/dense/Pow_grad/mul_1
bert/encoder/layer_10/attention/output/dense/bias/adam_m
add_595
Mul_110
	0.0029296875
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
add_24
add_418
Assign_25
bert/encoder/layer_4/intermediate/dense/bias
bert/encoder/layer_8/attention/output/LayerNorm/beta/read
bert/encoder/layer_9/attention/self/dropout/random_uniform
gradients/bert/encoder/layer_5/attention/self/key/MatMul_grad/MatMul
	12.0
Assign_153
add_192
clip_by_global_norm/mul_143
clip_by_global_norm/mul_52
gradients/AddN_78
bert/encoder/layer_8/attention/output/dense/bias/adam_m
mul_220
sub_8
gradients/AddN_17
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v/read
Mul_296
	0.0029296875
truediv_163
gradients/cls/predictions/LogSoftmax_grad/Sum
	0.00244140625
	0.000244140625
bert/encoder/layer_8/intermediate/dense/bias/adam_v/read
bert/encoder/Reshape
sub_62
global_norm/L2Loss_113
	0.000244140625
	0.0087890625
add_341
Sqrt_178
	0.0029296875
Mul_1066
	2.25
gradients/bert/encoder/layer_0/attention/self/dropout/mul_1_grad/Mul
mul_870
bert/encoder/layer_8/attention/self/dropout/random_uniform/RandomUniform
	24.0
bert/encoder/layer_8/output/dropout/Cast
	12.0
Mul_519
mul_440
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m/read
cls/predictions/transform/LayerNorm/gamma/read
truediv_78
mul_999
add_249
bert/encoder/layer_9/intermediate/dense/add
truediv_56
bert/encoder/layer_10/attention/output/LayerNorm/gamma/read
bert/encoder/layer_0/attention/self/key/kernel/adam_v/read
add_163
sub_57
add_411
Mul_404
	0.0029296875
clip_by_global_norm/mul_131
Assign_344
bert/encoder/layer_11/attention/self/add
bert/encoder/layer_5/attention/output/dropout/random_uniform
bert/encoder/layer_11/intermediate/dense/kernel
bert/encoder/layer_6/attention/self/key/kernel
gradients/bert/encoder/layer_7/attention/self/Reshape_1_grad/Reshape
gradients/bert/encoder/layer_6/attention/self/Reshape_2_grad/Reshape
Mul_1064
	2.25
Assign_195
bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1
gradients/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference_grad/sub
add_642
sub_27
bert/encoder/layer_1/attention/self/value/kernel/adam_v
bert/encoder/layer_7/attention/output/LayerNorm/beta
bert/encoder/layer_3/attention/self/key/kernel/read
bert/encoder/layer_0/output/LayerNorm/batchnorm/mul
	12.0
Square_72
	0.0029296875
add_399
global_norm/L2Loss_183
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_5/attention/self/Reshape_grad/Reshape
gradients/bert/encoder/layer_5/attention/self/MatMul_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_8/intermediate/dense/Pow_grad/mul
sub_95
bert/encoder/layer_10/attention/self/Softmax
	24.0
	24.0
bert/encoder/layer_11/attention/self/value/bias
bert/encoder/layer_2/attention/output/dense/bias/adam_m
Assign_364
Mul_759
	0.0029296875
Assign_173
cls/seq_relationship/mul
sub_133
add_132
Mul_861
	9.0
Assign_15
bert/encoder/layer_3/attention/self/query/kernel
add_21
add_647
add_273
add_634
bert/encoder/layer_4/attention/self/key/kernel/adam_v
Mul_765
	0.0029296875
gradients/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference_grad/scalar
bert/encoder/layer_3/intermediate/dense/kernel/adam_v
gradients/cls/predictions/transform/dense/Pow_grad/mul
Mul_200
Mul_438
	0.01171875
bert/encoder/layer_7/attention/output/dropout/mul_1
add_413
bert/encoder/layer_8/attention/self/key/bias/adam_m
Assign_225
bert/encoder/layer_5/attention/output/dense/bias/adam_m
gradients/bert/encoder/layer_9/attention/self/value/MatMul_grad/MatMul_1
	2.25
Assign_230
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_2/output/dense/bias/adam_m
Assign_396
clip_by_global_norm/mul_112
bert/encoder/layer_7/attention/self/key/bias/adam_m/read
bert/encoder/layer_10/output/LayerNorm/beta/adam_v
add_239
bert/encoder/layer_1/attention/output/LayerNorm/beta/read
bert/encoder/layer_1/intermediate/dense/mul_2
gradients/AddN_69
global_norm/mul
Assign_529
Mul_400
	2.25
Mul_642
	0.0029296875
Assign_74
global_norm/L2Loss_132
	0.000244140625
Assign_584
bert/encoder/layer_10/attention/self/key/bias/adam_v/read
add_376
Mul_774
	9.0
Mul_138
bert/encoder/layer_0/output/LayerNorm/moments/variance
	0.015625
add_9
clip_by_global_norm/mul_133
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
Mul_407
Mul_1067
add_667
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
bert/encoder/layer_0/output/dense/kernel/adam_v/read
gradients/bert/encoder/layer_11/output/dense/MatMul_grad/MatMul_1
	12.0
bert/encoder/layer_7/attention/self/dropout/mul
	24.0
add_336
bert/encoder/layer_3/attention/self/value/MatMul
	12.0
cls/predictions/transform/LayerNorm/gamma
bert/encoder/layer_3/attention/self/key/bias/adam_v/read
Assign_419
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub
sub_44
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/truediv
bert/encoder/layer_6/intermediate/dense/kernel
mul_150
add_197
bert/encoder/layer_11/attention/self/dropout/GreaterEqual
	6.0
bert/encoder/layer_8/attention/self/key/kernel/read
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v/read
gradients/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
Sqrt_36
	0.0029296875
bert/encoder/layer_0/attention/self/transpose
	12.0
gradients/bert/encoder/layer_7/attention/self/dropout/mul_1_grad/Mul
truediv_136
Mul_1001
	3.0
add_491
Assign_561
bert/encoder/layer_9/attention/self/query/bias/adam_m/read
gradients/bert/encoder/layer_6/intermediate/dense/mul_1_grad/Mul_1
add_95
gradients/bert/encoder/layer_11/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
Mul_238
mul_236
add_477
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m
bert/encoder/layer_5/attention/output/dense/bias/adam_v
Sqrt_73
	2.25
Mul_670
bert/encoder/layer_0/intermediate/dense/mul_2
Mul_877
	0.0029296875
Mul_516
	9.0
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
Sqrt_153
	2.25
mul_445
	9.0
clip_by_global_norm/mul_38
gradients/bert/encoder/layer_11/attention/self/key/MatMul_grad/MatMul
	12.0
bert/encoder/layer_2/intermediate/dense/MatMul
	48.0
bert/encoder/layer_11/intermediate/dense/kernel/adam_v/read
Assign_614
bert/encoder/layer_0/attention/self/key/bias/adam_m/read
truediv_96
Mul_307
	0.0029296875
global_norm/L2Loss_93
	0.000244140625
bert/encoder/layer_7/attention/self/value/BiasAdd
mul_1005
sub_175
Assign_92
bert/encoder/layer_4/output/dense/BiasAdd
Mul_431
Mul_1055
	0.0029296875
Mul_388
bert/encoder/layer_2/intermediate/dense/kernel/adam_m
Assign_236
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
Sqrt_187
	2.25
bert/encoder/layer_4/attention/self/query/MatMul
	12.0
bert/encoder/layer_7/attention/self/dropout/random_uniform
add_93
Sqrt_18
	0.0029296875
clip_by_global_norm/mul_25
bert/encoder/layer_5/attention/self/key/kernel
bert/encoder/layer_3/attention/self/Reshape_3
Mul_622
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
Square_189
bert/encoder/layer_8/attention/self/Softmax
	24.0
	24.0
bert/encoder/layer_5/output/LayerNorm/batchnorm/mul
	12.0
gradients/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference_grad/scalar
bert/encoder/layer_5/attention/self/value/kernel/adam_v
bert/encoder/layer_5/output/dense/kernel
Mul_221
	0.0029296875
bert/encoder/layer_3/attention/self/value/BiasAdd
truediv_202
gradients/bert/encoder/layer_2/attention/self/Reshape_2_grad/Reshape
bert/encoder/layer_1/attention/output/add
Mul_1071
	0.0029296875
Mul_259
add_99
Square_138
bert/encoder/layer_8/attention/self/Reshape_3
bert/encoder/layer_9/attention/self/query/bias/read
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
Square_83
	0.0029296875
clip_by_global_norm/mul_159
gradients/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul_1
Mul_361
	0.0029296875
bert/encoder/layer_6/attention/self/query/kernel/adam_m
bert/encoder/layer_11/attention/self/key/kernel/adam_v
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v
bert/encoder/layer_3/attention/output/dense/bias/adam_m/read
bert/encoder/layer_0/intermediate/dense/bias/adam_v/read
mul_563
	2.25
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
add_19
Assign_562
sub_194
gradients/bert/encoder/layer_6/attention/self/Reshape_1_grad/Reshape
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
Mul_1061
	0.0029296875
mul_930
mul_177
bert/encoder/layer_10/output/dropout/Cast
	12.0
mul_1074
gradients/bert/encoder/layer_0/intermediate/dense/mul_3_grad/Mul_1
	48.0
add_495
Assign_69
sub
Mul_255
	0.0029296875
gradients/bert/encoder/layer_4/output/LayerNorm/moments/mean_grad/truediv
Square_177
	9.0
mul_349
gradients/bert/encoder/layer_5/intermediate/dense/mul_3_grad/Mul_1
	48.0
bert/embeddings/LayerNorm/beta
bert/encoder/layer_11/attention/self/query/bias
Mul_17
add_594
Mul_239
	2.25
add_401
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Sum
	0.018310546875
add_432
bert/encoder/layer_6/attention/self/key/MatMul
	12.0
add_478
sub_20
bert/encoder/layer_1/output/LayerNorm/gamma/read
Sqrt_155
	2.25
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
Assign_234
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1
PolynomialDecay/Mul
add_408
truediv_129
bert/encoder/layer_11/output/LayerNorm/gamma
gradients/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul_1
	15.75
	0.0029296875
	0.0029296875
	0.0029296875
Mul_548
	2.25
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
Assign_284
bert/encoder/layer_5/attention/output/LayerNorm/beta
truediv_157
Mul_680
	0.0029296875
add_492
bert/encoder/layer_9/intermediate/dense/mul_3
Square_201
	0.0029296875
cls/predictions/transform/dense/mul
gradients/bert/encoder/layer_3/intermediate/dense/Pow_grad/Pow
	48.0
clip_by_global_norm/mul_102
gradients/AddN_85
bert/encoder/layer_8/intermediate/dense/add_1
	48.0
Assign_615
Mul_916
	2.25
Square_156
bert/encoder/Reshape_1/shape
bert/encoder/layer_3/attention/output/dense/bias
add_168
gradients/AddN_89
clip_by_global_norm/mul_72
bert/encoder/layer_1/attention/self/transpose_3
	12.0
add_406
bert/encoder/layer_9/intermediate/dense/kernel/adam_v
Mul_97
	9.0
gradients/bert/encoder/layer_9/intermediate/dense/MatMul_grad/MatMul
	12.0
bert/encoder/layer_10/attention/self/value/kernel/adam_m/read
mul_182
truediv_142
bert/encoder/layer_2/output/LayerNorm/gamma/adam_m
add_283
add_545
bert/encoder/layer_8/attention/output/dense/bias/adam_v/read
truediv_88
cls/predictions/transform/LayerNorm/beta/adam_m
bert/encoder/layer_0/output/LayerNorm/beta/adam_m/read
add_672
bert/encoder/layer_4/attention/self/transpose
	12.0
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/variance_grad/truediv
add_166
Cast
	0.000244140625
bert/encoder/layer_0/attention/self/query/kernel/adam_v/read
gradients/bert/encoder/layer_11/attention/self/MatMul_grad/MatMul_1
	17.419921875
	0.0029296875
	0.0029296875
	0.00390625
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
Sqrt_98
	0.0029296875
bert/encoder/layer_7/attention/self/dropout/mul_1
Assign_310
bert/encoder/layer_9/output/dense/bias/adam_v
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
bert/encoder/layer_3/output/LayerNorm/gamma
Mul_529
	9.0
bert/encoder/layer_11/output/LayerNorm/beta
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
bert/encoder/layer_5/output/dense/BiasAdd
Mul_860
	9.0
add_373
global_norm/L2Loss
	0.000244140625
	0.009765625
gradients/AddN_41
bert/encoder/layer_0/attention/self/key/MatMul
	12.0
Sqrt_97
	9.0
clip_by_global_norm/mul_179
Assign_437
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
bert/encoder/layer_3/output/dense/MatMul
	12.0
Mul_337
bert/encoder/layer_3/attention/self/query/bias/adam_v
bert/encoder/layer_3/output/LayerNorm/beta/adam_v/read
Square_81
	9.0
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/mean_grad/truediv
Mul_894
	2.25
bert/encoder/layer_4/attention/self/key/kernel/adam_m
bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2
	12.0
bert/encoder/layer_11/attention/self/query/bias/adam_m
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
gradients/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
Sqrt_161
	12.0
global_norm/L2Loss_95
	0.000244140625
	0.0087890625
Mul_1020
bert/embeddings/ArithmeticOptimizer/AddOpsRewrite_Leaf_1_add_1
bert/encoder/layer_4/output/LayerNorm/batchnorm/sub
bert/encoder/layer_9/attention/output/dense/kernel/adam_m/read
bert/encoder/layer_2/attention/self/query/kernel/adam_v/read
add_201
bert/encoder/layer_9/intermediate/dense/mul
bert/encoder/layer_8/attention/self/value/MatMul
	12.0
Assign_176
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
bert/encoder/layer_9/intermediate/dense/bias
add_404
sub_75
add_482
add_284
gradients/AddN_64
mul_289
bert/encoder/layer_2/attention/output/add
add_2
Mul_925
	2.25
Mul_154
Sqrt_12
	0.0029296875
bert/embeddings/LayerNorm/batchnorm/add_1
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
Mul_781
	0.01171875
gradients/bert/encoder/layer_7/attention/self/value/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_6/attention/self/Reshape_1
mul_687
bert/encoder/layer_6/attention/self/query/bias/adam_v
gradients/bert/encoder/layer_8/attention/self/Reshape_grad/Reshape
PolynomialDecay/sub_1
bert/encoder/layer_3/intermediate/dense/add
cls/predictions/transform/LayerNorm/batchnorm/add
add_297
cls/predictions/Sum_1
	0.000244140625
gradients/bert/encoder/layer_10/intermediate/dense/Tanh_grad/TanhGrad
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
mul_386
add_81
bert/encoder/layer_7/attention/output/LayerNorm/moments/variance
	0.015625
Mul_895
bert/encoder/layer_1/attention/self/key/kernel/adam_m/read
truediv_122
sub_131
truediv_42
add_524
add_550
bert/encoder/layer_3/attention/output/dropout/Cast
	12.0
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
gradients/bert/encoder/layer_11/attention/output/dropout/mul_1_grad/Mul
	12.0
bert/encoder/layer_2/attention/self/query/bias/read
cls/predictions/output_bias/adam_v/read
bert/encoder/layer_5/attention/self/query/bias/read
bert/encoder/layer_8/attention/self/query/bias/adam_v/read
bert/encoder/layer_11/attention/self/key/bias
truediv_32
Mul_1024
	0.0029296875
gradients/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference_grad/sub
Assign_302
gradients/bert/encoder/layer_8/attention/self/dropout/mul_grad/Mul
bert/encoder/layer_10/output/LayerNorm/moments/mean
	0.015625
bert/encoder/layer_4/attention/output/dense/bias/adam_v/read
gradients/bert/encoder/layer_10/output/LayerNorm/moments/variance_grad/truediv
gradients/bert/encoder/layer_10/output/LayerNorm/moments/mean_grad/truediv
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Mul_1
bert/encoder/layer_5/attention/output/dense/kernel/adam_v/read
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
truediv_206
Assign_208
bert/encoder/layer_9/intermediate/dense/bias/read
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/variance_grad/truediv
Assign_420
gradients/bert/encoder/layer_4/attention/self/MatMul_1_grad/MatMul
	24.0
	0.00439453125
	0.0029296875
	0.0029296875
add_449
mul_161
bert/encoder/layer_10/output/dropout/GreaterEqual
	3.0
bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference
	12.0
gradients/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference_grad/Mul
gradients/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Mul
bert/encoder/layer_7/output/dropout/random_uniform/mul
clip_by_global_norm/mul_97
bert/encoder/layer_11/output/add
add_250
add_409
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
clip_by_global_norm/mul_145
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m
bert/encoder/layer_1/intermediate/dense/kernel/adam_v
Square_204
gradients/bert/encoder/layer_9/output/LayerNorm/moments/mean_grad/Tile
	15.169921875
Sqrt_137
	2.25
clip_by_global_norm/mul_146
add_444
add_106
Mul_1013
	2.25
bert/encoder/layer_11/attention/self/dropout/mul_1
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
bert/encoder/layer_4/attention/self/key/bias/adam_v/read
Mul_756
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m/read
bert/encoder/layer_0/attention/self/Reshape_3
bert/encoder/layer_1/attention/self/dropout/mul
	24.0
mul_988
add_137
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
gradients/bert/encoder/layer_4/attention/self/transpose_3_grad/transpose
	12.0
bert/encoder/Reshape/shape
Mul_646
	2.25
bert/encoder/layer_1/attention/output/dense/MatMul
	12.0
Mul_162
	0.0029296875
Assign_538
bert/encoder/layer_1/attention/output/dense/bias/read
add_164
add_435
gradients/bert/encoder/layer_0/attention/self/Reshape_3_grad/Reshape
Sqrt_74
	0.0029296875
Mul_721
	2.25
bert/encoder/layer_9/intermediate/dense/mul_2
Mul_630
	0.0029296875
Square_197
clip_by_global_norm/mul_196
global_norm/L2Loss_120
	0.000244140625
mul_644
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
bert/encoder/layer_0/attention/self/transpose/perm
bert/encoder/layer_6/intermediate/dense/bias/adam_v/read
bert/encoder/layer_10/attention/output/dense/bias/adam_v/read
global_norm/L2Loss_32
	0.000244140625
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
truediv_41
bert/encoder/layer_7/attention/output/dense/bias/read
clip_by_global_norm/mul_54
global_norm/L2Loss_84
	0.000244140625
clip_by_global_norm/mul_186
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
bert/encoder/layer_11/attention/self/key/kernel/adam_v/read
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
gradients/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference_grad/scalar
sub_139
truediv_58
cls/predictions/transform/LayerNorm/beta/adam_m/read
Mul_969
bert/encoder/layer_8/output/LayerNorm/gamma/adam_m/read
Assign_129
bert/encoder/layer_6/output/dense/kernel/adam_v
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
bert/encoder/layer_11/attention/self/query/bias/adam_v
bert/embeddings/LayerNorm/gamma/adam_m/read
bert/encoder/layer_1/attention/output/dense/kernel/adam_m/read
bert/encoder/layer_9/output/LayerNorm/gamma/adam_m
Mul_441
	9.0
add_233
gradients/cls/predictions/transform/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad
add_671
gradients/bert/encoder/layer_2/attention/self/value/MatMul_grad/MatMul
	12.0
Mul_368
	0.0029296875
truediv_8
Mul_554
	0.0029296875
mul_451
bert/encoder/layer_3/intermediate/dense/bias/adam_v
bert/encoder/layer_7/output/LayerNorm/gamma/adam_v/read
mul_666
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2_grad/Mul
bert/embeddings/position_embeddings/adam_v/read
Mul_936
	0.0029296875
Mul_313
Mul_619
	0.0029296875
bert/encoder/layer_1/output/dropout/random_uniform/RandomUniform
	12.0
Assign_518
gradients/bert/encoder/layer_9/intermediate/dense/mul_3_grad/Mul
mul_547
Assign_145
Mul_934
truediv_47
gradients/AddN_13
sub_142
bert/encoder/layer_5/output/LayerNorm/moments/variance
	0.015625
bert/encoder/layer_10/attention/self/transpose_1
	12.0
mul_741
Mul_995
	0.0029296875
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2
	12.0
Mul_669
	2.25
add_194
Assign_588
global_norm/L2Loss_185
	0.000244140625
	0.009765625
gradients/bert/encoder/layer_8/attention/self/key/MatMul_grad/MatMul
	12.0
bert/encoder/layer_7/output/LayerNorm/beta/adam_m/read
bert/encoder/layer_7/attention/self/key/kernel/adam_v
gradients/bert/encoder/layer_3/attention/self/transpose_grad/transpose
	17.25
add_374
Assign_503
add_339
Sqrt_4
	0.0029296875
bert/encoder/layer_9/attention/self/key/bias/adam_m
bert/encoder/layer_4/attention/self/query/kernel/adam_m/read
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	15.75
Mul_683
	0.0029296875
Sqrt_44
	0.0029296875
Mul_81
	0.0029296875
bert/encoder/layer_6/output/LayerNorm/beta/adam_v/read
add_240
Square_63
	9.0
Assign_254
bert/encoder/layer_3/attention/output/LayerNorm/moments/mean
	0.015625
mul_37
Assign_390
bert/encoder/layer_2/attention/output/dropout/Cast
	12.0
gradients/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul
	19.5
Mul_493
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
Assign_244
gradients/bert/encoder/layer_3/attention/self/value/MatMul_grad/MatMul_1
	3.0
bert/encoder/layer_3/attention/output/dense/bias/adam_v
Assign_211
bert/encoder/layer_0/output/dense/kernel/adam_m/read
truediv_28
Mul_120
	2.25
bert/encoder/layer_2/intermediate/dense/bias/read
bert/encoder/layer_7/attention/self/value/kernel/adam_v
add_509
Square_55
	3.75
Assign_9
gradients/bert/encoder/layer_8/attention/self/query/MatMul_grad/MatMul
	12.0
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v
Sqrt_47
	9.0
add_332
Sqrt_17
	9.0
truediv_107
bert/encoder/layer_0/attention/output/dense/kernel/adam_m/read
sub_99
bert/encoder/layer_0/attention/output/dense/bias/read
bert/encoder/layer_0/output/dropout/GreaterEqual
	3.0
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
Mul_900
	0.0029296875
add_59
bert/encoder/layer_4/attention/self/key/kernel/adam_v/read
Assign_475
cls/predictions/transform/LayerNorm/batchnorm/mul
	1.875
Mul_933
	0.0029296875
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1
Mul_679
	0.0029296875
mul_902
Assign_159
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
bert/embeddings/ExpandDims/dim
Mul_1060
	0.0029296875
Assign_379
Mul_621
	0.0029296875
Assign_452
Mul_828
	2.25
bert/encoder/layer_6/output/dropout/GreaterEqual
	3.0
add_111
Mul_708
Mul_960
Mul_997
	0.0029296875
bert/encoder/layer_5/output/dense/bias/read
bert/encoder/layer_4/output/dense/bias
gradients/bert/encoder/layer_4/intermediate/dense/mul_3_grad/Mul_1
	48.0
add_143
bert/encoder/layer_5/intermediate/dense/BiasAdd
add_221
Mul_593
	0.0029296875
Mul_178
	0.01171875
Sqrt_11
	2.25
bert/encoder/layer_2/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_9/attention/self/transpose_grad/transpose
	15.169921875
bert/encoder/layer_8/output/LayerNorm/moments/variance
	0.015625
bert/encoder/layer_0/attention/self/query/bias/adam_m
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2
	12.0
Mul_931
	0.0029296875
add_660
add_280
Assign_527
Assign_412
Square_118
Sqrt_59
	2.25
bert/encoder/layer_10/attention/self/key/bias/read
Square_70
	0.0029296875
gradients/bert/encoder/layer_7/intermediate/dense/mul_2_grad/Mul_1
gradients/bert/encoder/layer_4/attention/output/dropout/mul_1_grad/Mul
	12.0
Assign_2
bert/encoder/layer_6/attention/self/Softmax
	24.0
	24.0
add_104
bert/encoder/layer_11/attention/self/query/kernel
Mul_422
	0.0029296875
Mul_928
add_623
bert/encoder/layer_11/attention/self/Reshape_3
Mul_479
	0.0029296875
gradients/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference_grad/mul_1
sub_72
cls/seq_relationship/output_bias/read
bert/encoder/layer_1/attention/output/LayerNorm/moments/variance
	0.015625
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
Mul_557
Mul_143
bert/encoder/layer_10/output/dense/bias/adam_m
gradients/cls/seq_relationship/MatMul_grad/MatMul
	0.09375
bert/encoder/layer_3/attention/self/value/kernel/adam_m
add_252
bert/encoder/layer_5/attention/self/query/BiasAdd
Mul_874
Sqrt_40
	0.0029296875
Mul_1110
bert/encoder/layer_10/output/dense/kernel
clip_by_global_norm/mul_86
bert/encoder/layer_11/intermediate/dense/kernel/adam_m
bert/encoder/layer_10/attention/self/Reshape
bert/encoder/layer_5/attention/self/key/kernel/adam_m
add_51
bert/encoder/layer_9/attention/self/key/bias/adam_v/read
global_norm/L2Loss_51
	0.000244140625
bert/encoder/layer_5/attention/self/dropout/random_uniform/mul
Mul_701
	9.0
global_norm/L2Loss_44
	0.000244140625
gradients/AddN_77
bert/encoder/layer_0/attention/self/ExpandDims/dim
bert/encoder/layer_5/intermediate/dense/add
truediv_167
global_norm/L2Loss_197
	0.000244140625
	0.0087890625
bert/encoder/layer_1/output/LayerNorm/gamma/adam_v/read
add_394
bert/encoder/layer_5/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
Mul_339
	0.0029296875
clip_by_global_norm/mul_78
bert/encoder/layer_4/attention/self/value/kernel/read
bert/embeddings/assert_less_equal/x
bert/encoder/layer_9/output/dropout/random_uniform/RandomUniform
	12.0
bert/encoder/layer_0/attention/output/dropout/random_uniform/mul
bert/encoder/layer_1/attention/self/dropout/random_uniform/RandomUniform
	24.0
bert/encoder/layer_0/output/dense/BiasAdd
add_474
bert/encoder/layer_6/intermediate/dense/kernel/adam_v
bert/encoder/layer_7/attention/self/query/kernel
bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1
mul_53
bert/encoder/layer_3/attention/self/key/bias/adam_m/read
mul_241
	2.25
add_487
bert/embeddings/assert_less_equal/y
Mul_345
bert/encoder/layer_2/attention/self/key/bias/adam_m
Assign_382
Mul_949
Assign_57
gradients/bert/encoder/layer_2/attention/self/key/MatMul_grad/MatMul
	19.5
bert/encoder/layer_8/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_10/output/dense/bias
bert/encoder/layer_11/intermediate/dense/bias/adam_m/read
Mul_566
	0.0029296875
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
global_norm/L2Loss_85
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_5/output/dense/MatMul_grad/MatMul
	48.0
Mul_92
	0.01171875
Assign_563
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
bert/encoder/layer_8/attention/self/value/BiasAdd
truediv_181
add_38
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2
	12.0
Sqrt_62
	0.0029296875
bert/encoder/layer_6/attention/output/dense/kernel/adam_v/read
Mul_216
bert/encoder/layer_3/output/dense/kernel/adam_v/read
gradients/bert/encoder/layer_1/attention/self/dropout/mul_1_grad/Mul
Mul_963
	0.0029296875
gradients/bert/encoder/layer_11/output/dense/MatMul_grad/MatMul
	74.5166015625
gradients/bert/encoder/layer_9/intermediate/dense/mul_3_grad/Mul_1
	48.0
bert/encoder/layer_6/intermediate/dense/kernel/adam_m/read
Assign_178
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add
bert/encoder/layer_7/attention/self/value/kernel/adam_m
bert/encoder/layer_8/attention/self/transpose_1
	12.0
add_141
clip_by_global_norm/mul_167
gradients/bert/encoder/layer_8/output/LayerNorm/moments/mean_grad/Tile
	12.0
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Reshape
Assign_508
bert/encoder/layer_8/attention/self/query/bias/adam_m/read
gradients/bert/encoder/layer_5/attention/self/query/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_0/output/dropout/mul
	12.0
bert/encoder/layer_4/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_3/output/LayerNorm/moments/mean_grad/truediv
Assign_203
Assign_42
gradients/bert/encoder/layer_5/attention/self/dropout/mul_grad/Mul
Assign_415
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v/read
bert/encoder/layer_11/attention/output/add
global_norm/L2Loss_3
	0.000244140625
truediv_43
bert/encoder/layer_7/intermediate/dense/bias/adam_m/read
Mul_412
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1
	12.0
Assign_343
bert/encoder/layer_1/attention/self/query/bias/adam_v
gradients/cls/predictions/LogSoftmax_grad/sub
global_norm/L2Loss_5
	0.000244140625
	0.0087890625
bert/encoder/layer_2/attention/self/query/bias/adam_v
Sqrt_199
	2.25
gradients/bert/encoder/layer_6/attention/self/dropout/mul_grad/Mul
gradients/bert/encoder/layer_1/intermediate/dense/mul_3_grad/Mul
Assign_372
bert/encoder/layer_4/output/dense/kernel
Sqrt_133
	2.25
Mul_579
gradients/bert/encoder/layer_7/attention/self/MatMul_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_9/intermediate/dense/mul_2_grad/Mul_1
gradients/bert/encoder/layer_3/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
add_407
Sqrt_51
	0.0029296875
global_norm/L2Loss_145
	0.000244140625
	0.013427734375
bert/encoder/layer_7/output/LayerNorm/batchnorm/add
bert/encoder/layer_11/attention/self/key/kernel/adam_m/read
global_norm/L2Loss_92
	0.000244140625
gradients/bert/encoder/layer_8/attention/self/Softmax_grad/mul_1
	24.0
add_320
Mul_631
	0.0029296875
bert/encoder/layer_6/attention/self/query/kernel/adam_v
bert/encoder/layer_7/output/LayerNorm/beta
global_step/cond/Read/ReadVariableOp/Switch
add_553
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
add_311
truediv_4
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
bert/encoder/layer_7/attention/self/key/bias/adam_v
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub
bert/encoder/layer_5/attention/self/Reshape
Assign_226
gradients/cls/predictions/transform/dense/Pow_grad/sub
bert/encoder/layer_11/attention/self/transpose_2
	12.0
gradients/bert/encoder/layer_7/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
add_396
global_norm/L2Loss_196
	0.000244140625
sub_180
gradients/bert/encoder/layer_2/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_6/output/LayerNorm/gamma/adam_m/read
add_590
Assign_322
Mul_792
	0.0029296875
bert/encoder/layer_1/attention/self/value/bias/adam_v/read
bert/encoder/layer_3/output/dropout/random_uniform/RandomUniform
	12.0
Mul_869
Mul_609
	0.01171875
bert/encoder/layer_0/attention/self/value/bias/read
bert/encoder/layer_10/attention/self/value/kernel/read
bert/encoder/layer_11/attention/self/dropout/random_uniform/RandomUniform
	24.0
Assign_409
add_486
add_469
gradients/bert/encoder/layer_2/intermediate/dense/mul_2_grad/Mul_1
mul_144
	2.25
Assign_271
mul_553
truediv_182
gradients/bert/encoder/layer_7/attention/self/Softmax_grad/Sum
	0.1875
bert/encoder/layer_3/intermediate/dense/bias/adam_m
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
bert/encoder/layer_1/intermediate/dense/mul
truediv_27
gradients/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference_grad/scalar
gradients/bert/encoder/layer_11/attention/self/Mul_grad/Mul
Assign_567
bert/encoder/layer_8/attention/output/LayerNorm/gamma
Sqrt_136
	0.0029296875
Assign_331
Square_169
	2.25
clip_by_global_norm/mul_202
global_norm/L2Loss_42
	0.000244140625
Square_42
	0.0029296875
Mul_442
sub_74
global_norm/L2Loss_122
	0.000244140625
clip_by_global_norm/mul_35
global_norm/L2Loss_153
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_4/output/dropout/mul_grad/Mul
gradients/bert/encoder/layer_6/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.019775390625
bert/encoder/layer_11/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
bert/encoder/layer_11/attention/self/value/bias/adam_v
bert/encoder/layer_3/attention/output/dense/BiasAdd
gradients/bert/encoder/layer_5/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_8/intermediate/dense/Tanh
bert/encoder/layer_11/intermediate/dense/add_1
	48.0
Sqrt_189
	0.0029296875
gradients/AddN_45
bert/encoder/layer_2/attention/self/value/kernel
bert/encoder/layer_3/intermediate/dense/mul_1
gradients/AddN_9
add_23
gradients/bert/encoder/layer_2/intermediate/dense/Tanh_grad/TanhGrad
truediv_53
Assign_139
gradients/cls/predictions/Sum_1_grad/Const
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m/read
Mul_602
	9.0
bert/embeddings/dropout/random_uniform/mul
bert/encoder/layer_6/intermediate/dense/MatMul
	48.0
bert/encoder/layer_6/output/dense/kernel/adam_m/read
bert/encoder/layer_1/attention/self/dropout/GreaterEqual
	6.0
add_256
mul_719
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2_grad/Reshape
Mul_1050
	0.0029296875
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
Square_190
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
sub_152
bert/encoder/layer_6/intermediate/dense/bias/read
bert/encoder/layer_5/attention/self/value/MatMul
	12.0
global_norm/L2Loss_135
	0.000244140625
	0.01416015625
clip_by_global_norm/mul_46
bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1
	12.0
bert/encoder/layer_3/attention/self/value/kernel/adam_v/read
bert/encoder/layer_2/attention/output/dense/kernel/read
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v
bert/encoder/layer_1/attention/self/key/BiasAdd
global_norm/L2Loss_17
	0.000244140625
	0.0087890625
bert/encoder/layer_9/output/LayerNorm/beta
truediv_67
Sqrt_203
	0.1640625
add_241
Assign_313
Assign_550
bert/encoder/layer_1/attention/output/dense/bias
bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt
add_663
global_norm/L2Loss_59
	0.000244140625
	0.0087890625
add_216
bert/encoder/layer_3/output/dense/bias
bert/encoder/layer_5/attention/self/value/kernel
bert/embeddings/LayerNorm/beta/adam_v/read
Mul_420
	0.0029296875
add_222
gradients/bert/encoder/layer_4/intermediate/dense/Pow_grad/mul_1
mul_478
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	15.75
gradients/AddN_33
gradients/bert/encoder/layer_7/attention/self/Mul_grad/Mul
bert/encoder/layer_5/attention/output/LayerNorm/moments/mean
	0.015625
bert/encoder/layer_8/attention/output/dropout/random_uniform/RandomUniform
	17.419921875
Assign_131
truediv_193
add_156
sub_187
Mul_1056
	0.0029296875
Mul_173
bert/encoder/layer_10/attention/self/query/BiasAdd
bert/encoder/layer_6/output/dropout/mul_1
gradients/cls/seq_relationship/LogSoftmax_grad/mul
bert/encoder/layer_10/attention/self/query/kernel/adam_v/read
truediv_171
Mul_1104
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Mul_1
mul_859
bert/encoder/layer_3/attention/self/value/kernel/read
bert/encoder/layer_3/attention/self/dropout/GreaterEqual
	6.0
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
add_30
truediv_81
bert/encoder/layer_2/output/LayerNorm/beta/adam_v
bert/encoder/layer_4/output/dense/bias/adam_v/read
global_norm/L2Loss_100
	0.000244140625
bert/encoder/layer_2/output/LayerNorm/gamma/read
gradients/bert/encoder/layer_7/intermediate/dense/mul_1_grad/Mul_1
bert/encoder/layer_0/attention/output/dense/MatMul
	12.0
sub_170
Sqrt_164
	0.0029296875
truediv_18
bert/encoder/layer_6/attention/self/MatMul
	24.0
	0.0029296875
	0.0029296875
	0.0029296875
Mul_160
gradients/bert/encoder/layer_2/attention/self/MatMul_grad/MatMul_1
	15.75
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum
	0.025634765625
gradients/bert/encoder/layer_3/attention/self/query/MatMul_grad/MatMul
	15.75
bert/encoder/layer_5/output/dense/MatMul
	12.0
Assign_107
bert/encoder/layer_6/attention/self/key/bias/adam_v/read
bert/encoder/layer_7/attention/self/Reshape_2
gradients/bert/encoder/layer_8/output/LayerNorm/moments/variance_grad/truediv
Assign_551
global_norm/L2Loss_88
	0.000244140625
Mul_163
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m/read
Mul_560
	2.25
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
bert/encoder/layer_4/output/LayerNorm/batchnorm/add
bert/encoder/layer_6/attention/output/dense/bias
gradients/bert/encoder/layer_8/intermediate/dense/Pow_grad/mul_1
add_138
add_567
Assign_97
truediv_113
cls/predictions/transform/LayerNorm/beta/read
Assign_158
bert/encoder/layer_9/intermediate/dense/kernel/adam_v/read
clip_by_global_norm/mul_114
gradients/cls/predictions/truediv_grad/RealDiv
	0.000244140625
Mul_841
	2.25
global_norm/L2Loss_203
	0.000244140625
	0.000244140625
truediv_102
Mul_373
	0.0029296875
gradients/bert/encoder/layer_10/attention/self/value/MatMul_grad/MatMul
	12.0
gradients/bert/encoder/layer_10/attention/self/transpose_3_grad/transpose
	12.0
add_463
bert/encoder/layer_2/output/add
bert/encoder/layer_9/attention/self/value/BiasAdd
Mul_807
	2.25
add_202
bert/encoder/layer_8/output/dense/kernel/adam_m/read
add_318
add_568
Square_50
	0.0029296875
add_521
bert/embeddings/word_embeddings
add_387
Assign_308
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Sum
	0.015625
Sqrt_170
	0.0029296875
add_446
mul_612
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.016357421875
bert/encoder/layer_0/attention/self/query/kernel/adam_m
mul_520
	9.0
Assign_317
Sqrt_41
	2.25
Mul_115
	0.0029296875
gradients/cls/seq_relationship/LogSoftmax_grad/Sum
	0.000244140625
bert/encoder/layer_6/attention/self/key/kernel/adam_v
mul_832
	2.25
bert/encoder/layer_6/attention/self/dropout/GreaterEqual
	6.0
Assign_113
bert/encoder/layer_0/intermediate/dense/mul
Mul_406
	0.0029296875
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
Mul_597
	0.0029296875
Assign_229
Sqrt_58
	0.0029296875
Sqrt_185
	2.25
bert/encoder/layer_8/attention/self/query/kernel/adam_m
add_326
mul_790
Mul_49
	0.0029296875
bert/encoder/layer_5/attention/output/LayerNorm/gamma
Assign_602
bert/encoder/layer_4/attention/self/transpose_2
	12.0
global_norm/L2Loss_96
	0.000244140625
Assign_580
add_149
global_norm/L2Loss_199
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/mean_grad/Tile
	15.75
sub_67
sub_184
Square_193
bert/encoder/layer_1/output/dense/bias
Sqrt_54
	0.003173828125
Assign_307
Assign_600
add_177
bert/encoder/layer_5/output/dense/kernel/adam_m/read
gradients/bert/embeddings/Reshape_1_grad/Reshape
bert/encoder/layer_1/attention/self/transpose_2
	12.0
Assign_151
Sqrt_65
	9.0
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.015625
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Mul_1
bert/encoder/layer_6/attention/self/dropout/Cast
	24.0
bert/encoder/layer_8/attention/self/query/bias/read
bert/encoder/layer_10/attention/self/query/kernel/adam_v
bert/encoder/layer_9/output/LayerNorm/batchnorm/add
add_605
Assign_323
bert/encoder/layer_4/attention/self/key/kernel/adam_m/read
bert/encoder/layer_1/intermediate/dense/Pow
	48.0
bert/encoder/layer_4/output/dropout/Cast
	12.0
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
bert/encoder/layer_7/attention/output/dense/kernel/adam_v/read
Mul_417
	0.0029296875
Assign_458
bert/encoder/layer_7/output/dense/bias/adam_m
add_552
add_195
gradients/bert/encoder/layer_10/attention/self/Softmax_grad/mul_1
	24.0
add_485
bert/encoder/layer_4/intermediate/dense/MatMul
	48.0
Square_155
Assign_553
gradients/bert/encoder/layer_7/intermediate/dense/Pow_grad/mul
bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference
	12.0
cls/seq_relationship/Sum/reduction_indices
mul_950
	9.0
add_699/y
bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1
	12.0
Assign_258
Assign_99
Mul_867
	0.01171875
gradients/bert/encoder/layer_2/intermediate/dense/Pow_grad/mul_1
bert/encoder/layer_1/attention/output/dropout/Cast
	12.0
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v/read
bert/encoder/layer_4/intermediate/dense/mul_2
global_norm/L2Loss_38
	0.000244140625
Assign_356
gradients/bert/encoder/layer_1/output/dropout/mul_1_grad/Mul
	12.0
Assign_12
Mul_217
	2.25
Square_75
	3.75
gradients/bert/encoder/layer_6/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
Assign_526
Assign_94
bert/encoder/layer_2/attention/self/query/bias/adam_m/read
Assign_5
add_600
clip_by_global_norm/mul_91
gradients/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.01171875
Assign_564
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape
bert/encoder/layer_6/attention/self/Reshape_3
bert/embeddings/dropout/GreaterEqual
	3.0
Mul_583
	2.25
PolynomialDecay/Cast_2/ReadVariableOp
bert/encoder/layer_1/intermediate/dense/mul_3
Assign_515
bert/encoder/layer_4/attention/self/dropout/random_uniform
Mul_149
Assign_497
gradients/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Tile
	12.0
gradients/bert/encoder/layer_2/attention/self/Mul_grad/Mul
bert/encoder/layer_7/attention/output/dropout/mul
	12.0
bert/encoder/layer_4/intermediate/dense/BiasAdd
Mul_654
gradients/bert/encoder/layer_7/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
mul_758
bert/encoder/layer_6/attention/self/value/BiasAdd
Mul_1025
sub_58
bert/encoder/layer_4/attention/self/key/kernel
Assign_334
Assign_330
truediv_194
bert/encoder/layer_4/attention/self/query/bias/adam_m
bert/encoder/layer_0/attention/self/query/kernel
Assign_366
bert/encoder/layer_10/attention/output/LayerNorm/moments/mean
	0.015625
edge_1734_cls/seq_relationship/Reshape@@MemcpyHtoD
bert/encoder/layer_0/intermediate/dense/kernel/adam_m/read
Mul_336
	0.0029296875
gradients/bert/encoder/layer_4/output/LayerNorm/moments/variance_grad/Tile
	12.0
mul_660
	2.25
Assign_388
Mul_624
	0.0029296875
clip_by_global_norm/mul_63
add_274
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum
	0.017333984375
bert/encoder/layer_2/attention/self/Reshape_2
Assign_115
truediv_176
bert/encoder/layer_9/attention/self/query/bias/adam_v
sub_102
Assign_537
add_683
Mul_954
	0.01171875
global_norm/L2Loss_13
	0.000244140625
gradients/cls/predictions/LogSoftmax_grad/Exp
	74.5166015625
gradients/bert/encoder/layer_5/attention/self/query/MatMul_grad/MatMul
	12.0
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m
gradients/bert/encoder/layer_6/attention/self/Reshape_grad/Reshape
gradients/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul
	12.0
Sqrt_67
	0.0029296875
Sqrt_29
	0.0029296875
add_452
bert/encoder/layer_2/intermediate/dense/kernel/adam_v/read
bert/encoder/layer_6/intermediate/dense/kernel/read
bert/encoder/layer_1/attention/self/query/bias
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	15.75
add_329
gradients/bert/encoder/layer_11/intermediate/dense/BiasAdd_grad/BiasAddGrad
	0.0126953125
Mul_837
Assign_519
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add
clip_by_global_norm/mul_155
gradients/AddN_67
gradients/AddN_46
bert/encoder/layer_6/attention/output/dropout/random_uniform
Assign_555
bert/encoder/layer_3/attention/output/add
bert/encoder/layer_1/intermediate/dense/Tanh
Assign_242
Mul_439
Assign_238
mul_1042
bert/encoder/layer_5/output/dropout/GreaterEqual
	3.0
add_35
Assign_413
Assign_461
bert/encoder/layer_3/attention/self/Reshape_2
add_437
Mul_332
bert/embeddings/LayerNorm/beta/adam_v
gradients/bert/encoder/layer_6/intermediate/dense/MatMul_grad/MatMul_1
	12.0
mul_500
add_579
bert/encoder/layer_2/attention/self/add
Square_52
	0.0029296875
mul_107
mul_328
Mul_213
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Mul_1
Assign_292
Mul_743
	2.25
bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1
Mul_82
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
bert/encoder/layer_2/output/dense/kernel/read
mul_203
bert/embeddings/MatMul
	12.0
bert/encoder/layer_0/output/LayerNorm/gamma/adam_v
gradients/bert/encoder/layer_7/intermediate/dense/mul_3_grad/Mul
sub_143
gradients/bert/encoder/layer_2/attention/self/Reshape_3_grad/Reshape
Sqrt_7
	2.25
Square_168
	0.0029296875
Square_93
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2_grad/Reshape
global_norm/L2Loss_159
	0.000244140625
	0.012451171875
add_198
sub_19
add_369
gradients/cls/predictions/mul_grad/Mul
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m/read
bert/encoder/layer_7/attention/self/Mul
truediv_137
bert/encoder/layer_10/intermediate/dense/bias/adam_v
Assign_243
bert/encoder/layer_7/output/dense/bias/read
gradients/bert/encoder/layer_9/intermediate/dense/Pow_grad/Pow
	48.0
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
bert/encoder/layer_5/output/LayerNorm/batchnorm/sub
gradients/AddN_20
Sqrt_56
	0.0029296875
bert/encoder/layer_11/attention/output/dense/kernel/adam_v/read
gradients/bert/encoder/layer_5/intermediate/dense/mul_2_grad/Mul_1
bert/encoder/layer_6/intermediate/dense/bias/adam_m/read
bert/encoder/layer_7/output/add
bert/embeddings/Slice/begin
mul_929
	2.25
add_661
add_190
bert/encoder/layer_8/intermediate/dense/kernel/adam_v
mul_156
gradients/cls/predictions/transform/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
mul_209
bert/encoder/layer_7/attention/self/add
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/variance_grad/truediv
sub_118
truediv_98
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
gradients/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference_grad/Mul
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar
bert/encoder/layer_10/attention/output/dense/kernel/adam_v
sub_13
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	17.25
Assign_291
Square_92
	0.0029296875
Sqrt_28
	0.0029296875
bert/encoder/layer_7/output/dense/MatMul
	12.0
Assign_582
bert/encoder/layer_11/attention/self/query/kernel/read
Assign_484
bert/encoder/layer_9/attention/self/key/kernel/adam_m
clip_by_global_norm/mul_29
bert/encoder/layer_9/attention/self/value/bias/adam_m/read
Sqrt_24
	0.0029296875
add_73
Assign_237
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Mul_1
Assign_261
bert/embeddings/position_embeddings/adam_m/read
gradients/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference_grad/Mul
Assign_268
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
sub_15
bert/encoder/layer_10/attention/self/value/bias/adam_v
mul_461
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
Assign_33
Mul_845
	0.0029296875
bert/encoder/layer_2/attention/self/query/MatMul
	12.0
Assign_165
global_norm/L2Loss_12
	0.000244140625
bert/encoder/layer_2/attention/output/LayerNorm/beta/read
gradients/AddN_55
Square_14
	0.0029296875
Assign_272
sub_147
Mul_733
	2.25
gradients/AddN_30
bert/encoder/layer_4/attention/output/dense/kernel/adam_m
Mul_459
	0.0029296875
gradients/bert/encoder/layer_3/attention/output/dense/BiasAdd_grad/BiasAddGrad
	0.0029296875
Sqrt_100
	0.0029296875
gradients/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Mul
clip_by_global_norm/mul_99
Assign_381
Mul_923
bert/encoder/layer_3/intermediate/dense/kernel/adam_m
Assign_149
global_norm/L2Loss_150
	0.000244140625
bert/encoder/layer_0/output/dense/bias/adam_v
gradients/bert/encoder/layer_3/attention/output/dense/MatMul_grad/MatMul_1
	2.25
add_69
bert/encoder/layer_2/attention/output/LayerNorm/moments/mean
	0.015625
add_344
truediv_104
bert/encoder/layer_8/attention/self/key/MatMul
	12.0
add_459
clip_by_global_norm/mul_68
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
global_norm/L2Loss_139
	0.000244140625
	0.0087890625
gradients/bert/encoder/layer_4/attention/self/Softmax_grad/mul
bert/encoder/layer_0/intermediate/dense/mul_1/x
gradients/AddN_16
Assign_547
cls/predictions/transform/LayerNorm/gamma/adam_m
add_308
bert/encoder/layer_4/intermediate/dense/Pow
	48.0
add_371
bert/encoder/layer_1/attention/self/query/kernel/read
bert/encoder/layer_0/output/LayerNorm/gamma/read
Mul_334
	0.0029296875
gradients/bert/encoder/layer_9/attention/self/query/MatMul_grad/MatMul_1
	2.25
Assign_373
add_658
Mul_202
gradients/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
bert/encoder/layer_2/intermediate/dense/bias/adam_v
bert/pooler/dense/Tanh
gradients/bert/encoder/layer_11/attention/self/Softmax_grad/sub
Assign_53
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v
Mul_1073
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
Sqrt_150
	0.0029296875
bert/encoder/layer_10/attention/self/query/bias/read
bert/encoder/layer_6/attention/self/transpose_3
	12.0
Square_144
gradients/cls/predictions/Sum_1_grad/Tile
	0.00244140625
mul_510
Sqrt_184
	0.0029296875
bert/encoder/layer_7/attention/self/value/kernel
add_193
cls/predictions/add/y
Square_110
add_47
add_182
bert/encoder/layer_8/attention/self/value/bias/adam_v/read
bert/encoder/layer_4/attention/self/key/kernel/read
sub_122
gradients/bert/encoder/layer_9/attention/self/Softmax_grad/sub
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul
gradients/bert/encoder/layer_8/intermediate/dense/mul_2_grad/Mul_1
mul_1021
bert/encoder/layer_1/output/dense/kernel/adam_v
add_83
Mul_35
add_161
bert/embeddings/LayerNorm/gamma/adam_v
add_613
Assign_10
bert/encoder/layer_0/attention/self/Reshape_3/shape
Mul_635
	2.25
Assign_350
truediv_198
bert/encoder/layer_2/attention/self/key/bias/adam_m/read
bert/encoder/layer_2/intermediate/dense/mul_3
add_500
bert/encoder/layer_7/attention/self/key/BiasAdd
bert/encoder/layer_5/output/LayerNorm/beta
bert/encoder/layer_9/output/LayerNorm/gamma/adam_m/read
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v/read
Mul_975
	0.0029296875
bert/encoder/layer_2/attention/self/key/kernel/read
bert/encoder/layer_10/intermediate/dense/Tanh
Mul_476
Assign_442
Sqrt_117
	2.25
bert/encoder/layer_10/output/LayerNorm/batchnorm/add
Mul_605
bert/encoder/layer_5/attention/self/key/bias/adam_m
bert/encoder/layer_5/attention/self/query/kernel/adam_v
Assign_29
add_698
truediv_115
Mul_409
	2.25
bert/encoder/layer_10/attention/output/dense/kernel
bert/encoder/layer_3/intermediate/dense/mul_3
add_112
bert/encoder/layer_6/attention/output/add
global_norm/L2Loss_181
	0.000244140625
	0.0087890625
bert/encoder/layer_6/attention/output/LayerNorm/gamma
global_norm/L2Loss_114
	0.000244140625
mul_70
truediv_35
Mul_517
	9.0
gradients/bert/encoder/layer_3/attention/self/Mul_grad/Mul
Sqrt_91
	2.25
bert/encoder/layer_4/intermediate/dense/kernel/adam_v/read
bert/encoder/layer_3/attention/output/dense/bias/adam_m
bert/encoder/layer_4/attention/self/value/kernel/adam_m/read
bert/encoder/layer_11/output/LayerNorm/batchnorm/add
cls/predictions/transform/dense/Tanh
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v/read
Assign_439
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
gradients/bert/encoder/layer_3/attention/self/key/MatMul_grad/MatMul_1
	2.25
bert/encoder/layer_4/output/LayerNorm/batchnorm/mul
	12.0
bert/encoder/layer_4/attention/output/dense/kernel/adam_v
bert/encoder/layer_4/attention/output/add
bert/embeddings/LayerNorm/moments/SquaredDifference
	12.0
bert/encoder/layer_5/intermediate/dense/Pow
	48.0
mul_102
Mul_73
	0.0029296875
bert/encoder/layer_8/attention/output/dense/bias/adam_v
gradients/bert/encoder/layer_10/attention/output/dropout/mul_grad/Mul
gradients/bert/encoder/layer_8/attention/self/Reshape_2_grad/Reshape
truediv_152
mul_456
sub_129
add_210
bert/encoder/layer_10/attention/output/dense/bias/adam_m/read
Mul_534
bert/encoder/layer_2/intermediate/dense/Tanh
Assign_353
bert/encoder/layer_1/attention/self/Reshape_3
bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference
	12.0
bert/encoder/layer_1/attention/self/value/bias/adam_m/read
bert/encoder/layer_9/attention/self/Reshape_1
Mul_226
	2.25
truediv_155
Mul_1000
	2.25
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1
	0.0029296875
Mul_675
	0.0029296875
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape
Sqrt_109
	0.0029296875
Assign_365
gradients/AddN_88
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/sub
Mul_766
	0.0029296875
add_230
bert/encoder/layer_6/attention/self/key/kernel/adam_m/read
bert/encoder/layer_11/intermediate/dense/kernel/adam_v
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1
Assign_603
sub_22
sub_173
Assign_583
Mul_471
edge_1725_bert/encoder/Reshape@@MemcpyHtoD
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul
	12.0
Assign_73
gradients/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Mul
clip_by_global_norm/mul_127
bert/encoder/layer_10/attention/self/Reshape_2
truediv_68
gradients/bert/encoder/layer_9/attention/self/key/BiasAdd_grad/BiasAddGrad
	0.0029296875
Square_90
	0.0029296875
bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1
global_norm/L2Loss_204
	0.000244140625
Mul_151
	2.25
add_188
Square_130
bert/encoder/layer_9/attention/self/key/bias/adam_v
clip_by_global_norm/mul_33
sub_185
Assign_506
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Tile
	12.0
gradients/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad
	0.0029296875
bert/encoder/layer_4/output/LayerNorm/gamma/adam_m
clip_by_global_norm/mul_12
gradients/bert/encoder/layer_2/attention/self/transpose_3_grad/transpose
	12.0
Mul_853
bert/encoder/layer_7/attention/self/query/bias/adam_v
add_588
global_norm/L2Loss_55
	0.000244140625
	0.013916015625
Assign_534
Mul_260
	9.0
add_126
bert/encoder/layer_10/intermediate/dense/MatMul
	48.0
Mul_889
	0.0029296875
add_94
Assign_405
Square_126
bert/encoder/layer_7/intermediate/dense/bias/adam_v/read
truediv_70
gradients/bert/encoder/layer_7/intermediate/dense/Tanh_grad/TanhGrad
Square_36
	0.0029296875
add_377
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/sub_grad/Sum
	0.0029296875
Assign_502
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
bert/encoder/layer_10/intermediate/dense/mul_1
add_654
global_norm/L2Loss_23
	0.000244140625
	0.011962890625
bert/encoder/layer_10/attention/self/add
Assign_513
bert/encoder/layer_5/attention/self/key/bias/adam_m/read
gradients/bert/encoder/layer_8/attention/self/transpose_2_grad/transpose
	12.0
Mul_978
	2.25
bert/encoder/layer_7/attention/self/key/kernel/read
global_norm/L2Loss_177
	0.000244140625
	0.012451171875
Mul_184
gradients/bert/embeddings/dropout/mul_1_grad/Mul
clip_by_global_norm/mul_128
bert/encoder/layer_9/attention/output/dense/bias
bert/encoder/layer_3/output/LayerNorm/gamma/adam_v/read
mul_21
add_514
global_norm/L2Loss_134
	0.000244140625
add_7
Mul_475
	2.25
Assign_594
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1
bert/encoder/layer_0/output/dense/kernel/adam_v
clip_by_global_norm/mul_17
mul_31
bert/encoder/layer_7/attention/output/dense/bias/adam_v/read
cls/seq_relationship/output_bias/adam_v/read
gradients/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference_grad/scalar
gradients/bert/encoder/layer_6/intermediate/dense/mul_3_grad/Mul_1
	48.0
bert/encoder/layer_10/attention/self/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
global_norm/L2Loss_138
	0.000244140625
global_norm/Sum
	0.000244140625
bert/encoder/layer_0/attention/self/key/kernel/adam_v
bert/encoder/layer_7/output/dense/kernel/adam_v/read
Square_59
	2.25
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Mul
	12.0
truediv_149
bert/encoder/layer_10/attention/self/query/bias/adam_m/read
Square_9
	2.25
bert/encoder/layer_5/output/dropout/mul_1
sub_14
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub_grad/Neg
	12.0
mul_886
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v
Mul_23
mul_295
bert/encoder/layer_7/output/LayerNorm/gamma
bert/encoder/layer_10/output/dropout/random_uniform/mul
truediv_14
Assign_471
mul_924
bert/encoder/layer_4/attention/self/transpose_3
	12.0
Mul_210
	0.0029296875
Assign_175
add_85
bert/encoder/layer_4/attention/self/value/MatMul
	12.0
add_346
bert/encoder/layer_0/output/LayerNorm/moments/mean
	0.015625
gradients/bert/embeddings/Slice_grad/concat
add_403
mul_532
bert/encoder/layer_2/attention/self/transpose
	12.0
bert/encoder/layer_6/intermediate/dense/mul_3
add_87
gradients/bert/encoder/layer_11/attention/self/dropout/mul_grad/Mul
add_294
Mul_1017
	0.0029296875
Assign_309
Mul_836
	0.0029296875
bert/encoder/layer_8/attention/self/value/kernel/read
bert/encoder/layer_1/attention/output/dense/kernel/adam_v/read
add_431
sub_53
bert/encoder/layer_7/attention/output/dense/kernel/adam_m
bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2
	12.0
add_539
gradients/AddN_19
PolynomialDecay/Minimum
add_682
bert/encoder/layer_3/attention/self/query/kernel/adam_m
Assign_509
bert/encoder/layer_6/attention/output/LayerNorm/beta
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul_1
	12.0
clip_by_global_norm/mul_165
Mul_1051
	0.0029296875
bert/encoder/layer_8/intermediate/dense/mul_3
Mul_350
	0.01171875
Mul_947
bert/encoder/layer_7/attention/self/value/kernel/read
mul_273
	9.0
Assign_120
add_232
Assign_298
Assign_1
gradients/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference_grad/scalar
Mul_1028
	0.0029296875
gradients/bert/encoder/layer_0/attention/self/transpose_3_grad/transpose
	12.0
gradients/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference_grad/Mul
bert/encoder/layer_10/attention/self/key/bias/adam_m/read
bert/encoder/layer_2/attention/self/value/bias/adam_v
add_415
add_471
gradients/bert/encoder/layer_7/attention/self/MatMul_1_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
Square_139
bert/encoder/layer_0/attention/self/key/kernel
clip_by_global_norm/mul_180
Assign_48
truediv_183
add_296
add_589
clip_by_global_norm/mul_36
Mul_726
	0.0029296875
truediv_55
bert/encoder/layer_11/output/LayerNorm/beta/adam_m
bert/encoder/layer_3/attention/self/transpose_2
	12.0
bert/encoder/layer_4/output/LayerNorm/gamma/read
bert/encoder/layer_9/attention/self/query/bias
gradients/bert/encoder/layer_9/attention/self/MatMul_grad/MatMul_1
	12.0
	0.0029296875
	0.0029296875
	0.0029296875
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul
add_445
bert/encoder/layer_11/output/LayerNorm/batchnorm/sub
bert/encoder/layer_0/intermediate/dense/mul_3
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub
Mul_974
cls/seq_relationship/output_weights/adam_m/read
Mul_541
sub_96
bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1
	12.0
clip_by_global_norm/mul_189
Mul_298
	0.0029296875
mul_994
bert/encoder/layer_5/attention/output/dense/BiasAdd
Sqrt_144
	0.01171875
Assign_599
bert/encoder/layer_11/output/dense/bias/adam_m/read
global_norm/L2Loss_170
	0.000244140625
sub_34
gradients/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference_grad/sub
bert/encoder/layer_10/intermediate/dense/BiasAdd
Assign_14
bert/encoder/layer_8/output/LayerNorm/beta
Square_116
add_226
mul_392
Assign_217
mul_354
