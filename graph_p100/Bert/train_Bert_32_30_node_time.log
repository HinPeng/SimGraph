edge_3447_Reshape_1@@MemcpyHtoD	-1	-1	-1	1608802723824885	86
edge_1822_bert/embeddings/Reshape@@MemcpyHtoD	-1	-1	-1	1608802723825431	41
edge_1721_bert/embeddings/Reshape_2@@MemcpyHtoD	-1	-1	-1	1608802723825701	29
edge_1725_cls/predictions/Reshape@@MemcpyHtoD	-1	-1	-1	1608802723825854	48
edge_686_IteratorGetNext@@MemcpyHtoD	-1	-1	-1	1608802723826034	65
edge_1731_cls/seq_relationship/Reshape@@MemcpyHtoD	-1	-1	-1	1608802723826789	6
edge_13_bert/embeddings/assert_less_equal/All@@MemcpyDtoH	-1	-1	-1	1608802723837021	20
edge_1735_bert/encoder/Reshape@@MemcpyHtoD	-1	-1	-1	1608802723862047	6
edge_1712_Cast@@MemcpyDtoH	-1	-1	-1	1608802723862176	17
edge_1817_Less@@MemcpyHtoD	-1	-1	-1	1608802723862500	57
global_step/add/_2560	-1	-1	-1	1608802723868070	3
add_1/_2558	-1	-1	-1	1608802724044533	8
_SOURCE	1608802723814378	1608802723814493	0	-1	-1
bert/encoder/layer_5/attention/output/dense/kernel/adam_v	1608802723815395	1608802723815431	902	-1	-1
global_step	1608802723815472	1608802723815484	41	-1	-1
bert/embeddings/Reshape_1/shape	1608802723815492	1608802723815518	8	-1	-1
bert/embeddings/assert_less_equal/y	1608802723815524	1608802723815531	6	-1	-1
bert/embeddings/assert_less_equal/All	1608802723815534	1608802723815544	3	-1	-1
bert/encoder/layer_0/attention/self/key/kernel	1608802723815552	1608802723815577	8	-1	-1
bert/encoder/ones/shape_as_tensor	1608802723815581	1608802723815596	4	-1	-1
bert/embeddings/dropout/truediv	1608802723815602	1608802723815664	6	-1	-1
bert/encoder/layer_6/attention/self/key/kernel/adam_m	1608802723815669	1608802723815685	5	-1	-1
bert/encoder/layer_0/attention/self/ExpandDims/dim	1608802723815695	1608802723815751	10	-1	-1
bert/embeddings/position_embeddings	1608802723815754	1608802723815766	3	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/gamma	1608802723815772	1608802723815786	6	-1	-1
bert/encoder/layer_6/attention/self/value/kernel/adam_v	1608802723815796	1608802723815808	10	-1	-1
mul_552/x	1608802723815811	1608802723815841	3	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/beta	1608802723815848	1608802723815858	7	-1	-1
bert/encoder/layer_1/output/LayerNorm/beta	1608802723815875	1608802723815893	17	-1	-1
bert/encoder/layer_2/attention/self/value/kernel	1608802723815905	1608802723815918	12	-1	-1
bert/encoder/layer_0/attention/output/dense/kernel	1608802723815925	1608802723815942	7	-1	-1
bert/encoder/layer_2/attention/self/query/bias	1608802723815950	1608802723815958	8	-1	-1
bert/encoder/layer_2/attention/self/value/bias	1608802723815962	1608802723815972	4	-1	-1
bert/encoder/layer_1/attention/self/key/kernel	1608802723815985	1608802723815996	13	-1	-1
bert/encoder/layer_1/output/dense/bias	1608802723816002	1608802723816011	6	-1	-1
bert/encoder/layer_0/attention/output/dense/bias	1608802723816016	1608802723816025	5	-1	-1
Mul_546/x	1608802723816029	1608802723816083	4	-1	-1
bert/encoder/layer_0/output/LayerNorm/beta	1608802723816087	1608802723816099	4	-1	-1
bert/encoder/layer_1/attention/self/key/bias	1608802723816101	1608802723816109	2	-1	-1
bert/encoder/layer_7/attention/output/dense/bias	1608802723816112	1608802723816127	3	-1	-1
bert/encoder/layer_7/attention/self/query/bias/adam_v	1608802723816132	1608802723816144	5	-1	-1
bert/encoder/layer_7/output/dense/kernel	1608802723816150	1608802723816162	6	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/beta	1608802723816168	1608802723816180	6	-1	-1
bert/encoder/layer_8/output/dense/kernel	1608802723816186	1608802723816196	6	-1	-1
bert/encoder/layer_9/attention/self/key/kernel	1608802723816203	1608802723816213	7	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/beta	1608802723816217	1608802723816225	4	-1	-1
bert/encoder/layer_9/output/LayerNorm/beta	1608802723816229	1608802723816236	4	-1	-1
bert/encoder/layer_10/attention/self/value/kernel	1608802723816243	1608802723816252	7	-1	-1
bert/encoder/layer_10/intermediate/dense/kernel	1608802723816255	1608802723816268	3	-1	-1
bert/encoder/layer_11/attention/self/query/bias	1608802723816273	1608802723816281	5	-1	-1
bert/encoder/layer_11/attention/output/dense/bias	1608802723816286	1608802723816294	5	-1	-1
bert/encoder/layer_11/intermediate/dense/bias	1608802723816298	1608802723816306	4	-1	-1
bert/pooler/strided_slice/stack	1608802723816311	1608802723816319	5	-1	-1
bert/encoder/layer_7/intermediate/dense/bias/adam_m	1608802723816323	1608802723816332	4	-1	-1
cls/predictions/one_hot/depth	1608802723816338	1608802723816347	6	-1	-1
Const_2	1608802723816350	1608802723816384	3	-1	-1
bert/encoder/layer_7/output/dense/bias/adam_m	1608802723816388	1608802723816399	4	-1	-1
gradients/cls/predictions/transform/dense/mul_grad/Mul_1	1608802723816404	1608802723816416	5	-1	-1
bert/encoder/layer_8/attention/self/query/kernel/adam_v	1608802723816419	1608802723816427	3	-1	-1
cls/seq_relationship/output_weights/adam_m	1608802723816431	1608802723816443	4	-1	-1
bert/encoder/layer_8/attention/output/dense/bias/adam_m	1608802723816448	1608802723816456	5	-1	-1
bert/encoder/layer_8/attention/self/query/bias/adam_m	1608802723816458	1608802723816466	2	-1	-1
gradients/bert/pooler/Squeeze_grad/Shape	1608802723816470	1608802723816479	4	-1	-1
bert/encoder/layer_7/output/LayerNorm/gamma/adam_m	1608802723816481	1608802723816492	2	-1	-1
bert/encoder/layer_11/output/dense/bias/adam_v	1608802723816500	1608802723816511	8	-1	-1
bert/encoder/layer_8/attention/self/value/kernel/adam_m	1608802723816513	1608802723816528	2	-1	-1
bert/encoder/layer_8/attention/output/dense/bias/adam_v	1608802723816531	1608802723816543	3	-1	-1
bert/encoder/layer_9/output/LayerNorm/gamma	1608802723816549	1608802723816557	6	-1	-1
bert/encoder/layer_9/attention/output/dense/bias/adam_m	1608802723816562	1608802723816574	5	-1	-1
bert/encoder/layer_8/attention/self/key/kernel	1608802723816581	1608802723816594	7	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m	1608802723816596	1608802723816606	2	-1	-1
bert/encoder/layer_8/output/dense/bias	1608802723816612	1608802723816621	6	-1	-1
bert/encoder/layer_9/attention/self/key/bias	1608802723816625	1608802723816637	4	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/gamma	1608802723816640	1608802723816652	3	-1	-1
cls/predictions/transform/dense/bias	1608802723816658	1608802723816665	6	-1	-1
bert/encoder/layer_10/attention/self/value/bias	1608802723816669	1608802723816676	4	-1	-1
bert/encoder/layer_11/intermediate/dense/kernel/adam_m	1608802723816682	1608802723816690	6	-1	-1
bert/encoder/layer_11/intermediate/dense/bias/adam_m	1608802723816696	1608802723816706	6	-1	-1
bert/encoder/layer_11/intermediate/dense/kernel/adam_v	1608802723816708	1608802723816719	2	-1	-1
bert/encoder/layer_11/output/dense/kernel	1608802723816722	1608802723816735	3	-1	-1
bert/pooler/strided_slice/stack_1	1608802723816739	1608802723816747	4	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m	1608802723816751	1608802723816761	4	-1	-1
cls/predictions/Const	1608802723816766	1608802723816789	5	-1	-1
truediv	1608802723816794	1608802723816804	5	-1	-1
bert/encoder/layer_9/attention/self/query/kernel/adam_m	1608802723816807	1608802723816817	3	-1	-1
bert/encoder/layer_7/output/LayerNorm/gamma/adam_v	1608802723816820	1608802723816828	3	-1	-1
bert/encoder/layer_8/attention/self/query/bias/adam_v	1608802723816838	1608802723816847	10	-1	-1
bert/encoder/layer_11/output/dense/kernel/adam_v	1608802723816853	1608802723816862	6	-1	-1
bert/pooler/strided_slice/stack_2	1608802723816869	1608802723816879	7	-1	-1
bert/encoder/layer_8/intermediate/dense/kernel/adam_m	1608802723816882	1608802723816896	3	-1	-1
cls/seq_relationship/output_weights/adam_v	1608802723816900	1608802723816910	4	-1	-1
bert/encoder/layer_10/attention/self/query/kernel	1608802723816916	1608802723816924	6	-1	-1
bert/encoder/layer_11/output/LayerNorm/gamma/adam_v	1608802723816927	1608802723816934	3	-1	-1
bert/encoder/layer_9/attention/output/dense/bias/adam_v	1608802723816937	1608802723816946	3	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v	1608802723816949	1608802723816960	3	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m	1608802723816965	1608802723816974	5	-1	-1
bert/encoder/layer_11/output/dense/bias	1608802723816978	1608802723816986	4	-1	-1
bert/encoder/layer_8/intermediate/dense/kernel/adam_v	1608802723816988	1608802723816997	2	-1	-1
cls/predictions/transform/LayerNorm/beta	1608802723817000	1608802723817010	3	-1	-1
bert/encoder/layer_7/attention/self/value/kernel/adam_v	1608802723817014	1608802723817023	4	-1	-1
bert/encoder/layer_7/attention/self/value/bias/adam_m	1608802723817027	1608802723817034	4	-1	-1
bert/encoder/layer_7/output/dense/bias/adam_v	1608802723817040	1608802723817047	6	-1	-1
bert/encoder/layer_10/attention/output/dense/kernel	1608802723817049	1608802723817059	2	-1	-1
bert/encoder/layer_7/attention/output/dense/bias/adam_v	1608802723817064	1608802723817071	5	-1	-1
bert/encoder/layer_8/attention/self/value/kernel/adam_v	1608802723817076	1608802723817085	5	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v	1608802723817088	1608802723817098	3	-1	-1
bert/encoder/layer_11/output/LayerNorm/beta	1608802723817100	1608802723817109	2	-1	-1
bert/encoder/layer_11/output/LayerNorm/beta/adam_m	1608802723817112	1608802723817119	3	-1	-1
bert/encoder/layer_9/attention/self/query/kernel/adam_v	1608802723817123	1608802723817131	4	-1	-1
cls/predictions/add/y	1608802723817133	1608802723817146	2	-1	-1
gradients/cls/predictions/Sum_1_grad/Const	1608802723817149	1608802723817159	3	-1	-1
bert/encoder/layer_9/intermediate/dense/kernel	1608802723817163	1608802723817172	4	-1	-1
gradients/cls/predictions/transform/dense/Pow_grad/sub	1608802723817175	1608802723817187	3	-1	-1
bert/encoder/layer_8/attention/self/key/kernel/adam_m	1608802723817191	1608802723817199	4	-1	-1
bert/encoder/layer_10/intermediate/dense/bias	1608802723817201	1608802723817209	2	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m	1608802723817213	1608802723817220	4	-1	-1
bert/encoder/layer_8/intermediate/dense/bias/adam_m	1608802723817223	1608802723817230	3	-1	-1
bert/encoder/layer_8/output/dense/bias/adam_v	1608802723817233	1608802723817242	3	-1	-1
bert/pooler/dense/kernel	1608802723817247	1608802723817257	5	-1	-1
bert/encoder/layer_9/attention/self/key/bias/adam_v	1608802723817260	1608802723817268	3	-1	-1
bert/pooler/dense/kernel/adam_m	1608802723817271	1608802723817280	3	-1	-1
bert/encoder/layer_7/output/dense/kernel/adam_m	1608802723817285	1608802723817293	5	-1	-1
bert/encoder/layer_7/output/LayerNorm/beta/adam_m	1608802723817297	1608802723817305	4	-1	-1
gradients/Reshape_2_grad/Reshape/strided_slice	1608802723817310	1608802723817318	5	-1	-1
bert/encoder/layer_10/attention/self/query/bias	1608802723817322	1608802723817332	4	-1	-1
bert/encoder/layer_10/attention/output/dense/bias	1608802723817335	1608802723817342	3	-1	-1
bert/encoder/layer_11/output/dense/bias/adam_m	1608802723817346	1608802723817354	4	-1	-1
bert/encoder/layer_8/intermediate/dense/bias/adam_v	1608802723817357	1608802723817364	3	-1	-1
bert/encoder/layer_8/output/LayerNorm/beta/adam_m	1608802723817368	1608802723817375	4	-1	-1
bert/encoder/layer_9/attention/self/query/bias/adam_m	1608802723817380	1608802723817388	5	-1	-1
bert/encoder/layer_9/attention/self/value/kernel/adam_m	1608802723817392	1608802723817402	4	-1	-1
cls/predictions/transform/LayerNorm/gamma	1608802723817404	1608802723817412	2	-1	-1
cls/seq_relationship/output_weights	1608802723817414	1608802723817423	2	-1	-1
bert/encoder/layer_7/output/dense/kernel/adam_v	1608802723817425	1608802723817433	2	-1	-1
gradients/cls/predictions/transform/LayerNorm/moments/variance_grad/Tile/multiples	1608802723817437	1608802723817456	4	-1	-1
bert/encoder/layer_8/attention/self/query/kernel/adam_m	1608802723817458	1608802723817468	2	-1	-1
bert/encoder/layer_8/attention/self/key/kernel/adam_v	1608802723817470	1608802723817479	2	-1	-1
bert/encoder/layer_8/attention/self/value/bias/adam_m	1608802723817481	1608802723817488	2	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v	1608802723817492	1608802723817500	4	-1	-1
bert/encoder/layer_8/output/dense/kernel/adam_m	1608802723817504	1608802723817511	4	-1	-1
bert/encoder/layer_11/output/LayerNorm/beta/adam_v	1608802723817514	1608802723817522	3	-1	-1
bert/encoder/layer_9/attention/self/query/bias/adam_v	1608802723817527	1608802723817535	5	-1	-1
bert/encoder/layer_9/attention/self/value/kernel/adam_v	1608802723817538	1608802723817546	3	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m	1608802723817550	1608802723817559	4	-1	-1
bert/encoder/layer_7/intermediate/dense/bias/adam_v	1608802723817562	1608802723817572	3	-1	-1
cls/seq_relationship/output_bias	1608802723817577	1608802723817584	5	-1	-1
gradients/cls/predictions/Sum_grad/Reshape/shape	1608802723817587	1608802723817595	3	-1	-1
bert/encoder/layer_7/output/LayerNorm/beta/adam_v	1608802723817599	1608802723817607	4	-1	-1
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Reshape/shape	1608802723817609	1608802723817625	2	-1	-1
bert/encoder/layer_8/attention/self/key/bias/adam_m	1608802723817629	1608802723817637	4	-1	-1
bert/encoder/layer_8/attention/self/value/bias/adam_v	1608802723817639	1608802723817646	2	-1	-1
add_344/y	1608802723817649	1608802723817686	3	-1	-1
bert/encoder/layer_8/output/dense/kernel/adam_v	1608802723817691	1608802723817699	5	-1	-1
bert/encoder/layer_8/output/LayerNorm/gamma/adam_v	1608802723817702	1608802723817709	3	-1	-1
bert/encoder/layer_9/attention/self/key/kernel/adam_m	1608802723817715	1608802723817723	6	-1	-1
bert/encoder/layer_9/attention/self/value/bias/adam_m	1608802723817727	1608802723817736	4	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v	1608802723817739	1608802723817746	3	-1	-1
bert/encoder/layer_0/intermediate/dense/kernel	1608802723817749	1608802723817756	3	-1	-1
bert/encoder/layer_0/output/LayerNorm/gamma	1608802723817761	1608802723817768	5	-1	-1
cls/seq_relationship/Sum/reduction_indices	1608802723817773	1608802723817782	5	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/gamma	1608802723817784	1608802723817791	2	-1	-1
bert/encoder/layer_1/output/LayerNorm/gamma	1608802723817794	1608802723817802	3	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/beta	1608802723817809	1608802723817819	7	-1	-1
bert/encoder/layer_11/output/dense/kernel/adam_m	1608802723817824	1608802723817834	5	-1	-1
bert/encoder/layer_8/attention/output/dense/kernel/adam_m	1608802723817836	1608802723817844	2	-1	-1
bert/encoder/layer_3/attention/output/dense/kernel	1608802723817849	1608802723817856	5	-1	-1
bert/encoder/layer_8/output/dense/bias/adam_m	1608802723817860	1608802723817876	4	-1	-1
bert/encoder/layer_8/output/LayerNorm/beta/adam_v	1608802723817880	1608802723817888	4	-1	-1
bert/encoder/layer_9/attention/self/key/bias/adam_m	1608802723817890	1608802723817898	2	-1	-1
bert/encoder/layer_9/attention/output/dense/kernel/adam_v	1608802723817900	1608802723817911	2	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m	1608802723817913	1608802723817921	2	-1	-1
bert/encoder/Reshape_1/shape	1608802723817926	1608802723817932	5	-1	-1
bert/encoder/layer_0/attention/self/value/kernel	1608802723817940	1608802723817947	8	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/beta	1608802723817953	1608802723817961	6	-1	-1
bert/encoder/layer_0/intermediate/dense/bias	1608802723817965	1608802723817975	4	-1	-1
bert/encoder/layer_1/attention/self/query/bias	1608802723817978	1608802723817986	3	-1	-1
bert/encoder/layer_1/attention/output/dense/kernel	1608802723817990	1608802723818000	4	-1	-1
bert/encoder/layer_1/output/dense/kernel	1608802723818003	1608802723818015	3	-1	-1
bert/encoder/layer_8/attention/self/key/bias/adam_v	1608802723818020	1608802723818027	5	-1	-1
bert/encoder/layer_8/attention/output/dense/kernel/adam_v	1608802723818031	1608802723818039	4	-1	-1
bert/encoder/layer_2/intermediate/dense/kernel	1608802723818048	1608802723818058	9	-1	-1
bert/encoder/layer_3/attention/self/query/kernel	1608802723818061	1608802723818068	3	-1	-1
bert/encoder/layer_8/output/LayerNorm/gamma/adam_m	1608802723818077	1608802723818088	9	-1	-1
bert/encoder/layer_11/output/LayerNorm/gamma/adam_m	1608802723818091	1608802723818100	3	-1	-1
bert/encoder/layer_9/attention/self/value/bias/adam_v	1608802723818102	1608802723818111	2	-1	-1
bert/pooler/dense/kernel/adam_v	1608802723818119	1608802723818133	8	-1	-1
bert/encoder/layer_6/attention/self/query/kernel/adam_m	1608802723818137	1608802723818145	4	-1	-1
bert/embeddings/assert_less_equal/x	1608802723818147	1608802723818155	2	-1	-1
bert/embeddings/LayerNorm/beta	1608802723818157	1608802723818166	2	-1	-1
bert/encoder/layer_6/attention/self/query/bias/adam_m	1608802723818168	1608802723818176	2	-1	-1
bert/encoder/layer_0/attention/self/value/bias	1608802723818179	1608802723818186	3	-1	-1
bert/encoder/layer_6/attention/self/key/kernel/adam_v	1608802723818200	1608802723818209	14	-1	-1
bert/encoder/layer_0/intermediate/dense/Pow/y	1608802723818212	1608802723818224	3	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v	1608802723818227	1608802723818239	3	-1	-1
bert/encoder/layer_1/attention/self/value/kernel	1608802723818242	1608802723818251	3	-1	-1
bert/encoder/layer_1/intermediate/dense/kernel	1608802723818253	1608802723818260	2	-1	-1
bert/encoder/layer_2/attention/self/query/kernel	1608802723818265	1608802723818277	5	-1	-1
bert/encoder/layer_6/attention/output/dense/kernel/adam_m	1608802723818282	1608802723818291	5	-1	-1
bert/encoder/layer_2/intermediate/dense/bias	1608802723818297	1608802723818306	6	-1	-1
bert/encoder/layer_9/attention/self/key/kernel/adam_v	1608802723818312	1608802723818320	6	-1	-1
bert/encoder/layer_9/attention/output/dense/kernel/adam_m	1608802723818323	1608802723818331	3	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v	1608802723818333	1608802723818344	2	-1	-1
bert/encoder/layer_4/attention/self/key/kernel	1608802723818348	1608802723818356	4	-1	-1
bert/encoder/layer_4/attention/output/dense/bias	1608802723818360	1608802723818372	4	-1	-1
Mul_1007/x	1608802723818376	1608802723818433	4	-1	-1
bert/embeddings/ExpandDims/dim	1608802723818436	1608802723818448	3	-1	-1
bert/embeddings/token_type_embeddings	1608802723818454	1608802723818462	6	-1	-1
bert/embeddings/LayerNorm/gamma	1608802723818465	1608802723818477	3	-1	-1
bert/encoder/layer_6/attention/self/query/bias/adam_v	1608802723818479	1608802723818488	2	-1	-1
bert/encoder/layer_0/attention/self/Reshape/shape	1608802723818493	1608802723818511	5	-1	-1
bert/encoder/layer_11/attention/output/dense/kernel/adam_m	1608802723818518	1608802723818528	7	-1	-1
bert/encoder/layer_0/intermediate/dense/mul/x	1608802723818531	1608802723818544	3	-1	-1
bert/encoder/layer_6/attention/self/key/bias/adam_m	1608802723818549	1608802723818562	5	-1	-1
bert/encoder/layer_1/attention/self/value/bias	1608802723818566	1608802723818573	4	-1	-1
bert/encoder/layer_1/intermediate/dense/bias	1608802723818577	1608802723818584	4	-1	-1
bert/encoder/layer_6/attention/self/value/bias/adam_m	1608802723818589	1608802723818602	5	-1	-1
bert/encoder/layer_6/attention/output/dense/kernel/adam_v	1608802723818608	1608802723818616	6	-1	-1
bert/encoder/layer_2/output/dense/kernel	1608802723818620	1608802723818628	4	-1	-1
bert/encoder/layer_3/attention/self/query/bias	1608802723818636	1608802723818645	8	-1	-1
bert/encoder/layer_3/attention/output/dense/bias	1608802723818647	1608802723818654	2	-1	-1
bert/encoder/layer_3/output/dense/kernel	1608802723818657	1608802723818669	3	-1	-1
bert/encoder/layer_4/attention/self/key/bias	1608802723818671	1608802723818679	2	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/beta	1608802723818683	1608802723818690	4	-1	-1
bert/encoder/layer_4/output/dense/bias	1608802723818695	1608802723818706	5	-1	-1
bert/encoder/layer_5/output/LayerNorm/gamma/adam_v	1608802723818711	1608802723818719	5	-1	-1
bert/encoder/layer_5/intermediate/dense/kernel	1608802723818721	1608802723818730	2	-1	-1
bert/embeddings/one_hot/on_value	1608802723818739	1608802723818751	9	-1	-1
bert/embeddings/LayerNorm/moments/mean/reduction_indices	1608802723818755	1608802723818761	4	-1	-1
bert/encoder/layer_0/attention/self/query/kernel	1608802723818764	1608802723818777	3	-1	-1
bert/encoder/layer_7/attention/self/query/kernel/adam_m	1608802723818781	1608802723818789	4	-1	-1
bert/encoder/layer_0/attention/self/dropout/Shape	1608802723818793	1608802723818804	4	-1	-1
bert/encoder/layer_0/intermediate/dense/mul_1/x	1608802723818829	1608802723818841	25	-1	-1
bert/encoder/layer_6/attention/self/key/bias/adam_v	1608802723818843	1608802723818853	2	-1	-1
bert/encoder/layer_1/attention/output/dense/bias	1608802723818856	1608802723818865	3	-1	-1
bert/encoder/layer_8/output/LayerNorm/beta	1608802723818869	1608802723818889	4	-1	-1
bert/encoder/layer_2/attention/self/key/kernel	1608802723818893	1608802723818904	4	-1	-1
bert/encoder/layer_2/attention/output/dense/kernel	1608802723818908	1608802723818916	4	-1	-1
bert/encoder/layer_2/output/dense/bias	1608802723818926	1608802723818933	10	-1	-1
bert/encoder/layer_3/attention/self/key/kernel	1608802723818939	1608802723818946	6	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/beta	1608802723818949	1608802723818965	3	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v	1608802723818967	1608802723818975	2	-1	-1
bert/encoder/layer_11/attention/output/dense/bias/adam_v	1608802723818980	1608802723818989	5	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/gamma	1608802723818991	1608802723819004	2	-1	-1
bert/encoder/layer_4/output/LayerNorm/beta	1608802723819007	1608802723819014	3	-1	-1
bert/encoder/layer_6/output/dense/kernel/adam_m	1608802723819016	1608802723819026	2	-1	-1
global_step/Initializer/zeros	1608802723819033	1608802723819041	7	-1	-1
bert/encoder/layer_5/output/LayerNorm/gamma	1608802723819043	1608802723819051	2	-1	-1
bert/encoder/layer_6/output/LayerNorm/beta/adam_v	1608802723819057	1608802723819070	6	-1	-1
bert/encoder/layer_6/intermediate/dense/bias	1608802723819073	1608802723819081	3	-1	-1
bert/encoder/layer_7/attention/self/key/kernel	1608802723819085	1608802723819094	4	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/beta	1608802723819096	1608802723819108	2	-1	-1
bert/encoder/layer_7/output/dense/bias	1608802723819111	1608802723819118	3	-1	-1
bert/encoder/layer_0/intermediate/dense/mul_2/x	1608802723819120	1608802723819133	2	-1	-1
bert/encoder/layer_1/attention/self/query/kernel	1608802723819137	1608802723819150	4	-1	-1
bert/encoder/layer_11/attention/output/dense/kernel/adam_v	1608802723819154	1608802723819163	4	-1	-1
bert/encoder/layer_9/attention/self/value/kernel	1608802723819165	1608802723819178	2	-1	-1
bert/encoder/layer_6/attention/self/value/bias/adam_v	1608802723819185	1608802723819194	7	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/gamma	1608802723819199	1608802723819207	5	-1	-1
bert/encoder/layer_2/output/LayerNorm/beta	1608802723819212	1608802723819223	5	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/gamma	1608802723819226	1608802723819233	3	-1	-1
bert/encoder/layer_3/output/dense/bias	1608802723819236	1608802723819243	3	-1	-1
bert/encoder/layer_6/intermediate/dense/kernel/adam_m	1608802723819248	1608802723819262	5	-1	-1
bert/encoder/layer_4/intermediate/dense/kernel	1608802723819266	1608802723819277	4	-1	-1
bert/encoder/layer_6/intermediate/dense/bias/adam_v	1608802723819279	1608802723819288	2	-1	-1
bert/encoder/layer_5/attention/self/value/kernel	1608802723819298	1608802723819307	10	-1	-1
bert/encoder/layer_5/intermediate/dense/bias	1608802723819310	1608802723819319	3	-1	-1
Mul_543/x	1608802723819321	1608802723819375	2	-1	-1
bert/encoder/layer_6/attention/self/query/kernel/adam_v	1608802723819379	1608802723819388	4	-1	-1
bert/encoder/layer_6/output/LayerNorm/gamma/adam_v	1608802723819390	1608802723819398	2	-1	-1
bert/encoder/layer_7/attention/self/key/bias	1608802723819408	1608802723819417	10	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/gamma	1608802723819421	1608802723819433	4	-1	-1
bert/encoder/layer_7/output/LayerNorm/beta	1608802723819437	1608802723819445	4	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m	1608802723819447	1608802723819456	2	-1	-1
bert/encoder/layer_0/output/dense/kernel	1608802723819460	1608802723819473	4	-1	-1
bert/encoder/layer_0/output/dense/bias	1608802723819476	1608802723819483	3	-1	-1
bert/encoder/layer_6/attention/self/value/kernel/adam_m	1608802723819488	1608802723819496	5	-1	-1
bert/encoder/layer_7/attention/self/value/bias/adam_v	1608802723819502	1608802723819511	6	-1	-1
bert/encoder/layer_2/attention/self/key/bias	1608802723819514	1608802723819521	3	-1	-1
bert/encoder/layer_2/attention/output/dense/bias	1608802723819523	1608802723819534	2	-1	-1
bert/encoder/layer_10/output/dense/kernel	1608802723819537	1608802723819545	3	-1	-1
bert/encoder/layer_3/attention/self/key/bias	1608802723819549	1608802723819556	4	-1	-1
bert/encoder/layer_3/intermediate/dense/kernel	1608802723819560	1608802723819571	4	-1	-1
cls/predictions/output_bias/adam_m	1608802723819574	1608802723819584	3	-1	-1
bert/encoder/layer_4/attention/self/value/kernel	1608802723819588	1608802723819595	4	-1	-1
bert/encoder/layer_4/intermediate/dense/bias	1608802723819603	1608802723819611	8	-1	-1
bert/encoder/layer_4/output/LayerNorm/gamma	1608802723819616	1608802723819623	5	-1	-1
bert/encoder/layer_5/attention/self/value/bias	1608802723819628	1608802723819638	5	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m	1608802723819642	1608802723819649	4	-1	-1
bert/encoder/layer_6/attention/self/query/kernel	1608802723819654	1608802723819662	5	-1	-1
bert/encoder/layer_6/attention/self/value/bias	1608802723819665	1608802723819676	3	-1	-1
bert/encoder/layer_6/output/dense/kernel	1608802723819679	1608802723819689	3	-1	-1
bert/encoder/layer_7/attention/self/query/kernel/adam_v	1608802723819694	1608802723819701	5	-1	-1
bert/encoder/layer_7/intermediate/dense/kernel	1608802723819709	1608802723819718	8	-1	-1
bert/encoder/layer_7/output/LayerNorm/gamma	1608802723819721	1608802723819728	3	-1	-1
bert/encoder/layer_8/attention/self/key/bias	1608802723819731	1608802723819743	3	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/gamma	1608802723819745	1608802723819753	2	-1	-1
bert/encoder/layer_8/output/LayerNorm/gamma	1608802723819756	1608802723819764	3	-1	-1
bert/encoder/layer_9/attention/self/value/bias	1608802723819766	1608802723819777	2	-1	-1
bert/encoder/layer_9/intermediate/dense/bias	1608802723819781	1608802723819789	4	-1	-1
bert/encoder/layer_7/attention/output/dense/kernel/adam_m	1608802723819791	1608802723819799	2	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/beta	1608802723819808	1608802723819817	9	-1	-1
bert/encoder/layer_10/output/dense/bias	1608802723819820	1608802723819827	3	-1	-1
bert/encoder/layer_11/attention/self/key/kernel	1608802723819829	1608802723819837	2	-1	-1
bert/encoder/layer_3/attention/self/value/kernel	1608802723819843	1608802723819852	6	-1	-1
bert/encoder/layer_3/intermediate/dense/bias	1608802723819859	1608802723819866	7	-1	-1
bert/encoder/layer_3/output/LayerNorm/beta	1608802723819868	1608802723819880	2	-1	-1
bert/encoder/layer_4/attention/self/value/bias	1608802723819884	1608802723819891	4	-1	-1
bert/encoder/layer_6/intermediate/dense/bias/adam_m	1608802723819895	1608802723819902	4	-1	-1
bert/encoder/layer_5/attention/self/query/kernel	1608802723819905	1608802723819918	3	-1	-1
bert/encoder/layer_6/output/dense/kernel/adam_v	1608802723819920	1608802723819927	2	-1	-1
bert/encoder/layer_6/output/dense/bias/adam_m	1608802723819930	1608802723819938	3	-1	-1
bert/encoder/layer_6/attention/self/query/bias	1608802723819946	1608802723819955	8	-1	-1
bert/encoder/layer_6/attention/output/dense/kernel	1608802723819957	1608802723819967	2	-1	-1
bert/encoder/layer_6/output/dense/bias	1608802723819971	1608802723819982	4	-1	-1
bert/encoder/layer_7/attention/self/value/kernel	1608802723819986	1608802723819995	4	-1	-1
bert/encoder/layer_7/attention/self/query/bias/adam_m	1608802723819997	1608802723820005	2	-1	-1
bert/encoder/layer_8/attention/self/query/kernel	1608802723820009	1608802723820029	4	-1	-1
bert/encoder/layer_7/attention/self/key/kernel/adam_v	1608802723820031	1608802723820040	2	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v	1608802723820043	1608802723820054	3	-1	-1
bert/encoder/layer_0/attention/self/Reshape_3/shape	1608802723820056	1608802723820080	2	-1	-1
bert/encoder/layer_9/attention/output/dense/kernel	1608802723820107	1608802723820121	27	-1	-1
bert/encoder/layer_9/output/dense/kernel	1608802723820125	1608802723820133	4	-1	-1
bert/encoder/layer_10/attention/self/key/kernel	1608802723820137	1608802723820145	4	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/gamma	1608802723820147	1608802723820155	2	-1	-1
bert/encoder/layer_10/output/LayerNorm/beta	1608802723820158	1608802723820170	3	-1	-1
bert/encoder/layer_11/attention/self/key/bias	1608802723820174	1608802723820182	4	-1	-1
bert/encoder/layer_6/attention/output/dense/bias/adam_m	1608802723820188	1608802723820195	6	-1	-1
bert/encoder/layer_3/attention/self/value/bias	1608802723820202	1608802723820210	7	-1	-1
bert/encoder/layer_11/attention/output/dense/bias/adam_m	1608802723820212	1608802723820219	2	-1	-1
bert/encoder/layer_3/output/LayerNorm/gamma	1608802723820223	1608802723820234	4	-1	-1
bert/encoder/layer_6/intermediate/dense/kernel/adam_v	1608802723820238	1608802723820245	4	-1	-1
bert/encoder/layer_4/output/dense/kernel	1608802723820248	1608802723820257	3	-1	-1
bert/encoder/layer_5/attention/self/query/bias	1608802723820260	1608802723820272	3	-1	-1
bert/encoder/layer_5/attention/output/dense/kernel	1608802723820276	1608802723820283	4	-1	-1
bert/encoder/layer_5/output/dense/kernel	1608802723820288	1608802723820295	5	-1	-1
bert/encoder/layer_6/attention/self/key/kernel	1608802723820302	1608802723820310	7	-1	-1
bert/encoder/layer_6/attention/output/dense/bias	1608802723820312	1608802723820320	2	-1	-1
bert/encoder/layer_6/output/LayerNorm/beta	1608802723820324	1608802723820337	4	-1	-1
Mul_545/x	1608802723820339	1608802723820382	2	-1	-1
bert/encoder/layer_7/intermediate/dense/bias	1608802723820385	1608802723820394	3	-1	-1
bert/encoder/layer_8/attention/self/query/bias	1608802723820399	1608802723820411	5	-1	-1
bert/encoder/layer_8/attention/self/value/kernel	1608802723820414	1608802723820422	3	-1	-1
bert/encoder/layer_8/intermediate/dense/kernel	1608802723820424	1608802723820432	2	-1	-1
bert/encoder/layer_0/attention/self/transpose/perm	1608802723820438	1608802723820464	6	-1	-1
bert/encoder/layer_9/attention/output/dense/bias	1608802723820467	1608802723820475	3	-1	-1
bert/encoder/layer_9/output/dense/bias	1608802723820479	1608802723820492	4	-1	-1
bert/encoder/layer_10/attention/self/key/bias	1608802723820495	1608802723820503	3	-1	-1
bert/encoder/layer_7/attention/output/dense/bias/adam_m	1608802723820507	1608802723820516	4	-1	-1
bert/encoder/layer_10/output/LayerNorm/gamma	1608802723820518	1608802723820530	2	-1	-1
bert/encoder/layer_11/attention/self/value/kernel	1608802723820564	1608802723820575	34	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/beta	1608802723820579	1608802723820590	4	-1	-1
bert/encoder/layer_2/output/LayerNorm/gamma	1608802723820595	1608802723820604	5	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m	1608802723820608	1608802723820618	4	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m	1608802723820620	1608802723820629	2	-1	-1
bert/encoder/layer_4/attention/self/query/kernel	1608802723820631	1608802723820640	2	-1	-1
bert/encoder/layer_4/attention/output/dense/kernel	1608802723820644	1608802723820652	4	-1	-1
bert/encoder/layer_11/intermediate/dense/bias/adam_v	1608802723820655	1608802723820664	3	-1	-1
bert/encoder/layer_5/attention/self/key/kernel	1608802723820666	1608802723820674	2	-1	-1
bert/encoder/layer_5/attention/output/dense/bias	1608802723820677	1608802723820684	3	-1	-1
bert/encoder/layer_5/output/dense/bias	1608802723820688	1608802723820695	4	-1	-1
bert/encoder/layer_6/attention/self/key/bias	1608802723820698	1608802723820707	3	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/beta	1608802723820709	1608802723820718	2	-1	-1
bert/encoder/layer_6/output/LayerNorm/gamma	1608802723820721	1608802723820729	3	-1	-1
bert/encoder/layer_7/attention/self/value/bias	1608802723820731	1608802723820738	2	-1	-1
bert/encoder/layer_7/attention/self/key/kernel/adam_m	1608802723820740	1608802723820749	2	-1	-1
bert/encoder/layer_8/attention/self/value/bias	1608802723820751	1608802723820759	2	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m	1608802723820761	1608802723820770	2	-1	-1
bert/encoder/layer_9/attention/self/query/kernel	1608802723820774	1608802723820783	4	-1	-1
bert/encoder/layer_0/attention/self/mul_1/y	1608802723820785	1608802723820793	2	-1	-1
bert/embeddings/word_embeddings/adam_m	1608802723820796	1608802723820807	3	-1	-1
bert/encoder/layer_7/attention/output/dense/kernel/adam_v	1608802723820811	1608802723820822	4	-1	-1
add_699/y	1608802723820826	1608802723820837	4	-1	-1
bert/encoder/layer_11/attention/self/query/kernel	1608802723820839	1608802723820848	2	-1	-1
bert/encoder/layer_11/attention/self/value/bias	1608802723820855	1608802723820864	7	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/gamma	1608802723820867	1608802723820875	3	-1	-1
bert/encoder/layer_11/output/LayerNorm/gamma	1608802723820878	1608802723820890	3	-1	-1
bert/pooler/dense/bias	1608802723820892	1608802723820900	2	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v	1608802723820905	1608802723820912	5	-1	-1
PolynomialDecay/sub	1608802723820915	1608802723820929	3	-1	-1
bert/encoder/layer_4/attention/self/query/bias	1608802723820932	1608802723820940	3	-1	-1
bert/encoder/layer_1/output/dense/bias/adam_v	1608802723820944	1608802723820957	4	-1	-1
cls/predictions/transform/dense/bias/adam_v	1608802723820965	1608802723820977	8	-1	-1
bert/encoder/layer_5/attention/self/key/bias	1608802723820979	1608802723820987	2	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/beta	1608802723820991	1608802723820999	4	-1	-1
bert/encoder/layer_6/output/dense/bias/adam_v	1608802723821005	1608802723821013	6	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v	1608802723821015	1608802723821025	2	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/gamma	1608802723821027	1608802723821039	2	-1	-1
bert/encoder/layer_7/attention/self/query/kernel	1608802723821043	1608802723821050	4	-1	-1
bert/encoder/layer_7/attention/output/dense/kernel	1608802723821053	1608802723821060	3	-1	-1
bert/encoder/layer_9/intermediate/dense/kernel/adam_m	1608802723821064	1608802723821077	4	-1	-1
cls/predictions/output_bias/adam_v	1608802723821079	1608802723821086	2	-1	-1
bert/embeddings/word_embeddings	1608802723821090	1608802723821099	4	-1	-1
bert/encoder/layer_7/attention/self/key/bias/adam_m	1608802723821105	1608802723821115	6	-1	-1
bert/encoder/Reshape/shape	1608802723821119	1608802723821128	4	-1	-1
bert/encoder/layer_0/attention/self/key/bias	1608802723821131	1608802723821143	3	-1	-1
bert/encoder/layer_0/attention/self/Mul/y	1608802723821147	1608802723821161	4	-1	-1
cls/predictions/transform/dense/kernel/adam_v	1608802723821165	1608802723821174	4	-1	-1
bert/encoder/layer_0/attention/self/key/bias/adam_v	1608802723821179	1608802723821199	5	-1	-1
bert/encoder/layer_0/attention/output/dense/bias/adam_v	1608802723821204	1608802723821214	5	-1	-1
bert/encoder/layer_11/attention/output/dense/kernel	1608802723821218	1608802723821227	4	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v	1608802723821235	1608802723821243	8	-1	-1
bert/encoder/layer_7/intermediate/dense/kernel/adam_m	1608802723821246	1608802723821254	3	-1	-1
Reshape	1608802723821258	1608802723821271	4	-1	-1
bert/encoder/layer_6/attention/output/dense/bias/adam_v	1608802723821275	1608802723821282	4	-1	-1
PolynomialDecay/Minimum/y	1608802723821286	1608802723821294	4	-1	-1
gradients/cls/predictions/Sum_grad/Tile/multiples	1608802723821298	1608802723821311	4	-1	-1
cls/seq_relationship/output_bias/adam_v	1608802723821314	1608802723821323	3	-1	-1
bert/encoder/layer_2/attention/self/key/bias/adam_v	1608802723821325	1608802723821334	2	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/gamma	1608802723821337	1608802723821350	3	-1	-1
bert/encoder/layer_5/output/LayerNorm/beta	1608802723821354	1608802723821361	4	-1	-1
bert/encoder/layer_6/output/LayerNorm/beta/adam_m	1608802723821364	1608802723821373	3	-1	-1
bert/encoder/layer_6/intermediate/dense/kernel	1608802723821380	1608802723821388	7	-1	-1
bert/encoder/layer_7/attention/self/query/bias	1608802723821391	1608802723821398	3	-1	-1
bert/encoder/layer_9/intermediate/dense/kernel/adam_v	1608802723821400	1608802723821413	2	-1	-1
bert/encoder/layer_9/output/dense/bias/adam_v	1608802723821415	1608802723821422	2	-1	-1
bert/encoder/layer_10/attention/self/query/bias/adam_m	1608802723821426	1608802723821434	4	-1	-1
bert/encoder/layer_8/attention/output/dense/kernel	1608802723821438	1608802723821451	4	-1	-1
bert/encoder/layer_8/intermediate/dense/bias	1608802723821455	1608802723821462	4	-1	-1
bert/embeddings/one_hot/off_value	1608802723821466	1608802723821475	4	-1	-1
bert/embeddings/LayerNorm/batchnorm/add/y	1608802723821482	1608802723821494	7	-1	-1
bert/encoder/layer_0/attention/self/query/bias	1608802723821498	1608802723821507	4	-1	-1
bert/encoder/layer_0/attention/self/value/kernel/adam_m	1608802723821512	1608802723821520	5	-1	-1
bert/encoder/layer_10/attention/self/value/bias/adam_m	1608802723821527	1608802723821536	7	-1	-1
bert/encoder/layer_0/intermediate/dense/kernel/adam_v	1608802723821540	1608802723821549	4	-1	-1
bert/encoder/layer_10/attention/output/dense/kernel/adam_v	1608802723821553	1608802723821565	4	-1	-1
bert/encoder/layer_11/intermediate/dense/kernel	1608802723821568	1608802723821575	3	-1	-1
bert/encoder/layer_7/intermediate/dense/kernel/adam_v	1608802723821577	1608802723821585	2	-1	-1
cls/predictions/transform/dense/kernel	1608802723821587	1608802723821598	2	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m	1608802723821602	1608802723821610	4	-1	-1
bert/encoder/layer_1/output/LayerNorm/beta/adam_m	1608802723821614	1608802723821623	4	-1	-1
bert/encoder/layer_2/attention/self/query/bias/adam_v	1608802723821630	1608802723821638	7	-1	-1
bert/encoder/layer_2/attention/self/value/kernel/adam_m	1608802723821643	1608802723821651	5	-1	-1
bert/encoder/layer_6/attention/self/value/kernel	1608802723821653	1608802723821666	2	-1	-1
bert/encoder/layer_6/output/LayerNorm/gamma/adam_m	1608802723821669	1608802723821676	3	-1	-1
bert/encoder/layer_9/intermediate/dense/bias/adam_m	1608802723821679	1608802723821687	3	-1	-1
bert/encoder/layer_9/output/LayerNorm/beta/adam_m	1608802723821690	1608802723821704	3	-1	-1
bert/encoder/layer_10/attention/self/query/bias/adam_v	1608802723821707	1608802723821714	3	-1	-1
clip_by_global_norm/Const_1	1608802723821717	1608802723821723	3	-1	-1
bert/encoder/layer_8/attention/output/dense/bias	1608802723821729	1608802723821736	6	-1	-1
bert/encoder/layer_7/attention/self/key/bias/adam_v	1608802723821739	1608802723821748	3	-1	-1
bert/encoder/layer_9/attention/self/query/bias	1608802723821752	1608802723821763	4	-1	-1
bert/embeddings/one_hot/depth	1608802723821766	1608802723821779	3	-1	-1
bert/encoder/layer_0/attention/self/value/kernel/adam_v	1608802723821784	1608802723821792	5	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m	1608802723821797	1608802723821810	5	-1	-1
bert/encoder/layer_0/intermediate/dense/bias/adam_m	1608802723821813	1608802723821820	3	-1	-1
bert/encoder/layer_0/output/LayerNorm/beta/adam_m	1608802723821824	1608802723821833	4	-1	-1
bert/encoder/layer_1/attention/self/query/bias/adam_m	1608802723821838	1608802723821850	5	-1	-1
bert/encoder/layer_1/attention/self/value/kernel/adam_m	1608802723821856	1608802723821864	6	-1	-1
bert/encoder/layer_1/attention/output/dense/bias/adam_v	1608802723821869	1608802723821882	5	-1	-1
bert/encoder/layer_1/intermediate/dense/bias/adam_m	1608802723821886	1608802723821893	4	-1	-1
cls/predictions/output_bias	1608802723821897	1608802723821905	4	-1	-1
bert/encoder/layer_10/intermediate/dense/kernel/adam_m	1608802723821907	1608802723821920	2	-1	-1
bert/encoder/layer_2/attention/self/value/kernel/adam_v	1608802723821923	1608802723821932	3	-1	-1
bert/encoder/layer_9/intermediate/dense/bias/adam_v	1608802723821935	1608802723821942	3	-1	-1
bert/pooler/dense/bias/adam_v	1608802723821945	1608802723821957	3	-1	-1
gradients/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum/reduction_indices	1608802723821960	1608802723821974	3	-1	-1
bert/encoder/layer_11/attention/self/value/kernel/adam_v	1608802723821977	1608802723821985	3	-1	-1
bert/encoder/layer_5/output/dense/kernel/adam_v	1608802723821993	1608802723822001	8	-1	-1
bert/embeddings/word_embeddings/adam_v	1608802723822004	1608802723822011	3	-1	-1
bert/embeddings/LayerNorm/beta/adam_m	1608802723822015	1608802723822028	4	-1	-1
bert/encoder/layer_7/attention/self/value/kernel/adam_m	1608802723822034	1608802723822042	6	-1	-1
bert/embeddings/GatherV2/axis	1608802723822044	1608802723822054	2	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v	1608802723822058	1608802723822070	4	-1	-1
bert/encoder/layer_0/intermediate/dense/bias/adam_v	1608802723822073	1608802723822080	3	-1	-1
bert/encoder/layer_0/output/LayerNorm/beta/adam_v	1608802723822082	1608802723822089	2	-1	-1
bert/encoder/layer_1/attention/self/query/bias/adam_v	1608802723822098	1608802723822105	9	-1	-1
bert/encoder/layer_1/attention/self/value/kernel/adam_v	1608802723822111	1608802723822118	6	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m	1608802723822121	1608802723822135	3	-1	-1
bert/encoder/layer_1/intermediate/dense/bias/adam_v	1608802723822139	1608802723822147	4	-1	-1
bert/encoder/layer_1/output/LayerNorm/beta/adam_v	1608802723822149	1608802723822158	2	-1	-1
bert/encoder/layer_2/attention/self/key/kernel/adam_m	1608802723822160	1608802723822173	2	-1	-1
bert/encoder/layer_2/attention/self/value/bias/adam_m	1608802723822179	1608802723822187	6	-1	-1
bert/encoder/layer_9/output/dense/kernel/adam_m	1608802723822190	1608802723822200	3	-1	-1
bert/encoder/layer_9/output/LayerNorm/beta/adam_v	1608802723822206	1608802723822213	6	-1	-1
bert/encoder/layer_10/attention/self/key/kernel/adam_m	1608802723822217	1608802723822225	4	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v	1608802723822228	1608802723822239	3	-1	-1
bert/encoder/layer_5/output/dense/bias/adam_m	1608802723822241	1608802723822249	2	-1	-1
bert/embeddings/token_type_embeddings/adam_m	1608802723822253	1608802723822261	4	-1	-1
bert/embeddings/LayerNorm/beta/adam_v	1608802723822265	1608802723822285	4	-1	-1
cls/seq_relationship/output_bias/adam_m	1608802723822287	1608802723822296	2	-1	-1
bert/encoder/layer_0/attention/self/value/bias/adam_m	1608802723822299	1608802723822309	3	-1	-1
bert/encoder/layer_10/attention/self/value/bias/adam_v	1608802723822319	1608802723822327	10	-1	-1
bert/encoder/layer_0/output/dense/kernel/adam_m	1608802723822329	1608802723822337	2	-1	-1
bert/encoder/layer_0/output/LayerNorm/gamma/adam_m	1608802723822339	1608802723822354	2	-1	-1
bert/encoder/layer_1/attention/self/key/kernel/adam_m	1608802723822356	1608802723822364	2	-1	-1
bert/encoder/layer_1/attention/self/value/bias/adam_m	1608802723822369	1608802723822377	5	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v	1608802723822381	1608802723822392	4	-1	-1
cls/predictions/transform/dense/bias/adam_m	1608802723822394	1608802723822402	2	-1	-1
bert/encoder/layer_1/output/LayerNorm/gamma/adam_m	1608802723822404	1608802723822413	2	-1	-1
bert/encoder/layer_10/intermediate/dense/kernel/adam_v	1608802723822418	1608802723822430	5	-1	-1
bert/encoder/layer_2/attention/self/value/bias/adam_v	1608802723822432	1608802723822439	2	-1	-1
bert/encoder/layer_2/attention/output/dense/bias/adam_v	1608802723822446	1608802723822455	7	-1	-1
bert/encoder/layer_10/intermediate/dense/bias/adam_m	1608802723822461	1608802723822468	6	-1	-1
bert/encoder/layer_2/intermediate/dense/kernel/adam_m	1608802723822472	1608802723822481	4	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m	1608802723822486	1608802723822499	5	-1	-1
bert/encoder/layer_2/intermediate/dense/kernel/adam_v	1608802723822503	1608802723822510	4	-1	-1
bert/encoder/layer_2/output/dense/bias/adam_m	1608802723822517	1608802723822525	7	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v	1608802723822528	1608802723822539	3	-1	-1
bert/encoder/layer_2/intermediate/dense/bias/adam_m	1608802723822543	1608802723822550	4	-1	-1
bert/encoder/layer_9/output/dense/kernel/adam_v	1608802723822554	1608802723822561	4	-1	-1
bert/encoder/layer_9/output/LayerNorm/gamma/adam_m	1608802723822571	1608802723822579	10	-1	-1
gradients/bert/embeddings/LayerNorm/moments/variance_grad/Tile/multiples	1608802723822582	1608802723822592	3	-1	-1
bert/encoder/layer_5/intermediate/dense/kernel/adam_m	1608802723822594	1608802723822606	2	-1	-1
bert/encoder/layer_11/attention/self/value/bias/adam_m	1608802723822609	1608802723822617	3	-1	-1
bert/embeddings/token_type_embeddings/adam_v	1608802723822622	1608802723822630	5	-1	-1
bert/embeddings/LayerNorm/gamma/adam_m	1608802723822634	1608802723822646	4	-1	-1
bert/encoder/layer_10/attention/self/value/kernel/adam_m	1608802723822649	1608802723822656	3	-1	-1
bert/encoder/layer_0/attention/self/value/bias/adam_v	1608802723822660	1608802723822668	4	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m	1608802723822677	1608802723822686	9	-1	-1
bert/encoder/layer_10/attention/output/dense/kernel/adam_m	1608802723822688	1608802723822696	2	-1	-1
bert/encoder/layer_0/output/LayerNorm/gamma/adam_v	1608802723822699	1608802723822712	3	-1	-1
bert/encoder/layer_10/attention/output/dense/bias/adam_m	1608802723822714	1608802723822723	2	-1	-1
bert/encoder/layer_1/attention/self/value/bias/adam_v	1608802723822727	1608802723822734	4	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v	1608802723822740	1608802723822752	6	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m	1608802723822756	1608802723822764	4	-1	-1
bert/encoder/layer_1/output/LayerNorm/gamma/adam_v	1608802723822768	1608802723822775	4	-1	-1
bert/encoder/layer_2/attention/self/key/kernel/adam_v	1608802723822784	1608802723822793	9	-1	-1
bert/encoder/layer_2/attention/output/dense/kernel/adam_m	1608802723822797	1608802723822806	4	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v	1608802723822811	1608802723822826	5	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m	1608802723822831	1608802723822839	5	-1	-1
bert/encoder/layer_2/intermediate/dense/bias/adam_v	1608802723822845	1608802723822852	6	-1	-1
bert/encoder/layer_2/output/dense/bias/adam_v	1608802723822856	1608802723822868	4	-1	-1
bert/encoder/layer_3/attention/self/query/kernel/adam_v	1608802723822874	1608802723822883	6	-1	-1
bert/encoder/layer_3/attention/self/key/bias/adam_v	1608802723822886	1608802723822894	3	-1	-1
bert/encoder/layer_3/attention/output/dense/bias/adam_m	1608802723822901	1608802723822909	7	-1	-1
bert/encoder/layer_3/intermediate/dense/kernel/adam_m	1608802723822922	1608802723822930	13	-1	-1
bert/encoder/layer_10/output/LayerNorm/gamma/adam_v	1608802723822934	1608802723822943	4	-1	-1
bert/encoder/layer_10/intermediate/dense/bias/adam_v	1608802723822948	1608802723822956	5	-1	-1
bert/encoder/layer_2/output/dense/kernel/adam_m	1608802723822963	1608802723822970	7	-1	-1
bert/encoder/layer_2/output/LayerNorm/beta/adam_m	1608802723822973	1608802723822984	3	-1	-1
bert/encoder/layer_9/output/dense/bias/adam_m	1608802723822990	1608802723822997	6	-1	-1
bert/encoder/layer_9/output/LayerNorm/gamma/adam_v	1608802723822999	1608802723823006	2	-1	-1
bert/encoder/layer_10/attention/self/key/kernel/adam_v	1608802723823012	1608802723823020	6	-1	-1
bert/encoder/layer_5/intermediate/dense/kernel/adam_v	1608802723823023	1608802723823032	3	-1	-1
bert/encoder/layer_5/output/dense/bias/adam_v	1608802723823036	1608802723823050	4	-1	-1
bert/encoder/layer_10/attention/self/key/bias/adam_m	1608802723823053	1608802723823060	3	-1	-1
bert/embeddings/LayerNorm/gamma/adam_v	1608802723823062	1608802723823070	2	-1	-1
bert/encoder/layer_0/attention/self/key/kernel/adam_m	1608802723823074	1608802723823086	4	-1	-1
bert/encoder/layer_0/attention/output/dense/kernel/adam_m	1608802723823089	1608802723823098	3	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v	1608802723823102	1608802723823110	4	-1	-1
bert/encoder/layer_0/output/dense/kernel/adam_v	1608802723823118	1608802723823126	8	-1	-1
bert/encoder/layer_1/attention/self/query/kernel/adam_m	1608802723823130	1608802723823138	4	-1	-1
bert/encoder/layer_1/attention/self/key/kernel/adam_v	1608802723823141	1608802723823152	3	-1	-1
bert/encoder/layer_1/attention/output/dense/kernel/adam_m	1608802723823155	1608802723823163	3	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m	1608802723823167	1608802723823174	4	-1	-1
bert/encoder/layer_1/output/dense/kernel/adam_m	1608802723823177	1608802723823189	3	-1	-1
bert/encoder/layer_2/attention/self/query/kernel/adam_m	1608802723823191	1608802723823199	2	-1	-1
bert/encoder/layer_2/attention/self/key/bias/adam_m	1608802723823201	1608802723823208	2	-1	-1
bert/encoder/layer_2/attention/output/dense/kernel/adam_v	1608802723823217	1608802723823225	9	-1	-1
bert/encoder/layer_3/attention/self/query/bias/adam_m	1608802723823228	1608802723823235	3	-1	-1
bert/encoder/layer_10/output/dense/bias/adam_v	1608802723823237	1608802723823248	2	-1	-1
bert/encoder/layer_3/attention/output/dense/bias/adam_v	1608802723823250	1608802723823259	2	-1	-1
bert/encoder/layer_3/intermediate/dense/kernel/adam_v	1608802723823261	1608802723823271	2	-1	-1
bert/encoder/layer_3/output/dense/bias/adam_m	1608802723823275	1608802723823286	4	-1	-1
bert/encoder/layer_4/attention/self/query/kernel/adam_v	1608802723823291	1608802723823298	5	-1	-1
bert/encoder/layer_4/attention/self/key/bias/adam_v	1608802723823301	1608802723823309	3	-1	-1
bert/encoder/layer_4/attention/output/dense/bias/adam_m	1608802723823318	1608802723823326	9	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v	1608802723823329	1608802723823336	3	-1	-1
bert/encoder/layer_2/output/dense/kernel/adam_v	1608802723823341	1608802723823360	5	-1	-1
bert/encoder/layer_10/output/dense/kernel/adam_v	1608802723823363	1608802723823371	3	-1	-1
bert/encoder/layer_3/attention/self/query/bias/adam_v	1608802723823375	1608802723823384	4	-1	-1
bert/encoder/layer_3/attention/self/value/kernel/adam_m	1608802723823386	1608802723823398	2	-1	-1
bert/pooler/dense/bias/adam_m	1608802723823402	1608802723823409	4	-1	-1
bert/encoder/layer_10/attention/self/query/kernel/adam_m	1608802723823413	1608802723823422	4	-1	-1
cls/predictions/transform/dense/kernel/adam_m	1608802723823429	1608802723823437	7	-1	-1
bert/encoder/layer_5/intermediate/dense/bias/adam_m	1608802723823441	1608802723823448	4	-1	-1
bert/encoder/layer_5/output/LayerNorm/beta/adam_m	1608802723823450	1608802723823468	2	-1	-1
bert/embeddings/position_embeddings/adam_m	1608802723823472	1608802723823479	4	-1	-1
bert/encoder/layer_0/attention/self/query/kernel/adam_m	1608802723823481	1608802723823489	2	-1	-1
bert/encoder/layer_0/attention/self/key/kernel/adam_v	1608802723823492	1608802723823504	3	-1	-1
bert/encoder/layer_0/attention/output/dense/kernel/adam_v	1608802723823506	1608802723823515	2	-1	-1
bert/encoder/layer_0/intermediate/dense/kernel/adam_m	1608802723823517	1608802723823525	2	-1	-1
bert/encoder/layer_0/output/dense/bias/adam_m	1608802723823535	1608802723823543	10	-1	-1
bert/encoder/layer_1/attention/self/query/kernel/adam_v	1608802723823547	1608802723823554	4	-1	-1
bert/encoder/layer_1/attention/self/key/bias/adam_m	1608802723823558	1608802723823570	4	-1	-1
bert/encoder/layer_1/attention/output/dense/kernel/adam_v	1608802723823575	1608802723823582	5	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v	1608802723823586	1608802723823593	4	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v	1608802723823601	1608802723823609	8	-1	-1
bert/encoder/layer_2/attention/self/query/kernel/adam_v	1608802723823612	1608802723823620	3	-1	-1
bert/encoder/layer_4/attention/output/dense/bias/adam_v	1608802723823623	1608802723823639	3	-1	-1
bert/encoder/layer_2/attention/output/dense/bias/adam_m	1608802723823645	1608802723823653	6	-1	-1
bert/encoder/layer_4/output/dense/bias/adam_m	1608802723823656	1608802723823663	3	-1	-1
bert/encoder/layer_5/attention/self/query/kernel/adam_v	1608802723823669	1608802723823680	6	-1	-1
bert/encoder/layer_10/output/dense/kernel/adam_m	1608802723823684	1608802723823691	4	-1	-1
bert/encoder/layer_2/output/LayerNorm/beta/adam_v	1608802723823696	1608802723823704	5	-1	-1
bert/encoder/layer_3/attention/self/key/kernel/adam_m	1608802723823706	1608802723823718	2	-1	-1
bert/encoder/layer_3/attention/self/value/kernel/adam_v	1608802723823722	1608802723823731	4	-1	-1
cls/predictions/transform/LayerNorm/beta/adam_v	1608802723823733	1608802723823740	2	-1	-1
bert/encoder/layer_3/intermediate/dense/bias/adam_m	1608802723823748	1608802723823755	8	-1	-1
bert/encoder/layer_3/output/dense/bias/adam_v	1608802723823758	1608802723823765	3	-1	-1
bert/encoder/layer_4/attention/self/query/bias/adam_m	1608802723823770	1608802723823781	5	-1	-1
bert/encoder/layer_4/attention/self/value/kernel/adam_m	1608802723823785	1608802723823792	4	-1	-1
bert/encoder/layer_11/attention/self/query/bias/adam_m	1608802723823798	1608802723823805	6	-1	-1
bert/encoder/layer_4/intermediate/dense/kernel/adam_m	1608802723823809	1608802723823822	4	-1	-1
bert/encoder/layer_4/output/dense/bias/adam_v	1608802723823825	1608802723823832	3	-1	-1
bert/encoder/layer_5/attention/self/query/bias/adam_m	1608802723823838	1608802723823845	6	-1	-1
bert/encoder/layer_10/attention/self/query/kernel/adam_v	1608802723823853	1608802723823861	8	-1	-1
bert/encoder/layer_5/attention/output/dense/bias/adam_m	1608802723823865	1608802723823873	4	-1	-1
bert/encoder/layer_5/intermediate/dense/bias/adam_v	1608802723823876	1608802723823887	3	-1	-1
bert/encoder/layer_11/attention/self/value/bias/adam_v	1608802723823889	1608802723823897	2	-1	-1
bert/encoder/layer_10/attention/self/key/bias/adam_v	1608802723823904	1608802723823911	7	-1	-1
bert/encoder/layer_0/attention/self/query/kernel/adam_v	1608802723823915	1608802723823927	4	-1	-1
bert/encoder/layer_10/attention/self/value/kernel/adam_v	1608802723823930	1608802723823938	3	-1	-1
bert/encoder/layer_0/attention/output/dense/bias/adam_m	1608802723823940	1608802723823948	2	-1	-1
bert/encoder/layer_4/attention/self/query/bias/adam_v	1608802723823954	1608802723823963	6	-1	-1
bert/encoder/layer_0/output/dense/bias/adam_v	1608802723823967	1608802723823975	4	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m	1608802723823978	1608802723823989	3	-1	-1
bert/encoder/layer_10/attention/output/dense/bias/adam_v	1608802723823992	1608802723824001	3	-1	-1
bert/encoder/layer_1/attention/output/dense/bias/adam_m	1608802723824003	1608802723824012	2	-1	-1
bert/encoder/layer_1/intermediate/dense/kernel/adam_m	1608802723824014	1608802723824027	2	-1	-1
bert/encoder/layer_1/output/dense/kernel/adam_v	1608802723824031	1608802723824038	4	-1	-1
bert/encoder/layer_2/attention/self/query/bias/adam_m	1608802723824042	1608802723824049	4	-1	-1
bert/encoder/layer_2/output/LayerNorm/gamma/adam_m	1608802723824069	1608802723824079	20	-1	-1
bert/encoder/layer_3/attention/self/key/kernel/adam_v	1608802723824082	1608802723824090	3	-1	-1
bert/encoder/layer_3/attention/self/value/bias/adam_m	1608802723824092	1608802723824104	2	-1	-1
bert/encoder/layer_10/output/LayerNorm/beta/adam_m	1608802723824107	1608802723824114	3	-1	-1
bert/encoder/layer_3/intermediate/dense/bias/adam_v	1608802723824116	1608802723824123	2	-1	-1
bert/encoder/layer_3/output/LayerNorm/beta/adam_m	1608802723824126	1608802723824139	3	-1	-1
bert/encoder/layer_11/attention/self/query/kernel/adam_m	1608802723824142	1608802723824150	3	-1	-1
bert/encoder/layer_4/attention/self/value/kernel/adam_v	1608802723824152	1608802723824159	2	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v	1608802723824168	1608802723824175	9	-1	-1
bert/encoder/layer_4/intermediate/dense/kernel/adam_v	1608802723824179	1608802723824187	4	-1	-1
bert/encoder/layer_11/attention/self/key/kernel/adam_v	1608802723824192	1608802723824203	5	-1	-1
bert/encoder/layer_5/attention/self/query/bias/adam_v	1608802723824205	1608802723824213	2	-1	-1
bert/encoder/layer_11/attention/self/key/bias/adam_v	1608802723824216	1608802723824223	3	-1	-1
bert/encoder/layer_5/attention/output/dense/bias/adam_v	1608802723824226	1608802723824238	3	-1	-1
bert/encoder/layer_2/output/LayerNorm/gamma/adam_v	1608802723824280	1608802723824290	42	-1	-1
cls/predictions/transform/LayerNorm/beta/adam_m	1608802723824295	1608802723824303	5	-1	-1
bert/encoder/layer_3/attention/self/value/bias/adam_v	1608802723824307	1608802723824315	4	-1	-1
bert/encoder/layer_5/output/dense/kernel/adam_m	1608802723824319	1608802723824327	4	-1	-1
add	1608802723824324	1608802723824536	-3	-1	-1
bert/encoder/layer_5/output/LayerNorm/beta/adam_v	1608802723824330	1608802723824337	-206	-1	-1
bert/embeddings/position_embeddings/adam_v	1608802723824340	1608802723824352	3	-1	-1
bert/encoder/layer_0/attention/self/query/bias/adam_m	1608802723824356	1608802723824373	4	-1	-1
bert/encoder/layer_0/attention/self/key/bias/adam_m	1608802723824378	1608802723824385	5	-1	-1
bert/encoder/layer_11/attention/self/query/bias/adam_v	1608802723824388	1608802723824590	3	-1	-1
Reshape_1	1608802723824576	1608802723824603	-14	-1	-1
bert/encoder/layer_4/intermediate/dense/bias/adam_m	1608802723824604	1608802723824619	1	-1	-1
bert/encoder/layer_4/output/LayerNorm/beta/adam_m	1608802723824624	1608802723824634	5	-1	-1
bert/encoder/layer_5/attention/self/key/kernel/adam_m	1608802723824643	1608802723824656	9	-1	-1
bert/encoder/layer_1/attention/self/key/bias/adam_v	1608802723824664	1608802723824698	8	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m	1608802723824701	1608802723824716	3	-1	-1
bert/encoder/layer_1/output/dense/bias/adam_m	1608802723824720	1608802723824729	4	-1	-1
bert/encoder/layer_3/attention/self/query/kernel/adam_m	1608802723824734	1608802723824744	5	-1	-1
bert/encoder/layer_10/output/dense/bias/adam_m	1608802723824746	1608802723824759	2	-1	-1
bert/encoder/layer_3/attention/output/dense/kernel/adam_m	1608802723824762	1608802723824771	3	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m	1608802723824776	1608802723824784	5	-1	-1
bert/encoder/layer_3/output/dense/kernel/adam_m	1608802723824808	1608802723824819	24	-1	-1
bert/encoder/layer_3/output/LayerNorm/beta/adam_v	1608802723824825	1608802723824834	6	-1	-1
bert/encoder/layer_4/attention/self/key/kernel/adam_m	1608802723824840	1608802723824855	6	-1	-1
bert/encoder/layer_4/attention/self/value/bias/adam_m	1608802723824859	1608802723824868	4	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m	1608802723824872	1608802723824881	4	-1	-1
bert/encoder/layer_4/intermediate/dense/bias/adam_v	1608802723824887	1608802723824901	6	-1	-1
bert/encoder/layer_4/output/LayerNorm/beta/adam_v	1608802723824905	1608802723824915	4	-1	-1
cls/predictions/transform/LayerNorm/gamma/adam_v	1608802723824919	1608802723824927	4	-1	-1
bert/encoder/layer_5/attention/self/key/bias/adam_v	1608802723824937	1608802723824947	10	-1	-1
bert/encoder/layer_11/attention/self/value/kernel/adam_m	1608802723824953	1608802723824962	6	-1	-1
bert/encoder/layer_3/attention/self/key/bias/adam_m	1608802723824999	1608802723825012	37	-1	-1
bert/encoder/layer_3/attention/output/dense/kernel/adam_v	1608802723825016	1608802723825027	4	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v	1608802723825031	1608802723825040	4	-1	-1
bert/embeddings/ExpandDims	1608802723825045	1608802723825216	5	-1	-1
bert/encoder/layer_5/output/LayerNorm/gamma/adam_m	1608802723825061	1608802723825073	-155	-1	-1
bert/encoder/layer_3/output/LayerNorm/gamma/adam_m	1608802723825076	1608802723825094	3	-1	-1
bert/encoder/layer_0/attention/self/query/bias/adam_v	1608802723825097	1608802723825108	3	-1	-1
bert/encoder/layer_4/attention/self/value/bias/adam_v	1608802723825234	1608802723825277	126	-1	-1
bert/embeddings/Reshape	1608802723825265	1608802723825282	-12	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v	1608802723825287	1608802723825297	5	-1	-1
bert/encoder/layer_4/output/dense/kernel/adam_m	1608802723825301	1608802723825331	4	-1	-1
bert/encoder/layer_4/output/LayerNorm/gamma/adam_m	1608802723825336	1608802723825357	5	-1	-1
bert/encoder/layer_11/attention/self/key/bias/adam_m	1608802723825364	1608802723825372	7	-1	-1
bert/encoder/layer_5/attention/self/value/kernel/adam_m	1608802723825380	1608802723825394	8	-1	-1
ConstantFolding/PolynomialDecay/truediv_recip	1608802723825398	1608802723825407	4	-1	-1
bert/encoder/layer_1/intermediate/dense/kernel/adam_v	1608802723825410	1608802723825418	3	-1	-1
bert/encoder/layer_10/output/LayerNorm/beta/adam_v	1608802723825429	1608802723825437	11	-1	-1
bert/encoder/layer_10/output/LayerNorm/gamma/adam_m	1608802723825443	1608802723825453	6	-1	-1
bert/encoder/layer_3/output/LayerNorm/gamma/adam_v	1608802723825459	1608802723825477	6	-1	-1
bert/encoder/layer_4/attention/self/key/kernel/adam_v	1608802723825480	1608802723825488	3	-1	-1
bert/encoder/layer_4/attention/output/dense/kernel/adam_m	1608802723825490	1608802723825498	2	-1	-1
bert/encoder/layer_11/attention/self/key/kernel/adam_m	1608802723825500	1608802723825515	2	-1	-1
bert/encoder/layer_4/output/LayerNorm/gamma/adam_v	1608802723825519	1608802723825527	4	-1	-1
bert/encoder/layer_5/attention/self/key/kernel/adam_v	1608802723825531	1608802723825539	4	-1	-1
bert/encoder/layer_5/attention/self/value/kernel/adam_v	1608802723825543	1608802723825558	4	-1	-1
ConstantFolding/gradients/cls/predictions/transform/LayerNorm/moments/variance_grad/truediv_recip	1608802723825561	1608802723825580	3	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m	1608802723825613	1608802723825623	33	-1	-1
bert/embeddings/Reshape_2	1608802723825622	1608802723825646	-1	-1	-1
bert/encoder/layer_3/output/dense/kernel/adam_v	1608802723825627	1608802723825635	-19	-1	-1
bert/encoder/layer_4/attention/self/query/kernel/adam_m	1608802723825638	1608802723825647	3	-1	-1
bert/encoder/layer_11/attention/self/query/kernel/adam_v	1608802723825649	1608802723825662	2	-1	-1
bert/encoder/layer_4/attention/output/dense/kernel/adam_v	1608802723825666	1608802723825675	4	-1	-1
bert/encoder/layer_4/output/dense/kernel/adam_v	1608802723825679	1608802723825687	4	-1	-1
bert/encoder/layer_5/attention/self/query/kernel/adam_m	1608802723825695	1608802723825704	8	-1	-1
bert/encoder/layer_5/attention/self/key/bias/adam_m	1608802723825706	1608802723825714	2	-1	-1
bert/encoder/layer_5/attention/self/value/bias/adam_m	1608802723825718	1608802723825730	4	-1	-1
gradients/cls/seq_relationship/Sum_grad/Tile	1608802723825732	1608802723825741	2	-1	-1
bert/encoder/layer_4/attention/self/key/bias/adam_m	1608802723825761	1608802723825770	20	-1	-1
cls/predictions/transform/LayerNorm/gamma/adam_m	1608802723825776	1608802723825799	6	-1	-1
cls/predictions/Reshape	1608802723825786	1608802723825805	-13	-1	-1
bert/encoder/layer_5/attention/self/value/bias/adam_v	1608802723825803	1608802723825812	-2	-1	-1
bert/embeddings/one_hot	1608802723825811	1608802723826045	-1	1608802723825887	126
bert/encoder/ones	1608802723825816	1608802723825828	-229	-1	-1
cls/predictions/one_hot	1608802723825957	1608802723826094	129	1608802723825996	788
bert/encoder/layer_5/attention/output/dense/kernel/adam_m	1608802723826150	1608802723826171	56	-1	-1
bert/encoder/layer_5/attention/output/dense/kernel/adam_v/read	1608802723826223	1608802723826234	52	-1	-1
cls/seq_relationship/Reshape	1608802723826223	1608802723826245	-11	-1	-1
cls/predictions/Reshape_1	1608802723826227	1608802723826248	-18	-1	-1
Cast/ReadVariableOp	1608802723826239	1608802723826256	-9	-1	-1
ReadVariableOp	1608802723826263	1608802723826275	7	-1	-1
global_step/VarIsInitializedOp	1608802723826279	1608802723826300	4	-1	-1
cls/predictions/Sum_2	1608802723826282	1608802723826407	-18	1608802723826786	6
PolynomialDecay/Cast_2/ReadVariableOp	1608802723826306	1608802723826319	-101	-1	-1
bert/embeddings/dropout/random_uniform/RandomUniform	1608802723826324	1608802723826474	5	1608802723826793	47
cls/predictions/add	1608802723826417	1608802723826522	-57	1608802723826842	4
bert/encoder/layer_0/attention/self/key/kernel/read	1608802723826499	1608802723826517	-23	-1	-1
bert/encoder/layer_6/attention/self/key/kernel/adam_m/read	1608802723826521	1608802723826538	4	-1	-1
gradients/cls/predictions/truediv_grad/RealDiv	1608802723826534	1608802723826610	-4	1608802723826848	4
bert/embeddings/position_embeddings/read	1608802723826550	1608802723826562	-60	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/gamma/read	1608802723826568	1608802723826578	6	-1	-1
bert/encoder/layer_6/attention/self/value/kernel/adam_v/read	1608802723826586	1608802723826597	8	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/beta/read	1608802723826604	1608802723826611	7	-1	-1
bert/encoder/layer_1/output/LayerNorm/beta/read	1608802723826616	1608802723826629	5	-1	-1
gradients/cls/predictions/Sum_1_grad/Reshape	1608802723826617	1608802723826631	-12	-1	-1
gradients/cls/predictions/Sum_1_grad/Tile	1608802723826636	1608802723826692	5	1608802723826853	6
bert/encoder/layer_2/attention/self/value/kernel/read	1608802723826636	1608802723826643	-56	-1	-1
bert/encoder/layer_0/attention/output/dense/kernel/read	1608802723826647	1608802723826655	4	-1	-1
bert/encoder/layer_2/attention/self/query/bias/read	1608802723826663	1608802723826670	8	-1	-1
bert/encoder/layer_2/attention/self/value/bias/read	1608802723826673	1608802723826681	3	-1	-1
bert/encoder/layer_1/attention/self/key/kernel/read	1608802723826685	1608802723826698	4	-1	-1
gradients/cls/predictions/mul_1_grad/Mul_1	1608802723826697	1608802723826745	-1	1608802723826860	4
bert/encoder/layer_1/output/dense/bias/read	1608802723826702	1608802723826710	-43	-1	-1
bert/encoder/layer_0/attention/output/dense/bias/read	1608802723826714	1608802723826722	4	-1	-1
bert/encoder/layer_0/output/LayerNorm/beta/read	1608802723826732	1608802723826744	10	-1	-1
bert/encoder/layer_1/attention/self/key/bias/read	1608802723826747	1608802723826755	3	-1	-1
gradients/cls/predictions/Neg_grad/Neg	1608802723826750	1608802723826801	-5	1608802723826866	4
bert/encoder/layer_7/attention/output/dense/bias/read	1608802723826759	1608802723826771	-42	-1	-1
bert/encoder/layer_7/attention/self/query/bias/adam_v/read	1608802723826776	1608802723826786	5	-1	-1
bert/encoder/layer_7/output/dense/kernel/read	1608802723826790	1608802723826800	4	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/beta/read	1608802723826806	1608802723826821	6	-1	-1
gradients/cls/predictions/Sum_grad/Reshape	1608802723826822	1608802723826835	1	-1	-1
bert/encoder/layer_8/output/dense/kernel/read	1608802723826828	1608802723826837	-7	-1	-1
gradients/cls/predictions/Sum_grad/Tile	1608802723826843	1608802723826909	6	1608802723826877	160
bert/encoder/layer_9/attention/self/key/kernel/read	1608802723826843	1608802723826852	-66	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/beta/read	1608802723826871	1608802723826882	19	-1	-1
bert/encoder/layer_9/output/LayerNorm/beta/read	1608802723826887	1608802723826896	5	-1	-1
bert/encoder/layer_10/attention/self/value/kernel/read	1608802723826901	1608802723826915	5	-1	-1
bert/encoder/layer_10/intermediate/dense/kernel/read	1608802723826921	1608802723826932	6	-1	-1
gradients/cls/predictions/mul_grad/Mul	1608802723826927	1608802723826975	-5	1608802723827039	434
bert/encoder/layer_11/attention/self/query/bias/read	1608802723826935	1608802723826941	-40	-1	-1
bert/encoder/layer_11/attention/output/dense/bias/read	1608802723826948	1608802723826956	7	-1	-1
cls/seq_relationship/one_hot	1608802723826951	1608802723827028	-5	1608802723827474	5
bert/encoder/layer_11/intermediate/dense/bias/read	1608802723826961	1608802723826969	-67	-1	-1
bert/encoder/layer_7/intermediate/dense/bias/adam_m/read	1608802723826974	1608802723826988	5	-1	-1
gradients/cls/predictions/LogSoftmax_grad/Sum	1608802723826982	1608802723827101	-6	1608802723827481	149
bert/encoder/layer_7/output/dense/bias/adam_m/read	1608802723826997	1608802723827005	-104	-1	-1
bert/encoder/layer_8/attention/self/query/kernel/adam_v/read	1608802723827010	1608802723827017	5	-1	-1
cls/seq_relationship/output_weights/adam_m/read	1608802723827026	1608802723827034	9	-1	-1
gradients/cls/seq_relationship/mul_grad/Mul_1	1608802723827040	1608802723827128	6	1608802723827631	4
bert/encoder/layer_8/attention/output/dense/bias/adam_m/read	1608802723827041	1608802723827049	-87	-1	-1
bert/encoder/layer_8/attention/self/query/bias/adam_m/read	1608802723827055	1608802723827067	6	-1	-1
bert/encoder/layer_7/output/LayerNorm/gamma/adam_m/read	1608802723827071	1608802723827080	4	-1	-1
bert/encoder/layer_11/output/dense/bias/adam_v/read	1608802723827086	1608802723827094	6	-1	-1
bert/encoder/layer_8/attention/self/value/kernel/adam_m/read	1608802723827099	1608802723827115	5	-1	-1
bert/encoder/layer_8/attention/output/dense/bias/adam_v/read	1608802723827119	1608802723827127	4	-1	-1
bert/encoder/layer_9/output/LayerNorm/gamma/read	1608802723827132	1608802723827140	5	-1	-1
gradients/cls/seq_relationship/LogSoftmax_grad/Sum	1608802723827135	1608802723827198	-5	1608802723827637	4
bert/encoder/layer_9/attention/output/dense/bias/adam_m/read	1608802723827147	1608802723827155	-51	-1	-1
bert/encoder/layer_8/attention/self/key/kernel/read	1608802723827164	1608802723827173	9	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m/read	1608802723827179	1608802723827191	6	-1	-1
bert/encoder/layer_8/output/dense/bias/read	1608802723827195	1608802723827202	4	-1	-1
bert/encoder/layer_9/attention/self/key/bias/read	1608802723827207	1608802723827213	5	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/gamma/read	1608802723827221	1608802723827228	8	-1	-1
cls/predictions/transform/dense/bias/read	1608802723827233	1608802723827243	5	-1	-1
bert/encoder/layer_10/attention/self/value/bias/read	1608802723827245	1608802723827256	2	-1	-1
bert/encoder/layer_11/intermediate/dense/kernel/adam_m/read	1608802723827263	1608802723827271	7	-1	-1
bert/encoder/layer_11/intermediate/dense/bias/adam_m/read	1608802723827275	1608802723827281	4	-1	-1
bert/encoder/layer_11/intermediate/dense/kernel/adam_v/read	1608802723827288	1608802723827296	7	-1	-1
bert/encoder/layer_11/output/dense/kernel/read	1608802723827300	1608802723827309	4	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m/read	1608802723827315	1608802723827325	6	-1	-1
bert/encoder/layer_9/attention/self/query/kernel/adam_m/read	1608802723827333	1608802723827342	8	-1	-1
bert/encoder/layer_7/output/LayerNorm/gamma/adam_v/read	1608802723827348	1608802723827354	6	-1	-1
bert/encoder/layer_8/attention/self/query/bias/adam_v/read	1608802723827362	1608802723827371	8	-1	-1
bert/encoder/layer_11/output/dense/kernel/adam_v/read	1608802723827376	1608802723827383	5	-1	-1
bert/encoder/layer_8/intermediate/dense/kernel/adam_m/read	1608802723827388	1608802723827398	5	-1	-1
cls/seq_relationship/output_weights/adam_v/read	1608802723827402	1608802723827410	4	-1	-1
bert/encoder/layer_10/attention/self/query/kernel/read	1608802723827415	1608802723827422	5	-1	-1
bert/encoder/layer_11/output/LayerNorm/gamma/adam_v/read	1608802723827432	1608802723827440	10	-1	-1
bert/encoder/layer_9/attention/output/dense/bias/adam_v/read	1608802723827443	1608802723827449	3	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v/read	1608802723827453	1608802723827463	4	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m/read	1608802723827470	1608802723827479	7	-1	-1
bert/encoder/layer_11/output/dense/bias/read	1608802723827484	1608802723827492	5	-1	-1
bert/encoder/layer_8/intermediate/dense/kernel/adam_v/read	1608802723827498	1608802723827510	6	-1	-1
cls/predictions/transform/LayerNorm/beta/read	1608802723827515	1608802723827521	5	-1	-1
bert/encoder/layer_7/attention/self/value/kernel/adam_v/read	1608802723827527	1608802723827535	6	-1	-1
bert/encoder/layer_7/attention/self/value/bias/adam_m/read	1608802723827543	1608802723827548	8	-1	-1
bert/encoder/layer_7/output/dense/bias/adam_v/read	1608802723827553	1608802723827561	5	-1	-1
bert/encoder/layer_10/attention/output/dense/kernel/read	1608802723827565	1608802723827578	4	-1	-1
bert/encoder/layer_7/attention/output/dense/bias/adam_v/read	1608802723827581	1608802723827590	3	-1	-1
bert/encoder/layer_8/attention/self/value/kernel/adam_v/read	1608802723827593	1608802723827601	3	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v/read	1608802723827617	1608802723827625	16	-1	-1
bert/encoder/layer_11/output/LayerNorm/beta/read	1608802723827630	1608802723827636	5	-1	-1
bert/encoder/layer_11/output/LayerNorm/beta/adam_m/read	1608802723827639	1608802723827650	3	-1	-1
bert/encoder/layer_9/attention/self/query/kernel/adam_v/read	1608802723827654	1608802723827660	4	-1	-1
bert/encoder/layer_9/intermediate/dense/kernel/read	1608802723827665	1608802723827675	5	-1	-1
bert/encoder/layer_8/attention/self/key/kernel/adam_m/read	1608802723827685	1608802723827692	10	-1	-1
bert/encoder/layer_10/intermediate/dense/bias/read	1608802723827696	1608802723827702	4	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m/read	1608802723827705	1608802723827716	3	-1	-1
bert/encoder/layer_8/intermediate/dense/bias/adam_m/read	1608802723827721	1608802723827730	5	-1	-1
bert/encoder/layer_8/output/dense/bias/adam_v/read	1608802723827735	1608802723827742	5	-1	-1
bert/pooler/dense/kernel/read	1608802723827752	1608802723827761	10	-1	-1
bert/encoder/layer_9/attention/self/key/bias/adam_v/read	1608802723827765	1608802723827771	4	-1	-1
bert/pooler/dense/kernel/adam_m/read	1608802723827776	1608802723827789	5	-1	-1
bert/encoder/layer_7/output/dense/kernel/adam_m/read	1608802723827794	1608802723827802	5	-1	-1
bert/encoder/layer_7/output/LayerNorm/beta/adam_m/read	1608802723827807	1608802723827812	5	-1	-1
bert/encoder/layer_10/attention/self/query/bias/read	1608802723827817	1608802723827828	5	-1	-1
bert/encoder/layer_10/attention/output/dense/bias/read	1608802723827831	1608802723827838	3	-1	-1
bert/encoder/layer_11/output/dense/bias/adam_m/read	1608802723827842	1608802723827850	4	-1	-1
bert/encoder/layer_8/intermediate/dense/bias/adam_v/read	1608802723827859	1608802723827868	9	-1	-1
bert/encoder/layer_8/output/LayerNorm/beta/adam_m/read	1608802723827875	1608802723827882	7	-1	-1
bert/encoder/layer_9/attention/self/query/bias/adam_m/read	1608802723827887	1608802723827898	5	-1	-1
bert/encoder/layer_9/attention/self/value/kernel/adam_m/read	1608802723827902	1608802723827910	4	-1	-1
cls/predictions/transform/LayerNorm/gamma/read	1608802723827914	1608802723827920	4	-1	-1
cls/seq_relationship/output_weights/read	1608802723827928	1608802723827937	8	-1	-1
bert/encoder/layer_7/output/dense/kernel/adam_v/read	1608802723827944	1608802723827953	7	-1	-1
bert/encoder/layer_8/attention/self/query/kernel/adam_m/read	1608802723827956	1608802723827968	3	-1	-1
bert/encoder/layer_8/attention/self/key/kernel/adam_v/read	1608802723827973	1608802723827979	5	-1	-1
bert/encoder/layer_8/attention/self/value/bias/adam_m/read	1608802723827984	1608802723827990	5	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v/read	1608802723827999	1608802723828005	9	-1	-1
bert/encoder/layer_8/output/dense/kernel/adam_m/read	1608802723828010	1608802723828016	5	-1	-1
bert/encoder/layer_11/output/LayerNorm/beta/adam_v/read	1608802723828023	1608802723828033	7	-1	-1
bert/encoder/layer_9/attention/self/query/bias/adam_v/read	1608802723828037	1608802723828045	4	-1	-1
bert/encoder/layer_9/attention/self/value/kernel/adam_v/read	1608802723828048	1608802723828054	3	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m/read	1608802723828062	1608802723828069	8	-1	-1
bert/encoder/layer_7/intermediate/dense/bias/adam_v/read	1608802723828073	1608802723828080	4	-1	-1
cls/seq_relationship/output_bias/read	1608802723828084	1608802723828095	4	-1	-1
bert/encoder/layer_7/output/LayerNorm/beta/adam_v/read	1608802723828101	1608802723828107	6	-1	-1
bert/encoder/layer_8/attention/self/key/bias/adam_m/read	1608802723828112	1608802723828118	5	-1	-1
bert/encoder/layer_8/attention/self/value/bias/adam_v/read	1608802723828121	1608802723828133	3	-1	-1
bert/encoder/layer_8/output/dense/kernel/adam_v/read	1608802723828136	1608802723828142	3	-1	-1
bert/encoder/layer_8/output/LayerNorm/gamma/adam_v/read	1608802723828145	1608802723828152	3	-1	-1
bert/encoder/layer_9/attention/self/key/kernel/adam_m/read	1608802723828160	1608802723828166	8	-1	-1
bert/encoder/layer_9/attention/self/value/bias/adam_m/read	1608802723828172	1608802723828180	6	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v/read	1608802723828184	1608802723828195	4	-1	-1
bert/encoder/layer_0/intermediate/dense/kernel/read	1608802723828200	1608802723828207	5	-1	-1
bert/encoder/layer_0/output/LayerNorm/gamma/read	1608802723828210	1608802723828218	3	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/gamma/read	1608802723828226	1608802723828234	8	-1	-1
bert/encoder/layer_1/output/LayerNorm/gamma/read	1608802723828238	1608802723828246	4	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/beta/read	1608802723828250	1608802723828264	4	-1	-1
bert/encoder/layer_11/output/dense/kernel/adam_m/read	1608802723828267	1608802723828276	3	-1	-1
bert/encoder/layer_8/attention/output/dense/kernel/adam_m/read	1608802723828280	1608802723828288	4	-1	-1
bert/encoder/layer_3/attention/output/dense/kernel/read	1608802723828296	1608802723828306	8	-1	-1
bert/encoder/layer_8/output/dense/bias/adam_m/read	1608802723828311	1608802723828317	5	-1	-1
bert/encoder/layer_8/output/LayerNorm/beta/adam_v/read	1608802723828322	1608802723828332	5	-1	-1
bert/encoder/layer_9/attention/self/key/bias/adam_m/read	1608802723828337	1608802723828347	5	-1	-1
bert/encoder/layer_9/attention/output/dense/kernel/adam_v/read	1608802723828350	1608802723828359	3	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m/read	1608802723828387	1608802723828395	28	-1	-1
bert/encoder/layer_0/attention/self/value/kernel/read	1608802723828399	1608802723828406	4	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/beta/read	1608802723828409	1608802723828420	3	-1	-1
bert/encoder/layer_0/intermediate/dense/bias/read	1608802723828423	1608802723828429	3	-1	-1
bert/encoder/layer_1/attention/self/query/bias/read	1608802723828434	1608802723828442	5	-1	-1
bert/encoder/layer_1/attention/output/dense/kernel/read	1608802723828446	1608802723828458	4	-1	-1
bert/encoder/layer_1/output/dense/kernel/read	1608802723828462	1608802723828472	4	-1	-1
bert/encoder/layer_8/attention/self/key/bias/adam_v/read	1608802723828477	1608802723828484	5	-1	-1
bert/encoder/layer_8/attention/output/dense/kernel/adam_v/read	1608802723828495	1608802723828504	11	-1	-1
bert/encoder/layer_2/intermediate/dense/kernel/read	1608802723828509	1608802723828517	5	-1	-1
bert/encoder/layer_3/attention/self/query/kernel/read	1608802723828521	1608802723828533	4	-1	-1
bert/encoder/layer_8/output/LayerNorm/gamma/adam_m/read	1608802723828537	1608802723828543	4	-1	-1
bert/encoder/layer_11/output/LayerNorm/gamma/adam_m/read	1608802723828548	1608802723828555	5	-1	-1
bert/encoder/layer_9/attention/self/value/bias/adam_v/read	1608802723828562	1608802723828571	7	-1	-1
bert/pooler/dense/kernel/adam_v/read	1608802723828576	1608802723828584	5	-1	-1
bert/encoder/layer_6/attention/self/query/kernel/adam_m/read	1608802723828587	1608802723828599	3	-1	-1
bert/embeddings/LayerNorm/beta/read	1608802723828604	1608802723828615	5	-1	-1
bert/encoder/layer_6/attention/self/query/bias/adam_m/read	1608802723828619	1608802723828629	4	-1	-1
bert/encoder/layer_0/attention/self/value/bias/read	1608802723828634	1608802723828647	5	-1	-1
bert/encoder/layer_6/attention/self/key/kernel/adam_v/read	1608802723828652	1608802723828660	5	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v/read	1608802723828664	1608802723828674	4	-1	-1
bert/encoder/layer_1/attention/self/value/kernel/read	1608802723828678	1608802723828686	4	-1	-1
bert/encoder/layer_1/intermediate/dense/kernel/read	1608802723828692	1608802723828701	6	-1	-1
bert/encoder/layer_2/attention/self/query/kernel/read	1608802723828704	1608802723828722	3	-1	-1
bert/encoder/layer_6/attention/output/dense/kernel/adam_m/read	1608802723828728	1608802723828736	6	-1	-1
bert/encoder/layer_2/intermediate/dense/bias/read	1608802723828742	1608802723828752	6	-1	-1
bert/encoder/layer_9/attention/self/key/kernel/adam_v/read	1608802723828757	1608802723828765	5	-1	-1
bert/encoder/layer_9/attention/output/dense/kernel/adam_m/read	1608802723828769	1608802723828777	4	-1	-1
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v/read	1608802723828784	1608802723828790	7	-1	-1
bert/encoder/layer_4/attention/self/key/kernel/read	1608802723828795	1608802723828803	5	-1	-1
bert/encoder/layer_4/attention/output/dense/bias/read	1608802723828808	1608802723828820	5	-1	-1
bert/embeddings/token_type_embeddings/read	1608802723828825	1608802723828834	5	-1	-1
bert/embeddings/LayerNorm/gamma/read	1608802723828838	1608802723828847	4	-1	-1
bert/encoder/layer_6/attention/self/query/bias/adam_v/read	1608802723828854	1608802723828865	7	-1	-1
bert/encoder/layer_11/attention/output/dense/kernel/adam_m/read	1608802723828870	1608802723828878	5	-1	-1
bert/encoder/layer_6/attention/self/key/bias/adam_m/read	1608802723828883	1608802723828891	5	-1	-1
bert/encoder/layer_1/attention/self/value/bias/read	1608802723828897	1608802723828907	6	-1	-1
bert/encoder/layer_1/intermediate/dense/bias/read	1608802723828911	1608802723828917	4	-1	-1
bert/encoder/layer_6/attention/self/value/bias/adam_m/read	1608802723828921	1608802723828933	4	-1	-1
bert/encoder/layer_6/attention/output/dense/kernel/adam_v/read	1608802723828940	1608802723828946	7	-1	-1
bert/encoder/layer_2/output/dense/kernel/read	1608802723828949	1608802723828959	3	-1	-1
bert/encoder/layer_3/attention/self/query/bias/read	1608802723828968	1608802723828979	9	-1	-1
bert/encoder/layer_3/attention/output/dense/bias/read	1608802723828984	1608802723828993	5	-1	-1
bert/encoder/layer_3/output/dense/kernel/read	1608802723828998	1608802723829010	5	-1	-1
bert/encoder/layer_4/attention/self/key/bias/read	1608802723829015	1608802723829023	5	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/beta/read	1608802723829027	1608802723829034	4	-1	-1
bert/encoder/layer_4/output/dense/bias/read	1608802723829037	1608802723829049	3	-1	-1
bert/encoder/layer_5/output/LayerNorm/gamma/adam_v/read	1608802723829054	1608802723829062	5	-1	-1
bert/encoder/layer_5/intermediate/dense/kernel/read	1608802723829068	1608802723829078	6	-1	-1
bert/encoder/layer_0/attention/self/query/kernel/read	1608802723829089	1608802723829096	11	-1	-1
bert/encoder/layer_7/attention/self/query/kernel/adam_m/read	1608802723829101	1608802723829107	5	-1	-1
bert/encoder/layer_11/attention/self/dropout/random_uniform/RandomUniform	1608802723829115	1608802723829189	8	1608802723829151	103
bert/encoder/layer_4/attention/self/dropout/random_uniform/RandomUniform	1608802723829203	1608802723829268	14	1608802723829256	84
bert/encoder/layer_7/attention/self/dropout/random_uniform/RandomUniform	1608802723829278	1608802723829333	10	1608802723829342	83
bert/encoder/layer_9/attention/self/dropout/random_uniform/RandomUniform	1608802723829343	1608802723829397	10	1608802723829427	84
bert/encoder/layer_0/attention/self/dropout/random_uniform/RandomUniform	1608802723829409	1608802723829454	12	1608802723829512	84
bert/encoder/layer_1/attention/self/dropout/random_uniform/RandomUniform	1608802723829469	1608802723829515	15	1608802723829597	83
bert/encoder/layer_2/attention/self/dropout/random_uniform/RandomUniform	1608802723829525	1608802723829577	10	1608802723829682	83
bert/encoder/layer_10/attention/self/dropout/random_uniform/RandomUniform	1608802723829588	1608802723829633	11	1608802723829767	83
bert/encoder/layer_5/attention/self/dropout/random_uniform/RandomUniform	1608802723829643	1608802723829686	10	1608802723829852	83
bert/encoder/layer_8/attention/self/dropout/random_uniform/RandomUniform	1608802723829695	1608802723829747	9	1608802723829937	83
bert/encoder/layer_6/attention/self/dropout/random_uniform/RandomUniform	1608802723829756	1608802723829803	9	1608802723830022	83
bert/encoder/layer_3/attention/self/dropout/random_uniform/RandomUniform	1608802723829813	1608802723829864	10	1608802723830107	84
bert/encoder/layer_6/attention/self/key/bias/adam_v/read	1608802723829873	1608802723829882	9	-1	-1
bert/encoder/layer_1/attention/output/dense/bias/read	1608802723829886	1608802723829893	4	-1	-1
bert/encoder/layer_8/output/LayerNorm/beta/read	1608802723829897	1608802723829910	4	-1	-1
bert/encoder/layer_2/attention/self/key/kernel/read	1608802723829914	1608802723829923	4	-1	-1
bert/encoder/layer_2/attention/output/dense/kernel/read	1608802723829927	1608802723829934	4	-1	-1
bert/encoder/layer_2/output/dense/bias/read	1608802723829942	1608802723829953	8	-1	-1
bert/encoder/layer_3/attention/self/key/kernel/read	1608802723829957	1608802723829964	4	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/beta/read	1608802723829969	1608802723829982	5	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v/read	1608802723829987	1608802723829995	5	-1	-1
bert/encoder/layer_11/attention/output/dense/bias/adam_v/read	1608802723830001	1608802723830011	6	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/gamma/read	1608802723830019	1608802723830029	8	-1	-1
bert/encoder/layer_4/output/LayerNorm/beta/read	1608802723830034	1608802723830042	5	-1	-1
bert/encoder/layer_6/output/dense/kernel/adam_m/read	1608802723830046	1608802723830059	4	-1	-1
bert/encoder/layer_5/output/LayerNorm/gamma/read	1608802723830062	1608802723830071	3	-1	-1
bert/encoder/layer_6/output/LayerNorm/beta/adam_v/read	1608802723830074	1608802723830082	3	-1	-1
bert/encoder/layer_6/intermediate/dense/bias/read	1608802723830091	1608802723830100	9	-1	-1
bert/encoder/layer_7/attention/self/key/kernel/read	1608802723830103	1608802723830111	3	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/beta/read	1608802723830117	1608802723830129	6	-1	-1
bert/encoder/layer_7/output/dense/bias/read	1608802723830134	1608802723830140	5	-1	-1
bert/encoder/layer_1/attention/self/query/kernel/read	1608802723830143	1608802723830153	3	-1	-1
bert/encoder/layer_11/attention/output/dense/kernel/adam_v/read	1608802723830160	1608802723830171	7	-1	-1
bert/encoder/layer_9/attention/self/value/kernel/read	1608802723830175	1608802723830183	4	-1	-1
bert/encoder/layer_6/attention/self/value/bias/adam_v/read	1608802723830187	1608802723830198	4	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/gamma/read	1608802723830203	1608802723830209	5	-1	-1
bert/encoder/layer_2/output/LayerNorm/beta/read	1608802723830214	1608802723830222	5	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/gamma/read	1608802723830227	1608802723830238	5	-1	-1
bert/encoder/layer_3/output/dense/bias/read	1608802723830241	1608802723830247	3	-1	-1
bert/encoder/layer_6/intermediate/dense/kernel/adam_m/read	1608802723830251	1608802723830257	4	-1	-1
bert/encoder/layer_4/intermediate/dense/kernel/read	1608802723830276	1608802723830283	19	-1	-1
bert/encoder/layer_6/intermediate/dense/bias/adam_v/read	1608802723830290	1608802723830299	7	-1	-1
bert/encoder/layer_5/attention/self/value/kernel/read	1608802723830302	1608802723830313	3	-1	-1
bert/encoder/layer_5/intermediate/dense/bias/read	1608802723830317	1608802723830326	4	-1	-1
bert/encoder/layer_6/attention/self/query/kernel/adam_v/read	1608802723830329	1608802723830337	3	-1	-1
bert/encoder/layer_6/output/LayerNorm/gamma/adam_v/read	1608802723830345	1608802723830351	8	-1	-1
bert/encoder/layer_7/attention/self/key/bias/read	1608802723830356	1608802723830362	5	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/gamma/read	1608802723830369	1608802723830382	7	-1	-1
bert/encoder/layer_7/output/LayerNorm/beta/read	1608802723830388	1608802723830394	6	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m/read	1608802723830398	1608802723830405	4	-1	-1
bert/encoder/layer_0/output/dense/kernel/read	1608802723830410	1608802723830420	5	-1	-1
bert/encoder/layer_0/output/dense/bias/read	1608802723830423	1608802723830431	3	-1	-1
bert/encoder/layer_6/attention/self/value/kernel/adam_m/read	1608802723830434	1608802723830448	3	-1	-1
bert/encoder/layer_7/attention/self/value/bias/adam_v/read	1608802723830451	1608802723830459	3	-1	-1
bert/encoder/layer_2/attention/self/key/bias/read	1608802723830462	1608802723830470	3	-1	-1
bert/encoder/layer_2/attention/output/dense/bias/read	1608802723830474	1608802723830485	4	-1	-1
bert/encoder/layer_10/output/dense/kernel/read	1608802723830491	1608802723830498	6	-1	-1
bert/encoder/layer_3/attention/self/key/bias/read	1608802723830501	1608802723830507	3	-1	-1
bert/encoder/layer_3/intermediate/dense/kernel/read	1608802723830514	1608802723830522	7	-1	-1
cls/predictions/output_bias/adam_m/read	1608802723830527	1608802723830533	5	-1	-1
bert/encoder/layer_4/attention/self/value/kernel/read	1608802723830536	1608802723830550	3	-1	-1
bert/encoder/layer_4/intermediate/dense/bias/read	1608802723830554	1608802723830560	4	-1	-1
bert/encoder/layer_4/output/LayerNorm/gamma/read	1608802723830564	1608802723830573	4	-1	-1
bert/encoder/layer_5/attention/self/value/bias/read	1608802723830580	1608802723830587	7	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m/read	1608802723830593	1608802723830598	6	-1	-1
bert/encoder/layer_6/attention/self/query/kernel/read	1608802723830602	1608802723830613	4	-1	-1
bert/encoder/layer_6/attention/self/value/bias/read	1608802723830619	1608802723830628	6	-1	-1
bert/encoder/layer_6/output/dense/kernel/read	1608802723830633	1608802723830640	5	-1	-1
bert/encoder/layer_7/attention/self/query/kernel/adam_v/read	1608802723830648	1608802723830659	8	-1	-1
bert/encoder/layer_7/intermediate/dense/kernel/read	1608802723830664	1608802723830672	5	-1	-1
bert/encoder/layer_7/output/LayerNorm/gamma/read	1608802723830677	1608802723830685	5	-1	-1
bert/encoder/layer_8/attention/self/key/bias/read	1608802723830693	1608802723830700	8	-1	-1
bert/encoder/layer_8/attention/output/LayerNorm/gamma/read	1608802723830703	1608802723830711	3	-1	-1
bert/encoder/layer_8/output/LayerNorm/gamma/read	1608802723830714	1608802723830726	3	-1	-1
bert/encoder/layer_9/attention/self/value/bias/read	1608802723830730	1608802723830738	4	-1	-1
bert/encoder/layer_9/intermediate/dense/bias/read	1608802723830742	1608802723830748	4	-1	-1
bert/encoder/layer_7/attention/output/dense/kernel/adam_m/read	1608802723830756	1608802723830763	8	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/beta/read	1608802723830766	1608802723830774	3	-1	-1
bert/encoder/layer_10/output/dense/bias/read	1608802723830777	1608802723830788	3	-1	-1
bert/encoder/layer_11/attention/self/key/kernel/read	1608802723830791	1608802723830797	3	-1	-1
bert/encoder/layer_3/attention/self/value/kernel/read	1608802723830802	1608802723830810	5	-1	-1
bert/encoder/layer_3/intermediate/dense/bias/read	1608802723830817	1608802723830825	7	-1	-1
bert/encoder/layer_3/output/LayerNorm/beta/read	1608802723830829	1608802723830835	4	-1	-1
bert/encoder/layer_4/attention/self/value/bias/read	1608802723830838	1608802723830851	3	-1	-1
bert/encoder/layer_6/intermediate/dense/bias/adam_m/read	1608802723830855	1608802723830861	4	-1	-1
bert/encoder/layer_5/attention/self/query/kernel/read	1608802723830864	1608802723830872	3	-1	-1
bert/encoder/layer_6/output/dense/kernel/adam_v/read	1608802723830876	1608802723830888	4	-1	-1
bert/encoder/layer_6/output/dense/bias/adam_m/read	1608802723830892	1608802723830897	4	-1	-1
bert/encoder/layer_6/attention/self/query/bias/read	1608802723830902	1608802723830910	5	-1	-1
bert/encoder/layer_6/attention/output/dense/kernel/read	1608802723830918	1608802723830925	8	-1	-1
bert/encoder/layer_6/output/dense/bias/read	1608802723830928	1608802723830934	3	-1	-1
bert/encoder/layer_7/attention/self/value/kernel/read	1608802723830937	1608802723830967	3	-1	-1
bert/encoder/layer_7/attention/self/query/bias/adam_m/read	1608802723830973	1608802723830979	6	-1	-1
bert/encoder/layer_8/attention/self/query/kernel/read	1608802723830982	1608802723830990	3	-1	-1
bert/encoder/layer_7/attention/self/key/kernel/adam_v/read	1608802723830998	1608802723831004	8	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v/read	1608802723831010	1608802723831016	6	-1	-1
bert/encoder/layer_0/output/dropout/random_uniform/RandomUniform	1608802723831021	1608802723831080	5	1608802723831050	60
bert/encoder/layer_6/attention/output/dropout/random_uniform/RandomUniform	1608802723831093	1608802723831143	13	1608802723831112	57
bert/encoder/layer_8/output/dropout/random_uniform/RandomUniform	1608802723831155	1608802723831201	12	1608802723831176	58
bert/encoder/layer_4/attention/output/dropout/random_uniform/RandomUniform	1608802723831217	1608802723831265	16	1608802723831240	57
bert/encoder/layer_9/output/dropout/random_uniform/RandomUniform	1608802723831276	1608802723831324	11	1608802723831299	58
bert/encoder/layer_2/attention/output/dropout/random_uniform/RandomUniform	1608802723831353	1608802723831405	29	1608802723831374	63
bert/encoder/layer_4/output/dropout/random_uniform/RandomUniform	1608802723831419	1608802723831464	14	1608802723831439	54
bert/encoder/layer_10/attention/output/dropout/random_uniform/RandomUniform	1608802723831477	1608802723831520	13	1608802723831497	56
bert/encoder/layer_10/output/dropout/random_uniform/RandomUniform	1608802723831529	1608802723831576	9	1608802723831555	54
bert/encoder/layer_1/attention/output/dropout/random_uniform/RandomUniform	1608802723831586	1608802723831631	10	1608802723831610	49
bert/encoder/layer_5/attention/output/dropout/random_uniform/RandomUniform	1608802723831639	1608802723831680	8	1608802723831661	52
bert/encoder/layer_9/attention/output/dropout/random_uniform/RandomUniform	1608802723831703	1608802723831745	23	1608802723831721	57
bert/encoder/layer_11/attention/output/dropout/random_uniform/RandomUniform	1608802723831752	1608802723831799	7	1608802723831779	53
bert/encoder/layer_1/output/dropout/random_uniform/RandomUniform	1608802723831809	1608802723831852	10	1608802723831834	48
bert/encoder/layer_3/attention/output/dropout/random_uniform/RandomUniform	1608802723831860	1608802723831906	8	1608802723831883	55
bert/encoder/layer_6/output/dropout/random_uniform/RandomUniform	1608802723831919	1608802723831964	13	1608802723831941	56
bert/encoder/layer_11/output/dropout/random_uniform/RandomUniform	1608802723831975	1608802723832021	11	1608802723831999	51
bert/encoder/layer_2/output/dropout/random_uniform/RandomUniform	1608802723832032	1608802723832070	11	1608802723832051	52
bert/encoder/layer_3/output/dropout/random_uniform/RandomUniform	1608802723832085	1608802723832123	15	1608802723832105	51
bert/encoder/layer_7/attention/output/dropout/random_uniform/RandomUniform	1608802723832131	1608802723832179	8	1608802723832157	54
bert/encoder/layer_0/attention/output/dropout/random_uniform/RandomUniform	1608802723832189	1608802723832232	10	1608802723832213	47
bert/encoder/layer_5/output/dropout/random_uniform/RandomUniform	1608802723832243	1608802723832288	11	1608802723832265	56
bert/encoder/layer_7/output/dropout/random_uniform/RandomUniform	1608802723832297	1608802723832340	9	1608802723832323	51
bert/encoder/layer_8/attention/output/dropout/random_uniform/RandomUniform	1608802723832352	1608802723832415	12	1608802723832384	57
bert/encoder/layer_9/attention/output/dense/kernel/read	1608802723832426	1608802723832438	11	-1	-1
bert/encoder/layer_9/output/dense/kernel/read	1608802723832440	1608802723832449	2	-1	-1
bert/encoder/layer_10/attention/self/key/kernel/read	1608802723832459	1608802723832467	10	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/gamma/read	1608802723832472	1608802723832481	5	-1	-1
bert/encoder/layer_10/output/LayerNorm/beta/read	1608802723832485	1608802723832499	4	-1	-1
bert/encoder/layer_11/attention/self/key/bias/read	1608802723832503	1608802723832510	4	-1	-1
bert/encoder/layer_6/attention/output/dense/bias/adam_m/read	1608802723832513	1608802723832519	3	-1	-1
bert/encoder/layer_3/attention/self/value/bias/read	1608802723832528	1608802723832535	9	-1	-1
bert/encoder/layer_11/attention/output/dense/bias/adam_m/read	1608802723832537	1608802723832545	2	-1	-1
bert/encoder/layer_3/output/LayerNorm/gamma/read	1608802723832550	1608802723832560	5	-1	-1
bert/encoder/layer_6/intermediate/dense/kernel/adam_v/read	1608802723832563	1608802723832569	3	-1	-1
bert/encoder/layer_4/output/dense/kernel/read	1608802723832572	1608802723832578	3	-1	-1
bert/encoder/layer_5/attention/self/query/bias/read	1608802723832587	1608802723832594	9	-1	-1
bert/encoder/layer_5/attention/output/dense/kernel/read	1608802723832612	1608802723832623	18	-1	-1
bert/encoder/layer_5/output/dense/kernel/read	1608802723832628	1608802723832636	5	-1	-1
bert/encoder/layer_6/attention/self/key/kernel/read	1608802723832641	1608802723832649	5	-1	-1
bert/encoder/layer_6/attention/output/dense/bias/read	1608802723832653	1608802723832659	4	-1	-1
bert/encoder/layer_6/output/LayerNorm/beta/read	1608802723832662	1608802723832668	3	-1	-1
bert/encoder/layer_7/intermediate/dense/bias/read	1608802723832671	1608802723832679	3	-1	-1
bert/encoder/layer_8/attention/self/query/bias/read	1608802723832683	1608802723832691	4	-1	-1
bert/encoder/layer_8/attention/self/value/kernel/read	1608802723832697	1608802723832705	6	-1	-1
bert/encoder/layer_8/intermediate/dense/kernel/read	1608802723832710	1608802723832718	5	-1	-1
bert/encoder/layer_9/attention/output/dense/bias/read	1608802723832724	1608802723832734	6	-1	-1
bert/encoder/layer_9/output/dense/bias/read	1608802723832740	1608802723832746	6	-1	-1
bert/encoder/layer_10/attention/self/key/bias/read	1608802723832749	1608802723832755	3	-1	-1
bert/encoder/layer_7/attention/output/dense/bias/adam_m/read	1608802723832764	1608802723832770	9	-1	-1
bert/encoder/layer_10/output/LayerNorm/gamma/read	1608802723832773	1608802723832779	3	-1	-1
bert/encoder/layer_11/attention/self/value/kernel/read	1608802723832782	1608802723832792	3	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/beta/read	1608802723832795	1608802723832803	3	-1	-1
bert/encoder/layer_2/output/LayerNorm/gamma/read	1608802723832806	1608802723832812	3	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m/read	1608802723832814	1608802723832824	2	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m/read	1608802723832827	1608802723832833	3	-1	-1
bert/encoder/layer_4/attention/self/query/kernel/read	1608802723832836	1608802723832846	3	-1	-1
bert/encoder/layer_4/attention/output/dense/kernel/read	1608802723832850	1608802723832858	4	-1	-1
bert/encoder/layer_11/intermediate/dense/bias/adam_v/read	1608802723832862	1608802723832869	4	-1	-1
bert/encoder/layer_5/attention/self/key/kernel/read	1608802723832872	1608802723832882	3	-1	-1
bert/encoder/layer_5/attention/output/dense/bias/read	1608802723832885	1608802723832891	3	-1	-1
bert/encoder/layer_5/output/dense/bias/read	1608802723832894	1608802723832903	3	-1	-1
bert/encoder/layer_6/attention/self/key/bias/read	1608802723832911	1608802723832917	8	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/beta/read	1608802723832922	1608802723832929	5	-1	-1
bert/encoder/layer_6/output/LayerNorm/gamma/read	1608802723832932	1608802723832942	3	-1	-1
bert/encoder/layer_7/attention/self/value/bias/read	1608802723832945	1608802723832951	3	-1	-1
bert/encoder/layer_7/attention/self/key/kernel/adam_m/read	1608802723832957	1608802723832963	6	-1	-1
bert/encoder/layer_8/attention/self/value/bias/read	1608802723832970	1608802723832977	7	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m/read	1608802723832982	1608802723832987	5	-1	-1
bert/encoder/layer_9/attention/self/query/kernel/read	1608802723832990	1608802723833000	3	-1	-1
bert/embeddings/word_embeddings/adam_m/read	1608802723833003	1608802723833010	3	-1	-1
bert/encoder/layer_7/attention/output/dense/kernel/adam_v/read	1608802723833017	1608802723833023	7	-1	-1
bert/encoder/layer_11/attention/self/query/kernel/read	1608802723833031	1608802723833037	8	-1	-1
bert/encoder/layer_11/attention/self/value/bias/read	1608802723833041	1608802723833047	4	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/gamma/read	1608802723833049	1608802723833060	2	-1	-1
bert/encoder/layer_11/output/LayerNorm/gamma/read	1608802723833062	1608802723833071	2	-1	-1
bert/pooler/dense/bias/read	1608802723833075	1608802723833081	4	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v/read	1608802723833084	1608802723833102	3	-1	-1
bert/encoder/layer_4/attention/self/query/bias/read	1608802723833107	1608802723833114	5	-1	-1
bert/encoder/layer_1/output/dense/bias/adam_v/read	1608802723833116	1608802723833122	2	-1	-1
cls/predictions/transform/dense/bias/adam_v/read	1608802723833133	1608802723833140	11	-1	-1
bert/encoder/layer_5/attention/self/key/bias/read	1608802723833147	1608802723833152	7	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/beta/read	1608802723833156	1608802723833166	4	-1	-1
bert/encoder/layer_6/output/dense/bias/adam_v/read	1608802723833170	1608802723833175	4	-1	-1
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v/read	1608802723833179	1608802723833185	4	-1	-1
bert/encoder/layer_6/attention/output/LayerNorm/gamma/read	1608802723833194	1608802723833202	9	-1	-1
bert/encoder/layer_7/attention/self/query/kernel/read	1608802723833204	1608802723833213	2	-1	-1
bert/encoder/layer_7/attention/output/dense/kernel/read	1608802723833216	1608802723833228	3	-1	-1
bert/encoder/layer_9/intermediate/dense/kernel/adam_m/read	1608802723833232	1608802723833238	4	-1	-1
cls/predictions/output_bias/adam_v/read	1608802723833242	1608802723833247	4	-1	-1
bert/embeddings/word_embeddings/read	1608802723833251	1608802723833261	4	-1	-1
bert/encoder/layer_7/attention/self/key/bias/adam_m/read	1608802723833265	1608802723833270	4	-1	-1
bert/encoder/Reshape	1608802723833276	1608802723833288	6	-1	-1
bert/encoder/layer_0/attention/self/key/bias/read	1608802723833296	1608802723833304	8	-1	-1
cls/predictions/transform/dense/kernel/adam_v/read	1608802723833308	1608802723833317	4	-1	-1
bert/encoder/layer_0/attention/self/key/bias/adam_v/read	1608802723833321	1608802723833333	4	-1	-1
bert/encoder/layer_0/attention/output/dense/bias/adam_v/read	1608802723833339	1608802723833346	6	-1	-1
bert/encoder/layer_11/attention/output/dense/kernel/read	1608802723833349	1608802723833355	3	-1	-1
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v/read	1608802723833365	1608802723833371	10	-1	-1
bert/encoder/layer_7/intermediate/dense/kernel/adam_m/read	1608802723833374	1608802723833380	3	-1	-1
bert/encoder/layer_6/attention/output/dense/bias/adam_v/read	1608802723833382	1608802723833392	2	-1	-1
cls/seq_relationship/output_bias/adam_v/read	1608802723833395	1608802723833402	3	-1	-1
bert/encoder/layer_2/attention/self/key/bias/adam_v/read	1608802723833406	1608802723833415	4	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/gamma/read	1608802723833421	1608802723833428	6	-1	-1
bert/encoder/layer_5/output/LayerNorm/beta/read	1608802723833431	1608802723833437	3	-1	-1
bert/encoder/layer_6/output/LayerNorm/beta/adam_m/read	1608802723833441	1608802723833450	4	-1	-1
bert/encoder/layer_6/intermediate/dense/kernel/read	1608802723833455	1608802723833461	5	-1	-1
bert/encoder/layer_7/attention/self/query/bias/read	1608802723833464	1608802723833469	3	-1	-1
bert/encoder/layer_9/intermediate/dense/kernel/adam_v/read	1608802723833476	1608802723833484	7	-1	-1
bert/encoder/layer_9/output/dense/bias/adam_v/read	1608802723833489	1608802723833495	5	-1	-1
bert/encoder/layer_10/attention/self/query/bias/adam_m/read	1608802723833499	1608802723833509	4	-1	-1
bert/encoder/layer_8/attention/output/dense/kernel/read	1608802723833514	1608802723833520	5	-1	-1
bert/encoder/layer_8/intermediate/dense/bias/read	1608802723833523	1608802723833531	3	-1	-1
bert/encoder/layer_0/attention/self/query/bias/read	1608802723833535	1608802723833546	4	-1	-1
bert/encoder/layer_0/attention/self/value/kernel/adam_m/read	1608802723833550	1608802723833557	4	-1	-1
bert/encoder/layer_10/attention/self/value/bias/adam_m/read	1608802723833562	1608802723833587	5	-1	-1
bert/encoder/layer_0/intermediate/dense/kernel/adam_v/read	1608802723833590	1608802723833597	3	-1	-1
bert/encoder/layer_10/attention/output/dense/kernel/adam_v/read	1608802723833604	1608802723833610	7	-1	-1
bert/encoder/layer_11/intermediate/dense/kernel/read	1608802723833617	1608802723833626	7	-1	-1
bert/encoder/layer_7/intermediate/dense/kernel/adam_v/read	1608802723833631	1608802723833638	5	-1	-1
cls/predictions/transform/dense/kernel/read	1608802723833641	1608802723833652	3	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m/read	1608802723833656	1608802723833663	4	-1	-1
bert/encoder/layer_1/output/LayerNorm/beta/adam_m/read	1608802723833667	1608802723833672	4	-1	-1
bert/encoder/layer_2/attention/self/query/bias/adam_v/read	1608802723833676	1608802723833686	4	-1	-1
bert/encoder/layer_2/attention/self/value/kernel/adam_m/read	1608802723833689	1608802723833695	3	-1	-1
bert/encoder/layer_6/attention/self/value/kernel/read	1608802723833700	1608802723833706	5	-1	-1
bert/encoder/layer_6/output/LayerNorm/gamma/adam_m/read	1608802723833716	1608802723833721	10	-1	-1
bert/encoder/layer_9/intermediate/dense/bias/adam_m/read	1608802723833724	1608802723833729	3	-1	-1
bert/encoder/layer_9/output/LayerNorm/beta/adam_m/read	1608802723833732	1608802723833741	3	-1	-1
bert/encoder/layer_10/attention/self/query/bias/adam_v/read	1608802723833745	1608802723833751	4	-1	-1
bert/encoder/layer_8/attention/output/dense/bias/read	1608802723833757	1608802723833762	6	-1	-1
bert/encoder/layer_7/attention/self/key/bias/adam_v/read	1608802723833770	1608802723833776	8	-1	-1
bert/encoder/layer_9/attention/self/query/bias/read	1608802723833780	1608802723833786	4	-1	-1
bert/encoder/layer_0/attention/self/value/kernel/adam_v/read	1608802723833788	1608802723833798	2	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m/read	1608802723833803	1608802723833808	5	-1	-1
bert/encoder/layer_0/intermediate/dense/bias/adam_m/read	1608802723833814	1608802723833820	6	-1	-1
bert/encoder/layer_0/output/LayerNorm/beta/adam_m/read	1608802723833827	1608802723833834	7	-1	-1
bert/encoder/layer_1/attention/self/query/bias/adam_m/read	1608802723833837	1608802723833843	3	-1	-1
bert/encoder/layer_1/attention/self/value/kernel/adam_m/read	1608802723833848	1608802723833857	5	-1	-1
bert/encoder/layer_1/attention/output/dense/bias/adam_v/read	1608802723833863	1608802723833871	6	-1	-1
bert/encoder/layer_1/intermediate/dense/bias/adam_m/read	1608802723833875	1608802723833882	4	-1	-1
cls/predictions/output_bias/read	1608802723833886	1608802723833895	4	-1	-1
bert/encoder/layer_10/intermediate/dense/kernel/adam_m/read	1608802723833898	1608802723833903	3	-1	-1
bert/encoder/layer_2/attention/self/value/kernel/adam_v/read	1608802723833906	1608802723833915	3	-1	-1
bert/encoder/layer_9/intermediate/dense/bias/adam_v/read	1608802723833919	1608802723833925	4	-1	-1
bert/pooler/dense/bias/adam_v/read	1608802723833928	1608802723833933	3	-1	-1
bert/encoder/layer_11/attention/self/value/kernel/adam_v/read	1608802723833937	1608802723833947	4	-1	-1
bert/encoder/layer_5/output/dense/kernel/adam_v/read	1608802723833953	1608802723833961	6	-1	-1
bert/embeddings/word_embeddings/adam_v/read	1608802723833964	1608802723833972	3	-1	-1
bert/embeddings/LayerNorm/beta/adam_m/read	1608802723833979	1608802723833988	7	-1	-1
bert/encoder/layer_7/attention/self/value/kernel/adam_m/read	1608802723833994	1608802723834001	6	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v/read	1608802723834004	1608802723834013	3	-1	-1
bert/encoder/layer_0/intermediate/dense/bias/adam_v/read	1608802723834017	1608802723834022	4	-1	-1
bert/encoder/layer_0/output/LayerNorm/beta/adam_v/read	1608802723834028	1608802723834033	6	-1	-1
bert/encoder/layer_1/attention/self/query/bias/adam_v/read	1608802723834052	1608802723834057	19	-1	-1
bert/encoder/layer_1/attention/self/value/kernel/adam_v/read	1608802723834060	1608802723834066	3	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m/read	1608802723834072	1608802723834083	6	-1	-1
bert/encoder/layer_1/intermediate/dense/bias/adam_v/read	1608802723834106	1608802723834115	23	-1	-1
bert/encoder/layer_1/output/LayerNorm/beta/adam_v/read	1608802723834118	1608802723834125	3	-1	-1
bert/encoder/layer_2/attention/self/key/kernel/adam_m/read	1608802723834135	1608802723834141	10	-1	-1
bert/encoder/layer_2/attention/self/value/bias/adam_m/read	1608802723834145	1608802723834152	4	-1	-1
bert/encoder/layer_9/output/dense/kernel/adam_m/read	1608802723834155	1608802723834165	3	-1	-1
bert/encoder/layer_9/output/LayerNorm/beta/adam_v/read	1608802723834170	1608802723834175	5	-1	-1
bert/encoder/layer_10/attention/self/key/kernel/adam_m/read	1608802723834180	1608802723834185	5	-1	-1
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v/read	1608802723834192	1608802723834199	7	-1	-1
bert/encoder/layer_5/output/dense/bias/adam_m/read	1608802723834204	1608802723834209	5	-1	-1
bert/embeddings/token_type_embeddings/adam_m/read	1608802723834213	1608802723834223	4	-1	-1
bert/embeddings/LayerNorm/beta/adam_v/read	1608802723834227	1608802723834233	4	-1	-1
cls/seq_relationship/output_bias/adam_m/read	1608802723834238	1608802723834243	5	-1	-1
bert/encoder/layer_0/attention/self/value/bias/adam_m/read	1608802723834246	1608802723834257	3	-1	-1
bert/encoder/layer_10/attention/self/value/bias/adam_v/read	1608802723834261	1608802723834268	4	-1	-1
bert/encoder/layer_0/output/dense/kernel/adam_m/read	1608802723834272	1608802723834281	4	-1	-1
bert/encoder/layer_0/output/LayerNorm/gamma/adam_m/read	1608802723834285	1608802723834290	4	-1	-1
bert/encoder/layer_1/attention/self/key/kernel/adam_m/read	1608802723834295	1608802723834301	5	-1	-1
bert/encoder/layer_1/attention/self/value/bias/adam_m/read	1608802723834304	1608802723834313	3	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v/read	1608802723834318	1608802723834323	5	-1	-1
cls/predictions/transform/dense/bias/adam_m/read	1608802723834328	1608802723834333	5	-1	-1
bert/encoder/layer_1/output/LayerNorm/gamma/adam_m/read	1608802723834340	1608802723834346	7	-1	-1
bert/encoder/layer_10/intermediate/dense/kernel/adam_v/read	1608802723834351	1608802723834359	5	-1	-1
bert/encoder/layer_2/attention/self/value/bias/adam_v/read	1608802723834362	1608802723834372	3	-1	-1
bert/encoder/layer_2/attention/output/dense/bias/adam_v/read	1608802723834377	1608802723834384	5	-1	-1
bert/encoder/layer_10/intermediate/dense/bias/adam_m/read	1608802723834388	1608802723834394	4	-1	-1
bert/encoder/layer_2/intermediate/dense/kernel/adam_m/read	1608802723834401	1608802723834408	7	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m/read	1608802723834412	1608802723834417	4	-1	-1
bert/encoder/layer_2/intermediate/dense/kernel/adam_v/read	1608802723834420	1608802723834432	3	-1	-1
bert/encoder/layer_2/output/dense/bias/adam_m/read	1608802723834436	1608802723834443	4	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v/read	1608802723834446	1608802723834452	3	-1	-1
bert/encoder/layer_2/intermediate/dense/bias/adam_m/read	1608802723834461	1608802723834466	9	-1	-1
bert/encoder/layer_9/output/dense/kernel/adam_v/read	1608802723834472	1608802723834477	6	-1	-1
bert/encoder/layer_9/output/LayerNorm/gamma/adam_m/read	1608802723834480	1608802723834491	3	-1	-1
bert/encoder/layer_5/intermediate/dense/kernel/adam_m/read	1608802723834494	1608802723834500	3	-1	-1
bert/encoder/layer_11/attention/self/value/bias/adam_m/read	1608802723834505	1608802723834513	5	-1	-1
bert/embeddings/token_type_embeddings/adam_v/read	1608802723834519	1608802723834526	6	-1	-1
bert/embeddings/LayerNorm/gamma/adam_m/read	1608802723834530	1608802723834536	4	-1	-1
bert/encoder/layer_10/attention/self/value/kernel/adam_m/read	1608802723834539	1608802723834550	3	-1	-1
bert/encoder/layer_0/attention/self/value/bias/adam_v/read	1608802723834553	1608802723834559	3	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m/read	1608802723834563	1608802723834568	4	-1	-1
bert/encoder/layer_10/attention/output/dense/kernel/adam_m/read	1608802723834571	1608802723834583	3	-1	-1
bert/encoder/layer_0/output/LayerNorm/gamma/adam_v/read	1608802723834588	1608802723834593	5	-1	-1
bert/encoder/layer_10/attention/output/dense/bias/adam_m/read	1608802723834598	1608802723834606	5	-1	-1
bert/encoder/layer_1/attention/self/value/bias/adam_v/read	1608802723834611	1608802723834618	5	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v/read	1608802723834622	1608802723834628	4	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m/read	1608802723834631	1608802723834640	3	-1	-1
bert/encoder/layer_1/output/LayerNorm/gamma/adam_v/read	1608802723834645	1608802723834650	5	-1	-1
bert/encoder/layer_2/attention/self/key/kernel/adam_v/read	1608802723834653	1608802723834664	3	-1	-1
bert/encoder/layer_2/attention/output/dense/kernel/adam_m/read	1608802723834666	1608802723834673	2	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v/read	1608802723834676	1608802723834683	3	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m/read	1608802723834688	1608802723834697	5	-1	-1
bert/encoder/layer_2/intermediate/dense/bias/adam_v/read	1608802723834702	1608802723834708	5	-1	-1
bert/encoder/layer_2/output/dense/bias/adam_v/read	1608802723834711	1608802723834716	3	-1	-1
bert/encoder/layer_3/attention/self/query/kernel/adam_v/read	1608802723834723	1608802723834730	7	-1	-1
bert/encoder/layer_3/attention/self/key/bias/adam_v/read	1608802723834733	1608802723834738	3	-1	-1
bert/encoder/layer_3/attention/output/dense/bias/adam_m/read	1608802723834744	1608802723834755	6	-1	-1
bert/encoder/layer_3/intermediate/dense/kernel/adam_m/read	1608802723834758	1608802723834765	3	-1	-1
bert/encoder/layer_10/output/LayerNorm/gamma/adam_v/read	1608802723834768	1608802723834775	3	-1	-1
bert/encoder/layer_10/intermediate/dense/bias/adam_v/read	1608802723834784	1608802723834790	9	-1	-1
bert/encoder/layer_2/output/dense/kernel/adam_m/read	1608802723834793	1608802723834799	3	-1	-1
bert/encoder/layer_2/output/LayerNorm/beta/adam_m/read	1608802723834802	1608802723834812	3	-1	-1
bert/encoder/layer_9/output/dense/bias/adam_m/read	1608802723834816	1608802723834823	4	-1	-1
bert/encoder/layer_9/output/LayerNorm/gamma/adam_v/read	1608802723834827	1608802723834832	4	-1	-1
bert/encoder/layer_10/attention/self/key/kernel/adam_v/read	1608802723834840	1608802723834846	8	-1	-1
bert/encoder/layer_5/intermediate/dense/kernel/adam_v/read	1608802723834850	1608802723834855	4	-1	-1
bert/encoder/layer_5/output/dense/bias/adam_v/read	1608802723834858	1608802723834868	3	-1	-1
bert/encoder/layer_10/attention/self/key/bias/adam_m/read	1608802723834872	1608802723834878	4	-1	-1
bert/embeddings/LayerNorm/gamma/adam_v/read	1608802723834885	1608802723834892	7	-1	-1
bert/encoder/layer_0/attention/self/key/kernel/adam_m/read	1608802723834902	1608802723834910	10	-1	-1
bert/encoder/layer_0/attention/output/dense/kernel/adam_m/read	1608802723834913	1608802723834919	3	-1	-1
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v/read	1608802723834924	1608802723834932	5	-1	-1
bert/encoder/layer_0/output/dense/kernel/adam_v/read	1608802723834937	1608802723834944	5	-1	-1
bert/encoder/layer_1/attention/self/query/kernel/adam_m/read	1608802723834947	1608802723834952	3	-1	-1
bert/encoder/layer_1/attention/self/key/kernel/adam_v/read	1608802723834962	1608802723834969	10	-1	-1
bert/encoder/layer_1/attention/output/dense/kernel/adam_m/read	1608802723834973	1608802723834978	4	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m/read	1608802723834981	1608802723834998	3	-1	-1
bert/encoder/layer_1/output/dense/kernel/adam_m/read	1608802723835001	1608802723835006	3	-1	-1
bert/encoder/layer_2/attention/self/query/kernel/adam_m/read	1608802723835010	1608802723835015	4	-1	-1
bert/encoder/layer_2/attention/self/key/bias/adam_m/read	1608802723835023	1608802723835029	8	-1	-1
bert/encoder/layer_2/attention/output/dense/kernel/adam_v/read	1608802723835033	1608802723835040	4	-1	-1
bert/encoder/layer_3/attention/self/query/bias/adam_m/read	1608802723835043	1608802723835051	3	-1	-1
bert/encoder/layer_10/output/dense/bias/adam_v/read	1608802723835054	1608802723835061	3	-1	-1
bert/encoder/layer_3/attention/output/dense/bias/adam_v/read	1608802723835064	1608802723835069	3	-1	-1
bert/encoder/layer_3/intermediate/dense/kernel/adam_v/read	1608802723835073	1608802723835082	4	-1	-1
bert/encoder/layer_3/output/dense/bias/adam_m/read	1608802723835085	1608802723835092	3	-1	-1
bert/encoder/layer_4/attention/self/query/kernel/adam_v/read	1608802723835097	1608802723835107	5	-1	-1
bert/encoder/layer_4/attention/self/key/bias/adam_v/read	1608802723835111	1608802723835117	4	-1	-1
bert/encoder/layer_4/attention/output/dense/bias/adam_m/read	1608802723835121	1608802723835129	4	-1	-1
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v/read	1608802723835133	1608802723835142	4	-1	-1
bert/encoder/layer_2/output/dense/kernel/adam_v/read	1608802723835146	1608802723835151	4	-1	-1
bert/encoder/layer_10/output/dense/kernel/adam_v/read	1608802723835156	1608802723835166	5	-1	-1
bert/encoder/layer_3/attention/self/query/bias/adam_v/read	1608802723835169	1608802723835176	3	-1	-1
bert/encoder/layer_3/attention/self/value/kernel/adam_m/read	1608802723835179	1608802723835186	3	-1	-1
bert/pooler/dense/bias/adam_m/read	1608802723835189	1608802723835198	3	-1	-1
bert/encoder/layer_10/attention/self/query/kernel/adam_m/read	1608802723835202	1608802723835209	4	-1	-1
cls/predictions/transform/dense/kernel/adam_m/read	1608802723835212	1608802723835218	3	-1	-1
bert/encoder/layer_5/intermediate/dense/bias/adam_m/read	1608802723835224	1608802723835230	6	-1	-1
bert/encoder/layer_5/output/LayerNorm/beta/adam_m/read	1608802723835232	1608802723835238	2	-1	-1
bert/embeddings/position_embeddings/adam_m/read	1608802723835240	1608802723835251	2	-1	-1
bert/encoder/layer_0/attention/self/query/kernel/adam_m/read	1608802723835256	1608802723835261	5	-1	-1
bert/encoder/layer_0/attention/self/key/kernel/adam_v/read	1608802723835266	1608802723835271	5	-1	-1
bert/encoder/layer_0/attention/output/dense/kernel/adam_v/read	1608802723835279	1608802723835284	8	-1	-1
bert/encoder/layer_0/intermediate/dense/kernel/adam_m/read	1608802723835288	1608802723835295	4	-1	-1
bert/encoder/layer_0/output/dense/bias/adam_m/read	1608802723835300	1608802723835310	5	-1	-1
bert/encoder/layer_1/attention/self/query/kernel/adam_v/read	1608802723835313	1608802723835320	3	-1	-1
bert/encoder/layer_1/attention/self/key/bias/adam_m/read	1608802723835325	1608802723835333	5	-1	-1
bert/encoder/layer_1/attention/output/dense/kernel/adam_v/read	1608802723835340	1608802723835348	7	-1	-1
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v/read	1608802723835354	1608802723835359	6	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v/read	1608802723835363	1608802723835372	4	-1	-1
bert/encoder/layer_2/attention/self/query/kernel/adam_v/read	1608802723835379	1608802723835384	7	-1	-1
bert/encoder/layer_4/attention/output/dense/bias/adam_v/read	1608802723835388	1608802723835395	4	-1	-1
bert/encoder/layer_2/attention/output/dense/bias/adam_m/read	1608802723835403	1608802723835408	8	-1	-1
bert/encoder/layer_4/output/dense/bias/adam_m/read	1608802723835413	1608802723835420	5	-1	-1
bert/encoder/layer_5/attention/self/query/kernel/adam_v/read	1608802723835424	1608802723835433	4	-1	-1
bert/encoder/layer_10/output/dense/kernel/adam_m/read	1608802723835437	1608802723835444	4	-1	-1
bert/encoder/layer_2/output/LayerNorm/beta/adam_v/read	1608802723835447	1608802723835452	3	-1	-1
bert/encoder/layer_3/attention/self/key/kernel/adam_m/read	1608802723835462	1608802723835468	10	-1	-1
bert/encoder/layer_3/attention/self/value/kernel/adam_v/read	1608802723835472	1608802723835477	4	-1	-1
cls/predictions/transform/LayerNorm/beta/adam_v/read	1608802723835483	1608802723835496	6	-1	-1
bert/encoder/layer_3/intermediate/dense/bias/adam_m/read	1608802723835499	1608802723835504	3	-1	-1
bert/encoder/layer_3/output/dense/bias/adam_v/read	1608802723835507	1608802723835514	3	-1	-1
bert/encoder/layer_4/attention/self/query/bias/adam_m/read	1608802723835518	1608802723835527	4	-1	-1
bert/encoder/layer_4/attention/self/value/kernel/adam_m/read	1608802723835531	1608802723835537	4	-1	-1
bert/encoder/layer_11/attention/self/query/bias/adam_m/read	1608802723835542	1608802723835552	5	-1	-1
bert/encoder/layer_4/intermediate/dense/kernel/adam_m/read	1608802723835557	1608802723835563	5	-1	-1
bert/encoder/layer_4/output/dense/bias/adam_v/read	1608802723835568	1608802723835575	5	-1	-1
bert/encoder/layer_5/attention/self/query/bias/adam_m/read	1608802723835578	1608802723835590	3	-1	-1
bert/encoder/layer_10/attention/self/query/kernel/adam_v/read	1608802723835594	1608802723835599	4	-1	-1
bert/encoder/layer_5/attention/output/dense/bias/adam_m/read	1608802723835602	1608802723835613	3	-1	-1
bert/encoder/layer_5/intermediate/dense/bias/adam_v/read	1608802723835617	1608802723835624	4	-1	-1
bert/encoder/layer_11/attention/self/value/bias/adam_v/read	1608802723835626	1608802723835634	2	-1	-1
bert/encoder/layer_10/attention/self/key/bias/adam_v/read	1608802723835637	1608802723835646	3	-1	-1
bert/encoder/layer_0/attention/self/query/kernel/adam_v/read	1608802723835650	1608802723835657	4	-1	-1
bert/encoder/layer_10/attention/self/value/kernel/adam_v/read	1608802723835662	1608802723835671	5	-1	-1
bert/encoder/layer_0/attention/output/dense/bias/adam_m/read	1608802723835675	1608802723835681	4	-1	-1
bert/encoder/layer_4/attention/self/query/bias/adam_v/read	1608802723835686	1608802723835691	5	-1	-1
bert/encoder/layer_0/output/dense/bias/adam_v/read	1608802723835694	1608802723835705	3	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m/read	1608802723835708	1608802723835716	3	-1	-1
bert/encoder/layer_10/attention/output/dense/bias/adam_v/read	1608802723835721	1608802723835726	5	-1	-1
bert/encoder/layer_1/attention/output/dense/bias/adam_m/read	1608802723835735	1608802723835740	9	-1	-1
bert/encoder/layer_1/intermediate/dense/kernel/adam_m/read	1608802723835745	1608802723835752	5	-1	-1
bert/encoder/layer_1/output/dense/kernel/adam_v/read	1608802723835755	1608802723835764	3	-1	-1
bert/encoder/layer_2/attention/self/query/bias/adam_m/read	1608802723835768	1608802723835775	4	-1	-1
bert/encoder/layer_2/output/LayerNorm/gamma/adam_m/read	1608802723835778	1608802723835783	3	-1	-1
bert/encoder/layer_3/attention/self/key/kernel/adam_v/read	1608802723835791	1608802723835797	8	-1	-1
bert/encoder/layer_3/attention/self/value/bias/adam_m/read	1608802723835800	1608802723835805	3	-1	-1
bert/encoder/layer_10/output/LayerNorm/beta/adam_m/read	1608802723835808	1608802723835818	3	-1	-1
bert/encoder/layer_3/intermediate/dense/bias/adam_v/read	1608802723835821	1608802723835827	3	-1	-1
bert/encoder/layer_3/output/LayerNorm/beta/adam_m/read	1608802723835831	1608802723835836	4	-1	-1
bert/encoder/layer_11/attention/self/query/kernel/adam_m/read	1608802723835843	1608802723835848	7	-1	-1
bert/encoder/layer_4/attention/self/value/kernel/adam_v/read	1608802723835855	1608802723835860	7	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v/read	1608802723835863	1608802723835883	3	-1	-1
bert/encoder/layer_4/intermediate/dense/kernel/adam_v/read	1608802723835887	1608802723835892	4	-1	-1
bert/encoder/layer_11/attention/self/key/kernel/adam_v/read	1608802723835896	1608802723835902	4	-1	-1
bert/encoder/layer_5/attention/self/query/bias/adam_v/read	1608802723835911	1608802723835917	9	-1	-1
bert/encoder/layer_11/attention/self/key/bias/adam_v/read	1608802723835919	1608802723835924	2	-1	-1
bert/encoder/layer_5/attention/output/dense/bias/adam_v/read	1608802723835929	1608802723835939	5	-1	-1
bert/encoder/layer_2/output/LayerNorm/gamma/adam_v/read	1608802723835942	1608802723835949	3	-1	-1
cls/predictions/transform/LayerNorm/beta/adam_m/read	1608802723835951	1608802723835958	2	-1	-1
bert/encoder/layer_3/attention/self/value/bias/adam_v/read	1608802723835965	1608802723835972	7	-1	-1
bert/encoder/layer_5/output/dense/kernel/adam_m/read	1608802723835975	1608802723835981	3	-1	-1
bert/encoder/layer_5/output/LayerNorm/beta/adam_v/read	1608802723835985	1608802723835995	4	-1	-1
bert/embeddings/position_embeddings/adam_v/read	1608802723836000	1608802723836005	5	-1	-1
bert/encoder/layer_0/attention/self/query/bias/adam_m/read	1608802723836008	1608802723836013	3	-1	-1
bert/encoder/layer_0/attention/self/key/bias/adam_m/read	1608802723836017	1608802723836027	4	-1	-1
bert/encoder/layer_11/attention/self/query/bias/adam_v/read	1608802723836030	1608802723836036	3	-1	-1
bert/encoder/layer_4/intermediate/dense/bias/adam_m/read	1608802723836040	1608802723836046	4	-1	-1
bert/encoder/layer_4/output/LayerNorm/beta/adam_m/read	1608802723836052	1608802723836058	6	-1	-1
bert/encoder/layer_5/attention/self/key/kernel/adam_m/read	1608802723836061	1608802723836068	3	-1	-1
bert/encoder/layer_1/attention/self/key/bias/adam_v/read	1608802723836072	1608802723836083	4	-1	-1
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m/read	1608802723836086	1608802723836091	3	-1	-1
bert/encoder/layer_1/output/dense/bias/adam_m/read	1608802723836094	1608802723836099	3	-1	-1
bert/encoder/layer_3/attention/self/query/kernel/adam_m/read	1608802723836108	1608802723836114	9	-1	-1
bert/encoder/layer_10/output/dense/bias/adam_m/read	1608802723836118	1608802723836125	4	-1	-1
bert/encoder/layer_3/attention/output/dense/kernel/adam_m/read	1608802723836130	1608802723836140	5	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m/read	1608802723836147	1608802723836155	7	-1	-1
bert/encoder/layer_3/output/dense/kernel/adam_m/read	1608802723836160	1608802723836165	5	-1	-1
bert/encoder/layer_3/output/LayerNorm/beta/adam_v/read	1608802723836172	1608802723836180	7	-1	-1
bert/encoder/layer_4/attention/self/key/kernel/adam_m/read	1608802723836182	1608802723836191	2	-1	-1
bert/encoder/layer_4/attention/self/value/bias/adam_m/read	1608802723836195	1608802723836205	4	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m/read	1608802723836210	1608802723836215	5	-1	-1
bert/encoder/layer_4/intermediate/dense/bias/adam_v/read	1608802723836220	1608802723836227	5	-1	-1
bert/encoder/layer_4/output/LayerNorm/beta/adam_v/read	1608802723836234	1608802723836240	7	-1	-1
cls/predictions/transform/LayerNorm/gamma/adam_v/read	1608802723836243	1608802723836251	3	-1	-1
bert/encoder/layer_5/attention/self/key/bias/adam_v/read	1608802723836256	1608802723836267	5	-1	-1
bert/encoder/layer_11/attention/self/value/kernel/adam_m/read	1608802723836270	1608802723836277	3	-1	-1
bert/encoder/layer_3/attention/self/key/bias/adam_m/read	1608802723836281	1608802723836286	4	-1	-1
bert/encoder/layer_3/attention/output/dense/kernel/adam_v/read	1608802723836293	1608802723836299	7	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v/read	1608802723836303	1608802723836308	4	-1	-1
bert/encoder/layer_5/output/LayerNorm/gamma/adam_m/read	1608802723836313	1608802723836323	5	-1	-1
bert/encoder/layer_3/output/LayerNorm/gamma/adam_m/read	1608802723836326	1608802723836333	3	-1	-1
bert/encoder/layer_0/attention/self/query/bias/adam_v/read	1608802723836336	1608802723836342	3	-1	-1
bert/encoder/layer_4/attention/self/value/bias/adam_v/read	1608802723836344	1608802723836353	2	-1	-1
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v/read	1608802723836357	1608802723836371	4	-1	-1
bert/encoder/layer_4/output/dense/kernel/adam_m/read	1608802723836374	1608802723836379	3	-1	-1
bert/encoder/layer_4/output/LayerNorm/gamma/adam_m/read	1608802723836386	1608802723836393	7	-1	-1
bert/encoder/layer_11/attention/self/key/bias/adam_m/read	1608802723836397	1608802723836402	4	-1	-1
bert/encoder/layer_5/attention/self/value/kernel/adam_m/read	1608802723836406	1608802723836415	4	-1	-1
bert/encoder/layer_1/intermediate/dense/kernel/adam_v/read	1608802723836419	1608802723836425	4	-1	-1
bert/encoder/layer_10/output/LayerNorm/beta/adam_v/read	1608802723836428	1608802723836433	3	-1	-1
bert/encoder/layer_10/output/LayerNorm/gamma/adam_m/read	1608802723836441	1608802723836446	8	-1	-1
bert/encoder/layer_3/output/LayerNorm/gamma/adam_v/read	1608802723836450	1608802723836455	4	-1	-1
bert/encoder/layer_4/attention/self/key/kernel/adam_v/read	1608802723836458	1608802723836467	3	-1	-1
bert/encoder/layer_4/attention/output/dense/kernel/adam_m/read	1608802723836470	1608802723836475	3	-1	-1
bert/encoder/layer_11/attention/self/key/kernel/adam_m/read	1608802723836480	1608802723836485	5	-1	-1
bert/encoder/layer_4/output/LayerNorm/gamma/adam_v/read	1608802723836492	1608802723836500	7	-1	-1
bert/encoder/layer_5/attention/self/key/kernel/adam_v/read	1608802723836503	1608802723836509	3	-1	-1
bert/encoder/layer_5/attention/self/value/kernel/adam_v/read	1608802723836512	1608802723836525	3	-1	-1
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m/read	1608802723836529	1608802723836536	4	-1	-1
bert/encoder/layer_3/output/dense/kernel/adam_v/read	1608802723836539	1608802723836544	3	-1	-1
bert/encoder/layer_4/attention/self/query/kernel/adam_m/read	1608802723836551	1608802723836557	7	-1	-1
bert/encoder/layer_11/attention/self/query/kernel/adam_v/read	1608802723836559	1608802723836565	2	-1	-1
bert/encoder/layer_4/attention/output/dense/kernel/adam_v/read	1608802723836568	1608802723836578	3	-1	-1
bert/encoder/layer_4/output/dense/kernel/adam_v/read	1608802723836581	1608802723836587	3	-1	-1
bert/encoder/layer_5/attention/self/query/kernel/adam_m/read	1608802723836589	1608802723836595	2	-1	-1
bert/encoder/layer_5/attention/self/key/bias/adam_m/read	1608802723836601	1608802723836608	6	-1	-1
bert/encoder/layer_5/attention/self/value/bias/adam_m/read	1608802723836611	1608802723836617	3	-1	-1
bert/encoder/layer_4/attention/self/key/bias/adam_m/read	1608802723836621	1608802723836632	4	-1	-1
cls/predictions/transform/LayerNorm/gamma/adam_m/read	1608802723836637	1608802723836642	5	-1	-1
bert/encoder/layer_5/attention/self/value/bias/adam_v/read	1608802723836645	1608802723836650	3	-1	-1
bert/encoder/layer_5/attention/output/dense/kernel/adam_m/read	1608802723836659	1608802723836664	9	-1	-1
Mul_497	1608802723836668	1608802723836728	4	1608802723836695	29
Cast	1608802723836743	1608802723836798	15	1608802723836767	25
add_699	1608802723836803	1608802723836857	5	1608802723836823	27
global_step/cond/Switch_1	1608802723836867	1608802723836875	10	-1	-1
global_step/cond/Read/ReadVariableOp/Switch	1608802723836878	1608802723836888	3	-1	-1
PolynomialDecay/Cast_2	1608802723836891	1608802723836951	3	1608802723836924	22
bert/embeddings/dropout/random_uniform/mul	1608802723836956	1608802723836966	5	-1	-1
mul_47	1608802723837079	1608802723837140	113	1608802723837104	29
Mul_559	1608802723837150	1608802723837201	10	1608802723837167	26
bert/embeddings/assert_less_equal/Assert/Assert	1608802723837178	1608802723837215	-23	-1	-1
mul_20	1608802723837210	1608802723837256	-5	1608802723837232	20
bert/embeddings/Slice/begin	1608802723837244	1608802723837261	-12	-1	-1
Mul_572	1608802723837263	1608802723837312	2	1608802723837287	23
bert/embeddings/Slice/size	1608802723837265	1608802723837275	-47	-1	-1
bert/embeddings/Reshape_4/shape	1608802723837280	1608802723837288	5	-1	-1
gradients/bert/embeddings/Slice_grad/concat	1608802723837292	1608802723837304	4	-1	-1
mul_230	1608802723837321	1608802723837370	17	1608802723837338	22
bert/embeddings/Slice	1608802723837323	1608802723837348	-47	-1	-1
bert/embeddings/Reshape_4	1608802723837354	1608802723837368	6	-1	-1
mul_69	1608802723837376	1608802723837423	8	1608802723837393	23
mul_133	1608802723837429	1608802723837478	6	1608802723837453	23
Mul_642	1608802723837486	1608802723837531	8	1608802723837502	18
mul_703	1608802723837535	1608802723837577	4	1608802723837553	49
mul_789	1608802723837584	1608802723837635	7	1608802723837606	54
mul_821	1608802723837642	1608802723837680	7	1608802723837662	18
mul_918	1608802723837687	1608802723837733	7	1608802723837709	22
mul_950	1608802723837739	1608802723837782	6	1608802723837759	49
Mul_694	1608802723837795	1608802723837833	13	1608802723837810	17
Mul_705	1608802723837840	1608802723837881	7	1608802723837855	20
Mul_722	1608802723837885	1608802723837922	4	1608802723837900	22
Mul_1101	1608802723837936	1608802723837975	14	1608802723837952	17
Mul_759	1608802723837981	1608802723838025	6	1608802723837997	16
Mul_726	1608802723838028	1608802723838067	3	1608802723838045	16
Mul_715	1608802723838070	1608802723838111	3	1608802723838088	17
Mul_1051	1608802723838115	1608802723838155	4	1608802723838128	16
Mul_742	1608802723838158	1608802723838194	3	1608802723838172	23
Mul_761	1608802723838201	1608802723838247	7	1608802723838223	17
Mul_845	1608802723838250	1608802723838288	3	1608802723838266	16
mul_735	1608802723838297	1608802723838335	9	1608802723838313	22
Mul_678	1608802723838342	1608802723838383	7	1608802723838355	21
Mul_1032	1608802723838387	1608802723838423	4	1608802723838401	49
Mul_1038	1608802723838430	1608802723838474	7	1608802723838452	17
Mul_1034	1608802723838480	1608802723838525	6	1608802723838498	48
mul_1047	1608802723838534	1608802723838573	9	1608802723838551	50
Mul_764	1608802723838580	1608802723838624	7	1608802723838602	16
Mul_806	1608802723838628	1608802723838670	4	1608802723838643	21
Mul_717	1608802723838678	1608802723838717	8	1608802723838694	17
Mul_728	1608802723838720	1608802723838763	3	1608802723838740	17
Mul_1045	1608802723838766	1608802723838804	3	1608802723838782	49
Mul_774	1608802723838816	1608802723838862	12	1608802723838833	54
Mul_1103	1608802723838869	1608802723838917	7	1608802723838893	17
mul_896	1608802723838921	1608802723838961	4	1608802723838935	21
Mul_1061	1608802723838967	1608802723839005	6	1608802723838982	17
Mul_847	1608802723839008	1608802723839051	3	1608802723839028	17
Mul_680	1608802723839055	1608802723839089	4	1608802723839069	15
Mul_683	1608802723839099	1608802723839133	10	1608802723839112	16
Mul_776	1608802723839138	1608802723839182	5	1608802723839154	49
Mul_658	1608802723839189	1608802723839228	7	1608802723839205	23
Mul_662	1608802723839239	1608802723839277	11	1608802723839254	17
Mul_707	1608802723839280	1608802723839335	3	1608802723839296	32
mul_929	1608802723839339	1608802723839380	4	1608802723839357	22
Mul_675	1608802723839386	1608802723839433	6	1608802723839410	17
Mul_744	1608802723839437	1608802723839483	4	1608802723839453	22
Mul_766	1608802723839490	1608802723839530	7	1608802723839507	17
Mul_1054	1608802723839533	1608802723839578	3	1608802723839555	17
Mul_808	1608802723839582	1608802723839619	4	1608802723839598	22
mul_864	1608802723839631	1608802723839672	12	1608802723839648	49
Mul_731	1608802723839679	1608802723839725	7	1608802723839701	23
Mul_769	1608802723839732	1608802723839768	7	1608802723839746	16
Mul_780	1608802723839779	1608802723839817	11	1608802723839795	17
Mul_793	1608802723839822	1608802723839865	5	1608802723839838	20
mul_1068	1608802723839868	1608802723839903	3	1608802723839882	22
Mul_825	1608802723839913	1608802723839957	10	1608802723839934	17
Mul_1064	1608802723839960	1608802723840001	3	1608802723839974	22
Mul_699	1608802723840008	1608802723840046	7	1608802723840023	49
Mul_710	1608802723840052	1608802723840095	6	1608802723840073	15
Mul_1049	1608802723840098	1608802723840136	3	1608802723840115	16
Mul_782	1608802723840144	1608802723840182	8	1608802723840160	17
Mul_796	1608802723840186	1608802723840230	4	1608802723840203	20
Mul_812	1608802723840233	1608802723840269	3	1608802723840247	16
Mul_828	1608802723840272	1608802723840316	3	1608802723840294	21
mul_1105	1608802723840323	1608802723840382	7	1608802723840341	17
Mul_701	1608802723840386	1608802723840429	4	1608802723840405	50
Mul_720	1608802723840436	1608802723840481	7	1608802723840458	21
Mul_733	1608802723840487	1608802723840532	6	1608802723840502	22
Mul_748	1608802723840538	1608802723840576	6	1608802723840553	18
Mul_771	1608802723840579	1608802723840622	3	1608802723840599	16
Mul_785	1608802723840625	1608802723840682	3	1608802723840643	63
Mul_1056	1608802723840691	1608802723840732	9	1608802723840709	17
Mul_814	1608802723840736	1608802723840771	4	1608802723840750	16
Mul_830	1608802723840774	1608802723840819	3	1608802723840795	23
Mul_850	1608802723840825	1608802723840878	6	1608802723840852	15
Mul_696	1608802723840882	1608802723840917	4	1608802723840896	15
Mul_712	1608802723840920	1608802723840958	3	1608802723840932	21
Mul_737	1608802723840961	1608802723840997	3	1608802723840977	15
Mul_750	1608802723841007	1608802723841043	10	1608802723841022	15
Mul_787	1608802723841046	1608802723841085	3	1608802723841060	47
Mul_803	1608802723841092	1608802723841129	7	1608802723841109	14
Mul_817	1608802723841132	1608802723841171	3	1608802723841150	21
Mul_834	1608802723841177	1608802723841216	6	1608802723841190	15
Mul_852	1608802723841219	1608802723841254	3	1608802723841234	15
mul_90	1608802723841259	1608802723841299	5	1608802723841277	49
Mul_1043	1608802723841305	1608802723841341	6	1608802723841328	40
Mul_753	1608802723841352	1608802723841389	11	1608802723841369	19
mul_327	1608802723841395	1608802723841441	6	1608802723841411	29
Mul_791	1608802723841447	1608802723841481	6	1608802723841461	16
Mul_798	1608802723841497	1608802723841535	16	1608802723841514	16
Mul_823	1608802723841538	1608802723841579	3	1608802723841553	20
Mul_841	1608802723841582	1608802723841615	3	1608802723841595	21
Mul_855	1608802723841622	1608802723841664	7	1608802723841643	17
mul_58	1608802723841668	1608802723841711	4	1608802723841685	21
mul_155	1608802723841717	1608802723841755	6	1608802723841734	22
mul_187	1608802723841761	1608802723841803	6	1608802723841781	49
Mul_739	1608802723841809	1608802723841848	6	1608802723841832	8
Mul_755	1608802723841852	1608802723841887	4	1608802723841866	21
mul_262	1608802723841893	1608802723841938	6	1608802723841915	49
mul_294	1608802723841944	1608802723841981	6	1608802723841966	15
Mul_801	1608802723841992	1608802723842029	11	1608802723842007	17
Mul_1059	1608802723842033	1608802723842070	4	1608802723842045	19
Mul_836	1608802723842073	1608802723842110	3	1608802723842089	16
Mul_1066	1608802723842113	1608802723842153	3	1608802723842132	21
Mul_548	1608802723842159	1608802723842201	6	1608802723842175	21
Mul_554	1608802723842207	1608802723842245	6	1608802723842223	17
Mul_561	1608802723842248	1608802723842288	3	1608802723842267	22
Mul_508	1608802723842296	1608802723842336	8	1608802723842313	15
mul_144	1608802723842342	1608802723842379	6	1608802723842358	21
mul_176	1608802723842385	1608802723842430	6	1608802723842403	54
mul_208	1608802723842437	1608802723842474	7	1608802723842459	15
Mul_581	1608802723842485	1608802723842521	11	1608802723842499	22
Mul_819	1608802723842527	1608802723842568	6	1608802723842541	21
Mul_839	1608802723842573	1608802723842609	5	1608802723842588	21
Mul_857	1608802723842619	1608802723842655	10	1608802723842634	16
mul_391	1608802723842659	1608802723842701	4	1608802723842674	21
mul_14	1608802723842708	1608802723842748	7	1608802723842727	16
bert/embeddings/MatMul	1608802723842752	1608802723842833	4	1608802723842796	62
Mul_556	1608802723842843	1608802723842888	10	1608802723842860	16
Mul_1011	1608802723842893	1608802723842929	5	1608802723842909	22
Mul_565	1608802723842938	1608802723842980	9	1608802723842958	17
Mul_576	1608802723842983	1608802723843018	3	1608802723842998	15
Mul_583	1608802723843026	1608802723843060	8	1608802723843040	20
mul_273	1608802723843067	1608802723843107	7	1608802723843080	49
mul_359	1608802723843114	1608802723843154	7	1608802723843132	49
Mul_545	1608802723843165	1608802723843201	11	1608802723843183	13
mul_520	1608802723843205	1608802723843245	4	1608802723843220	48
mul_36	1608802723843252	1608802723843289	7	1608802723843269	20
Mul_634	1608802723843295	1608802723843336	6	1608802723843315	21
bert/encoder/layer_11/attention/self/dropout/random_uniform/mul	1608802723843343	1608802723843355	7	-1	-1
bert/encoder/layer_4/attention/self/dropout/random_uniform/mul	1608802723843366	1608802723843374	11	-1	-1
bert/encoder/layer_7/attention/self/dropout/random_uniform/mul	1608802723843378	1608802723843386	4	-1	-1
bert/encoder/layer_9/attention/self/dropout/random_uniform/mul	1608802723843391	1608802723843404	5	-1	-1
bert/encoder/layer_0/attention/self/dropout/random_uniform/mul	1608802723843407	1608802723843414	3	-1	-1
bert/encoder/layer_1/attention/self/dropout/random_uniform/mul	1608802723843418	1608802723843427	4	-1	-1
bert/encoder/layer_2/attention/self/dropout/random_uniform/mul	1608802723843430	1608802723843436	3	-1	-1
bert/encoder/layer_10/attention/self/dropout/random_uniform/mul	1608802723843443	1608802723843449	7	-1	-1
bert/encoder/layer_5/attention/self/dropout/random_uniform/mul	1608802723843457	1608802723843465	8	-1	-1
bert/encoder/layer_8/attention/self/dropout/random_uniform/mul	1608802723843469	1608802723843476	4	-1	-1
bert/encoder/layer_6/attention/self/dropout/random_uniform/mul	1608802723843480	1608802723843499	4	-1	-1
bert/encoder/layer_3/attention/self/dropout/random_uniform/mul	1608802723843503	1608802723843511	4	-1	-1
Mul_567	1608802723843515	1608802723843561	4	1608802723843534	21
mul_219	1608802723843564	1608802723843598	3	1608802723843578	21
mul_241	1608802723843609	1608802723843648	11	1608802723843626	21
mul_305	1608802723843654	1608802723843694	6	1608802723843667	21
Mul_599	1608802723843700	1608802723843735	6	1608802723843714	16
Mul_1019	1608802723843739	1608802723843795	4	1608802723843760	29
Mul_613	1608802723843800	1608802723843840	5	1608802723843819	48
Mul_626	1608802723843847	1608802723843890	7	1608802723843869	11
mul_649	1608802723843895	1608802723843941	5	1608802723843910	27
mul_122	1608802723843948	1608802723843990	7	1608802723843968	22
Mul_1013	1608802723843998	1608802723844061	8	1608802723844013	36
mul_832	1608802723844067	1608802723844105	6	1608802723844083	22
Mul_578	1608802723844110	1608802723844153	5	1608802723844131	16
Mul_602	1608802723844157	1608802723844192	4	1608802723844172	47
mul_434	1608802723844206	1608802723844242	14	1608802723844221	48
Mul_610	1608802723844251	1608802723844293	9	1608802723844271	17
mul_488	1608802723844296	1608802723844332	3	1608802723844312	21
Mul_550	1608802723844345	1608802723844392	13	1608802723844367	23
Mul_631	1608802723844402	1608802723844447	10	1608802723844420	21
Mul_1027	1608802723844451	1608802723844487	4	1608802723844467	16
mul_101	1608802723844491	1608802723844533	4	1608802723844512	49
Mul_570	1608802723844540	1608802723844583	7	1608802723844562	15
Mul_664	1608802723844589	1608802723844626	6	1608802723844604	16
mul_961	1608802723844629	1608802723844669	3	1608802723844647	49
mul_348	1608802723844675	1608802723844718	6	1608802723844697	43
Mul_1096	1608802723844725	1608802723844763	7	1608802723844742	15
mul_402	1608802723844769	1608802723844815	6	1608802723844792	22
Mul_1022	1608802723844822	1608802723844857	7	1608802723844836	16
mul_552	1608802723844866	1608802723844903	9	1608802723844882	21
mul_617	1608802723844909	1608802723844949	6	1608802723844922	48
Mul_636	1608802723844955	1608802723844993	6	1608802723844972	20
mul_692	1608802723845000	1608802723845043	7	1608802723845021	49
Mul_667	1608802723845049	1608802723845091	6	1608802723845072	13
mul_993	1608802723845097	1608802723845133	6	1608802723845112	22
mul_316	1608802723845139	1608802723845183	6	1608802723845161	22
Mul_608	1608802723845189	1608802723845230	6	1608802723845203	16
mul_466	1608802723845233	1608802723845270	3	1608802723845250	21
Mul_615	1608802723845278	1608802723845323	8	1608802723845301	50
Mul_619	1608802723845330	1608802723845368	7	1608802723845352	10
mul_585	1608802723845378	1608802723845413	10	1608802723845392	22
mul_660	1608802723845419	1608802723845462	6	1608802723845436	27
Mul_640	1608802723845468	1608802723845502	6	1608802723845482	15
mul_724	1608802723845511	1608802723845545	9	1608802723845525	21
Mul_647	1608802723845551	1608802723845595	6	1608802723845568	21
Mul_1029	1608802723845601	1608802723845638	6	1608802723845617	16
bert/encoder/layer_0/output/dropout/random_uniform/mul	1608802723845643	1608802723845658	5	-1	-1
bert/encoder/layer_6/attention/output/dropout/random_uniform/mul	1608802723845663	1608802723845672	5	-1	-1
bert/encoder/layer_8/output/dropout/random_uniform/mul	1608802723845677	1608802723845699	5	-1	-1
bert/encoder/layer_4/attention/output/dropout/random_uniform/mul	1608802723845702	1608802723845709	3	-1	-1
bert/encoder/layer_9/output/dropout/random_uniform/mul	1608802723845713	1608802723845722	4	-1	-1
bert/encoder/layer_2/attention/output/dropout/random_uniform/mul	1608802723845725	1608802723845735	3	-1	-1
bert/encoder/layer_4/output/dropout/random_uniform/mul	1608802723845739	1608802723845745	4	-1	-1
bert/encoder/layer_10/attention/output/dropout/random_uniform/mul	1608802723845748	1608802723845760	3	-1	-1
bert/encoder/layer_10/output/dropout/random_uniform/mul	1608802723845765	1608802723845773	5	-1	-1
bert/encoder/layer_1/attention/output/dropout/random_uniform/mul	1608802723845776	1608802723845783	3	-1	-1
bert/encoder/layer_5/attention/output/dropout/random_uniform/mul	1608802723845791	1608802723845797	8	-1	-1
bert/encoder/layer_9/attention/output/dropout/random_uniform/mul	1608802723845800	1608802723845806	3	-1	-1
bert/encoder/layer_11/attention/output/dropout/random_uniform/mul	1608802723845809	1608802723845821	3	-1	-1
bert/encoder/layer_1/output/dropout/random_uniform/mul	1608802723845824	1608802723845830	3	-1	-1
bert/encoder/layer_3/attention/output/dropout/random_uniform/mul	1608802723845834	1608802723845841	4	-1	-1
bert/encoder/layer_6/output/dropout/random_uniform/mul	1608802723845848	1608802723845856	7	-1	-1
bert/encoder/layer_11/output/dropout/random_uniform/mul	1608802723845859	1608802723845865	3	-1	-1
bert/encoder/layer_2/output/dropout/random_uniform/mul	1608802723845868	1608802723845878	3	-1	-1
bert/encoder/layer_3/output/dropout/random_uniform/mul	1608802723845881	1608802723845887	3	-1	-1
bert/encoder/layer_7/attention/output/dropout/random_uniform/mul	1608802723845891	1608802723845899	4	-1	-1
bert/encoder/layer_0/attention/output/dropout/random_uniform/mul	1608802723845907	1608802723845915	8	-1	-1
bert/encoder/layer_5/output/dropout/random_uniform/mul	1608802723845918	1608802723845924	3	-1	-1
bert/encoder/layer_7/output/dropout/random_uniform/mul	1608802723845928	1608802723845938	4	-1	-1
bert/encoder/layer_8/attention/output/dropout/random_uniform/mul	1608802723845941	1608802723845948	3	-1	-1
mul_843	1608802723845952	1608802723845996	4	1608802723845967	23
mul_875	1608802723846002	1608802723846041	6	1608802723846020	49
mul_907	1608802723846052	1608802723846091	11	1608802723846070	20
Mul_587	1608802723846097	1608802723846137	6	1608802723846111	15
Mul_1017	1608802723846140	1608802723846176	3	1608802723846156	15
Mul_604	1608802723846181	1608802723846222	5	1608802723846201	49
mul_445	1608802723846230	1608802723846273	8	1608802723846251	43
mul_499	1608802723846279	1608802723846315	6	1608802723846295	19
mul_531	1608802723846321	1608802723846363	6	1608802723846341	49
mul_563	1608802723846370	1608802723846404	7	1608802723846392	13
mul_746	1608802723846417	1608802723846455	13	1608802723846433	22
mul_778	1608802723846462	1608802723846506	7	1608802723846478	49
Mul_673	1608802723846513	1608802723846548	7	1608802723846529	14
mul_1004	1608802723846557	1608802723846592	9	1608802723846572	20
Mul_592	1608802723846598	1608802723846639	6	1608802723846612	21
Mul_597	1608802723846642	1608802723846676	3	1608802723846656	16
mul_380	1608802723846679	1608802723846722	3	1608802723846700	21
mul_413	1608802723846728	1608802723846771	6	1608802723846744	21
Mul_1040	1608802723846777	1608802723846816	6	1608802723846794	17
mul_477	1608802723846820	1608802723846863	4	1608802723846842	22
Mul_645	1608802723846870	1608802723846910	7	1608802723846884	21
Mul_506	1608802723846917	1608802723846955	7	1608802723846933	17
mul_810	1608802723846961	1608802723847002	6	1608802723846980	22
Mul_4	1608802723847008	1608802723847049	6	1608802723847028	371
Mul_669	1608802723847064	1608802723847116	15	1608802723847401	13
mul_982	1608802723847123	1608802723847159	7	1608802723847415	13
Mul_594	1608802723847164	1608802723847201	5	1608802723847430	4
Mul_191	1608802723847206	1608802723847241	5	1608802723847435	5
Mul_1083	1608802723847245	1608802723847276	4	1608802723847442	4
Mul_621	1608802723847280	1608802723847312	4	1608802723847447	4
Mul_1024	1608802723847315	1608802723847355	3	1608802723847453	4
mul_638	1608802723847358	1608802723847398	3	1608802723847459	13
mul_671	1608802723847404	1608802723847477	6	1608802723847473	13
Mul_860	1608802723847483	1608802723847541	6	1608802723847518	49
Mul_1098	1608802723847548	1608802723847587	7	1608802723847569	13
mul_8	1608802723847600	1608802723847641	13	1608802723847619	372
bert/embeddings/GatherV2	1608802723847649	1608802723847706	8	1608802723847993	78
Mul_651	1608802723847715	1608802723847752	9	1608802723848073	4
Mul_1077	1608802723847772	1608802723847810	20	1608802723848079	12
Mul_51	1608802723847818	1608802723847863	8	1608802723848093	4
Mul_73	1608802723847867	1608802723847902	4	1608802723848098	4
mul_1015	1608802723847910	1608802723847945	8	1608802723848104	13
Mul_685	1608802723847951	1608802723847991	6	1608802723848119	4
Mul_688	1608802723847996	1608802723848029	5	1608802723848125	39
Mul_589	1608802723848041	1608802723848080	12	1608802723848166	4
Mul_1109	1608802723848084	1608802723848122	4	1608802723848171	4
Mul_223	1608802723848125	1608802723848163	3	1608802723848177	4
Mul_624	1608802723848166	1608802723848206	3	1608802723848186	15
mul_606	1608802723848211	1608802723848251	5	1608802723848227	47
Mul_862	1608802723848258	1608802723848297	7	1608802723848275	49
Mul_879	1608802723848304	1608802723848348	7	1608802723848326	16
Mul_898	1608802723848351	1608802723848397	3	1608802723848375	16
mul_757	1608802723848406	1608802723848441	9	1608802723848420	20
Mul_54	1608802723848448	1608802723848490	7	1608802723848461	23
Mul_920	1608802723848495	1608802723848530	5	1608802723848509	16
Mul_88	1608802723848540	1608802723848576	10	1608802723848555	48
Mul_927	1608802723848583	1608802723848625	7	1608802723848605	15
mul_1036	1608802723848631	1608802723848667	6	1608802723848646	48
Mul_690	1608802723848674	1608802723848716	7	1608802723848696	47
mul_1079	1608802723848722	1608802723848761	6	1608802723848744	13
Mul_511	1608802723848768	1608802723848804	7	1608802723848782	16
Mul_194	1608802723848807	1608802723848850	3	1608802723848829	16
Mul_212	1608802723848853	1608802723848890	3	1608802723848870	15
Mul_226	1608802723848898	1608802723848933	8	1608802723848913	21
mul_574	1608802723848940	1608802723848983	7	1608802723848959	24
Mul_629	1608802723848989	1608802723849024	6	1608802723849003	16
Mul_866	1608802723849033	1608802723849068	9	1608802723849048	16
Mul_882	1608802723849074	1608802723849114	6	1608802723849088	19
Mul_900	1608802723849117	1608802723849153	3	1608802723849132	16
Mul_653	1608802723849156	1608802723849197	3	1608802723849176	16
Mul_56	1608802723849200	1608802723849242	3	1608802723849216	21
Mul_76	1608802723849248	1608802723849286	6	1608802723849264	16
Mul_92	1608802723849289	1608802723849332	3	1608802723849311	16
Mul_108	1608802723849336	1608802723849370	4	1608802723849350	15
Mul_124	1608802723849378	1608802723849414	8	1608802723849393	16
Mul_140	1608802723849417	1608802723849459	3	1608802723849433	21
Mul_159	1608802723849465	1608802723849504	6	1608802723849483	16
Mul_178	1608802723849510	1608802723849553	6	1608802723849532	15
Mul_946	1608802723849556	1608802723849595	3	1608802723849571	47
Mul_228	1608802723849602	1608802723849640	7	1608802723849619	21
Mul_868	1608802723849645	1608802723849688	5	1608802723849666	16
Mul_1072	1608802723849691	1608802723849746	3	1608802723849706	28
Mul_1002	1608802723849749	1608802723849787	3	1608802723849766	21
Mul_529	1608802723849793	1608802723849837	6	1608802723849815	49
Mul_6	1608802723849844	1608802723849882	7	1608802723849866	366
Mul_22	1608802723849897	1608802723849936	15	1608802723850235	4
Mul_656	1608802723849939	1608802723849978	3	1608802723850241	12
Mul_78	1608802723849985	1608802723850025	7	1608802723850254	4
Mul_94	1608802723850028	1608802723850068	3	1608802723850260	4
Mul_110	1608802723850073	1608802723850112	5	1608802723850266	4
Mul_126	1608802723850116	1608802723850152	4	1608802723850272	4
Mul_142	1608802723850155	1608802723850196	3	1608802723850277	12
Mul_162	1608802723850204	1608802723850245	8	1608802723850291	4
Mul_180	1608802723850249	1608802723850285	4	1608802723850297	4
Mul_196	1608802723850288	1608802723850329	3	1608802723850304	20
Mul_215	1608802723850332	1608802723850367	3	1608802723850347	21
Mul_232	1608802723850378	1608802723850418	11	1608802723850396	16
Mul_871	1608802723850422	1608802723850464	4	1608802723850437	48
Mul_884	1608802723850471	1608802723850507	7	1608802723850487	16
Mul_903	1608802723850512	1608802723850552	5	1608802723850531	20
Mul_513	1608802723850558	1608802723850600	6	1608802723850573	15
Mul_533	1608802723850603	1608802723850639	3	1608802723850619	15
Mul_10	1608802723850642	1608802723850685	3	1608802723850664	16
Mul_24	1608802723850688	1608802723850729	3	1608802723850703	15
Mul_1107	1608802723850732	1608802723850766	3	1608802723850746	15
Mul_60	1608802723850770	1608802723850809	4	1608802723850785	19
Mul_922	1608802723850812	1608802723850848	3	1608802723850827	16
Mul_97	1608802723850852	1608802723850894	4	1608802723850873	48
Mul_113	1608802723850901	1608802723850950	7	1608802723850923	14
Mul_129	1608802723850955	1608802723850996	5	1608802723850974	22
Mul_146	1608802723851002	1608802723851047	6	1608802723851025	17
Mul_938	1608802723851052	1608802723851092	5	1608802723851067	15
Mul_1081	1608802723851095	1608802723851132	3	1608802723851112	15
Mul_199	1608802723851135	1608802723851177	3	1608802723851153	19
Mul_948	1608802723851180	1608802723851217	3	1608802723851197	47
Mul_234	1608802723851229	1608802723851267	12	1608802723851247	15
Mul_245	1608802723851270	1608802723851310	3	1608802723851285	19
Mul_952	1608802723851313	1608802723851349	3	1608802723851328	16
Mul_258	1608802723851354	1608802723851395	5	1608802723851374	48
Mul_248	1608802723851402	1608802723851444	7	1608802723851423	10
Mul_260	1608802723851448	1608802723851486	4	1608802723851465	48
Mul_275	1608802723851493	1608802723851536	7	1608802723851515	16
Mul_250	1608802723851539	1608802723851582	3	1608802723851556	16
Mul_264	1608802723851585	1608802723851621	3	1608802723851600	16
Mul_873	1608802723851627	1608802723851669	6	1608802723851644	48
Mul_887	1608802723851676	1608802723851712	7	1608802723851693	13
Mul_516	1608802723851721	1608802723851758	9	1608802723851737	49
Mul_1006	1608802723851765	1608802723851805	7	1608802723851788	11
Mul_12	1608802723851809	1608802723851846	4	1608802723851825	17
Mul_27	1608802723851849	1608802723851898	3	1608802723851877	16
Mul_914	1608802723851902	1608802723851942	4	1608802723851917	21
Mul_62	1608802723851949	1608802723851986	7	1608802723851964	16
Mul_81	1608802723851989	1608802723852030	3	1608802723852009	16
Mul_925	1608802723852034	1608802723852067	4	1608802723852048	20
Mul_115	1608802723852079	1608802723852117	12	1608802723852095	17
Mul_931	1608802723852121	1608802723852161	4	1608802723852136	20
Mul_148	1608802723852165	1608802723852201	4	1608802723852180	15
Mul_164	1608802723852204	1608802723852245	3	1608802723852224	16
Mul_941	1608802723852250	1608802723852293	5	1608802723852266	15
Mul_201	1608802723852296	1608802723852332	3	1608802723852311	16
Mul_217	1608802723852336	1608802723852388	4	1608802723852355	30
Mul_237	1608802723852395	1608802723852441	7	1608802723852413	22
Mul_341	1608802723852448	1608802723852486	7	1608802723852464	17
Mul_253	1608802723852489	1608802723852530	3	1608802723852509	16
Mul_266	1608802723852535	1608802723852571	5	1608802723852551	15
Mul_277	1608802723852581	1608802723852627	10	1608802723852607	15
Mul_292	1608802723852630	1608802723852668	3	1608802723852644	20
Mul_309	1608802723852676	1608802723852710	8	1608802723852691	15
Mul_329	1608802723852720	1608802723852755	10	1608802723852735	15
Mul_344	1608802723852758	1608802723852797	3	1608802723852773	47
Mul_975	1608802723852803	1608802723852840	6	1608802723852822	13
Mul_954	1608802723852845	1608802723852886	5	1608802723852866	15
Mul_269	1608802723852889	1608802723852926	3	1608802723852903	47
Mul_280	1608802723852932	1608802723852968	6	1608802723852952	11
Mul_877	1608802723852971	1608802723853010	3	1608802723852990	15
Mul_889	1608802723853013	1608802723853047	3	1608802723853028	14
Mul_905	1608802723853054	1608802723853089	7	1608802723853069	20
Mul_518	1608802723853095	1608802723853136	6	1608802723853111	47
Mul_535	1608802723853143	1608802723853177	7	1608802723853160	13
Mul_909	1608802723853182	1608802723853220	5	1608802723853201	14
Mul_29	1608802723853223	1608802723853262	3	1608802723853237	14
Mul_43	1608802723853265	1608802723853299	3	1608802723853280	20
Mul_65	1608802723853305	1608802723853345	6	1608802723853325	22
Mul_83	1608802723853351	1608802723853392	6	1608802723853367	15
Mul_99	1608802723853395	1608802723853429	3	1608802723853409	48
Mul_118	1608802723853435	1608802723853475	6	1608802723853459	17
Mul_131	1608802723853481	1608802723853520	6	1608802723853497	24
Mul_151	1608802723853531	1608802723853567	11	1608802723853546	20
Mul_167	1608802723853573	1608802723853614	6	1608802723853588	20
Mul_183	1608802723853618	1608802723853652	4	1608802723853633	48
Mul_204	1608802723853664	1608802723853749	12	1608802723853683	58
Mul_221	1608802723853755	1608802723853804	6	1608802723853783	16
Mul_239	1608802723853813	1608802723853850	9	1608802723853829	22
Mul_296	1608802723853856	1608802723853900	6	1608802723853874	20
Mul_965	1608802723853903	1608802723853939	3	1608802723853919	15
Mul_331	1608802723853961	1608802723853997	22	1608802723853976	15
Mul_346	1608802723854000	1608802723854039	3	1608802723854016	47
Mul_361	1608802723854046	1608802723854083	7	1608802723854065	14
Mul_378	1608802723854088	1608802723854130	5	1608802723854110	20
Mul_395	1608802723854138	1608802723854178	8	1608802723854153	15
Mul_415	1608802723854182	1608802723854217	4	1608802723854198	15
Mul_255	1608802723854221	1608802723854261	4	1608802723854241	15
Mul_271	1608802723854265	1608802723854299	4	1608802723854280	48
Mul_959	1608802723854312	1608802723854350	13	1608802723854329	48
Mul_298	1608802723854358	1608802723854398	8	1608802723854379	14
Mul_312	1608802723854402	1608802723854437	4	1608802723854418	21
Mul_1070	1608802723854449	1608802723854484	12	1608802723854464	16
Mul_892	1608802723854487	1608802723854525	3	1608802723854501	20
Mul_1075	1608802723854531	1608802723854568	6	1608802723854547	22
Mul_522	1608802723854573	1608802723854616	5	1608802723854596	15
Mul_538	1608802723854620	1608802723854659	4	1608802723854635	15
Mul_16	1608802723854665	1608802723854699	6	1608802723854680	17
Mul_32	1608802723854706	1608802723854747	7	1608802723854726	22
Mul_45	1608802723854754	1608802723854793	7	1608802723854768	21
Mul_67	1608802723854799	1608802723854834	6	1608802723854813	22
Mul_86	1608802723854840	1608802723854881	6	1608802723854860	48
Mul_103	1608802723854887	1608802723854924	6	1608802723854910	9
Mul_120	1608802723854933	1608802723854968	9	1608802723854948	20
Mul_135	1608802723854974	1608802723855015	6	1608802723854990	19
Mul_153	1608802723855018	1608802723855054	3	1608802723855034	21
Mul_169	1608802723855060	1608802723855099	6	1608802723855079	15
Mul_943	1608802723855103	1608802723855145	4	1608802723855118	15
Mul_206	1608802723855148	1608802723855182	3	1608802723855163	21
Mul_417	1608802723855190	1608802723855232	8	1608802723855211	16
Mul_243	1608802723855235	1608802723855275	3	1608802723855251	14
Mul_447	1608802723855278	1608802723855314	3	1608802723855294	15
Mul_464	1608802723855319	1608802723855356	5	1608802723855332	21
Mul_957	1608802723855363	1608802723855398	7	1608802723855378	48
Mul_282	1608802723855409	1608802723855443	11	1608802723855428	10
Mul_301	1608802723855447	1608802723855488	4	1608802723855464	20
Mul_314	1608802723855495	1608802723855531	7	1608802723855510	21
Mul_1088	1608802723855537	1608802723855580	6	1608802723855560	15
Mul_350	1608802723855584	1608802723855621	4	1608802723855596	15
Mul_363	1608802723855624	1608802723855657	3	1608802723855637	15
Mul_382	1608802723855660	1608802723855699	3	1608802723855679	16
Mul_398	1608802723855703	1608802723855736	4	1608802723855718	20
Mul_984	1608802723855747	1608802723855784	11	1608802723855763	16
Mul_430	1608802723855787	1608802723855827	3	1608802723855803	48
Mul_449	1608802723855833	1608802723855869	6	1608802723855852	12
Mul_468	1608802723855879	1608802723855913	10	1608802723855894	15
Mul_894	1608802723855917	1608802723855953	4	1608802723855929	20
Mul_501	1608802723855959	1608802723855993	6	1608802723855974	15
Mul_524	1608802723855997	1608802723856038	4	1608802723856018	15
Mul_1008	1608802723856041	1608802723856084	3	1608802723856053	14
Mul_911	1608802723856087	1608802723856121	3	1608802723856101	15
Mul_34	1608802723856124	1608802723856162	3	1608802723856142	21
Mul_916	1608802723856168	1608802723856202	6	1608802723856182	21
Mul_71	1608802723856213	1608802723856247	11	1608802723856227	15
Mul_384	1608802723856252	1608802723856293	5	1608802723856267	21
Mul_105	1608802723856297	1608802723856329	4	1608802723856310	15
Mul_420	1608802723856339	1608802723856388	10	1608802723856357	26
Mul_933	1608802723856392	1608802723856433	4	1608802723856408	15
Mul_157	1608802723856436	1608802723856471	3	1608802723856451	15
Mul_172	1608802723856476	1608802723856518	5	1608802723856498	48
Mul_185	1608802723856525	1608802723856568	7	1608802723856548	43
Mul_210	1608802723856575	1608802723856611	7	1608802723856593	13
Mul_285	1608802723856614	1608802723856655	3	1608802723856635	16
Mul_303	1608802723856659	1608802723856693	4	1608802723856674	20
Mul_318	1608802723856706	1608802723856743	13	1608802723856722	16
Mul_968	1608802723856748	1608802723856792	5	1608802723856762	24
Mul_352	1608802723856794	1608802723856827	2	1608802723856808	15
Mul_366	1608802723856830	1608802723856868	3	1608802723856848	15
Mul_978	1608802723856875	1608802723856913	7	1608802723856890	20
Mul_400	1608802723856921	1608802723856957	8	1608802723856936	21
Mul_422	1608802723856962	1608802723857003	5	1608802723856982	15
Mul_432	1608802723857006	1608802723857045	3	1608802723857021	47
Mul_991	1608802723857051	1608802723857089	6	1608802723857071	19
Mul_470	1608802723857095	1608802723857136	6	1608802723857115	16
Mul_997	1608802723857139	1608802723857171	3	1608802723857153	14
Mul_503	1608802723857180	1608802723857212	9	1608802723857193	14
Mul_287	1608802723857215	1608802723857253	3	1608802723857230	18
Mul_1086	1608802723857256	1608802723857290	3	1608802723857270	16
Mul_320	1608802723857293	1608802723857333	3	1608802723857313	15
Mul_527	1608802723857336	1608802723857376	3	1608802723857352	47
Mul_540	1608802723857383	1608802723857417	7	1608802723857401	12
Mul_18	1608802723857421	1608802723857461	4	1608802723857441	17
Mul_38	1608802723857467	1608802723857503	6	1608802723857482	15
Mul_49	1608802723857510	1608802723857546	7	1608802723857526	16
Mul_986	1608802723857552	1608802723857589	6	1608802723857566	18
Mul_436	1608802723857595	1608802723857629	6	1608802723857609	15
Mul_452	1608802723857632	1608802723857671	3	1608802723857651	15
Mul_473	1608802723857675	1608802723857711	4	1608802723857688	19
Mul_137	1608802723857717	1608802723857754	6	1608802723857734	16
Mul_936	1608802723857757	1608802723857799	3	1608802723857779	15
Mul_189	1608802723857802	1608802723857838	3	1608802723857815	14
Mul_290	1608802723857841	1608802723857877	3	1608802723857857	21
Mul_963	1608802723857883	1608802723857925	6	1608802723857905	16
Mul_323	1608802723857929	1608802723857963	4	1608802723857944	21
Mul_334	1608802723857973	1608802723858010	10	1608802723857990	15
Mul_355	1608802723858013	1608802723858050	3	1608802723858026	47
Mul_368	1608802723858056	1608802723858091	6	1608802723858075	12
Mul_387	1608802723858094	1608802723858133	3	1608802723858114	20
Mul_404	1608802723858140	1608802723858188	7	1608802723858157	15
Mul_425	1608802723858191	1608802723858228	3	1608802723858207	15
Mul_438	1608802723858231	1608802723858272	3	1608802723858251	16
Mul_454	1608802723858275	1608802723858308	3	1608802723858290	15
Mul_1093	1608802723858317	1608802723858352	9	1608802723858332	16
Mul_481	1608802723858356	1608802723858393	4	1608802723858368	19
Mul_1000	1608802723858396	1608802723858429	3	1608802723858409	21
Mul_307	1608802723858436	1608802723858476	7	1608802723858456	16
Mul_325	1608802723858479	1608802723858541	3	1608802723858496	45
Mul_336	1608802723858547	1608802723858585	6	1608802723858564	16
Mul_543	1608802723858588	1608802723858622	3	1608802723858602	15
Mul_371	1608802723858627	1608802723858659	5	1608802723858640	14
Mul_40	1608802723858662	1608802723858697	3	1608802723858678	14
Mul_406	1608802723858700	1608802723858733	3	1608802723858714	14
Mul_427	1608802723858736	1608802723858769	3	1608802723858750	14
Mul_441	1608802723858774	1608802723858806	5	1608802723858788	47
Mul_457	1608802723858813	1608802723858848	7	1608802723858837	6
Mul_995	1608802723858851	1608802723858886	3	1608802723858867	14
Mul_484	1608802723858889	1608802723858931	3	1608802723858908	23
Mul_174	1608802723858939	1608802723858979	8	1608802723858955	48
Mul_970	1608802723858987	1608802723859024	8	1608802723859004	14
Mul_973	1608802723859027	1608802723859068	3	1608802723859048	15
Mul_373	1608802723859071	1608802723859105	3	1608802723859086	15
Mul_389	1608802723859112	1608802723859148	7	1608802723859129	20
Mul_409	1608802723859154	1608802723859198	6	1608802723859177	21
Mul_989	1608802723859204	1608802723859240	6	1608802723859220	21
Mul_459	1608802723859250	1608802723859286	10	1608802723859266	16
Mul_475	1608802723859289	1608802723859327	3	1608802723859303	20
Mul_486	1608802723859333	1608802723859367	6	1608802723859347	21
Mul_339	1608802723859373	1608802723859414	6	1608802723859394	16
Mul_357	1608802723859417	1608802723859458	3	1608802723859434	47
Mul_376	1608802723859465	1608802723859499	7	1608802723859483	16
Mul_980	1608802723859504	1608802723859548	5	1608802723859527	21
Mul_411	1608802723859554	1608802723859595	6	1608802723859570	20
Mul_443	1608802723859601	1608802723859638	6	1608802723859616	48
Mul_462	1608802723859643	1608802723859683	5	1608802723859666	17
Mul_479	1608802723859689	1608802723859724	6	1608802723859703	15
Mul_490	1608802723859730	1608802723859763	6	1608802723859744	15
Mul_393	1608802723859766	1608802723859805	3	1608802723859781	19
Mul_1091	1608802723859808	1608802723859842	3	1608802723859823	16
Mul_492	1608802723859846	1608802723859884	4	1608802723859864	15
Mul_495	1608802723859887	1608802723859924	3	1608802723859900	20
Cast_1	1608802723859930	1608802723859972	6	1608802723859949	18
AssignVariableOp	1608802723859992	1608802723860010	20	-1	-1
global_step/cond/Read/ReadVariableOp	1608802723860012	1608802723860019	2	-1	-1
PolynomialDecay/Minimum	1608802723860024	1608802723860074	5	1608802723860042	24
bert/embeddings/dropout/GreaterEqual	1608802723860078	1608802723860126	4	1608802723860096	57
bert/embeddings/Reshape_3	1608802723860134	1608802723860158	8	-1	-1
bert/encoder/layer_11/attention/self/dropout/GreaterEqual	1608802723860162	1608802723860201	4	1608802723860177	83
bert/encoder/layer_4/attention/self/dropout/GreaterEqual	1608802723860215	1608802723860256	14	1608802723860262	73
bert/encoder/layer_7/attention/self/dropout/GreaterEqual	1608802723860263	1608802723860308	7	1608802723860337	72
bert/encoder/layer_9/attention/self/dropout/GreaterEqual	1608802723860316	1608802723860367	8	1608802723860411	73
bert/encoder/layer_0/attention/self/dropout/GreaterEqual	1608802723860374	1608802723860417	7	1608802723860485	74
bert/encoder/layer_1/attention/self/dropout/GreaterEqual	1608802723860423	1608802723860470	6	1608802723860561	72
bert/encoder/layer_2/attention/self/dropout/GreaterEqual	1608802723860479	1608802723860523	9	1608802723860634	73
bert/encoder/layer_10/attention/self/dropout/GreaterEqual	1608802723860531	1608802723860570	8	1608802723860709	72
bert/encoder/layer_5/attention/self/dropout/GreaterEqual	1608802723860584	1608802723860623	14	1608802723860782	74
bert/encoder/layer_8/attention/self/dropout/GreaterEqual	1608802723860631	1608802723860676	8	1608802723860858	72
bert/encoder/layer_6/attention/self/dropout/GreaterEqual	1608802723860683	1608802723860726	7	1608802723860932	72
bert/encoder/layer_3/attention/self/dropout/GreaterEqual	1608802723860733	1608802723860771	7	1608802723861006	74
bert/encoder/layer_0/output/dropout/GreaterEqual	1608802723860777	1608802723860823	6	1608802723861081	38
bert/encoder/layer_6/attention/output/dropout/GreaterEqual	1608802723860829	1608802723860872	6	1608802723861121	38
bert/encoder/layer_8/output/dropout/GreaterEqual	1608802723860879	1608802723860921	7	1608802723861161	38
bert/encoder/layer_4/attention/output/dropout/GreaterEqual	1608802723860927	1608802723860973	6	1608802723861201	38
bert/encoder/layer_9/output/dropout/GreaterEqual	1608802723860981	1608802723861027	8	1608802723861241	38
bert/encoder/layer_2/attention/output/dropout/GreaterEqual	1608802723861036	1608802723861075	9	1608802723861281	39
bert/encoder/layer_4/output/dropout/GreaterEqual	1608802723861087	1608802723861127	12	1608802723861321	39
bert/encoder/layer_10/attention/output/dropout/GreaterEqual	1608802723861133	1608802723861178	6	1608802723861362	38
bert/encoder/layer_10/output/dropout/GreaterEqual	1608802723861185	1608802723861226	7	1608802723861401	40
bert/encoder/layer_1/attention/output/dropout/GreaterEqual	1608802723861238	1608802723861278	12	1608802723861443	39
bert/encoder/layer_5/attention/output/dropout/GreaterEqual	1608802723861284	1608802723861329	6	1608802723861483	38
bert/encoder/layer_9/attention/output/dropout/GreaterEqual	1608802723861336	1608802723861373	7	1608802723861523	39
bert/encoder/layer_11/attention/output/dropout/GreaterEqual	1608802723861384	1608802723861423	11	1608802723861563	38
bert/encoder/layer_1/output/dropout/GreaterEqual	1608802723861429	1608802723861474	6	1608802723861603	38
bert/encoder/layer_3/attention/output/dropout/GreaterEqual	1608802723861481	1608802723861523	7	1608802723861643	39
bert/encoder/layer_6/output/dropout/GreaterEqual	1608802723861530	1608802723861571	7	1608802723861683	37
bert/encoder/layer_11/output/dropout/GreaterEqual	1608802723861579	1608802723861623	8	1608802723861722	38
bert/encoder/layer_2/output/dropout/GreaterEqual	1608802723861630	1608802723861675	7	1608802723861762	38
bert/encoder/layer_3/output/dropout/GreaterEqual	1608802723861682	1608802723861722	7	1608802723861802	39
bert/encoder/layer_7/attention/output/dropout/GreaterEqual	1608802723861728	1608802723861772	6	1608802723861842	38
bert/encoder/layer_0/attention/output/dropout/GreaterEqual	1608802723861781	1608802723861823	9	1608802723861882	39
bert/encoder/layer_5/output/dropout/GreaterEqual	1608802723861830	1608802723861870	7	1608802723861923	38
bert/encoder/layer_7/output/dropout/GreaterEqual	1608802723861876	1608802723861922	6	1608802723861963	39
bert/encoder/layer_8/attention/output/dropout/GreaterEqual	1608802723861929	1608802723861971	7	1608802723862004	39
bert/embeddings/Reshape_1	1608802723861977	1608802723861988	6	-1	-1
mul_1	1608802723862084	1608802723862132	96	1608802723862103	21
bert/encoder/Cast	1608802723862198	1608802723862324	66	1608802723862258	44
global_step/cond/Identity	1608802723862238	1608802723862253	-86	-1	-1
PolynomialDecay/truediv	1608802723862259	1608802723862344	6	1608802723862315	23
Less	1608802723862264	1608802723862385	-80	-1	-1
bert/encoder/mul	1608802723862338	1608802723862446	-47	1608802723862378	46
bert/embeddings/dropout/Cast	1608802723862349	1608802723862476	-97	1608802723862416	69
bert/encoder/layer_0/attention/self/ExpandDims	1608802723862459	1608802723862509	-17	-1	-1
bert/encoder/layer_11/attention/self/dropout/Cast	1608802723862496	1608802723862840	-13	1608802723862610	244
bert/encoder/layer_0/attention/self/sub	1608802723862515	1608802723862783	-325	1608802723862546	204
Cast_3	1608802723862725	1608802723862901	-58	1608802723862855	24
bert/encoder/layer_0/attention/self/mul_1	1608802723862795	1608802723862928	-106	1608802723862890	30
bert/encoder/layer_4/attention/self/dropout/Cast	1608802723862903	1608802723863048	-25	1608802723862965	112
sub	1608802723862911	1608802723863078	-137	1608802723862985	97
bert/encoder/layer_7/attention/self/dropout/Cast	1608802723863062	1608802723863168	-16	1608802723863092	84
mul_3	1608802723863086	1608802723863214	-82	1608802723863174	8
bert/encoder/layer_9/attention/self/dropout/Cast	1608802723863180	1608802723863246	-34	1608802723863211	84
bert/encoder/layer_0/attention/self/dropout/Cast	1608802723863256	1608802723863312	10	1608802723863296	69
bert/encoder/layer_1/attention/self/dropout/Cast	1608802723863321	1608802723863375	9	1608802723863366	69
bert/encoder/layer_2/attention/self/dropout/Cast	1608802723863384	1608802723863430	9	1608802723863437	69
bert/encoder/layer_10/attention/self/dropout/Cast	1608802723863446	1608802723863495	16	1608802723863508	69
bert/encoder/layer_5/attention/self/dropout/Cast	1608802723863503	1608802723863555	8	1608802723863578	69
bert/encoder/layer_8/attention/self/dropout/Cast	1608802723863564	1608802723863609	9	1608802723863649	68
bert/encoder/layer_6/attention/self/dropout/Cast	1608802723863625	1608802723863673	16	1608802723863718	68
bert/encoder/layer_3/attention/self/dropout/Cast	1608802723863684	1608802723863735	11	1608802723863789	68
bert/encoder/layer_0/output/dropout/Cast	1608802723863744	1608802723863787	9	1608802723863858	36
bert/encoder/layer_6/attention/output/dropout/Cast	1608802723863804	1608802723863871	17	1608802723863896	36
bert/encoder/layer_8/output/dropout/Cast	1608802723863883	1608802723863936	12	1608802723863934	36
bert/encoder/layer_4/attention/output/dropout/Cast	1608802723863944	1608802723863994	8	1608802723863972	40
bert/encoder/layer_9/output/dropout/Cast	1608802723864010	1608802723864058	16	1608802723864031	47
bert/encoder/layer_2/attention/output/dropout/Cast	1608802723864067	1608802723864118	9	1608802723864090	47
bert/encoder/layer_4/output/dropout/Cast	1608802723864126	1608802723864171	8	1608802723864145	46
bert/encoder/layer_10/attention/output/dropout/Cast	1608802723864188	1608802723864241	17	1608802723864213	48
bert/encoder/layer_10/output/dropout/Cast	1608802723864249	1608802723864301	8	1608802723864268	53
bert/encoder/layer_1/attention/output/dropout/Cast	1608802723864309	1608802723864352	8	1608802723864326	46
bert/encoder/layer_5/attention/output/dropout/Cast	1608802723864403	1608802723864455	51	1608802723864425	48
bert/encoder/layer_9/attention/output/dropout/Cast	1608802723864464	1608802723864519	9	1608802723864492	47
bert/encoder/layer_11/attention/output/dropout/Cast	1608802723864527	1608802723864571	8	1608802723864544	46
bert/encoder/layer_1/output/dropout/Cast	1608802723864585	1608802723864630	14	1608802723864604	46
bert/encoder/layer_3/attention/output/dropout/Cast	1608802723864638	1608802723864690	8	1608802723864662	49
bert/encoder/layer_6/output/dropout/Cast	1608802723864701	1608802723864748	11	1608802723864721	47
bert/encoder/layer_11/output/dropout/Cast	1608802723864764	1608802723864811	16	1608802723864783	48
bert/encoder/layer_2/output/dropout/Cast	1608802723864819	1608802723864871	8	1608802723864844	48
bert/encoder/layer_3/output/dropout/Cast	1608802723864879	1608802723864925	8	1608802723864899	46
bert/encoder/layer_7/attention/output/dropout/Cast	1608802723864939	1608802723864985	14	1608802723864958	47
bert/encoder/layer_0/attention/output/dropout/Cast	1608802723864994	1608802723865045	9	1608802723865018	47
bert/encoder/layer_5/output/dropout/Cast	1608802723865054	1608802723865096	9	1608802723865071	46
bert/encoder/layer_7/output/dropout/Cast	1608802723865117	1608802723865163	21	1608802723865136	47
bert/encoder/layer_8/attention/output/dropout/Cast	1608802723865171	1608802723865223	8	1608802723865190	53
bert/embeddings/ArithmeticOptimizer/AddOpsRewrite_Leaf_1_add_1	1608802723865234	1608802723865290	11	1608802723865259	86
global_step/cond/Merge	1608802723865302	1608802723865328	12	-1	-1
PolynomialDecay/sub_1	1608802723865333	1608802723865384	5	1608802723865351	19
gradients/bert/embeddings/dropout/mul_1_grad/Mul	1608802723865388	1608802723865434	4	1608802723865407	63
bert/encoder/layer_11/attention/self/dropout/mul	1608802723865437	1608802723865492	3	1608802723865472	106
bert/encoder/layer_4/attention/self/dropout/mul	1608802723865505	1608802723865554	13	1608802723865579	99
bert/encoder/layer_7/attention/self/dropout/mul	1608802723865564	1608802723865607	10	1608802723865680	100
bert/encoder/layer_9/attention/self/dropout/mul	1608802723865624	1608802723865670	17	1608802723865781	99
bert/encoder/layer_0/attention/self/dropout/mul	1608802723865678	1608802723865726	8	1608802723865882	99
bert/encoder/layer_1/attention/self/dropout/mul	1608802723865734	1608802723865783	8	1608802723865982	100
bert/encoder/layer_2/attention/self/dropout/mul	1608802723865792	1608802723865837	9	1608802723866084	99
bert/encoder/layer_10/attention/self/dropout/mul	1608802723865845	1608802723865893	8	1608802723866184	99
bert/encoder/layer_5/attention/self/dropout/mul	1608802723865901	1608802723865954	8	1608802723866285	99
bert/encoder/layer_8/attention/self/dropout/mul	1608802723865962	1608802723866006	8	1608802723866386	99
bert/encoder/layer_6/attention/self/dropout/mul	1608802723866019	1608802723866063	13	1608802723866487	99
bert/encoder/layer_3/attention/self/dropout/mul	1608802723866071	1608802723866120	8	1608802723866588	99
bert/encoder/layer_0/output/dropout/mul	1608802723866128	1608802723866174	8	1608802723866689	52
bert/encoder/layer_6/attention/output/dropout/mul	1608802723866184	1608802723866226	10	1608802723866742	51
bert/encoder/layer_8/output/dropout/mul	1608802723866233	1608802723866280	7	1608802723866795	52
bert/encoder/layer_4/attention/output/dropout/mul	1608802723866288	1608802723866334	8	1608802723866848	52
bert/encoder/layer_9/output/dropout/mul	1608802723866345	1608802723866387	11	1608802723866901	51
bert/encoder/layer_2/attention/output/dropout/mul	1608802723866401	1608802723866445	14	1608802723866954	52
bert/encoder/layer_4/output/dropout/mul	1608802723866456	1608802723866503	11	1608802723867008	51
bert/encoder/layer_10/attention/output/dropout/mul	1608802723866511	1608802723866553	8	1608802723867061	51
bert/encoder/layer_10/output/dropout/mul	1608802723866568	1608802723866611	15	1608802723867114	51
bert/encoder/layer_1/attention/output/dropout/mul	1608802723866618	1608802723866666	7	1608802723867166	51
bert/encoder/layer_5/attention/output/dropout/mul	1608802723866673	1608802723866717	7	1608802723867219	51
bert/encoder/layer_9/attention/output/dropout/mul	1608802723866730	1608802723866773	13	1608802723867272	51
bert/encoder/layer_11/attention/output/dropout/mul	1608802723866781	1608802723866829	8	1608802723867325	51
bert/encoder/layer_1/output/dropout/mul	1608802723866836	1608802723866884	7	1608802723867378	52
bert/encoder/layer_3/attention/output/dropout/mul	1608802723866892	1608802723866934	8	1608802723867431	51
bert/encoder/layer_6/output/dropout/mul	1608802723866941	1608802723866991	7	1608802723867484	51
bert/encoder/layer_11/output/dropout/mul	1608802723866998	1608802723867045	7	1608802723867537	51
bert/encoder/layer_2/output/dropout/mul	1608802723867053	1608802723867096	8	1608802723867590	51
bert/encoder/layer_3/output/dropout/mul	1608802723867103	1608802723867151	7	1608802723867643	51
bert/encoder/layer_7/attention/output/dropout/mul	1608802723867159	1608802723867204	8	1608802723867696	52
bert/encoder/layer_0/attention/output/dropout/mul	1608802723867212	1608802723867252	8	1608802723867749	51
bert/encoder/layer_5/output/dropout/mul	1608802723867265	1608802723867310	13	1608802723867802	51
bert/encoder/layer_7/output/dropout/mul	1608802723867317	1608802723867366	7	1608802723867855	52
bert/encoder/layer_8/attention/output/dropout/mul	1608802723867373	1608802723867414	7	1608802723867908	52
bert/embeddings/ArithmeticOptimizer/AddOpsRewrite_add_1	1608802723867427	1608802723867492	13	1608802723867961	58
global_step/add	1608802723867497	1608802723867594	5	1608802723868021	4
PolynomialDecay/Mul	1608802723867601	1608802723867643	7	1608802723868027	4
bert/embeddings/LayerNorm/moments/mean	1608802723867648	1608802723867725	5	1608802723868033	32
PolynomialDecay	1608802723867846	1608802723867859	121	-1	-1
bert/embeddings/LayerNorm/moments/SquaredDifference	1608802723867866	1608802723867928	7	1608802723868066	54
mul_2	1608802723867949	1608802723867995	21	1608802723868122	4
bert/embeddings/LayerNorm/moments/variance	1608802723868000	1608802723868059	5	1608802723868128	31
add_2	1608802723868064	1608802723868140	5	1608802723868161	4
bert/embeddings/LayerNorm/batchnorm/add	1608802723868147	1608802723868203	7	1608802723868167	25
bert/embeddings/LayerNorm/batchnorm/Rsqrt	1608802723868292	1608802723868338	89	1608802723868311	20
bert/embeddings/LayerNorm/batchnorm/mul	1608802723868342	1608802723868410	4	1608802723868377	59
bert/embeddings/LayerNorm/batchnorm/mul_1	1608802723868422	1608802723868649	12	1608802723868592	100
bert/embeddings/LayerNorm/batchnorm/mul_2	1608802723868668	1608802723868747	19	1608802723868708	74
bert/embeddings/LayerNorm/batchnorm/sub	1608802723868758	1608802723868814	11	1608802723868785	69
bert/embeddings/LayerNorm/batchnorm/add_1	1608802723868822	1608802723868871	8	1608802723868855	73
bert/embeddings/dropout/mul_1	1608802723868880	1608802723868922	9	1608802723868929	72
bert/encoder/Reshape_1	1608802723868927	1608802723868940	5	-1	-1
bert/encoder/layer_0/attention/self/query/MatMul	1608802723868944	1608802723869014	4	1608802723869003	641
bert/encoder/layer_0/attention/self/key/MatMul	1608802723869026	1608802723869075	12	1608802723869647	632
bert/encoder/layer_0/attention/self/value/MatMul	1608802723869084	1608802723869130	9	1608802723870281	630
bert/encoder/layer_0/attention/self/query/BiasAdd	1608802723869138	1608802723869192	8	1608802723870913	62
bert/encoder/layer_0/attention/self/key/BiasAdd	1608802723869197	1608802723869234	5	1608802723870977	61
bert/encoder/layer_0/attention/self/value/BiasAdd	1608802723869241	1608802723869275	7	1608802723871039	61
bert/encoder/layer_0/attention/self/Reshape	1608802723869280	1608802723869289	5	-1	-1
bert/encoder/layer_0/attention/self/Reshape_1	1608802723869294	1608802723869301	5	-1	-1
bert/encoder/layer_0/attention/self/Reshape_2	1608802723869306	1608802723869313	5	-1	-1
bert/encoder/layer_0/attention/self/transpose	1608802723869317	1608802723869377	4	1608802723871101	190
bert/encoder/layer_0/attention/self/transpose_1	1608802723869387	1608802723869451	10	1608802723871293	190
bert/encoder/layer_0/attention/self/transpose_2	1608802723869461	1608802723869514	10	1608802723871484	189
bert/encoder/layer_0/attention/self/MatMul	1608802723869529	1608802723869836	15	1608802723871675	165
bert/encoder/layer_0/attention/self/Mul	1608802723869850	1608802723869903	14	1608802723871841	99
bert/encoder/layer_0/attention/self/add	1608802723869909	1608802723869954	6	1608802723871942	135
bert/encoder/layer_0/attention/self/Softmax	1608802723869959	1608802723870073	5	1608802723872078	320
gradients/bert/encoder/layer_0/attention/self/Softmax_grad/mul_1	1608802723870084	1608802723870131	11	1608802723872400	100
bert/encoder/layer_0/attention/self/dropout/mul_1	1608802723870140	1608802723870180	9	1608802723872502	141
bert/encoder/layer_0/attention/self/MatMul_1	1608802723870185	1608802723870432	5	1608802723872644	254
bert/encoder/layer_0/attention/self/transpose_3	1608802723870445	1608802723870501	13	1608802723872899	189
bert/encoder/layer_0/attention/self/Reshape_3	1608802723870510	1608802723870522	9	-1	-1
bert/encoder/layer_0/attention/output/dense/MatMul	1608802723870527	1608802723870579	5	1608802723873091	631
bert/encoder/layer_0/attention/output/dense/BiasAdd	1608802723870588	1608802723870628	9	1608802723873724	62
bert/encoder/layer_0/attention/output/dropout/mul_1	1608802723870635	1608802723870677	7	1608802723873787	73
bert/encoder/layer_0/attention/output/add	1608802723870682	1608802723870720	5	1608802723873862	72
bert/encoder/layer_0/attention/output/LayerNorm/moments/mean	1608802723870724	1608802723870776	4	1608802723873936	32
bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference	1608802723870781	1608802723870828	5	1608802723873969	55
bert/encoder/layer_0/attention/output/LayerNorm/moments/variance	1608802723870838	1608802723870884	10	1608802723874026	31
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add	1608802723870890	1608802723870933	6	1608802723874059	5
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723870940	1608802723870981	7	1608802723874066	4
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul	1608802723870986	1608802723871031	5	1608802723874072	39
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2	1608802723871041	1608802723871085	10	1608802723874112	55
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1	1608802723871093	1608802723871135	8	1608802723874169	73
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub	1608802723871143	1608802723871186	8	1608802723874244	54
bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1	1608802723871200	1608802723871242	14	1608802723874300	73
bert/encoder/layer_0/intermediate/dense/MatMul	1608802723871247	1608802723871308	5	1608802723874374	2194
bert/encoder/layer_0/intermediate/dense/BiasAdd	1608802723871319	1608802723871365	11	1608802723876570	225
bert/encoder/layer_0/intermediate/dense/Pow	1608802723871373	1608802723871423	8	1608802723876796	366
gradients/bert/encoder/layer_0/intermediate/dense/mul_3_grad/Mul_1	1608802723871432	1608802723871489	9	1608802723877163	195
gradients/bert/encoder/layer_0/intermediate/dense/Pow_grad/Pow	1608802723871497	1608802723871553	8	1608802723877360	196
bert/encoder/layer_0/intermediate/dense/mul	1608802723871563	1608802723871605	10	1608802723877558	195
gradients/bert/encoder/layer_0/intermediate/dense/Pow_grad/mul	1608802723871610	1608802723871656	5	1608802723877755	196
bert/encoder/layer_0/intermediate/dense/add	1608802723871661	1608802723871714	5	1608802723877953	279
bert/encoder/layer_0/intermediate/dense/mul_1	1608802723871719	1608802723871757	5	1608802723878233	195
bert/encoder/layer_0/intermediate/dense/Tanh	1608802723871767	1608802723871811	10	1608802723878430	207
bert/encoder/layer_0/intermediate/dense/add_1	1608802723871816	1608802723871866	5	1608802723878638	195
bert/encoder/layer_0/intermediate/dense/mul_2	1608802723871876	1608802723871916	10	1608802723878835	195
bert/encoder/layer_0/intermediate/dense/mul_3	1608802723871928	1608802723871967	12	1608802723879032	279
bert/encoder/layer_0/output/dense/MatMul	1608802723871971	1608802723872027	4	1608802723879312	2473
bert/encoder/layer_0/output/dense/BiasAdd	1608802723872037	1608802723872075	10	1608802723881787	61
bert/encoder/layer_0/output/dropout/mul_1	1608802723872086	1608802723872127	11	1608802723881849	73
bert/encoder/layer_0/output/add	1608802723872135	1608802723872179	8	1608802723881923	73
bert/encoder/layer_0/output/LayerNorm/moments/mean	1608802723872183	1608802723872229	4	1608802723881998	31
bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference	1608802723872241	1608802723872286	12	1608802723882031	56
bert/encoder/layer_0/output/LayerNorm/moments/variance	1608802723872296	1608802723872350	10	1608802723882088	32
bert/encoder/layer_0/output/LayerNorm/batchnorm/add	1608802723872355	1608802723872430	5	1608802723882122	5
bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt	1608802723872435	1608802723872475	5	1608802723882128	4
bert/encoder/layer_0/output/LayerNorm/batchnorm/mul	1608802723872478	1608802723872528	3	1608802723882134	40
bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2	1608802723872538	1608802723872589	10	1608802723882175	54
bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1	1608802723872599	1608802723872645	10	1608802723882231	73
bert/encoder/layer_0/output/LayerNorm/batchnorm/sub	1608802723872653	1608802723872704	8	1608802723882305	56
bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1	1608802723872711	1608802723872760	7	1608802723882362	73
bert/encoder/layer_1/attention/self/query/MatMul	1608802723872765	1608802723872818	5	1608802723882437	631
bert/encoder/layer_1/attention/self/key/MatMul	1608802723872828	1608802723872887	10	1608802723883070	636
bert/encoder/layer_1/attention/self/value/MatMul	1608802723872896	1608802723872953	9	1608802723883707	634
bert/encoder/layer_1/attention/self/query/BiasAdd	1608802723872964	1608802723873005	11	1608802723884343	61
bert/encoder/layer_1/attention/self/key/BiasAdd	1608802723873016	1608802723873054	11	1608802723884406	61
bert/encoder/layer_1/attention/self/value/BiasAdd	1608802723873059	1608802723873100	5	1608802723884468	61
bert/encoder/layer_1/attention/self/Reshape	1608802723873104	1608802723873116	4	-1	-1
bert/encoder/layer_1/attention/self/Reshape_1	1608802723873120	1608802723873132	4	-1	-1
bert/encoder/layer_1/attention/self/Reshape_2	1608802723873139	1608802723873147	7	-1	-1
bert/encoder/layer_1/attention/self/transpose	1608802723873151	1608802723873206	4	1608802723884531	190
bert/encoder/layer_1/attention/self/transpose_1	1608802723873215	1608802723873262	9	1608802723884723	190
bert/encoder/layer_1/attention/self/transpose_2	1608802723873277	1608802723873323	15	1608802723884914	190
bert/encoder/layer_1/attention/self/MatMul	1608802723873332	1608802723873609	9	1608802723885106	160
bert/encoder/layer_1/attention/self/Mul	1608802723873622	1608802723873676	13	1608802723885268	99
bert/encoder/layer_1/attention/self/add	1608802723873682	1608802723873732	6	1608802723885369	134
bert/encoder/layer_1/attention/self/Softmax	1608802723873737	1608802723873834	5	1608802723885504	320
gradients/bert/encoder/layer_1/attention/self/Softmax_grad/mul_1	1608802723873845	1608802723873894	11	1608802723885825	100
bert/encoder/layer_1/attention/self/dropout/mul_1	1608802723873904	1608802723873968	10	1608802723885927	141
bert/encoder/layer_1/attention/self/MatMul_1	1608802723873973	1608802723874208	5	1608802723886070	246
bert/encoder/layer_1/attention/self/transpose_3	1608802723874221	1608802723874279	13	1608802723886317	189
bert/encoder/layer_1/attention/self/Reshape_3	1608802723874291	1608802723874303	12	-1	-1
bert/encoder/layer_1/attention/output/dense/MatMul	1608802723874309	1608802723874363	6	1608802723886508	631
bert/encoder/layer_1/attention/output/dense/BiasAdd	1608802723874373	1608802723874414	10	1608802723887141	61
bert/encoder/layer_1/attention/output/dropout/mul_1	1608802723874418	1608802723874459	4	1608802723887203	73
bert/encoder/layer_1/attention/output/add	1608802723874464	1608802723874503	5	1608802723887278	73
bert/encoder/layer_1/attention/output/LayerNorm/moments/mean	1608802723874510	1608802723874559	7	1608802723887352	32
bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference	1608802723874564	1608802723874612	5	1608802723887385	55
bert/encoder/layer_1/attention/output/LayerNorm/moments/variance	1608802723874622	1608802723874672	10	1608802723887442	32
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add	1608802723874677	1608802723874717	5	1608802723887475	5
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723874722	1608802723874758	5	1608802723887482	5
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul	1608802723874762	1608802723874808	4	1608802723887488	39
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2	1608802723874822	1608802723874867	14	1608802723887528	55
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1	1608802723874876	1608802723874923	9	1608802723887585	73
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub	1608802723874932	1608802723874974	9	1608802723887659	54
bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1	1608802723874980	1608802723875030	6	1608802723887714	73
bert/encoder/layer_1/intermediate/dense/MatMul	1608802723875035	1608802723875098	5	1608802723887789	2193
bert/encoder/layer_1/intermediate/dense/BiasAdd	1608802723875109	1608802723875159	11	1608802723889985	227
bert/encoder/layer_1/intermediate/dense/Pow	1608802723875165	1608802723875223	6	1608802723890214	366
gradients/bert/encoder/layer_1/intermediate/dense/mul_3_grad/Mul_1	1608802723875235	1608802723875284	12	1608802723890582	196
gradients/bert/encoder/layer_1/intermediate/dense/Pow_grad/Pow	1608802723875299	1608802723875343	15	1608802723890780	197
bert/encoder/layer_1/intermediate/dense/mul	1608802723875352	1608802723875400	9	1608802723890978	194
gradients/bert/encoder/layer_1/intermediate/dense/Pow_grad/mul	1608802723875405	1608802723875444	5	1608802723891174	195
bert/encoder/layer_1/intermediate/dense/add	1608802723875456	1608802723875498	12	1608802723891371	279
bert/encoder/layer_1/intermediate/dense/mul_1	1608802723875503	1608802723875547	5	1608802723891652	195
bert/encoder/layer_1/intermediate/dense/Tanh	1608802723875551	1608802723875592	4	1608802723891849	206
bert/encoder/layer_1/intermediate/dense/add_1	1608802723875602	1608802723875648	10	1608802723892057	196
bert/encoder/layer_1/intermediate/dense/mul_2	1608802723875658	1608802723875708	10	1608802723892255	195
bert/encoder/layer_1/intermediate/dense/mul_3	1608802723875712	1608802723875759	4	1608802723892452	280
bert/encoder/layer_1/output/dense/MatMul	1608802723875764	1608802723875814	5	1608802723892734	2474
bert/encoder/layer_1/output/dense/BiasAdd	1608802723875824	1608802723875873	10	1608802723895210	61
bert/encoder/layer_1/output/dropout/mul_1	1608802723875877	1608802723875928	4	1608802723895273	74
bert/encoder/layer_1/output/add	1608802723875933	1608802723875973	5	1608802723895348	72
bert/encoder/layer_1/output/LayerNorm/moments/mean	1608802723875978	1608802723876033	5	1608802723895422	32
bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference	1608802723876037	1608802723876090	4	1608802723895456	56
bert/encoder/layer_1/output/LayerNorm/moments/variance	1608802723876107	1608802723876156	17	1608802723895513	32
bert/encoder/layer_1/output/LayerNorm/batchnorm/add	1608802723876160	1608802723876210	4	1608802723895547	5
bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt	1608802723876215	1608802723876258	5	1608802723895553	5
bert/encoder/layer_1/output/LayerNorm/batchnorm/mul	1608802723876262	1608802723876307	4	1608802723895559	40
bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2	1608802723876324	1608802723876384	17	1608802723895601	54
bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1	1608802723876394	1608802723876451	10	1608802723895656	73
bert/encoder/layer_1/output/LayerNorm/batchnorm/sub	1608802723876460	1608802723876504	9	1608802723895731	55
bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1	1608802723876515	1608802723876562	11	1608802723895787	73
bert/encoder/layer_2/attention/self/query/MatMul	1608802723876566	1608802723876624	4	1608802723895861	631
bert/encoder/layer_2/attention/self/key/MatMul	1608802723876634	1608802723876682	10	1608802723896494	632
bert/encoder/layer_2/attention/self/value/MatMul	1608802723876697	1608802723876750	15	1608802723897128	633
bert/encoder/layer_2/attention/self/query/BiasAdd	1608802723876760	1608802723876809	10	1608802723897763	62
bert/encoder/layer_2/attention/self/key/BiasAdd	1608802723876814	1608802723876849	5	1608802723897827	62
bert/encoder/layer_2/attention/self/value/BiasAdd	1608802723876859	1608802723876895	10	1608802723897890	63
bert/encoder/layer_2/attention/self/Reshape	1608802723876899	1608802723876921	4	-1	-1
bert/encoder/layer_2/attention/self/Reshape_1	1608802723876925	1608802723876932	4	-1	-1
bert/encoder/layer_2/attention/self/Reshape_2	1608802723876936	1608802723876946	4	-1	-1
bert/encoder/layer_2/attention/self/transpose	1608802723876956	1608802723877008	10	1608802723897954	189
bert/encoder/layer_2/attention/self/transpose_1	1608802723877019	1608802723877074	11	1608802723898145	189
bert/encoder/layer_2/attention/self/transpose_2	1608802723877084	1608802723877139	10	1608802723898336	190
bert/encoder/layer_2/attention/self/MatMul	1608802723877148	1608802723877415	9	1608802723898528	161
bert/encoder/layer_2/attention/self/Mul	1608802723877430	1608802723877585	15	1608802723898691	99
bert/encoder/layer_2/attention/self/add	1608802723877591	1608802723877635	6	1608802723898792	130
bert/encoder/layer_2/attention/self/Softmax	1608802723877640	1608802723877739	5	1608802723898923	320
gradients/bert/encoder/layer_2/attention/self/Softmax_grad/mul_1	1608802723877749	1608802723877796	10	1608802723899244	99
bert/encoder/layer_2/attention/self/dropout/mul_1	1608802723877805	1608802723877851	9	1608802723899346	141
bert/encoder/layer_2/attention/self/MatMul_1	1608802723877856	1608802723878094	5	1608802723899489	244
bert/encoder/layer_2/attention/self/transpose_3	1608802723878107	1608802723878162	13	1608802723899735	189
bert/encoder/layer_2/attention/self/Reshape_3	1608802723878175	1608802723878187	13	-1	-1
bert/encoder/layer_2/attention/output/dense/MatMul	1608802723878191	1608802723878245	4	1608802723899927	633
bert/encoder/layer_2/attention/output/dense/BiasAdd	1608802723878254	1608802723878298	9	1608802723900562	62
bert/encoder/layer_2/attention/output/dropout/mul_1	1608802723878304	1608802723878346	6	1608802723900626	73
bert/encoder/layer_2/attention/output/add	1608802723878350	1608802723878392	4	1608802723900701	73
bert/encoder/layer_2/attention/output/LayerNorm/moments/mean	1608802723878396	1608802723878444	4	1608802723900776	33
bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference	1608802723878449	1608802723878491	5	1608802723900810	55
bert/encoder/layer_2/attention/output/LayerNorm/moments/variance	1608802723878502	1608802723878547	11	1608802723900867	32
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add	1608802723878553	1608802723878593	6	1608802723900901	5
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723878598	1608802723878636	5	1608802723900907	4
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul	1608802723878640	1608802723878682	4	1608802723900913	39
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2	1608802723878693	1608802723878736	11	1608802723900954	54
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1	1608802723878745	1608802723878786	9	1608802723901010	72
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub	1608802723878795	1608802723878840	9	1608802723901084	56
bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1	1608802723878846	1608802723878896	6	1608802723901142	73
bert/encoder/layer_2/intermediate/dense/MatMul	1608802723878905	1608802723878959	9	1608802723901216	2199
bert/encoder/layer_2/intermediate/dense/BiasAdd	1608802723878975	1608802723879018	16	1608802723903417	223
bert/encoder/layer_2/intermediate/dense/Pow	1608802723879022	1608802723879075	4	1608802723903643	366
gradients/bert/encoder/layer_2/intermediate/dense/mul_3_grad/Mul_1	1608802723879084	1608802723879139	9	1608802723904010	197
gradients/bert/encoder/layer_2/intermediate/dense/Pow_grad/Pow	1608802723879148	1608802723879192	9	1608802723904209	196
bert/encoder/layer_2/intermediate/dense/mul	1608802723879202	1608802723879248	10	1608802723904406	195
gradients/bert/encoder/layer_2/intermediate/dense/Pow_grad/mul	1608802723879255	1608802723879303	7	1608802723904603	196
bert/encoder/layer_2/intermediate/dense/add	1608802723879309	1608802723879350	6	1608802723904801	280
bert/encoder/layer_2/intermediate/dense/mul_1	1608802723879355	1608802723879399	5	1608802723905083	194
bert/encoder/layer_2/intermediate/dense/Tanh	1608802723879404	1608802723879446	5	1608802723905279	208
bert/encoder/layer_2/intermediate/dense/add_1	1608802723879450	1608802723879495	4	1608802723905489	196
bert/encoder/layer_2/intermediate/dense/mul_2	1608802723879511	1608802723879553	16	1608802723905687	195
bert/encoder/layer_2/intermediate/dense/mul_3	1608802723879557	1608802723879614	4	1608802723905883	280
bert/encoder/layer_2/output/dense/MatMul	1608802723879619	1608802723879670	5	1608802723906165	2476
bert/encoder/layer_2/output/dense/BiasAdd	1608802723879686	1608802723879726	16	1608802723908643	60
bert/encoder/layer_2/output/dropout/mul_1	1608802723879731	1608802723879777	5	1608802723908705	73
bert/encoder/layer_2/output/add	1608802723879782	1608802723879821	5	1608802723908780	73
bert/encoder/layer_2/output/LayerNorm/moments/mean	1608802723879833	1608802723879880	12	1608802723908855	32
bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference	1608802723879885	1608802723879940	5	1608802723908888	55
bert/encoder/layer_2/output/LayerNorm/moments/variance	1608802723879951	1608802723879998	11	1608802723908945	32
bert/encoder/layer_2/output/LayerNorm/batchnorm/add	1608802723880009	1608802723880051	11	1608802723908979	5
bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt	1608802723880055	1608802723880100	4	1608802723908985	4
bert/encoder/layer_2/output/LayerNorm/batchnorm/mul	1608802723880107	1608802723880149	7	1608802723908991	39
bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2	1608802723880164	1608802723880209	15	1608802723909032	55
bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1	1608802723880218	1608802723880271	9	1608802723909088	73
bert/encoder/layer_2/output/LayerNorm/batchnorm/sub	1608802723880280	1608802723880327	9	1608802723909163	55
bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1	1608802723880332	1608802723880392	5	1608802723909220	74
bert/encoder/layer_3/attention/self/query/MatMul	1608802723880399	1608802723880458	7	1608802723909295	632
bert/encoder/layer_3/attention/self/key/MatMul	1608802723880471	1608802723880525	13	1608802723909929	636
bert/encoder/layer_3/attention/self/value/MatMul	1608802723880534	1608802723880581	9	1608802723910569	632
bert/encoder/layer_3/attention/self/query/BiasAdd	1608802723880595	1608802723880635	14	1608802723911205	63
bert/encoder/layer_3/attention/self/key/BiasAdd	1608802723880640	1608802723880680	5	1608802723911270	61
bert/encoder/layer_3/attention/self/value/BiasAdd	1608802723880684	1608802723880718	4	1608802723911332	61
bert/encoder/layer_3/attention/self/Reshape	1608802723880723	1608802723880738	5	-1	-1
bert/encoder/layer_3/attention/self/Reshape_1	1608802723880742	1608802723880751	4	-1	-1
bert/encoder/layer_3/attention/self/Reshape_2	1608802723880755	1608802723880767	4	-1	-1
bert/encoder/layer_3/attention/self/transpose	1608802723880770	1608802723880818	3	1608802723911395	190
bert/encoder/layer_3/attention/self/transpose_1	1608802723880830	1608802723880882	12	1608802723911587	189
bert/encoder/layer_3/attention/self/transpose_2	1608802723880891	1608802723880945	9	1608802723911778	190
bert/encoder/layer_3/attention/self/MatMul	1608802723880953	1608802723881224	8	1608802723911970	162
bert/encoder/layer_3/attention/self/Mul	1608802723881237	1608802723881291	13	1608802723912133	99
bert/encoder/layer_3/attention/self/add	1608802723881297	1608802723881339	6	1608802723912234	129
bert/encoder/layer_3/attention/self/Softmax	1608802723881343	1608802723881437	4	1608802723912365	319
gradients/bert/encoder/layer_3/attention/self/Softmax_grad/mul_1	1608802723881447	1608802723881493	10	1608802723912686	100
bert/encoder/layer_3/attention/self/dropout/mul_1	1608802723881505	1608802723881548	12	1608802723912788	142
bert/encoder/layer_3/attention/self/MatMul_1	1608802723881553	1608802723881797	5	1608802723912931	233
bert/encoder/layer_3/attention/self/transpose_3	1608802723881810	1608802723881866	13	1608802723913166	189
bert/encoder/layer_3/attention/self/Reshape_3	1608802723881877	1608802723881891	11	-1	-1
bert/encoder/layer_3/attention/output/dense/MatMul	1608802723881897	1608802723881948	6	1608802723913357	632
bert/encoder/layer_3/attention/output/dense/BiasAdd	1608802723881958	1608802723881997	10	1608802723913991	61
bert/encoder/layer_3/attention/output/dropout/mul_1	1608802723882002	1608802723882048	5	1608802723914054	74
bert/encoder/layer_3/attention/output/add	1608802723882053	1608802723882092	5	1608802723914129	73
bert/encoder/layer_3/attention/output/LayerNorm/moments/mean	1608802723882096	1608802723882146	4	1608802723914204	32
bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference	1608802723882151	1608802723882196	5	1608802723914238	55
bert/encoder/layer_3/attention/output/LayerNorm/moments/variance	1608802723882206	1608802723882251	10	1608802723914295	32
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add	1608802723882256	1608802723882297	5	1608802723914329	5
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723882302	1608802723882339	5	1608802723914336	5
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul	1608802723882347	1608802723882392	8	1608802723914342	39
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2	1608802723882402	1608802723882445	10	1608802723914383	54
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1	1608802723882454	1608802723882496	9	1608802723914439	73
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub	1608802723882505	1608802723882547	9	1608802723914513	56
bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1	1608802723882552	1608802723882603	5	1608802723914571	73
bert/encoder/layer_3/intermediate/dense/MatMul	1608802723882608	1608802723882665	5	1608802723914646	2194
bert/encoder/layer_3/intermediate/dense/BiasAdd	1608802723882682	1608802723882726	17	1608802723916842	224
bert/encoder/layer_3/intermediate/dense/Pow	1608802723882731	1608802723882786	5	1608802723917068	367
gradients/bert/encoder/layer_3/intermediate/dense/mul_3_grad/Mul_1	1608802723882796	1608802723882843	10	1608802723917436	196
gradients/bert/encoder/layer_3/intermediate/dense/Pow_grad/Pow	1608802723882860	1608802723882905	17	1608802723917634	197
bert/encoder/layer_3/intermediate/dense/mul	1608802723882914	1608802723882960	9	1608802723917833	196
gradients/bert/encoder/layer_3/intermediate/dense/Pow_grad/mul	1608802723882966	1608802723883005	6	1608802723918030	195
bert/encoder/layer_3/intermediate/dense/add	1608802723883015	1608802723883054	10	1608802723918228	281
bert/encoder/layer_3/intermediate/dense/mul_1	1608802723883061	1608802723883105	7	1608802723918510	194
bert/encoder/layer_3/intermediate/dense/Tanh	1608802723883110	1608802723883154	5	1608802723918707	208
bert/encoder/layer_3/intermediate/dense/add_1	1608802723883162	1608802723883210	8	1608802723918916	195
bert/encoder/layer_3/intermediate/dense/mul_2	1608802723883221	1608802723883267	11	1608802723919114	196
bert/encoder/layer_3/intermediate/dense/mul_3	1608802723883273	1608802723883320	6	1608802723919312	279
bert/encoder/layer_3/output/dense/MatMul	1608802723883324	1608802723883374	4	1608802723919593	2475
bert/encoder/layer_3/output/dense/BiasAdd	1608802723883384	1608802723883432	10	1608802723922069	62
bert/encoder/layer_3/output/dropout/mul_1	1608802723883437	1608802723883484	5	1608802723922133	73
bert/encoder/layer_3/output/add	1608802723883491	1608802723883531	7	1608802723922207	73
bert/encoder/layer_3/output/LayerNorm/moments/mean	1608802723883536	1608802723883593	5	1608802723922282	32
bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference	1608802723883598	1608802723883651	5	1608802723922316	55
bert/encoder/layer_3/output/LayerNorm/moments/variance	1608802723883661	1608802723883708	10	1608802723922373	32
bert/encoder/layer_3/output/LayerNorm/batchnorm/add	1608802723883719	1608802723883762	11	1608802723922407	5
bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt	1608802723883766	1608802723883809	4	1608802723922413	4
bert/encoder/layer_3/output/LayerNorm/batchnorm/mul	1608802723883814	1608802723883856	5	1608802723922419	39
bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2	1608802723883872	1608802723883926	16	1608802723922460	54
bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1	1608802723883935	1608802723883987	9	1608802723922516	73
bert/encoder/layer_3/output/LayerNorm/batchnorm/sub	1608802723883996	1608802723884038	9	1608802723922590	56
bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1	1608802723884049	1608802723884092	11	1608802723922648	73
bert/encoder/layer_4/attention/self/query/MatMul	1608802723884097	1608802723884157	5	1608802723922723	637
bert/encoder/layer_4/attention/self/key/MatMul	1608802723884169	1608802723884237	12	1608802723923362	638
bert/encoder/layer_4/attention/self/value/MatMul	1608802723884253	1608802723884301	16	1608802723924001	632
bert/encoder/layer_4/attention/self/query/BiasAdd	1608802723884311	1608802723884357	10	1608802723924635	62
bert/encoder/layer_4/attention/self/key/BiasAdd	1608802723884376	1608802723884422	19	1608802723924699	62
bert/encoder/layer_4/attention/self/value/BiasAdd	1608802723884429	1608802723884466	7	1608802723924763	61
bert/encoder/layer_4/attention/self/Reshape	1608802723884470	1608802723884487	4	-1	-1
bert/encoder/layer_4/attention/self/Reshape_1	1608802723884491	1608802723884497	4	-1	-1
bert/encoder/layer_4/attention/self/Reshape_2	1608802723884501	1608802723884508	4	-1	-1
bert/encoder/layer_4/attention/self/transpose	1608802723884519	1608802723884568	11	1608802723924826	190
bert/encoder/layer_4/attention/self/transpose_1	1608802723884578	1608802723884636	10	1608802723925017	189
bert/encoder/layer_4/attention/self/transpose_2	1608802723884648	1608802723884711	12	1608802723925209	189
bert/encoder/layer_4/attention/self/MatMul	1608802723884721	1608802723884980	10	1608802723925400	162
bert/encoder/layer_4/attention/self/Mul	1608802723884993	1608802723885046	13	1608802723925565	99
bert/encoder/layer_4/attention/self/add	1608802723885052	1608802723885091	6	1608802723925666	130
bert/encoder/layer_4/attention/self/Softmax	1608802723885096	1608802723885186	5	1608802723925798	320
gradients/bert/encoder/layer_4/attention/self/Softmax_grad/mul_1	1608802723885196	1608802723885239	10	1608802723926120	100
bert/encoder/layer_4/attention/self/dropout/mul_1	1608802723885246	1608802723885285	7	1608802723926222	142
bert/encoder/layer_4/attention/self/MatMul_1	1608802723885290	1608802723885510	5	1608802723926366	245
bert/encoder/layer_4/attention/self/transpose_3	1608802723885522	1608802723885574	12	1608802723926613	189
bert/encoder/layer_4/attention/self/Reshape_3	1608802723885583	1608802723885594	9	-1	-1
bert/encoder/layer_4/attention/output/dense/MatMul	1608802723885599	1608802723885648	5	1608802723926804	631
bert/encoder/layer_4/attention/output/dense/BiasAdd	1608802723885657	1608802723885696	9	1608802723927437	61
bert/encoder/layer_4/attention/output/dropout/mul_1	1608802723885702	1608802723889000	6	1608802723927500	75
bert/encoder/layer_4/attention/output/add	1608802723889008	1608802723889065	8	1608802723927576	73
bert/encoder/layer_4/attention/output/LayerNorm/moments/mean	1608802723889070	1608802723889124	5	1608802723927651	32
bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference	1608802723889129	1608802723889181	5	1608802723927685	55
bert/encoder/layer_4/attention/output/LayerNorm/moments/variance	1608802723889194	1608802723889240	13	1608802723927742	32
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add	1608802723889246	1608802723889285	6	1608802723927776	5
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723889290	1608802723889327	5	1608802723927782	4
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul	1608802723889333	1608802723889386	6	1608802723927788	39
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2	1608802723889397	1608802723889449	11	1608802723927829	55
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1	1608802723889458	1608802723889501	9	1608802723927886	73
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub	1608802723889515	1608802723889558	14	1608802723927961	55
bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1	1608802723889563	1608802723889612	5	1608802723928018	73
bert/encoder/layer_4/intermediate/dense/MatMul	1608802723889617	1608802723889678	5	1608802723928092	2195
bert/encoder/layer_4/intermediate/dense/BiasAdd	1608802723889709	1608802723889752	31	1608802723930289	223
bert/encoder/layer_4/intermediate/dense/Pow	1608802723889758	1608802723889810	6	1608802723930514	369
gradients/bert/encoder/layer_4/intermediate/dense/mul_3_grad/Mul_1	1608802723889820	1608802723889873	10	1608802723930884	195
gradients/bert/encoder/layer_4/intermediate/dense/Pow_grad/Pow	1608802723889882	1608802723889924	9	1608802723931081	196
bert/encoder/layer_4/intermediate/dense/mul	1608802723889933	1608802723889978	9	1608802723931279	195
gradients/bert/encoder/layer_4/intermediate/dense/Pow_grad/mul	1608802723889983	1608802723890024	5	1608802723931476	195
bert/encoder/layer_4/intermediate/dense/add	1608802723890029	1608802723890068	5	1608802723931673	283
bert/encoder/layer_4/intermediate/dense/mul_1	1608802723890073	1608802723890115	5	1608802723931958	194
bert/encoder/layer_4/intermediate/dense/Tanh	1608802723890119	1608802723890162	4	1608802723932154	210
bert/encoder/layer_4/intermediate/dense/add_1	1608802723890166	1608802723890207	4	1608802723932367	196
bert/encoder/layer_4/intermediate/dense/mul_2	1608802723890223	1608802723890263	16	1608802723932564	196
bert/encoder/layer_4/intermediate/dense/mul_3	1608802723890267	1608802723890309	4	1608802723932761	280
bert/encoder/layer_4/output/dense/MatMul	1608802723890316	1608802723890364	7	1608802723933043	2475
bert/encoder/layer_4/output/dense/BiasAdd	1608802723890380	1608802723890419	16	1608802723935520	65
bert/encoder/layer_4/output/dropout/mul_1	1608802723890424	1608802723890469	5	1608802723935587	73
bert/encoder/layer_4/output/add	1608802723890475	1608802723890513	6	1608802723935662	73
bert/encoder/layer_4/output/LayerNorm/moments/mean	1608802723890526	1608802723890573	13	1608802723935737	32
bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference	1608802723890578	1608802723890628	5	1608802723935770	55
bert/encoder/layer_4/output/LayerNorm/moments/variance	1608802723890638	1608802723890683	10	1608802723935827	32
bert/encoder/layer_4/output/LayerNorm/batchnorm/add	1608802723890694	1608802723890734	11	1608802723935861	8
bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt	1608802723890738	1608802723890783	4	1608802723935870	4
bert/encoder/layer_4/output/LayerNorm/batchnorm/mul	1608802723890788	1608802723890827	5	1608802723935876	43
bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2	1608802723890843	1608802723890886	16	1608802723935921	55
bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1	1608802723890894	1608802723890944	8	1608802723935978	73
bert/encoder/layer_4/output/LayerNorm/batchnorm/sub	1608802723890953	1608802723890999	9	1608802723936052	55
bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1	1608802723891004	1608802723891044	5	1608802723936108	72
bert/encoder/layer_5/attention/self/query/MatMul	1608802723891049	1608802723891105	5	1608802723936183	631
bert/encoder/layer_5/attention/self/key/MatMul	1608802723891114	1608802723891165	9	1608802723936815	631
bert/encoder/layer_5/attention/self/value/MatMul	1608802723891176	1608802723891222	11	1608802723937448	632
bert/encoder/layer_5/attention/self/query/BiasAdd	1608802723891237	1608802723891277	15	1608802723938082	61
bert/encoder/layer_5/attention/self/key/BiasAdd	1608802723891281	1608802723891319	4	1608802723938145	61
bert/encoder/layer_5/attention/self/value/BiasAdd	1608802723891323	1608802723891357	4	1608802723938208	61
bert/encoder/layer_5/attention/self/Reshape	1608802723891361	1608802723891376	4	-1	-1
bert/encoder/layer_5/attention/self/Reshape_1	1608802723891380	1608802723891386	4	-1	-1
bert/encoder/layer_5/attention/self/Reshape_2	1608802723891392	1608802723891402	6	-1	-1
bert/encoder/layer_5/attention/self/transpose	1608802723891406	1608802723891453	4	1608802723938271	189
bert/encoder/layer_5/attention/self/transpose_1	1608802723891465	1608802723891516	12	1608802723938462	190
bert/encoder/layer_5/attention/self/transpose_2	1608802723891526	1608802723891575	10	1608802723938653	189
bert/encoder/layer_5/attention/self/MatMul	1608802723891584	1608802723891850	9	1608802723938844	162
bert/encoder/layer_5/attention/self/Mul	1608802723891866	1608802723891916	16	1608802723939008	99
bert/encoder/layer_5/attention/self/add	1608802723891921	1608802723891961	5	1608802723939109	129
bert/encoder/layer_5/attention/self/Softmax	1608802723891966	1608802723892057	5	1608802723939239	320
gradients/bert/encoder/layer_5/attention/self/Softmax_grad/mul_1	1608802723892067	1608802723892110	10	1608802723939561	100
bert/encoder/layer_5/attention/self/dropout/mul_1	1608802723892118	1608802723892157	8	1608802723939662	142
bert/encoder/layer_5/attention/self/MatMul_1	1608802723892161	1608802723892407	4	1608802723939806	232
bert/encoder/layer_5/attention/self/transpose_3	1608802723892419	1608802723892476	12	1608802723940040	190
bert/encoder/layer_5/attention/self/Reshape_3	1608802723892485	1608802723892496	9	-1	-1
bert/encoder/layer_5/attention/output/dense/MatMul	1608802723892500	1608802723892550	4	1608802723940232	637
bert/encoder/layer_5/attention/output/dense/BiasAdd	1608802723892558	1608802723892598	8	1608802723940870	62
bert/encoder/layer_5/attention/output/dropout/mul_1	1608802723892602	1608802723892641	4	1608802723940934	73
bert/encoder/layer_5/attention/output/add	1608802723892645	1608802723892683	4	1608802723941009	73
bert/encoder/layer_5/attention/output/LayerNorm/moments/mean	1608802723892688	1608802723892733	5	1608802723941084	32
bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference	1608802723892738	1608802723892779	5	1608802723941117	55
bert/encoder/layer_5/attention/output/LayerNorm/moments/variance	1608802723892788	1608802723892832	9	1608802723941174	32
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add	1608802723892837	1608802723892876	5	1608802723941208	5
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723892880	1608802723892915	4	1608802723941214	4
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul	1608802723892922	1608802723892964	7	1608802723941220	39
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2	1608802723892974	1608802723893015	10	1608802723941261	54
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1	1608802723893023	1608802723893062	8	1608802723941316	73
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub	1608802723893070	1608802723893109	8	1608802723941391	56
bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1	1608802723893114	1608802723893151	5	1608802723941449	73
bert/encoder/layer_5/intermediate/dense/MatMul	1608802723893156	1608802723893218	5	1608802723941523	2198
bert/encoder/layer_5/intermediate/dense/BiasAdd	1608802723893228	1608802723893275	10	1608802723943723	225
bert/encoder/layer_5/intermediate/dense/Pow	1608802723893280	1608802723893325	5	1608802723943950	367
gradients/bert/encoder/layer_5/intermediate/dense/mul_3_grad/Mul_1	1608802723893333	1608802723893386	8	1608802723944319	195
gradients/bert/encoder/layer_5/intermediate/dense/Pow_grad/Pow	1608802723893394	1608802723893442	8	1608802723944516	197
bert/encoder/layer_5/intermediate/dense/mul	1608802723893451	1608802723893490	9	1608802723944715	195
gradients/bert/encoder/layer_5/intermediate/dense/Pow_grad/mul	1608802723893500	1608802723893596	10	1608802723944911	194
bert/encoder/layer_5/intermediate/dense/add	1608802723893602	1608802723893640	6	1608802723945108	280
bert/encoder/layer_5/intermediate/dense/mul_1	1608802723893645	1608802723893680	5	1608802723945389	195
bert/encoder/layer_5/intermediate/dense/Tanh	1608802723893684	1608802723893719	4	1608802723945586	207
bert/encoder/layer_5/intermediate/dense/add_1	1608802723893723	1608802723893766	4	1608802723945795	196
bert/encoder/layer_5/intermediate/dense/mul_2	1608802723893775	1608802723893823	9	1608802723945993	195
bert/encoder/layer_5/intermediate/dense/mul_3	1608802723893828	1608802723893863	5	1608802723946190	280
bert/encoder/layer_5/output/dense/MatMul	1608802723893868	1608802723893914	5	1608802723946472	2476
bert/encoder/layer_5/output/dense/BiasAdd	1608802723893924	1608802723893960	10	1608802723948950	64
bert/encoder/layer_5/output/dropout/mul_1	1608802723893965	1608802723894002	5	1608802723949016	73
bert/encoder/layer_5/output/add	1608802723894007	1608802723894061	5	1608802723949090	73
bert/encoder/layer_5/output/LayerNorm/moments/mean	1608802723894065	1608802723894109	4	1608802723949165	32
bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference	1608802723894115	1608802723894159	6	1608802723949198	56
bert/encoder/layer_5/output/LayerNorm/moments/variance	1608802723894169	1608802723894216	10	1608802723949256	32
bert/encoder/layer_5/output/LayerNorm/batchnorm/add	1608802723894223	1608802723894260	7	1608802723949290	5
bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt	1608802723894264	1608802723894298	4	1608802723949297	4
bert/encoder/layer_5/output/LayerNorm/batchnorm/mul	1608802723894302	1608802723894342	4	1608802723949302	39
bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2	1608802723894352	1608802723894393	10	1608802723949343	53
bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1	1608802723894403	1608802723894449	10	1608802723949398	73
bert/encoder/layer_5/output/LayerNorm/batchnorm/sub	1608802723894458	1608802723894508	9	1608802723949473	56
bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1	1608802723894514	1608802723894574	6	1608802723949531	73
bert/encoder/layer_6/attention/self/query/MatMul	1608802723894579	1608802723894630	5	1608802723949605	633
bert/encoder/layer_6/attention/self/key/MatMul	1608802723894639	1608802723894693	9	1608802723950240	635
bert/encoder/layer_6/attention/self/value/MatMul	1608802723894702	1608802723894753	9	1608802723950876	633
bert/encoder/layer_6/attention/self/query/BiasAdd	1608802723894762	1608802723894800	9	1608802723951511	61
bert/encoder/layer_6/attention/self/key/BiasAdd	1608802723894807	1608802723894845	7	1608802723951574	62
bert/encoder/layer_6/attention/self/value/BiasAdd	1608802723894850	1608802723894888	5	1608802723951637	61
bert/encoder/layer_6/attention/self/Reshape	1608802723894895	1608802723894905	7	-1	-1
bert/encoder/layer_6/attention/self/Reshape_1	1608802723894909	1608802723894920	4	-1	-1
bert/encoder/layer_6/attention/self/Reshape_2	1608802723894924	1608802723894930	4	-1	-1
bert/encoder/layer_6/attention/self/transpose	1608802723894937	1608802723894990	7	1608802723951700	189
bert/encoder/layer_6/attention/self/transpose_1	1608802723894999	1608802723895045	9	1608802723951891	189
bert/encoder/layer_6/attention/self/transpose_2	1608802723895060	1608802723895106	15	1608802723952082	189
bert/encoder/layer_6/attention/self/MatMul	1608802723895114	1608802723895367	8	1608802723952273	161
bert/encoder/layer_6/attention/self/Mul	1608802723895380	1608802723895429	13	1608802723952436	99
bert/encoder/layer_6/attention/self/add	1608802723895437	1608802723895478	8	1608802723952537	129
bert/encoder/layer_6/attention/self/Softmax	1608802723895483	1608802723895573	5	1608802723952668	319
gradients/bert/encoder/layer_6/attention/self/Softmax_grad/mul_1	1608802723895584	1608802723895628	11	1608802723952988	100
bert/encoder/layer_6/attention/self/dropout/mul_1	1608802723895637	1608802723895675	9	1608802723953090	141
bert/encoder/layer_6/attention/self/MatMul_1	1608802723895683	1608802723895911	8	1608802723953233	246
bert/encoder/layer_6/attention/self/transpose_3	1608802723895923	1608802723895976	12	1608802723953481	190
bert/encoder/layer_6/attention/self/Reshape_3	1608802723895986	1608802723895997	10	-1	-1
bert/encoder/layer_6/attention/output/dense/MatMul	1608802723896001	1608802723896050	4	1608802723953673	632
bert/encoder/layer_6/attention/output/dense/BiasAdd	1608802723896059	1608802723896098	9	1608802723954306	61
bert/encoder/layer_6/attention/output/dropout/mul_1	1608802723896103	1608802723896143	5	1608802723954368	73
bert/encoder/layer_6/attention/output/add	1608802723896148	1608802723896189	5	1608802723954443	73
bert/encoder/layer_6/attention/output/LayerNorm/moments/mean	1608802723896194	1608802723896242	5	1608802723954518	32
bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference	1608802723896247	1608802723896289	5	1608802723954551	55
bert/encoder/layer_6/attention/output/LayerNorm/moments/variance	1608802723896299	1608802723896343	10	1608802723954609	32
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add	1608802723896349	1608802723896414	6	1608802723954642	5
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723896420	1608802723896458	6	1608802723954648	4
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul	1608802723896462	1608802723896504	4	1608802723954654	39
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2	1608802723896515	1608802723896557	11	1608802723954695	54
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1	1608802723896566	1608802723896611	9	1608802723954751	73
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub	1608802723896619	1608802723896659	8	1608802723954826	54
bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1	1608802723896664	1608802723896722	5	1608802723954882	73
bert/encoder/layer_6/intermediate/dense/MatMul	1608802723896727	1608802723896779	5	1608802723954957	2196
bert/encoder/layer_6/intermediate/dense/BiasAdd	1608802723896794	1608802723896844	15	1608802723957154	224
bert/encoder/layer_6/intermediate/dense/Pow	1608802723896848	1608802723896897	4	1608802723957380	366
gradients/bert/encoder/layer_6/intermediate/dense/mul_3_grad/Mul_1	1608802723896907	1608802723896951	10	1608802723957748	196
gradients/bert/encoder/layer_6/intermediate/dense/Pow_grad/Pow	1608802723896967	1608802723897011	16	1608802723957946	196
bert/encoder/layer_6/intermediate/dense/mul	1608802723897019	1608802723897061	8	1608802723958143	196
gradients/bert/encoder/layer_6/intermediate/dense/Pow_grad/mul	1608802723897066	1608802723897101	5	1608802723958341	195
bert/encoder/layer_6/intermediate/dense/add	1608802723897120	1608802723897157	19	1608802723958537	280
bert/encoder/layer_6/intermediate/dense/mul_1	1608802723897162	1608802723897203	5	1608802723958819	198
bert/encoder/layer_6/intermediate/dense/Tanh	1608802723897208	1608802723897241	5	1608802723959019	208
bert/encoder/layer_6/intermediate/dense/add_1	1608802723897250	1608802723897293	9	1608802723959229	195
bert/encoder/layer_6/intermediate/dense/mul_2	1608802723897303	1608802723897347	10	1608802723959426	194
bert/encoder/layer_6/intermediate/dense/mul_3	1608802723897352	1608802723897385	5	1608802723959622	280
bert/encoder/layer_6/output/dense/MatMul	1608802723897395	1608802723897440	10	1608802723959903	2476
bert/encoder/layer_6/output/dense/BiasAdd	1608802723897451	1608802723897496	11	1608802723962381	64
bert/encoder/layer_6/output/dropout/mul_1	1608802723897501	1608802723897543	5	1608802723962447	73
bert/encoder/layer_6/output/add	1608802723897548	1608802723897584	5	1608802723962521	73
bert/encoder/layer_6/output/LayerNorm/moments/mean	1608802723897588	1608802723897640	4	1608802723962596	31
bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference	1608802723897645	1608802723897694	5	1608802723962629	55
bert/encoder/layer_6/output/LayerNorm/moments/variance	1608802723897704	1608802723897747	10	1608802723962685	32
bert/encoder/layer_6/output/LayerNorm/batchnorm/add	1608802723897754	1608802723897798	7	1608802723962719	5
bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt	1608802723897803	1608802723897842	5	1608802723962725	4
bert/encoder/layer_6/output/LayerNorm/batchnorm/mul	1608802723897847	1608802723897886	5	1608802723962731	39
bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2	1608802723897897	1608802723897944	11	1608802723962772	53
bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1	1608802723897952	1608802723898000	8	1608802723962827	73
bert/encoder/layer_6/output/LayerNorm/batchnorm/sub	1608802723898007	1608802723898046	7	1608802723962902	54
bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1	1608802723898056	1608802723898094	10	1608802723962958	73
bert/encoder/layer_7/attention/self/query/MatMul	1608802723898099	1608802723898153	5	1608802723963033	630
bert/encoder/layer_7/attention/self/key/MatMul	1608802723898163	1608802723898207	10	1608802723963665	634
bert/encoder/layer_7/attention/self/value/MatMul	1608802723898222	1608802723898265	15	1608802723964301	634
bert/encoder/layer_7/attention/self/query/BiasAdd	1608802723898273	1608802723898314	8	1608802723964937	63
bert/encoder/layer_7/attention/self/key/BiasAdd	1608802723898319	1608802723898352	5	1608802723965005	61
bert/encoder/layer_7/attention/self/value/BiasAdd	1608802723898362	1608802723898394	10	1608802723965067	62
bert/encoder/layer_7/attention/self/Reshape	1608802723898397	1608802723898411	3	-1	-1
bert/encoder/layer_7/attention/self/Reshape_1	1608802723898415	1608802723898421	4	-1	-1
bert/encoder/layer_7/attention/self/Reshape_2	1608802723898425	1608802723898430	4	-1	-1
bert/encoder/layer_7/attention/self/transpose	1608802723898441	1608802723898486	11	1608802723965131	189
bert/encoder/layer_7/attention/self/transpose_1	1608802723898497	1608802723898545	11	1608802723965322	189
bert/encoder/layer_7/attention/self/transpose_2	1608802723898554	1608802723898597	9	1608802723965513	190
bert/encoder/layer_7/attention/self/MatMul	1608802723898612	1608802723898862	15	1608802723965705	160
bert/encoder/layer_7/attention/self/Mul	1608802723898873	1608802723898922	11	1608802723965867	99
bert/encoder/layer_7/attention/self/add	1608802723898927	1608802723898967	5	1608802723965968	130
bert/encoder/layer_7/attention/self/Softmax	1608802723898971	1608802723899055	4	1608802723966100	319
gradients/bert/encoder/layer_7/attention/self/Softmax_grad/mul_1	1608802723899066	1608802723899106	11	1608802723966421	99
bert/encoder/layer_7/attention/self/dropout/mul_1	1608802723899114	1608802723899151	8	1608802723966523	141
bert/encoder/layer_7/attention/self/MatMul_1	1608802723899156	1608802723899368	5	1608802723966666	244
bert/encoder/layer_7/attention/self/transpose_3	1608802723899380	1608802723899431	12	1608802723966912	189
bert/encoder/layer_7/attention/self/Reshape_3	1608802723899441	1608802723899451	10	-1	-1
bert/encoder/layer_7/attention/output/dense/MatMul	1608802723899455	1608802723899503	4	1608802723967103	636
bert/encoder/layer_7/attention/output/dense/BiasAdd	1608802723899511	1608802723899548	8	1608802723967740	61
bert/encoder/layer_7/attention/output/dropout/mul_1	1608802723899552	1608802723899590	4	1608802723967804	73
bert/encoder/layer_7/attention/output/add	1608802723899596	1608802723899632	6	1608802723967878	73
bert/encoder/layer_7/attention/output/LayerNorm/moments/mean	1608802723899636	1608802723899679	4	1608802723967953	32
bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference	1608802723899683	1608802723899728	4	1608802723967987	54
bert/encoder/layer_7/attention/output/LayerNorm/moments/variance	1608802723899738	1608802723899779	10	1608802723968043	32
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add	1608802723899784	1608802723899822	5	1608802723968076	5
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723899826	1608802723899860	4	1608802723968083	4
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul	1608802723899863	1608802723899901	3	1608802723968089	39
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2	1608802723899911	1608802723899961	10	1608802723968129	54
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1	1608802723899970	1608802723900595	9	1608802723968185	73
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub	1608802723900604	1608802723900655	9	1608802723968260	56
bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1	1608802723900664	1608802723900732	9	1608802723968317	73
bert/encoder/layer_7/intermediate/dense/MatMul	1608802723900737	1608802723900814	5	1608802723968392	2198
bert/encoder/layer_7/intermediate/dense/BiasAdd	1608802723900824	1608802723900863	10	1608802723970591	225
bert/encoder/layer_7/intermediate/dense/Pow	1608802723900875	1608802723900920	12	1608802723970817	365
gradients/bert/encoder/layer_7/intermediate/dense/mul_3_grad/Mul_1	1608802723900932	1608802723900983	12	1608802723971184	195
gradients/bert/encoder/layer_7/intermediate/dense/Pow_grad/Pow	1608802723900991	1608802723901029	8	1608802723971382	196
bert/encoder/layer_7/intermediate/dense/mul	1608802723901043	1608802723901083	14	1608802723971579	194
gradients/bert/encoder/layer_7/intermediate/dense/Pow_grad/mul	1608802723901088	1608802723901131	5	1608802723971776	195
bert/encoder/layer_7/intermediate/dense/add	1608802723901136	1608802723901170	5	1608802723971973	280
bert/encoder/layer_7/intermediate/dense/mul_1	1608802723901180	1608802723901214	10	1608802723972255	197
bert/encoder/layer_7/intermediate/dense/Tanh	1608802723901218	1608802723901261	4	1608802723972453	207
bert/encoder/layer_7/intermediate/dense/add_1	1608802723901266	1608802723901312	5	1608802723972662	196
bert/encoder/layer_7/intermediate/dense/mul_2	1608802723901322	1608802723903448	10	1608802723972860	194
bert/encoder/layer_7/intermediate/dense/mul_3	1608802723903453	1608802723903671	5	1608802723973056	280
bert/encoder/layer_7/output/dense/MatMul	1608802723903676	1608802723904051	5	1608802723973338	2479
bert/encoder/layer_7/output/dense/BiasAdd	1608802723904064	1608802723904257	13	1608802723975819	62
bert/encoder/layer_7/output/dropout/mul_1	1608802723904262	1608802723904441	5	1608802723975883	73
bert/encoder/layer_7/output/add	1608802723904446	1608802723904638	5	1608802723975958	73
bert/encoder/layer_7/output/LayerNorm/moments/mean	1608802723904645	1608802723904834	7	1608802723976033	32
bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference	1608802723904839	1608802723905113	5	1608802723976066	56
bert/encoder/layer_7/output/LayerNorm/moments/variance	1608802723905124	1608802723905319	11	1608802723976124	32
bert/encoder/layer_7/output/LayerNorm/batchnorm/add	1608802723905324	1608802723905518	5	1608802723976157	5
bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt	1608802723905529	1608802723905715	11	1608802723976164	4
bert/encoder/layer_7/output/LayerNorm/batchnorm/mul	1608802723905719	1608802723905917	4	1608802723976169	39
bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2	1608802723905929	1608802723906195	12	1608802723976210	55
bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1	1608802723906210	1608802723908689	15	1608802723976266	73
bert/encoder/layer_7/output/LayerNorm/batchnorm/sub	1608802723908698	1608802723908744	9	1608802723976342	55
bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1	1608802723908749	1608802723908808	5	1608802723976399	73
bert/encoder/layer_8/attention/self/query/MatMul	1608802723908820	1608802723908886	12	1608802723976474	632
bert/encoder/layer_8/attention/self/key/MatMul	1608802723908896	1608802723908945	10	1608802723977108	631
bert/encoder/layer_8/attention/self/value/MatMul	1608802723908954	1608802723909004	9	1608802723977740	631
bert/encoder/layer_8/attention/self/query/BiasAdd	1608802723909013	1608802723909050	9	1608802723978373	61
bert/encoder/layer_8/attention/self/key/BiasAdd	1608802723909054	1608802723909092	4	1608802723978436	62
bert/encoder/layer_8/attention/self/value/BiasAdd	1608802723909096	1608802723909143	4	1608802723978500	62
bert/encoder/layer_8/attention/self/Reshape	1608802723909147	1608802723909156	4	-1	-1
bert/encoder/layer_8/attention/self/Reshape_1	1608802723909160	1608802723909166	4	-1	-1
bert/encoder/layer_8/attention/self/Reshape_2	1608802723909173	1608802723909179	7	-1	-1
bert/encoder/layer_8/attention/self/transpose	1608802723909182	1608802723909232	3	1608802723978563	189
bert/encoder/layer_8/attention/self/transpose_1	1608802723909241	1608802723909283	9	1608802723978754	189
bert/encoder/layer_8/attention/self/transpose_2	1608802723909292	1608802723909339	9	1608802723978945	189
bert/encoder/layer_8/attention/self/MatMul	1608802723909347	1608802723910615	8	1608802723979136	162
bert/encoder/layer_8/attention/self/Mul	1608802723910627	1608802723911236	12	1608802723979300	99
bert/encoder/layer_8/attention/self/add	1608802723911242	1608802723911298	6	1608802723979401	128
bert/encoder/layer_8/attention/self/Softmax	1608802723911303	1608802723911614	5	1608802723979531	320
gradients/bert/encoder/layer_8/attention/self/Softmax_grad/mul_1	1608802723911624	1608802723911807	10	1608802723979852	99
bert/encoder/layer_8/attention/self/dropout/mul_1	1608802723911816	1608802723911997	9	1608802723979953	142
bert/encoder/layer_8/attention/self/MatMul_1	1608802723912002	1608802723912227	5	1608802723980097	233
bert/encoder/layer_8/attention/self/transpose_3	1608802723912239	1608802723912290	12	1608802723980332	189
bert/encoder/layer_8/attention/self/Reshape_3	1608802723912301	1608802723912312	11	-1	-1
bert/encoder/layer_8/attention/output/dense/MatMul	1608802723912318	1608802723912403	6	1608802723980523	634
bert/encoder/layer_8/attention/output/dense/BiasAdd	1608802723912413	1608802723912454	10	1608802723981159	61
bert/encoder/layer_8/attention/output/dropout/mul_1	1608802723912458	1608802723912559	4	1608802723981222	73
bert/encoder/layer_8/attention/output/add	1608802723912566	1608802723912714	7	1608802723981297	73
bert/encoder/layer_8/attention/output/LayerNorm/moments/mean	1608802723912718	1608802723912819	4	1608802723981372	33
bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference	1608802723912823	1608802723912958	4	1608802723981406	55
bert/encoder/layer_8/attention/output/LayerNorm/moments/variance	1608802723912969	1608802723913013	11	1608802723981463	32
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add	1608802723913018	1608802723913055	5	1608802723981497	5
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723913060	1608802723913093	5	1608802723981503	4
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul	1608802723913097	1608802723913192	4	1608802723981509	39
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2	1608802723913202	1608802723913385	10	1608802723981549	53
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1	1608802723913394	1608802723914018	9	1608802723981605	73
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub	1608802723914026	1608802723914081	8	1608802723981679	57
bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1	1608802723914086	1608802723914164	5	1608802723981738	73
bert/encoder/layer_8/intermediate/dense/MatMul	1608802723914168	1608802723914235	4	1608802723981813	2194
bert/encoder/layer_8/intermediate/dense/BiasAdd	1608802723914245	1608802723914295	10	1608802723984009	224
bert/encoder/layer_8/intermediate/dense/Pow	1608802723914301	1608802723914344	6	1608802723984234	366
gradients/bert/encoder/layer_8/intermediate/dense/mul_3_grad/Mul_1	1608802723914363	1608802723914409	19	1608802723984602	195
gradients/bert/encoder/layer_8/intermediate/dense/Pow_grad/Pow	1608802723914417	1608802723914464	8	1608802723984799	197
bert/encoder/layer_8/intermediate/dense/mul	1608802723914473	1608802723914508	9	1608802723984998	195
gradients/bert/encoder/layer_8/intermediate/dense/Pow_grad/mul	1608802723914522	1608802723914558	14	1608802723985194	196
bert/encoder/layer_8/intermediate/dense/add	1608802723914563	1608802723914609	5	1608802723985392	279
bert/encoder/layer_8/intermediate/dense/mul_1	1608802723914614	1608802723914647	5	1608802723985673	194
bert/encoder/layer_8/intermediate/dense/Tanh	1608802723914657	1608802723914692	10	1608802723985869	209
bert/encoder/layer_8/intermediate/dense/add_1	1608802723914696	1608802723914749	4	1608802723986080	196
bert/encoder/layer_8/intermediate/dense/mul_2	1608802723914758	1608802723916873	9	1608802723986278	194
bert/encoder/layer_8/intermediate/dense/mul_3	1608802723916886	1608802723917096	13	1608802723986473	280
bert/encoder/layer_8/output/dense/MatMul	1608802723917101	1608802723917468	5	1608802723986755	2474
bert/encoder/layer_8/output/dense/BiasAdd	1608802723917478	1608802723917672	10	1608802723989233	60
bert/encoder/layer_8/output/dropout/mul_1	1608802723917680	1608802723917863	8	1608802723989294	73
bert/encoder/layer_8/output/add	1608802723917867	1608802723918060	4	1608802723989369	73
bert/encoder/layer_8/output/LayerNorm/moments/mean	1608802723918065	1608802723918265	5	1608802723989444	32
bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference	1608802723918269	1608802723918539	4	1608802723989477	55
bert/encoder/layer_8/output/LayerNorm/moments/variance	1608802723918548	1608802723918738	9	1608802723989534	32
bert/encoder/layer_8/output/LayerNorm/batchnorm/add	1608802723918743	1608802723918954	5	1608802723989568	5
bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt	1608802723918962	1608802723919139	8	1608802723989575	4
bert/encoder/layer_8/output/LayerNorm/batchnorm/mul	1608802723919143	1608802723919340	4	1608802723989581	40
bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2	1608802723919349	1608802723919629	9	1608802723989622	53
bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1	1608802723919637	1608802723922102	8	1608802723989677	73
bert/encoder/layer_8/output/LayerNorm/batchnorm/sub	1608802723922120	1608802723922161	18	1608802723989752	54
bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1	1608802723922167	1608802723922242	6	1608802723989808	73
bert/encoder/layer_9/attention/self/query/MatMul	1608802723922247	1608802723922311	5	1608802723989883	633
bert/encoder/layer_9/attention/self/key/MatMul	1608802723922327	1608802723922370	16	1608802723990517	635
bert/encoder/layer_9/attention/self/value/MatMul	1608802723922378	1608802723922426	8	1608802723991153	640
bert/encoder/layer_9/attention/self/query/BiasAdd	1608802723922434	1608802723922468	8	1608802723991795	61
bert/encoder/layer_9/attention/self/key/BiasAdd	1608802723922478	1608802723922509	10	1608802723991857	62
bert/encoder/layer_9/attention/self/value/BiasAdd	1608802723922514	1608802723922549	5	1608802723991921	61
bert/encoder/layer_9/attention/self/Reshape	1608802723922552	1608802723922560	3	-1	-1
bert/encoder/layer_9/attention/self/Reshape_1	1608802723922565	1608802723922575	5	-1	-1
bert/encoder/layer_9/attention/self/Reshape_2	1608802723922578	1608802723922583	3	-1	-1
bert/encoder/layer_9/attention/self/transpose	1608802723922586	1608802723922633	3	1608802723991984	189
bert/encoder/layer_9/attention/self/transpose_1	1608802723922641	1608802723922680	8	1608802723992175	189
bert/encoder/layer_9/attention/self/transpose_2	1608802723922693	1608802723922733	13	1608802723992366	189
bert/encoder/layer_9/attention/self/MatMul	1608802723922740	1608802723924046	7	1608802723992557	161
bert/encoder/layer_9/attention/self/Mul	1608802723924058	1608802723924668	12	1608802723992719	99
bert/encoder/layer_9/attention/self/add	1608802723924675	1608802723924725	7	1608802723992820	129
bert/encoder/layer_9/attention/self/Softmax	1608802723924729	1608802723925044	4	1608802723992951	318
gradients/bert/encoder/layer_9/attention/self/Softmax_grad/mul_1	1608802723925057	1608802723925238	13	1608802723993271	99
bert/encoder/layer_9/attention/self/dropout/mul_1	1608802723925246	1608802723925426	8	1608802723993371	141
bert/encoder/layer_9/attention/self/MatMul_1	1608802723925430	1608802723925640	4	1608802723993514	233
bert/encoder/layer_9/attention/self/transpose_3	1608802723925650	1608802723925699	10	1608802723993748	189
bert/encoder/layer_9/attention/self/Reshape_3	1608802723925708	1608802723925718	9	-1	-1
bert/encoder/layer_9/attention/output/dense/MatMul	1608802723925722	1608802723925828	4	1608802723993939	636
bert/encoder/layer_9/attention/output/dense/BiasAdd	1608802723925836	1608802723925885	8	1608802723994577	61
bert/encoder/layer_9/attention/output/dropout/mul_1	1608802723925891	1608802723925992	6	1608802723994639	74
bert/encoder/layer_9/attention/output/add	1608802723925996	1608802723926146	4	1608802723994715	73
bert/encoder/layer_9/attention/output/LayerNorm/moments/mean	1608802723926150	1608802723926251	4	1608802723994790	31
bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference	1608802723926256	1608802723926392	5	1608802723994823	54
bert/encoder/layer_9/attention/output/LayerNorm/moments/variance	1608802723926401	1608802723926442	9	1608802723994879	31
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add	1608802723926447	1608802723926482	5	1608802723994912	5
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723926486	1608802723926518	4	1608802723994919	4
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul	1608802723926522	1608802723926646	4	1608802723994924	38
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2	1608802723926657	1608802723926831	11	1608802723994965	54
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1	1608802723926839	1608802723927463	8	1608802723995021	73
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub	1608802723927470	1608802723927526	7	1608802723995096	55
bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1	1608802723927530	1608802723927612	4	1608802723995153	73
bert/encoder/layer_9/intermediate/dense/MatMul	1608802723927617	1608802723927680	5	1608802723995227	2194
bert/encoder/layer_9/intermediate/dense/BiasAdd	1608802723927697	1608802723927734	17	1608802723997423	224
bert/encoder/layer_9/intermediate/dense/Pow	1608802723927738	1608802723927785	4	1608802723997648	367
gradients/bert/encoder/layer_9/intermediate/dense/mul_3_grad/Mul_1	1608802723927795	1608802723927836	10	1608802723998017	195
gradients/bert/encoder/layer_9/intermediate/dense/Pow_grad/Pow	1608802723927852	1608802723927889	16	1608802723998214	198
bert/encoder/layer_9/intermediate/dense/mul	1608802723927897	1608802723927938	8	1608802723998413	195
gradients/bert/encoder/layer_9/intermediate/dense/Pow_grad/mul	1608802723927942	1608802723927981	4	1608802723998610	195
bert/encoder/layer_9/intermediate/dense/add	1608802723927986	1608802723928018	5	1608802723998806	280
bert/encoder/layer_9/intermediate/dense/mul_1	1608802723928022	1608802723928060	4	1608802723999088	194
bert/encoder/layer_9/intermediate/dense/Tanh	1608802723928064	1608802723928101	4	1608802723999284	212
bert/encoder/layer_9/intermediate/dense/add_1	1608802723928107	1608802723928145	6	1608802723999498	196
bert/encoder/layer_9/intermediate/dense/mul_2	1608802723928153	1608802723930322	8	1608802723999696	195
bert/encoder/layer_9/intermediate/dense/mul_3	1608802723930326	1608802723930545	4	1608802723999893	280
bert/encoder/layer_9/output/dense/MatMul	1608802723930549	1608802723930913	4	1608802724000175	2474
bert/encoder/layer_9/output/dense/BiasAdd	1608802723930928	1608802723931107	15	1608802724002651	61
bert/encoder/layer_9/output/dropout/mul_1	1608802723931111	1608802723931312	4	1608802724002713	73
bert/encoder/layer_9/output/add	1608802723931316	1608802723931504	4	1608802724002788	73
bert/encoder/layer_9/output/LayerNorm/moments/mean	1608802723931508	1608802723931704	4	1608802724002863	31
bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference	1608802723931708	1608802723931992	4	1608802724002896	56
bert/encoder/layer_9/output/LayerNorm/moments/variance	1608802723932001	1608802723932184	9	1608802724002953	31
bert/encoder/layer_9/output/LayerNorm/batchnorm/add	1608802723932196	1608802723932400	12	1608802724002986	5
bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt	1608802723932404	1608802723932589	4	1608802724002993	4
bert/encoder/layer_9/output/LayerNorm/batchnorm/mul	1608802723932594	1608802723932797	5	1608802724002999	39
bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2	1608802723932812	1608802723933069	15	1608802724003040	54
bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1	1608802723933076	1608802723935546	7	1608802724003096	73
bert/encoder/layer_9/output/LayerNorm/batchnorm/sub	1608802723935555	1608802723935613	9	1608802724003171	63
bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1	1608802723935623	1608802723935688	10	1608802724003235	73
bert/encoder/layer_10/attention/self/query/MatMul	1608802723935693	1608802723935764	5	1608802724003310	635
bert/encoder/layer_10/attention/self/key/MatMul	1608802723935773	1608802723935822	9	1608802724003947	630
bert/encoder/layer_10/attention/self/value/MatMul	1608802723935830	1608802723935870	8	1608802724004579	630
bert/encoder/layer_10/attention/self/query/BiasAdd	1608802723935881	1608802723935919	11	1608802724005211	62
bert/encoder/layer_10/attention/self/key/BiasAdd	1608802723935927	1608802723935963	8	1608802724005275	62
bert/encoder/layer_10/attention/self/value/BiasAdd	1608802723935967	1608802723935994	4	1608802724005338	61
bert/encoder/layer_10/attention/self/Reshape	1608802723936001	1608802723936019	7	-1	-1
bert/encoder/layer_10/attention/self/Reshape_1	1608802723936024	1608802723936031	5	-1	-1
bert/encoder/layer_10/attention/self/Reshape_2	1608802723936033	1608802723936041	2	-1	-1
bert/encoder/layer_10/attention/self/transpose	1608802723936048	1608802723936087	7	1608802724005400	189
bert/encoder/layer_10/attention/self/transpose_1	1608802723936096	1608802723936139	9	1608802724005591	190
bert/encoder/layer_10/attention/self/transpose_2	1608802723936146	1608802723936187	7	1608802724005783	189
bert/encoder/layer_10/attention/self/MatMul	1608802723936196	1608802723937490	9	1608802724005974	161
bert/encoder/layer_10/attention/self/Mul	1608802723937501	1608802723938110	11	1608802724006137	99
bert/encoder/layer_10/attention/self/add	1608802723938117	1608802723938169	7	1608802724006237	130
bert/encoder/layer_10/attention/self/Softmax	1608802723938173	1608802723938487	4	1608802724006368	319
gradients/bert/encoder/layer_10/attention/self/Softmax_grad/mul_1	1608802723938495	1608802723938679	8	1608802724006689	100
bert/encoder/layer_10/attention/self/dropout/mul_1	1608802723938687	1608802723938869	8	1608802724006791	142
bert/encoder/layer_10/attention/self/MatMul_1	1608802723938873	1608802723939059	4	1608802724006934	233
bert/encoder/layer_10/attention/self/transpose_3	1608802723939071	1608802723939138	12	1608802724007169	189
bert/encoder/layer_10/attention/self/Reshape_3	1608802723939146	1608802723939156	8	-1	-1
bert/encoder/layer_10/attention/output/dense/MatMul	1608802723939159	1608802723939267	3	1608802724007360	634
bert/encoder/layer_10/attention/output/dense/BiasAdd	1608802723939275	1608802723939324	8	1608802724007995	62
bert/encoder/layer_10/attention/output/dropout/mul_1	1608802723939329	1608802723939431	5	1608802724008059	74
bert/encoder/layer_10/attention/output/add	1608802723939437	1608802723939586	6	1608802724008135	73
bert/encoder/layer_10/attention/output/LayerNorm/moments/mean	1608802723939590	1608802723939689	4	1608802724008209	32
bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference	1608802723939693	1608802723939829	4	1608802724008243	55
bert/encoder/layer_10/attention/output/LayerNorm/moments/variance	1608802723939837	1608802723939874	8	1608802724008300	32
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add	1608802723939879	1608802723939912	5	1608802724008333	5
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723939916	1608802723939945	4	1608802724008340	4
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul	1608802723939948	1608802723940064	3	1608802724008346	39
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2	1608802723940072	1608802723940256	8	1608802724008386	53
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1	1608802723940263	1608802723940897	7	1608802724008441	73
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub	1608802723940905	1608802723940958	8	1608802724008516	57
bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1	1608802723940963	1608802723941033	5	1608802724008574	73
bert/encoder/layer_10/intermediate/dense/MatMul	1608802723941038	1608802723941112	5	1608802724008649	2196
bert/encoder/layer_10/intermediate/dense/BiasAdd	1608802723941124	1608802723941165	12	1608802724010846	225
bert/encoder/layer_10/intermediate/dense/Pow	1608802723941170	1608802723941208	5	1608802724011073	366
gradients/bert/encoder/layer_10/intermediate/dense/mul_3_grad/Mul_1	1608802723941218	1608802723941264	10	1608802724011440	195
gradients/bert/encoder/layer_10/intermediate/dense/Pow_grad/Pow	1608802723941271	1608802723941310	7	1608802724011636	196
bert/encoder/layer_10/intermediate/dense/mul	1608802723941319	1608802723941350	9	1608802724011834	195
gradients/bert/encoder/layer_10/intermediate/dense/Pow_grad/mul	1608802723941360	1608802723941392	10	1608802724012030	195
bert/encoder/layer_10/intermediate/dense/add	1608802723941396	1608802723941431	4	1608802724012228	280
bert/encoder/layer_10/intermediate/dense/mul_1	1608802723941436	1608802723941465	5	1608802724012510	194
bert/encoder/layer_10/intermediate/dense/Tanh	1608802723941474	1608802723941505	9	1608802724012706	210
bert/encoder/layer_10/intermediate/dense/add_1	1608802723941511	1608802723941552	6	1608802724012917	196
bert/encoder/layer_10/intermediate/dense/mul_2	1608802723941562	1608802723943749	10	1608802724013115	194
bert/encoder/layer_10/intermediate/dense/mul_3	1608802723943761	1608802723943974	12	1608802724013310	280
bert/encoder/layer_10/output/dense/MatMul	1608802723943978	1608802723944353	4	1608802724013591	2474
bert/encoder/layer_10/output/dense/BiasAdd	1608802723944371	1608802723944541	18	1608802724016067	62
bert/encoder/layer_10/output/dropout/mul_1	1608802723944551	1608802723944740	10	1608802724016131	73
bert/encoder/layer_10/output/add	1608802723944744	1608802723944935	4	1608802724016206	73
bert/encoder/layer_10/output/LayerNorm/moments/mean	1608802723944939	1608802723945138	4	1608802724016281	32
bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference	1608802723945142	1608802723945412	4	1608802724016314	55
bert/encoder/layer_10/output/LayerNorm/moments/variance	1608802723945421	1608802723945612	9	1608802724016371	32
bert/encoder/layer_10/output/LayerNorm/batchnorm/add	1608802723945616	1608802723945839	4	1608802724016404	5
bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt	1608802723945843	1608802723946016	4	1608802724016411	4
bert/encoder/layer_10/output/LayerNorm/batchnorm/mul	1608802723946020	1608802723946213	4	1608802724016416	38
bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2	1608802723946222	1608802723946500	9	1608802724016456	54
bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1	1608802723946507	1608802723948976	7	1608802724016512	73
bert/encoder/layer_10/output/LayerNorm/batchnorm/sub	1608802723948989	1608802723949041	13	1608802724016587	55
bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1	1608802723949044	1608802723949120	3	1608802724016644	73
bert/encoder/layer_11/attention/self/query/MatMul	1608802723949125	1608802723949190	5	1608802724016718	633
bert/encoder/layer_11/attention/self/key/MatMul	1608802723949200	1608802723949242	10	1608802724017353	636
bert/encoder/layer_11/attention/self/value/MatMul	1608802723949249	1608802723949294	7	1608802724017990	632
bert/encoder/layer_11/attention/self/query/BiasAdd	1608802723949301	1608802723949332	7	1608802724018624	62
bert/encoder/layer_11/attention/self/key/BiasAdd	1608802723949342	1608802723949370	10	1608802724018688	61
bert/encoder/layer_11/attention/self/value/BiasAdd	1608802723949375	1608802723949404	5	1608802724018751	61
bert/encoder/layer_11/attention/self/Reshape	1608802723949409	1608802723949416	5	-1	-1
bert/encoder/layer_11/attention/self/Reshape_1	1608802723949419	1608802723949429	3	-1	-1
bert/encoder/layer_11/attention/self/Reshape_2	1608802723949432	1608802723949436	3	-1	-1
bert/encoder/layer_11/attention/self/transpose	1608802723949439	1608802723949482	3	1608802724018813	189
bert/encoder/layer_11/attention/self/transpose_1	1608802723949490	1608802723949524	8	1608802724019004	189
bert/encoder/layer_11/attention/self/transpose_2	1608802723949536	1608802723949572	12	1608802724019195	189
bert/encoder/layer_11/attention/self/MatMul	1608802723949579	1608802723950915	7	1608802724019385	161
bert/encoder/layer_11/attention/self/Mul	1608802723950924	1608802723951537	9	1608802724019548	99
bert/encoder/layer_11/attention/self/add	1608802723951541	1608802723951598	4	1608802724019648	129
bert/encoder/layer_11/attention/self/Softmax	1608802723951602	1608802723951914	4	1608802724019779	319
gradients/bert/encoder/layer_11/attention/self/Softmax_grad/mul_1	1608802723951923	1608802723952106	9	1608802724020101	100
bert/encoder/layer_11/attention/self/dropout/mul_1	1608802723952113	1608802723952296	7	1608802724020202	142
bert/encoder/layer_11/attention/self/MatMul_1	1608802723952300	1608802723952487	4	1608802724020346	233
bert/encoder/layer_11/attention/self/transpose_3	1608802723952496	1608802723952565	9	1608802724020580	189
bert/encoder/layer_11/attention/self/Reshape_3	1608802723952573	1608802723952582	8	-1	-1
bert/encoder/layer_11/attention/output/dense/MatMul	1608802723952586	1608802723952695	4	1608802724020771	638
bert/encoder/layer_11/attention/output/dense/BiasAdd	1608802723952702	1608802723952750	7	1608802724021410	62
bert/encoder/layer_11/attention/output/dropout/mul_1	1608802723952754	1608802723952857	4	1608802724021474	73
bert/encoder/layer_11/attention/output/add	1608802723952861	1608802723953012	4	1608802724021548	72
bert/encoder/layer_11/attention/output/LayerNorm/moments/mean	1608802723953016	1608802723953115	4	1608802724021622	32
bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference	1608802723953119	1608802723953256	4	1608802724021655	54
bert/encoder/layer_11/attention/output/LayerNorm/moments/variance	1608802723953264	1608802723953300	8	1608802724021711	32
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add	1608802723953307	1608802723953339	7	1608802724021745	5
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt	1608802723953344	1608802723953373	5	1608802724021751	5
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul	1608802723953377	1608802723953504	4	1608802724021758	39
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2	1608802723953512	1608802723953695	8	1608802724021798	55
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1	1608802723953702	1608802723954329	7	1608802724021854	73
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub	1608802723954335	1608802723954391	6	1608802724021929	55
bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1	1608802723954396	1608802723954475	5	1608802724021986	73
bert/encoder/layer_11/intermediate/dense/MatMul	1608802723954481	1608802723954543	6	1608802724022061	2194
bert/encoder/layer_11/intermediate/dense/BiasAdd	1608802723954563	1608802723954596	20	1608802724024257	225
bert/encoder/layer_11/intermediate/dense/Pow	1608802723954600	1608802723954644	4	1608802724024484	366
gradients/bert/encoder/layer_11/intermediate/dense/mul_3_grad/Mul_1	1608802723954652	1608802723954689	8	1608802724024851	195
gradients/bert/encoder/layer_11/intermediate/dense/Pow_grad/Pow	1608802723954700	1608802723954734	11	1608802724025048	196
bert/encoder/layer_11/intermediate/dense/mul	1608802723954740	1608802723954776	6	1608802724025246	195
gradients/bert/encoder/layer_11/intermediate/dense/Pow_grad/mul	1608802723954780	1608802723954815	4	1608802724025442	194
bert/encoder/layer_11/intermediate/dense/add	1608802723954818	1608802723954847	3	1608802724025638	280
bert/encoder/layer_11/intermediate/dense/mul_1	1608802723954851	1608802723954884	4	1608802724025920	194
bert/encoder/layer_11/intermediate/dense/Tanh	1608802723954887	1608802723954920	3	1608802724026116	210
bert/encoder/layer_11/intermediate/dense/add_1	1608802723954923	1608802723954979	3	1608802724026328	196
bert/encoder/layer_11/intermediate/dense/mul_2	1608802723954987	1608802723957180	8	1608802724026526	195
bert/encoder/layer_11/intermediate/dense/mul_3	1608802723957184	1608802723957405	4	1608802724026723	281
bert/encoder/layer_11/output/dense/MatMul	1608802723957409	1608802723957771	4	1608802724027005	2474
bert/encoder/layer_11/output/dense/BiasAdd	1608802723957779	1608802723957967	8	1608802724029481	62
bert/encoder/layer_11/output/dropout/mul_1	1608802723957970	1608802723958172	3	1608802724029545	73
bert/encoder/layer_11/output/add	1608802723958178	1608802723958363	6	1608802724029620	73
bert/encoder/layer_11/output/LayerNorm/moments/mean	1608802723958366	1608802723958562	3	1608802724029695	32
bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference	1608802723958566	1608802723958850	4	1608802724029728	55
bert/encoder/layer_11/output/LayerNorm/moments/variance	1608802723958860	1608802723959045	10	1608802724029785	31
bert/encoder/layer_11/output/LayerNorm/batchnorm/add	1608802723959054	1608802723959251	9	1608802724029819	5
bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt	1608802723959256	1608802723959452	5	1608802724029825	4
bert/encoder/layer_11/output/LayerNorm/batchnorm/mul	1608802723959456	1608802723959643	4	1608802724029831	39
bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2	1608802723959657	1608802723959926	14	1608802724029871	54
bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1	1608802723959935	1608802723962409	9	1608802724029927	73
bert/encoder/layer_11/output/LayerNorm/batchnorm/sub	1608802723962415	1608802723962468	6	1608802724030001	54
bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1	1608802723962477	1608802723962543	9	1608802724030057	73
bert/encoder/Reshape_13	1608802723962547	1608802723962560	4	-1	-1
GatherV2	1608802723962564	1608802723962621	4	1608802724030132	19
bert/pooler/strided_slice	1608802723962629	1608802723962687	8	1608802724030153	6
cls/predictions/transform/dense/MatMul	1608802723962694	1608802723962780	7	1608802724030165	151
bert/pooler/Squeeze	1608802723962789	1608802723962805	9	-1	-1
cls/predictions/transform/dense/BiasAdd	1608802723962809	1608802723962846	4	1608802724030317	9
bert/pooler/dense/MatMul	1608802723962850	1608802723962893	4	1608802724030328	26
cls/predictions/transform/dense/Pow	1608802723962896	1608802723962935	3	1608802724030356	18
gradients/cls/predictions/transform/dense/Pow_grad/Pow	1608802723962942	1608802723962978	7	1608802724030376	7
bert/pooler/dense/BiasAdd	1608802723962985	1608802723963012	7	1608802724030385	5
cls/predictions/transform/dense/mul	1608802723963016	1608802723963049	4	1608802724030392	11
gradients/cls/predictions/transform/dense/Pow_grad/mul	1608802723963054	1608802723963085	5	1608802724030404	8
bert/pooler/dense/Tanh	1608802723963088	1608802723963115	3	1608802724030413	4
cls/predictions/transform/dense/add	1608802723963118	1608802723963681	3	1608802724030419	15
cls/seq_relationship/MatMul	1608802723963684	1608802723964324	3	1608802724030436	24
cls/predictions/transform/dense/mul_1	1608802723964328	1608802723964954	4	1608802724030462	7
cls/seq_relationship/BiasAdd	1608802723964965	1608802723965018	11	1608802724030473	4
cls/predictions/transform/dense/Tanh	1608802723965022	1608802723965082	4	1608802724030478	10
cls/seq_relationship/LogSoftmax	1608802723965086	1608802723965530	4	1608802724030490	16
cls/predictions/transform/dense/add_1	1608802723965534	1608802723965725	4	1608802724030508	7
gradients/cls/seq_relationship/LogSoftmax_grad/Exp	1608802723965733	1608802723965768	8	1608802724030516	4
cls/seq_relationship/mul	1608802723965774	1608802723965809	6	1608802724030522	4
cls/predictions/transform/dense/mul_2	1608802723965813	1608802723965846	4	1608802724030528	7
gradients/cls/seq_relationship/LogSoftmax_grad/mul	1608802723965849	1608802723965885	3	1608802724030536	5
cls/seq_relationship/Sum	1608802723965889	1608802723965986	4	1608802724030542	4
cls/predictions/transform/dense/mul_3	1608802723965992	1608802723966117	6	1608802724030548	12
gradients/cls/seq_relationship/LogSoftmax_grad/sub	1608802723966127	1608802723966177	10	1608802724030562	4
cls/seq_relationship/Neg	1608802723966182	1608802723966279	5	1608802724030567	5
cls/predictions/transform/LayerNorm/moments/mean	1608802723966284	1608802723966438	5	1608802724030574	6
gradients/cls/seq_relationship/BiasAdd_grad/BiasAddGrad	1608802723966442	1608802723966532	4	1608802724030587	9
gradients/cls/seq_relationship/MatMul_grad/MatMul	1608802723966543	1608802723966676	11	1608802724030598	14
gradients/cls/seq_relationship/MatMul_grad/MatMul_1	1608802723966680	1608802723966736	4	1608802724030614	23
cls/seq_relationship/Mean	1608802723966740	1608802723966778	4	1608802724030638	6
cls/predictions/transform/LayerNorm/moments/SquaredDifference	1608802723966786	1608802723966821	8	1608802724030645	11
global_norm/L2Loss_205	1608802723966829	1608802723966921	8	1608802724030658	5
gradients/bert/pooler/dense/Tanh_grad/TanhGrad	1608802723966924	1608802723967113	3	1608802724030665	6
global_norm/L2Loss_204	1608802723967123	1608802723967748	10	1608802724030673	6
cls/predictions/transform/LayerNorm/moments/variance	1608802723967751	1608802723967816	3	1608802724030680	6
gradients/bert/pooler/dense/BiasAdd_grad/BiasAddGrad	1608802723967819	1608802723967866	3	1608802724030691	9
gradients/bert/pooler/dense/MatMul_grad/MatMul	1608802723967871	1608802723967914	5	1608802724030702	25
gradients/bert/pooler/dense/MatMul_grad/MatMul_1	1608802723967920	1608802723967984	6	1608802724030729	16
cls/predictions/transform/LayerNorm/batchnorm/add	1608802723967991	1608802723968027	7	1608802724030747	4
global_norm/L2Loss_198	1608802723968036	1608802723968066	9	1608802724030752	5
gradients/bert/pooler/Squeeze_grad/Reshape	1608802723968069	1608802723968076	3	-1	-1
global_norm/L2Loss_197	1608802723968084	1608802723968164	8	1608802724030759	15
cls/predictions/transform/LayerNorm/batchnorm/Rsqrt	1608802723968167	1608802723968202	3	1608802724030775	5
gradients/bert/pooler/strided_slice_grad/StridedSliceGrad	1608802723968206	1608802723968286	4	1608802724030782	32
cls/predictions/transform/LayerNorm/batchnorm/mul	1608802723968295	1608802723968331	9	1608802724030816	13
cls/predictions/transform/LayerNorm/batchnorm/mul_2	1608802723968339	1608802723968392	8	1608802724030830	9
cls/predictions/transform/LayerNorm/batchnorm/mul_1	1608802723968399	1608802723968435	7	1608802724030841	14
cls/predictions/transform/LayerNorm/batchnorm/sub	1608802723968445	1608802723970612	10	1608802724030856	13
cls/predictions/transform/LayerNorm/batchnorm/add_1	1608802723970616	1608802723970844	4	1608802724030871	9
cls/predictions/MatMul	1608802723970849	1608802723971212	5	1608802724030881	3500
cls/predictions/BiasAdd	1608802723971227	1608802723971403	15	1608802724034383	343
cls/predictions/LogSoftmax	1608802723971406	1608802723971993	3	1608802724034728	841
gradients/cls/predictions/LogSoftmax_grad/Exp	1608802723972002	1608802723972277	9	1608802724035571	307
cls/predictions/mul	1608802723972284	1608802723972485	7	1608802724035880	433
gradients/cls/predictions/LogSoftmax_grad/mul	1608802723972489	1608802723972685	4	1608802724036314	309
cls/predictions/Sum	1608802723972689	1608802723972892	4	1608802724036625	151
gradients/cls/predictions/LogSoftmax_grad/sub	1608802723972896	1608802723973081	4	1608802724036778	429
cls/predictions/Neg	1608802723973090	1608802723973360	9	1608802724037209	4
gradients/cls/predictions/BiasAdd_grad/BiasAddGrad	1608802723973364	1608802723975892	4	1608802724037217	155
gradients/cls/predictions/MatMul_grad/MatMul	1608802723975901	1608802723975961	9	1608802724037378	3558
gradients/cls/predictions/MatMul_grad/MatMul_1	1608802723975973	1608802723976019	12	1608802724040938	3405
cls/predictions/mul_1	1608802723976027	1608802723976078	8	1608802724044345	7
global_norm/L2Loss_203	1608802723976082	1608802723976150	4	1608802724044354	14
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_1_grad/Mul	1608802723976154	1608802723976185	4	1608802724044369	15
gradients/cls/predictions/transform/LayerNorm/batchnorm/sub_grad/Neg	1608802723976192	1608802723976227	7	1608802724044386	10
gradients/cls/predictions/transform/LayerNorm/batchnorm/sub_grad/Sum	1608802723976234	1608802723976276	7	1608802724044397	15
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802723976279	1608802723976315	3	1608802724044414	14
cls/predictions/Sum_1	1608802723976318	1608802723976350	3	1608802724044429	5
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_2_grad/Mul	1608802723976354	1608802723976398	4	1608802724044436	16
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802723976403	1608802723976440	5	1608802724044453	10
global_norm/L2Loss_201	1608802723976443	1608802723976493	3	1608802724044464	6
cls/predictions/truediv	1608802723976496	1608802723977132	3	1608802724044472	5
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_2_grad/Sum	1608802723977137	1608802723977763	5	1608802724044478	7
gradients/AddN	1608802723977772	1608802723978398	9	1608802724044487	13
add_1	1608802723978403	1608802723978463	5	1608802724044502	4
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802723978467	1608802723978474	4	-1	-1
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Mul	1608802723978477	1608802723978521	3	1608802724044508	11
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Mul_1	1608802723978529	1608802723978588	8	1608802724044521	9
gradients/cls/predictions/transform/LayerNorm/moments/mean_grad/Tile	1608802723978660	1608802723978790	72	1608802724044532	9
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Sum	1608802723978798	1608802723978972	8	1608802724044542	9
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Sum_1	1608802723978978	1608802723979161	6	1608802724044553	17
gradients/cls/predictions/transform/LayerNorm/moments/mean_grad/truediv	1608802723979171	1608802723979206	10	1608802724044571	10
gradients/cls/predictions/transform/LayerNorm/batchnorm/mul_grad/Reshape	1608802723979210	1608802723979216	4	-1	-1
global_norm/L2Loss_202	1608802723979219	1608802723979254	3	1608802724044582	4
gradients/cls/predictions/transform/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802723979258	1608802723979289	4	1608802724044588	4
gradients/cls/predictions/transform/LayerNorm/moments/variance_grad/Tile	1608802723979294	1608802723979331	5	1608802724044594	9
gradients/cls/predictions/transform/LayerNorm/moments/variance_grad/truediv	1608802723979338	1608802723979427	7	1608802724044605	7
gradients/cls/predictions/transform/LayerNorm/moments/SquaredDifference_grad/scalar	1608802723979431	1608802723979439	4	-1	-1
gradients/cls/predictions/transform/LayerNorm/moments/SquaredDifference_grad/sub	1608802723979441	1608802723979561	2	1608802724044613	13
gradients/cls/predictions/transform/LayerNorm/moments/SquaredDifference_grad/Mul	1608802723979564	1608802723979613	3	1608802724044628	7
gradients/cls/predictions/transform/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802723979617	1608802723979718	4	1608802724044637	8
gradients/AddN_1	1608802723979723	1608802723979884	5	1608802724044647	22
gradients/cls/predictions/transform/dense/mul_3_grad/Mul_1	1608802723979889	1608802723979974	5	1608802724044670	7
gradients/cls/predictions/transform/dense/mul_3_grad/Mul	1608802723979987	1608802723980119	13	1608802724044679	14
gradients/cls/predictions/transform/dense/mul_2_grad/Mul_1	1608802723980124	1608802723980158	5	1608802724044695	15
gradients/cls/predictions/transform/dense/Tanh_grad/TanhGrad	1608802723980161	1608802723980190	3	1608802724044711	12
gradients/cls/predictions/transform/dense/mul_1_grad/Mul_1	1608802723980198	1608802723980227	8	1608802724044725	7
gradients/cls/predictions/transform/dense/Pow_grad/mul_1	1608802723980231	1608802723980357	4	1608802724044733	11
gradients/AddN_2	1608802723980372	1608802723980549	15	1608802724044746	15
gradients/cls/predictions/transform/dense/BiasAdd_grad/BiasAddGrad	1608802723980559	1608802723981176	10	1608802724044767	12
gradients/cls/predictions/transform/dense/MatMul_grad/MatMul	1608802723981180	1608802723981243	4	1608802724044784	163
gradients/cls/predictions/transform/dense/MatMul_grad/MatMul_1	1608802723981250	1608802723981302	7	1608802724044950	143
global_norm/L2Loss_200	1608802723981314	1608802723981346	12	1608802724045094	6
gradients/Reshape_2_grad/Reshape/tensor	1608802723981349	1608802723981429	3	1608802724045101	53
global_norm/L2Loss_199	1608802723981437	1608802723981518	8	1608802724045155	19
gradients/Reshape_2_grad/Reshape	1608802723981524	1608802723981531	6	-1	-1
gradients/AddN_3	1608802723981534	1608802723981577	3	1608802724045175	72
gradients/bert/encoder/Reshape_13_grad/Reshape	1608802723981582	1608802723981588	5	-1	-1
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802723981591	1608802723981627	3	1608802724045249	74
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/sub_grad/Neg	1608802723981634	1608802723981667	7	1608802724045324	51
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/sub_grad/Sum	1608802723981674	1608802723981708	7	1608802724045377	74
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802723981711	1608802723981744	3	1608802724045453	68
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802723981748	1608802723981778	4	1608802724045523	72
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802723981781	1608802723981832	3	1608802724045596	53
global_norm/L2Loss_195	1608802723981836	1608802723984028	4	1608802724045651	5
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802723984031	1608802723984263	3	1608802724045658	32
gradients/AddN_4	1608802723984268	1608802723984627	5	1608802724045691	69
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802723984631	1608802723984642	4	-1	-1
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Mul	1608802723984645	1608802723984820	3	1608802724045762	55
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802723984833	1608802723985020	13	1608802724045818	54
gradients/bert/encoder/layer_11/output/LayerNorm/moments/mean_grad/Tile	1608802723985024	1608802723985217	4	1608802724045873	27
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Sum	1608802723985226	1608802723985420	9	1608802724045902	33
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802723985425	1608802723985697	5	1608802724045937	65
gradients/bert/encoder/layer_11/output/LayerNorm/moments/mean_grad/truediv	1608802723985706	1608802723985890	9	1608802724046003	47
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802723985894	1608802723985905	4	-1	-1
global_norm/L2Loss_196	1608802723985908	1608802723986100	3	1608802724046052	5
gradients/bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802723986103	1608802723986304	3	1608802724046059	5
gradients/bert/encoder/layer_11/output/LayerNorm/moments/variance_grad/Tile	1608802723986308	1608802723986495	4	1608802724046065	27
gradients/bert/encoder/layer_11/output/LayerNorm/moments/variance_grad/truediv	1608802723986515	1608802723986777	20	1608802724046094	51
gradients/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802723986783	1608802723986796	6	-1	-1
gradients/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802723986799	1608802723989257	3	1608802724046147	54
gradients/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802723989261	1608802723989315	4	1608802724046202	51
gradients/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802723989318	1608802723989395	3	1608802724046255	73
gradients/AddN_5	1608802723989399	1608802723989466	4	1608802724046329	95
gradients/bert/encoder/layer_11/output/dropout/mul_1_grad/Mul	1608802723989472	1608802723989508	6	1608802724046426	52
gradients/bert/encoder/layer_11/output/dropout/mul_grad/Mul	1608802723989515	1608802723989560	7	1608802724046480	72
gradients/bert/encoder/layer_11/output/dense/BiasAdd_grad/BiasAddGrad	1608802723989564	1608802723989608	4	1608802724046560	53
gradients/bert/encoder/layer_11/output/dense/MatMul_grad/MatMul	1608802723989615	1608802723989653	7	1608802724046615	2223
gradients/bert/encoder/layer_11/output/dense/MatMul_grad/MatMul_1	1608802723989660	1608802723989704	7	1608802724048840	2475
global_norm/L2Loss_194	1608802723989710	1608802723989741	6	1608802724051316	8
gradients/bert/encoder/layer_11/intermediate/dense/mul_3_grad/Mul	1608802723989744	1608802723989777	3	1608802724051326	280
gradients/bert/encoder/layer_11/intermediate/dense/mul_2_grad/Mul_1	1608802723989781	1608802723989812	4	1608802724051607	280
global_norm/L2Loss_193	1608802723989815	1608802723989901	3	1608802724051888	33
gradients/bert/encoder/layer_11/intermediate/dense/Tanh_grad/TanhGrad	1608802723989905	1608802723990531	4	1608802724051923	275
gradients/bert/encoder/layer_11/intermediate/dense/mul_1_grad/Mul_1	1608802723990535	1608802723991179	4	1608802724052200	195
gradients/bert/encoder/layer_11/intermediate/dense/Pow_grad/mul_1	1608802723991183	1608802723991812	4	1608802724052396	279
gradients/AddN_6	1608802723991816	1608802723991873	4	1608802724052677	367
gradients/bert/encoder/layer_11/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802723991876	1608802723991929	3	1608802724053049	108
gradients/bert/encoder/layer_11/intermediate/dense/MatMul_grad/MatMul	1608802723991933	1608802723991999	4	1608802724053159	2504
gradients/bert/encoder/layer_11/intermediate/dense/MatMul_grad/MatMul_1	1608802723992006	1608802723992187	7	1608802724055667	2469
global_norm/L2Loss_192	1608802723992194	1608802723992380	7	1608802724058137	10
gradients/AddN_7	1608802723992383	1608802723992571	3	1608802724058149	75
global_norm/L2Loss_191	1608802723992575	1608802723992639	4	1608802724058225	33
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802723992655	1608802723992687	16	1608802724058260	69
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802723992694	1608802723992727	7	1608802724058330	51
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802723992733	1608802723992830	6	1608802724058382	74
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802723992852	1608802723992958	22	1608802724058458	69
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802723992961	1608802723993017	3	1608802724058529	73
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802723993022	1608802723993126	5	1608802724058603	52
global_norm/L2Loss_189	1608802723993130	1608802723993277	4	1608802724058657	5
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802723993280	1608802723993381	3	1608802724058664	31
gradients/AddN_8	1608802723993384	1608802723993526	3	1608802724058697	69
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802723993531	1608802723993537	5	-1	-1
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802723993540	1608802723993572	3	1608802724058767	55
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802723993579	1608802723993611	7	1608802724058823	54
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/mean_grad/Tile	1608802723993614	1608802723993644	3	1608802724058878	27
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802723993654	1608802723993758	10	1608802724058907	33
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802723993763	1608802723993949	5	1608802724058941	66
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/mean_grad/truediv	1608802723993953	1608802723994587	4	1608802724059009	47
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802723994595	1608802723994601	8	-1	-1
global_norm/L2Loss_190	1608802723994605	1608802723994649	4	1608802724059057	5
gradients/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802723994653	1608802723994722	4	1608802724059064	5
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/variance_grad/Tile	1608802723994726	1608802723994798	4	1608802724059071	27
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/variance_grad/truediv	1608802723994806	1608802723994835	8	1608802724059099	52
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802723994844	1608802723994851	9	-1	-1
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802723994853	1608802723994888	2	1608802724059153	54
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802723994896	1608802723994922	8	1608802724059208	51
gradients/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802723994927	1608802723994959	5	1608802724059261	73
gradients/AddN_9	1608802723994963	1608802723994994	4	1608802724059335	96
gradients/bert/encoder/layer_11/attention/output/dropout/mul_1_grad/Mul	1608802723994998	1608802723995027	4	1608802724059432	51
gradients/bert/encoder/layer_11/attention/output/dropout/mul_grad/Mul	1608802723995034	1608802723995066	7	1608802724059485	73
gradients/bert/encoder/layer_11/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802723995071	1608802723995117	5	1608802724059562	53
gradients/bert/encoder/layer_11/attention/output/dense/MatMul_grad/MatMul	1608802723995120	1608802723995156	3	1608802724059617	638
gradients/bert/encoder/layer_11/attention/output/dense/MatMul_grad/MatMul_1	1608802723995167	1608802723995219	11	1608802724060262	657
global_norm/L2Loss_188	1608802723995226	1608802723995260	7	1608802724060923	6
gradients/bert/encoder/layer_11/attention/self/Reshape_3_grad/Reshape	1608802723995263	1608802723995269	3	-1	-1
global_norm/L2Loss_187	1608802723995272	1608802723997663	3	1608802724060931	12
gradients/bert/encoder/layer_11/attention/self/transpose_3_grad/transpose	1608802723997666	1608802723998032	3	1608802724060945	190
gradients/bert/encoder/layer_11/attention/self/MatMul_1_grad/MatMul	1608802723998040	1608802723998832	8	1608802724061136	162
gradients/bert/encoder/layer_11/attention/self/MatMul_1_grad/MatMul_1	1608802723998841	1608802723999720	9	1608802724061299	242
gradients/bert/encoder/layer_11/attention/self/dropout/mul_1_grad/Mul	1608802723999728	1608802723999908	8	1608802724061543	99
gradients/bert/encoder/layer_11/attention/self/transpose_2_grad/transpose	1608802723999912	1608802724000189	4	1608802724061643	189
gradients/bert/encoder/layer_11/attention/self/dropout/mul_grad/Mul	1608802724000196	1608802724002668	7	1608802724061834	142
gradients/bert/encoder/layer_11/attention/self/Reshape_2_grad/Reshape	1608802724002671	1608802724002679	3	-1	-1
gradients/bert/encoder/layer_11/attention/self/Softmax_grad/mul	1608802724002681	1608802724002725	2	1608802724061978	141
gradients/bert/encoder/layer_11/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724002728	1608802724002795	3	1608802724062121	55
gradients/bert/encoder/layer_11/attention/self/value/MatMul_grad/MatMul	1608802724002799	1608802724002871	4	1608802724062178	640
gradients/bert/encoder/layer_11/attention/self/value/MatMul_grad/MatMul_1	1608802724002878	1608802724002932	7	1608802724062821	617
gradients/bert/encoder/layer_11/attention/self/Softmax_grad/Sum	1608802724002938	1608802724002975	6	1608802724063440	55
global_norm/L2Loss_186	1608802724002982	1608802724003009	7	1608802724063497	5
global_norm/L2Loss_185	1608802724003012	1608802724003070	3	1608802724063504	14
gradients/bert/encoder/layer_11/attention/self/Softmax_grad/sub	1608802724003073	1608802724003103	3	1608802724063520	100
gradients/bert/encoder/layer_11/attention/self/Mul_grad/Mul	1608802724003107	1608802724003132	4	1608802724063621	142
gradients/bert/encoder/layer_11/attention/self/MatMul_grad/MatMul	1608802724003138	1608802724003341	6	1608802724063765	248
gradients/bert/encoder/layer_11/attention/self/MatMul_grad/MatMul_1	1608802724003350	1608802724005307	9	1608802724064015	244
gradients/bert/encoder/layer_11/attention/self/transpose_grad/transpose	1608802724005314	1608802724005360	7	1608802724064261	189
gradients/bert/encoder/layer_11/attention/self/transpose_1_grad/transpose	1608802724005369	1608802724005420	9	1608802724064452	190
gradients/bert/encoder/layer_11/attention/self/Reshape_grad/Reshape	1608802724005426	1608802724005433	6	-1	-1
gradients/bert/encoder/layer_11/attention/self/Reshape_1_grad/Reshape	1608802724005436	1608802724005440	3	-1	-1
gradients/bert/encoder/layer_11/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724005443	1608802724005605	3	1608802724064646	53
gradients/bert/encoder/layer_11/attention/self/query/MatMul_grad/MatMul	1608802724005609	1608802724005796	4	1608802724064701	641
gradients/bert/encoder/layer_11/attention/self/query/MatMul_grad/MatMul_1	1608802724005802	1608802724005986	6	1608802724065350	610
gradients/bert/encoder/layer_11/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724005992	1608802724006029	6	1608802724065966	57
gradients/bert/encoder/layer_11/attention/self/key/MatMul_grad/MatMul	1608802724006033	1608802724006063	4	1608802724066025	638
gradients/bert/encoder/layer_11/attention/self/key/MatMul_grad/MatMul_1	1608802724006070	1608802724006116	7	1608802724066668	618
global_norm/L2Loss_182	1608802724006123	1608802724006151	7	1608802724067290	5
global_norm/L2Loss_181	1608802724006156	1608802724006251	5	1608802724067297	15
global_norm/L2Loss_184	1608802724006254	1608802724006379	3	1608802724067313	5
gradients/AddN_10	1608802724006382	1608802724006442	3	1608802724067320	119
global_norm/L2Loss_183	1608802724006447	1608802724006703	5	1608802724067441	17
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724006707	1608802724006803	4	1608802724067459	72
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724006816	1608802724006946	13	1608802724067533	72
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724006952	1608802724006982	6	1608802724067607	51
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724006988	1608802724007021	6	1608802724067660	74
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724007031	1608802724007057	10	1608802724067735	69
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724007062	1608802724007181	5	1608802724067805	53
global_norm/L2Loss_179	1608802724007184	1608802724007370	3	1608802724067860	5
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724007377	1608802724008011	7	1608802724067867	31
gradients/AddN_11	1608802724008015	1608802724008077	4	1608802724067900	69
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724008080	1608802724008086	3	-1	-1
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724008088	1608802724008147	2	1608802724067970	55
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724008153	1608802724008224	6	1608802724068027	52
gradients/bert/encoder/layer_10/output/LayerNorm/moments/mean_grad/Tile	1608802724008228	1608802724008260	4	1608802724068081	27
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724008270	1608802724008314	10	1608802724068109	32
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724008317	1608802724008352	3	1608802724068143	66
gradients/bert/encoder/layer_10/output/LayerNorm/moments/mean_grad/truediv	1608802724008356	1608802724008397	4	1608802724068211	47
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724008401	1608802724008407	4	-1	-1
global_norm/L2Loss_180	1608802724008409	1608802724008441	2	1608802724068259	5
gradients/bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724008444	1608802724008469	3	1608802724068266	6
gradients/bert/encoder/layer_10/output/LayerNorm/moments/variance_grad/Tile	1608802724008472	1608802724008503	3	1608802724068274	27
gradients/bert/encoder/layer_10/output/LayerNorm/moments/variance_grad/truediv	1608802724008510	1608802724008537	7	1608802724068302	52
gradients/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724008540	1608802724008559	3	-1	-1
gradients/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724008562	1608802724008592	3	1608802724068356	53
gradients/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724008603	1608802724008661	11	1608802724068411	51
gradients/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724008664	1608802724010860	3	1608802724068464	72
gradients/AddN_12	1608802724010863	1608802724011086	3	1608802724068538	96
gradients/bert/encoder/layer_10/output/dropout/mul_1_grad/Mul	1608802724011095	1608802724011454	9	1608802724068635	51
gradients/bert/encoder/layer_10/output/dropout/mul_grad/Mul	1608802724011461	1608802724011650	7	1608802724068688	73
gradients/bert/encoder/layer_10/output/dense/BiasAdd_grad/BiasAddGrad	1608802724011654	1608802724011846	4	1608802724068768	55
gradients/bert/encoder/layer_10/output/dense/MatMul_grad/MatMul	1608802724011849	1608802724012039	3	1608802724068825	2223
gradients/bert/encoder/layer_10/output/dense/MatMul_grad/MatMul_1	1608802724012046	1608802724012237	7	1608802724071049	2467
global_norm/L2Loss_178	1608802724012243	1608802724012525	6	1608802724073518	5
gradients/bert/encoder/layer_10/intermediate/dense/mul_3_grad/Mul	1608802724012529	1608802724012712	4	1608802724073524	279
gradients/bert/encoder/layer_10/intermediate/dense/mul_2_grad/Mul_1	1608802724012716	1608802724012925	4	1608802724073805	280
global_norm/L2Loss_177	1608802724012931	1608802724013319	6	1608802724074087	33
gradients/bert/encoder/layer_10/intermediate/dense/Tanh_grad/TanhGrad	1608802724013321	1608802724013599	2	1608802724074122	275
gradients/bert/encoder/layer_10/intermediate/dense/mul_1_grad/Mul_1	1608802724013606	1608802724016075	7	1608802724074399	195
gradients/bert/encoder/layer_10/intermediate/dense/Pow_grad/mul_1	1608802724016081	1608802724016137	6	1608802724074595	279
gradients/AddN_13	1608802724016141	1608802724016215	4	1608802724074876	366
gradients/bert/encoder/layer_10/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724016222	1608802724016261	7	1608802724075249	108
gradients/bert/encoder/layer_10/intermediate/dense/MatMul_grad/MatMul	1608802724016265	1608802724016302	4	1608802724075359	2503
gradients/bert/encoder/layer_10/intermediate/dense/MatMul_grad/MatMul_1	1608802724016309	1608802724016341	7	1608802724077866	2470
global_norm/L2Loss_176	1608802724016352	1608802724016392	11	1608802724080337	11
gradients/AddN_14	1608802724016396	1608802724016428	4	1608802724080350	72
global_norm/L2Loss_175	1608802724016431	1608802724016491	3	1608802724080425	33
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724016494	1608802724016522	3	1608802724080459	68
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724016528	1608802724016558	6	1608802724080529	72
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724016564	1608802724016608	6	1608802724080603	51
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724016615	1608802724016665	7	1608802724080656	75
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724016668	1608802724016735	3	1608802724080732	69
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724016739	1608802724017373	4	1608802724080803	53
global_norm/L2Loss_173	1608802724017377	1608802724018006	4	1608802724080858	6
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724018009	1608802724018643	3	1608802724080865	32
gradients/AddN_15	1608802724018649	1608802724018709	6	1608802724080899	69
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724018713	1608802724018718	4	-1	-1
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724018723	1608802724018768	5	1608802724080969	55
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724018774	1608802724018838	6	1608802724081026	53
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724018842	1608802724019021	4	1608802724081080	27
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724019033	1608802724019215	12	1608802724081109	33
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724019218	1608802724019405	3	1608802724081144	66
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724019408	1608802724019438	3	1608802724081211	47
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724019441	1608802724019446	3	-1	-1
global_norm/L2Loss_174	1608802724019448	1608802724019475	2	1608802724081260	5
gradients/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724019478	1608802724019501	3	1608802724081267	5
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724019504	1608802724019567	3	1608802724081274	27
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724019575	1608802724019678	8	1608802724081302	52
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724019681	1608802724019688	3	-1	-1
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724019690	1608802724019804	2	1608802724081356	53
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724019807	1608802724019856	3	1608802724081411	51
gradients/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724019862	1608802724019962	6	1608802724081464	72
gradients/AddN_16	1608802724019966	1608802724020124	4	1608802724081538	95
gradients/bert/encoder/layer_10/attention/output/dropout/mul_1_grad/Mul	1608802724020127	1608802724020219	3	1608802724081635	51
gradients/bert/encoder/layer_10/attention/output/dropout/mul_grad/Mul	1608802724020231	1608802724020373	12	1608802724081687	72
gradients/bert/encoder/layer_10/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724020377	1608802724020422	4	1608802724081763	55
gradients/bert/encoder/layer_10/attention/output/dense/MatMul_grad/MatMul	1608802724020425	1608802724020460	3	1608802724081820	636
gradients/bert/encoder/layer_10/attention/output/dense/MatMul_grad/MatMul_1	1608802724020467	1608802724020517	7	1608802724082463	615
global_norm/L2Loss_172	1608802724020523	1608802724020586	6	1608802724083081	7
gradients/bert/encoder/layer_10/attention/self/Reshape_3_grad/Reshape	1608802724020589	1608802724020595	3	-1	-1
global_norm/L2Loss_171	1608802724020597	1608802724021418	2	1608802724083090	13
gradients/bert/encoder/layer_10/attention/self/transpose_3_grad/transpose	1608802724021423	1608802724021482	5	1608802724083104	189
gradients/bert/encoder/layer_10/attention/self/MatMul_1_grad/MatMul	1608802724021488	1608802724021728	6	1608802724083295	161
gradients/bert/encoder/layer_10/attention/self/MatMul_1_grad/MatMul_1	1608802724021735	1608802724021864	7	1608802724083457	242
gradients/bert/encoder/layer_10/attention/self/dropout/mul_1_grad/Mul	1608802724021872	1608802724021903	8	1608802724083700	99
gradients/bert/encoder/layer_10/attention/self/transpose_2_grad/transpose	1608802724021908	1608802724021938	5	1608802724083801	189
gradients/bert/encoder/layer_10/attention/self/dropout/mul_grad/Mul	1608802724021944	1608802724021993	6	1608802724083992	142
gradients/bert/encoder/layer_10/attention/self/Reshape_2_grad/Reshape	1608802724021997	1608802724022002	4	-1	-1
gradients/bert/encoder/layer_10/attention/self/Softmax_grad/mul	1608802724022007	1608802724022067	5	1608802724084135	141
gradients/bert/encoder/layer_10/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724022070	1608802724022106	3	1608802724084281	57
gradients/bert/encoder/layer_10/attention/self/value/MatMul_grad/MatMul	1608802724022109	1608802724024276	3	1608802724084339	641
gradients/bert/encoder/layer_10/attention/self/value/MatMul_grad/MatMul_1	1608802724024282	1608802724024502	6	1608802724084986	615
gradients/bert/encoder/layer_10/attention/self/Softmax_grad/Sum	1608802724024509	1608802724024866	7	1608802724085603	54
global_norm/L2Loss_170	1608802724024871	1608802724025059	5	1608802724085658	5
global_norm/L2Loss_169	1608802724025061	1608802724025454	2	1608802724085665	15
gradients/bert/encoder/layer_10/attention/self/Softmax_grad/sub	1608802724025456	1608802724025651	2	1608802724085682	99
gradients/bert/encoder/layer_10/attention/self/Mul_grad/Mul	1608802724025654	1608802724025932	3	1608802724085783	142
gradients/bert/encoder/layer_10/attention/self/MatMul_grad/MatMul	1608802724025936	1608802724026743	4	1608802724085926	233
gradients/bert/encoder/layer_10/attention/self/MatMul_grad/MatMul_1	1608802724026751	1608802724029642	8	1608802724086160	243
gradients/bert/encoder/layer_10/attention/self/transpose_grad/transpose	1608802724029650	1608802724029708	8	1608802724086404	189
gradients/bert/encoder/layer_10/attention/self/transpose_1_grad/transpose	1608802724029714	1608802724029743	6	1608802724086595	190
gradients/bert/encoder/layer_10/attention/self/Reshape_grad/Reshape	1608802724029750	1608802724029757	7	-1	-1
gradients/bert/encoder/layer_10/attention/self/Reshape_1_grad/Reshape	1608802724029760	1608802724029764	3	-1	-1
gradients/bert/encoder/layer_10/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724029766	1608802724029803	2	1608802724086790	55
gradients/bert/encoder/layer_10/attention/self/query/MatMul_grad/MatMul	1608802724029806	1608802724029836	3	1608802724086847	639
gradients/bert/encoder/layer_10/attention/self/query/MatMul_grad/MatMul_1	1608802724029842	1608802724029886	6	1608802724087488	612
gradients/bert/encoder/layer_10/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724029892	1608802724029924	6	1608802724088107	54
gradients/bert/encoder/layer_10/attention/self/key/MatMul_grad/MatMul	1608802724029927	1608802724029954	3	1608802724088163	638
gradients/bert/encoder/layer_10/attention/self/key/MatMul_grad/MatMul_1	1608802724029960	1608802724030002	6	1608802724088811	615
global_norm/L2Loss_166	1608802724030008	1608802724030035	6	1608802724089427	5
global_norm/L2Loss_165	1608802724030038	1608802724030092	3	1608802724089434	18
global_norm/L2Loss_168	1608802724030095	1608802724030137	3	1608802724089454	5
gradients/AddN_17	1608802724030140	1608802724030170	3	1608802724089461	119
global_norm/L2Loss_167	1608802724030175	1608802724030330	5	1608802724089582	16
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724030333	1608802724030365	3	1608802724089600	71
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724030372	1608802724030399	7	1608802724089673	72
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724030404	1608802724030433	5	1608802724089747	51
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724030438	1608802724030472	5	1608802724089799	76
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724030476	1608802724030500	4	1608802724089877	69
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724030504	1608802724030533	4	1608802724089947	53
global_norm/L2Loss_163	1608802724030537	1608802724030565	4	1608802724090002	5
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724030568	1608802724030593	3	1608802724090009	32
gradients/AddN_18	1608802724030597	1608802724030627	4	1608802724090042	69
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724030631	1608802724030636	4	-1	-1
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724030639	1608802724030668	3	1608802724090113	56
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724030674	1608802724030701	6	1608802724090171	53
gradients/bert/encoder/layer_9/output/LayerNorm/moments/mean_grad/Tile	1608802724030705	1608802724030731	4	1608802724090225	28
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724030741	1608802724030771	10	1608802724090254	33
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724030778	1608802724030806	7	1608802724090289	65
gradients/bert/encoder/layer_9/output/LayerNorm/moments/mean_grad/truediv	1608802724030809	1608802724030838	3	1608802724090356	47
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724030841	1608802724030846	3	-1	-1
global_norm/L2Loss_164	1608802724030848	1608802724030877	2	1608802724090404	5
gradients/bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724030881	1608802724030904	4	1608802724090411	5
gradients/bert/encoder/layer_9/output/LayerNorm/moments/variance_grad/Tile	1608802724030908	1608802724030937	4	1608802724090418	28
gradients/bert/encoder/layer_9/output/LayerNorm/moments/variance_grad/truediv	1608802724030943	1608802724030968	6	1608802724090448	52
gradients/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724030975	1608802724030981	7	-1	-1
gradients/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724030983	1608802724031012	2	1608802724090501	54
gradients/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724031016	1608802724031039	4	1608802724090557	52
gradients/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724031041	1608802724031068	2	1608802724090610	73
gradients/AddN_19	1608802724031072	1608802724031101	4	1608802724090685	96
gradients/bert/encoder/layer_9/output/dropout/mul_1_grad/Mul	1608802724031104	1608802724031129	3	1608802724090782	52
gradients/bert/encoder/layer_9/output/dropout/mul_grad/Mul	1608802724031136	1608802724031165	7	1608802724090836	72
gradients/bert/encoder/layer_9/output/dense/BiasAdd_grad/BiasAddGrad	1608802724031169	1608802724031209	4	1608802724090913	55
gradients/bert/encoder/layer_9/output/dense/MatMul_grad/MatMul	1608802724031212	1608802724031242	3	1608802724090969	2223
gradients/bert/encoder/layer_9/output/dense/MatMul_grad/MatMul_1	1608802724031253	1608802724031284	11	1608802724093194	2467
global_norm/L2Loss_162	1608802724031290	1608802724031318	6	1608802724095663	7
gradients/bert/encoder/layer_9/intermediate/dense/mul_3_grad/Mul	1608802724031320	1608802724031344	2	1608802724095672	280
gradients/bert/encoder/layer_9/intermediate/dense/mul_2_grad/Mul_1	1608802724031353	1608802724031375	9	1608802724095953	279
global_norm/L2Loss_161	1608802724031380	1608802724031441	5	1608802724096235	33
gradients/bert/encoder/layer_9/intermediate/dense/Tanh_grad/TanhGrad	1608802724031444	1608802724031474	3	1608802724096270	275
gradients/bert/encoder/layer_9/intermediate/dense/mul_1_grad/Mul_1	1608802724031477	1608802724031502	3	1608802724096547	195
gradients/bert/encoder/layer_9/intermediate/dense/Pow_grad/mul_1	1608802724031504	1608802724031531	2	1608802724096743	281
gradients/AddN_20	1608802724031534	1608802724031562	3	1608802724097026	367
gradients/bert/encoder/layer_9/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724031567	1608802724031603	5	1608802724097400	111
gradients/bert/encoder/layer_9/intermediate/dense/MatMul_grad/MatMul	1608802724031606	1608802724031649	3	1608802724097513	2501
gradients/bert/encoder/layer_9/intermediate/dense/MatMul_grad/MatMul_1	1608802724031657	1608802724031693	8	1608802724100018	2467
global_norm/L2Loss_160	1608802724031699	1608802724031723	6	1608802724102489	9
gradients/AddN_21	1608802724031726	1608802724031859	3	1608802724102499	72
global_norm/L2Loss_159	1608802724031862	1608802724031917	3	1608802724102573	32
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724031921	1608802724031947	4	1608802724102607	69
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724031953	1608802724031977	6	1608802724102678	73
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724031982	1608802724032005	5	1608802724102752	52
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724032010	1608802724032040	5	1608802724102805	74
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724032049	1608802724032073	9	1608802724102881	69
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724032077	1608802724032105	4	1608802724102952	53
global_norm/L2Loss_157	1608802724032108	1608802724034394	3	1608802724103007	6
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724034405	1608802724034740	11	1608802724103014	32
gradients/AddN_22	1608802724034744	1608802724034896	4	1608802724103047	69
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724034899	1608802724034905	3	-1	-1
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724034911	1608802724035151	6	1608802724103118	55
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724035157	1608802724035582	6	1608802724103174	54
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724035585	1608802724035897	3	1608802724103230	28
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724035905	1608802724036328	8	1608802724103259	33
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724036331	1608802724036639	3	1608802724103294	65
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724036643	1608802724036794	4	1608802724103361	47
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724036797	1608802724036802	3	-1	-1
global_norm/L2Loss_158	1608802724036807	1608802724037224	5	1608802724103410	5
gradients/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724037227	1608802724037252	3	1608802724103416	5
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724037255	1608802724037382	3	1608802724103423	27
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724037388	1608802724040955	6	1608802724103452	52
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724040960	1608802724040966	5	-1	-1
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724040969	1608802724044368	3	1608802724103505	54
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724044372	1608802724044398	4	1608802724103561	52
gradients/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724044406	1608802724044431	8	1608802724103614	72
gradients/AddN_23	1608802724044434	1608802724044463	3	1608802724103688	96
gradients/bert/encoder/layer_9/attention/output/dropout/mul_1_grad/Mul	1608802724044466	1608802724044491	3	1608802724103785	51
gradients/bert/encoder/layer_9/attention/output/dropout/mul_grad/Mul	1608802724044502	1608802724044528	11	1608802724103838	73
gradients/bert/encoder/layer_9/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724044531	1608802724044577	3	1608802724103916	55
gradients/bert/encoder/layer_9/attention/output/dense/MatMul_grad/MatMul	1608802724044580	1608802724044743	3	1608802724103972	641
gradients/bert/encoder/layer_9/attention/output/dense/MatMul_grad/MatMul_1	1608802724044774	1608802724044895	31	1608802724104619	614
global_norm/L2Loss_156	1608802724044906	1608802724044968	11	1608802724105234	7
gradients/bert/encoder/layer_9/attention/self/Reshape_3_grad/Reshape	1608802724044973	1608802724044985	5	-1	-1
global_norm/L2Loss_155	1608802724044989	1608802724045113	4	1608802724105243	13
gradients/bert/encoder/layer_9/attention/self/transpose_3_grad/transpose	1608802724045117	1608802724045182	4	1608802724105257	189
gradients/bert/encoder/layer_9/attention/self/MatMul_1_grad/MatMul	1608802724045193	1608802724045479	11	1608802724105448	160
gradients/bert/encoder/layer_9/attention/self/MatMul_1_grad/MatMul_1	1608802724045492	1608802724045713	13	1608802724105610	241
gradients/bert/encoder/layer_9/attention/self/dropout/mul_1_grad/Mul	1608802724045725	1608802724045777	12	1608802724105853	99
gradients/bert/encoder/layer_9/attention/self/transpose_2_grad/transpose	1608802724045782	1608802724045829	5	1608802724105954	190
gradients/bert/encoder/layer_9/attention/self/dropout/mul_grad/Mul	1608802724045838	1608802724045882	9	1608802724106145	141
gradients/bert/encoder/layer_9/attention/self/Reshape_2_grad/Reshape	1608802724045886	1608802724045897	4	-1	-1
gradients/bert/encoder/layer_9/attention/self/Softmax_grad/mul	1608802724045901	1608802724045936	4	1608802724106288	142
gradients/bert/encoder/layer_9/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724045940	1608802724046033	4	1608802724106435	55
gradients/bert/encoder/layer_9/attention/self/value/MatMul_grad/MatMul	1608802724046072	1608802724046124	39	1608802724106492	641
gradients/bert/encoder/layer_9/attention/self/value/MatMul_grad/MatMul_1	1608802724046134	1608802724046205	10	1608802724107138	612
gradients/bert/encoder/layer_9/attention/self/Softmax_grad/Sum	1608802724046214	1608802724046276	9	1608802724107752	57
global_norm/L2Loss_154	1608802724046284	1608802724046324	8	1608802724107811	5
global_norm/L2Loss_153	1608802724046328	1608802724046417	4	1608802724107817	15
gradients/bert/encoder/layer_9/attention/self/Softmax_grad/sub	1608802724046421	1608802724046466	4	1608802724107834	101
gradients/bert/encoder/layer_9/attention/self/Mul_grad/Mul	1608802724046471	1608802724046510	5	1608802724107936	141
gradients/bert/encoder/layer_9/attention/self/MatMul_grad/MatMul	1608802724046514	1608802724046753	4	1608802724108079	234
gradients/bert/encoder/layer_9/attention/self/MatMul_grad/MatMul_1	1608802724046765	1608802724046973	12	1608802724108315	243
gradients/bert/encoder/layer_9/attention/self/transpose_grad/transpose	1608802724046985	1608802724047038	12	1608802724108560	189
gradients/bert/encoder/layer_9/attention/self/transpose_1_grad/transpose	1608802724047047	1608802724047089	9	1608802724108751	189
gradients/bert/encoder/layer_9/attention/self/Reshape_grad/Reshape	1608802724047097	1608802724047108	8	-1	-1
gradients/bert/encoder/layer_9/attention/self/Reshape_1_grad/Reshape	1608802724047113	1608802724047120	5	-1	-1
gradients/bert/encoder/layer_9/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724047123	1608802724047178	3	1608802724108946	55
gradients/bert/encoder/layer_9/attention/self/query/MatMul_grad/MatMul	1608802724047182	1608802724047231	4	1608802724109002	642
gradients/bert/encoder/layer_9/attention/self/query/MatMul_grad/MatMul_1	1608802724047240	1608802724047308	9	1608802724109653	613
gradients/bert/encoder/layer_9/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724047317	1608802724047368	9	1608802724110271	54
gradients/bert/encoder/layer_9/attention/self/key/MatMul_grad/MatMul	1608802724047373	1608802724047414	5	1608802724110327	637
gradients/bert/encoder/layer_9/attention/self/key/MatMul_grad/MatMul_1	1608802724047424	1608802724047490	10	1608802724110971	615
global_norm/L2Loss_150	1608802724047499	1608802724047546	9	1608802724111588	6
global_norm/L2Loss_149	1608802724047552	1608802724047648	6	1608802724111595	16
global_norm/L2Loss_152	1608802724047653	1608802724047688	5	1608802724111612	5
gradients/AddN_24	1608802724047693	1608802724047736	5	1608802724111619	119
global_norm/L2Loss_151	1608802724047746	1608802724047839	10	1608802724111740	16
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724047844	1608802724047886	5	1608802724111758	71
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724047902	1608802724047944	16	1608802724111831	73
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724047954	1608802724048001	10	1608802724111906	51
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724048011	1608802724048061	10	1608802724111958	74
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724048073	1608802724048111	12	1608802724112034	68
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724048116	1608802724048161	5	1608802724112105	53
global_norm/L2Loss_147	1608802724048165	1608802724048200	4	1608802724112160	5
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724048209	1608802724048251	9	1608802724112166	32
gradients/AddN_25	1608802724048256	1608802724048300	5	1608802724112200	69
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724048305	1608802724048314	5	-1	-1
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724048318	1608802724048387	4	1608802724112271	55
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724048397	1608802724048444	10	1608802724112327	53
gradients/bert/encoder/layer_8/output/LayerNorm/moments/mean_grad/Tile	1608802724048448	1608802724048502	4	1608802724112382	27
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724048517	1608802724048563	15	1608802724112411	33
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724048568	1608802724048617	5	1608802724112446	66
gradients/bert/encoder/layer_8/output/LayerNorm/moments/mean_grad/truediv	1608802724048623	1608802724048668	6	1608802724112513	47
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724048672	1608802724048681	4	-1	-1
global_norm/L2Loss_148	1608802724048687	1608802724048728	6	1608802724112562	5
gradients/bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724048733	1608802724048851	5	1608802724112569	5
gradients/bert/encoder/layer_8/output/LayerNorm/moments/variance_grad/Tile	1608802724048856	1608802724051334	5	1608802724112575	28
gradients/bert/encoder/layer_8/output/LayerNorm/moments/variance_grad/truediv	1608802724051344	1608802724051386	10	1608802724112605	52
gradients/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724051392	1608802724051408	6	-1	-1
gradients/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724051413	1608802724051619	5	1608802724112658	53
gradients/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724051630	1608802724051896	11	1608802724112713	52
gradients/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724051900	1608802724051945	4	1608802724112766	73
gradients/AddN_26	1608802724051949	1608802724051992	4	1608802724112841	95
gradients/bert/encoder/layer_8/output/dropout/mul_1_grad/Mul	1608802724052002	1608802724052209	10	1608802724112938	51
gradients/bert/encoder/layer_8/output/dropout/mul_grad/Mul	1608802724052219	1608802724052410	10	1608802724112990	73
gradients/bert/encoder/layer_8/output/dense/BiasAdd_grad/BiasAddGrad	1608802724052415	1608802724052474	5	1608802724113069	55
gradients/bert/encoder/layer_8/output/dense/MatMul_grad/MatMul	1608802724052485	1608802724052708	11	1608802724113126	2222
gradients/bert/encoder/layer_8/output/dense/MatMul_grad/MatMul_1	1608802724052720	1608802724053174	12	1608802724115350	2471
global_norm/L2Loss_146	1608802724053183	1608802724055680	9	1608802724117822	5
gradients/bert/encoder/layer_8/intermediate/dense/mul_3_grad/Mul	1608802724055683	1608802724058148	3	1608802724117829	280
gradients/bert/encoder/layer_8/intermediate/dense/mul_2_grad/Mul_1	1608802724058152	1608802724058200	4	1608802724118110	279
global_norm/L2Loss_145	1608802724058226	1608802724058322	26	1608802724118392	32
gradients/bert/encoder/layer_8/intermediate/dense/Tanh_grad/TanhGrad	1608802724058326	1608802724058367	4	1608802724118426	283
gradients/bert/encoder/layer_8/intermediate/dense/mul_1_grad/Mul_1	1608802724058377	1608802724058417	10	1608802724118710	195
gradients/bert/encoder/layer_8/intermediate/dense/Pow_grad/mul_1	1608802724058421	1608802724058462	4	1608802724118907	280
gradients/AddN_27	1608802724058466	1608802724058508	4	1608802724119188	367
gradients/bert/encoder/layer_8/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724058519	1608802724058586	11	1608802724119560	110
gradients/bert/encoder/layer_8/intermediate/dense/MatMul_grad/MatMul	1608802724058590	1608802724058647	4	1608802724119672	2499
gradients/bert/encoder/layer_8/intermediate/dense/MatMul_grad/MatMul_1	1608802724058658	1608802724058708	11	1608802724122174	2470
global_norm/L2Loss_144	1608802724058724	1608802724058793	16	1608802724124646	9
gradients/AddN_28	1608802724058797	1608802724058843	4	1608802724124656	73
global_norm/L2Loss_143	1608802724058851	1608802724058947	8	1608802724124730	33
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724058951	1608802724058993	4	1608802724124764	69
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724059002	1608802724059048	9	1608802724124834	73
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724059056	1608802724059100	8	1608802724124909	51
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724059110	1608802724059159	10	1608802724124962	74
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724059163	1608802724059209	4	1608802724125038	69
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724059213	1608802724059256	4	1608802724125108	53
global_norm/L2Loss_141	1608802724059260	1608802724059296	4	1608802724125162	6
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724059300	1608802724059347	4	1608802724125170	32
gradients/AddN_29	1608802724059351	1608802724059395	4	1608802724125203	68
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724059402	1608802724059412	7	-1	-1
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724059420	1608802724059462	8	1608802724125273	54
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724059472	1608802724059515	10	1608802724125329	53
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724059520	1608802724059563	5	1608802724125384	27
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724059578	1608802724059622	15	1608802724125414	32
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724059627	1608802724059674	5	1608802724125447	65
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724059679	1608802724059725	5	1608802724125514	47
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724059729	1608802724059737	4	-1	-1
global_norm/L2Loss_142	1608802724059743	1608802724059787	6	1608802724125563	5
gradients/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724059791	1608802724060270	4	1608802724125570	5
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724060274	1608802724060943	4	1608802724125576	27
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724060953	1608802724060995	10	1608802724125605	52
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724061004	1608802724061013	9	-1	-1
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724061016	1608802724061062	3	1608802724125658	55
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724061066	1608802724061101	4	1608802724125715	51
gradients/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724061110	1608802724061154	9	1608802724125768	73
gradients/AddN_30	1608802724061158	1608802724061204	4	1608802724125842	96
gradients/bert/encoder/layer_8/attention/output/dropout/mul_1_grad/Mul	1608802724061208	1608802724061246	4	1608802724125940	51
gradients/bert/encoder/layer_8/attention/output/dropout/mul_grad/Mul	1608802724061260	1608802724061298	14	1608802724125992	73
gradients/bert/encoder/layer_8/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724061303	1608802724061361	5	1608802724126068	55
gradients/bert/encoder/layer_8/attention/output/dense/MatMul_grad/MatMul	1608802724061366	1608802724061415	5	1608802724126124	638
gradients/bert/encoder/layer_8/attention/output/dense/MatMul_grad/MatMul_1	1608802724061428	1608802724061501	13	1608802724126769	614
global_norm/L2Loss_140	1608802724061509	1608802724061556	8	1608802724127385	7
gradients/bert/encoder/layer_8/attention/self/Reshape_3_grad/Reshape	1608802724061560	1608802724061569	4	-1	-1
global_norm/L2Loss_139	1608802724061572	1608802724061660	3	1608802724127394	13
gradients/bert/encoder/layer_8/attention/self/transpose_3_grad/transpose	1608802724061664	1608802724061715	4	1608802724127408	189
gradients/bert/encoder/layer_8/attention/self/MatMul_1_grad/MatMul	1608802724061724	1608802724062847	9	1608802724127599	159
gradients/bert/encoder/layer_8/attention/self/MatMul_1_grad/MatMul_1	1608802724062858	1608802724063573	11	1608802724127760	229
gradients/bert/encoder/layer_8/attention/self/dropout/mul_1_grad/Mul	1608802724063584	1608802724063631	11	1608802724127991	99
gradients/bert/encoder/layer_8/attention/self/transpose_2_grad/transpose	1608802724063635	1608802724063679	4	1608802724128092	190
gradients/bert/encoder/layer_8/attention/self/dropout/mul_grad/Mul	1608802724063691	1608802724063783	12	1608802724128283	141
gradients/bert/encoder/layer_8/attention/self/Reshape_2_grad/Reshape	1608802724063787	1608802724063797	4	-1	-1
gradients/bert/encoder/layer_8/attention/self/Softmax_grad/mul	1608802724063800	1608802724063833	3	1608802724128426	142
gradients/bert/encoder/layer_8/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724063837	1608802724063889	4	1608802724128574	55
gradients/bert/encoder/layer_8/attention/self/value/MatMul_grad/MatMul	1608802724063893	1608802724063937	4	1608802724128632	640
gradients/bert/encoder/layer_8/attention/self/value/MatMul_grad/MatMul_1	1608802724063947	1608802724064009	10	1608802724129280	618
gradients/bert/encoder/layer_8/attention/self/Softmax_grad/Sum	1608802724064020	1608802724064068	11	1608802724129899	54
global_norm/L2Loss_138	1608802724064076	1608802724064115	8	1608802724129955	5
global_norm/L2Loss_137	1608802724064119	1608802724064200	4	1608802724129962	15
gradients/bert/encoder/layer_8/attention/self/Softmax_grad/sub	1608802724064203	1608802724064288	3	1608802724129979	100
gradients/bert/encoder/layer_8/attention/self/Mul_grad/Mul	1608802724064293	1608802724064481	5	1608802724130081	141
gradients/bert/encoder/layer_8/attention/self/MatMul_grad/MatMul	1608802724064497	1608802724066070	16	1608802724130224	234
gradients/bert/encoder/layer_8/attention/self/MatMul_grad/MatMul_1	1608802724066082	1608802724067380	12	1608802724130459	241
gradients/bert/encoder/layer_8/attention/self/transpose_grad/transpose	1608802724067391	1608802724067442	11	1608802724130702	190
gradients/bert/encoder/layer_8/attention/self/transpose_1_grad/transpose	1608802724067451	1608802724067499	9	1608802724130894	189
gradients/bert/encoder/layer_8/attention/self/Reshape_grad/Reshape	1608802724067507	1608802724067518	8	-1	-1
gradients/bert/encoder/layer_8/attention/self/Reshape_1_grad/Reshape	1608802724067522	1608802724067530	4	-1	-1
gradients/bert/encoder/layer_8/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724067534	1608802724067588	4	1608802724131088	55
gradients/bert/encoder/layer_8/attention/self/query/MatMul_grad/MatMul	1608802724067596	1608802724067643	8	1608802724131145	639
gradients/bert/encoder/layer_8/attention/self/query/MatMul_grad/MatMul_1	1608802724067651	1608802724067720	8	1608802724131790	614
gradients/bert/encoder/layer_8/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724067728	1608802724067777	8	1608802724132411	54
gradients/bert/encoder/layer_8/attention/self/key/MatMul_grad/MatMul	1608802724067784	1608802724067826	7	1608802724132466	639
gradients/bert/encoder/layer_8/attention/self/key/MatMul_grad/MatMul_1	1608802724067834	1608802724067895	8	1608802724133111	664
global_norm/L2Loss_134	1608802724067904	1608802724067943	9	1608802724133777	7
global_norm/L2Loss_133	1608802724067946	1608802724068028	3	1608802724133786	15
global_norm/L2Loss_136	1608802724068031	1608802724068063	3	1608802724133803	5
gradients/AddN_31	1608802724068066	1608802724068104	3	1608802724133810	118
global_norm/L2Loss_135	1608802724068110	1608802724068186	6	1608802724133930	17
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724068191	1608802724068229	5	1608802724133949	71
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724068237	1608802724068283	8	1608802724134022	73
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724068291	1608802724068328	8	1608802724134096	51
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724068343	1608802724068403	15	1608802724134150	74
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724068407	1608802724068452	4	1608802724134225	69
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724068457	1608802724068517	5	1608802724134295	53
global_norm/L2Loss_131	1608802724068521	1608802724068557	4	1608802724134350	5
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724068561	1608802724068606	4	1608802724134357	32
gradients/AddN_32	1608802724068611	1608802724068649	5	1608802724134391	69
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724068660	1608802724068669	11	-1	-1
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724068672	1608802724068716	3	1608802724134462	54
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724068725	1608802724068762	9	1608802724134517	53
gradients/bert/encoder/layer_7/output/LayerNorm/moments/mean_grad/Tile	1608802724068766	1608802724068815	4	1608802724134572	28
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724068831	1608802724068875	16	1608802724134601	33
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724068882	1608802724068928	7	1608802724134636	65
gradients/bert/encoder/layer_7/output/LayerNorm/moments/mean_grad/truediv	1608802724068932	1608802724068969	4	1608802724134703	48
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724068978	1608802724068987	9	-1	-1
global_norm/L2Loss_132	1608802724068992	1608802724069026	5	1608802724134753	5
gradients/bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724069036	1608802724071063	10	1608802724134759	5
gradients/bert/encoder/layer_7/output/LayerNorm/moments/variance_grad/Tile	1608802724071068	1608802724073530	5	1608802724134766	27
gradients/bert/encoder/layer_7/output/LayerNorm/moments/variance_grad/truediv	1608802724073548	1608802724073589	18	1608802724134795	51
gradients/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724073594	1608802724073602	5	-1	-1
gradients/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724073612	1608802724073816	10	1608802724134848	54
gradients/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724073821	1608802724074094	5	1608802724134903	51
gradients/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724074101	1608802724074158	7	1608802724134956	72
gradients/AddN_33	1608802724074162	1608802724074203	4	1608802724135031	95
gradients/bert/encoder/layer_7/output/dropout/mul_1_grad/Mul	1608802724074207	1608802724074406	4	1608802724135128	52
gradients/bert/encoder/layer_7/output/dropout/mul_grad/Mul	1608802724074415	1608802724074609	9	1608802724135181	73
gradients/bert/encoder/layer_7/output/dense/BiasAdd_grad/BiasAddGrad	1608802724074614	1608802724074664	5	1608802724135259	56
gradients/bert/encoder/layer_7/output/dense/MatMul_grad/MatMul	1608802724074668	1608802724074902	4	1608802724135316	2221
gradients/bert/encoder/layer_7/output/dense/MatMul_grad/MatMul_1	1608802724074913	1608802724075373	11	1608802724137539	2469
global_norm/L2Loss_130	1608802724075382	1608802724077874	9	1608802724140010	5
gradients/bert/encoder/layer_7/intermediate/dense/mul_3_grad/Mul	1608802724077877	1608802724080348	3	1608802724140017	279
gradients/bert/encoder/layer_7/intermediate/dense/mul_2_grad/Mul_1	1608802724080352	1608802724080402	4	1608802724140298	279
global_norm/L2Loss_129	1608802724080406	1608802724080489	4	1608802724140579	33
gradients/bert/encoder/layer_7/intermediate/dense/Tanh_grad/TanhGrad	1608802724080499	1608802724080536	10	1608802724140614	276
gradients/bert/encoder/layer_7/intermediate/dense/mul_1_grad/Mul_1	1608802724080539	1608802724080579	3	1608802724140892	194
gradients/bert/encoder/layer_7/intermediate/dense/Pow_grad/mul_1	1608802724080583	1608802724080619	4	1608802724141088	280
gradients/AddN_34	1608802724080634	1608802724080674	15	1608802724141370	368
gradients/bert/encoder/layer_7/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724080678	1608802724080735	4	1608802724141744	109
gradients/bert/encoder/layer_7/intermediate/dense/MatMul_grad/MatMul	1608802724080739	1608802724080789	4	1608802724141854	2502
gradients/bert/encoder/layer_7/intermediate/dense/MatMul_grad/MatMul_1	1608802724080800	1608802724080847	11	1608802724144359	2467
global_norm/L2Loss_128	1608802724080856	1608802724080902	9	1608802724146827	9
gradients/AddN_35	1608802724080906	1608802724080940	4	1608802724146838	72
global_norm/L2Loss_127	1608802724080949	1608802724081029	9	1608802724146912	33
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724081033	1608802724081079	4	1608802724146947	69
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724081087	1608802724081130	8	1608802724147017	73
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724081137	1608802724081172	7	1608802724147092	51
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724081184	1608802724081229	12	1608802724147145	74
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724081233	1608802724081272	4	1608802724147220	68
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724081276	1608802724081312	4	1608802724147291	53
global_norm/L2Loss_125	1608802724081321	1608802724081356	9	1608802724147345	5
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724081359	1608802724081401	3	1608802724147352	32
gradients/AddN_36	1608802724081405	1608802724081442	4	1608802724147385	69
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724081452	1608802724081460	10	-1	-1
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724081463	1608802724081504	3	1608802724147456	54
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724081513	1608802724081552	9	1608802724147512	54
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724081555	1608802724081596	3	1608802724147567	28
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724081604	1608802724081651	8	1608802724147597	32
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724081655	1608802724081699	4	1608802724147631	65
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724081705	1608802724081740	6	1608802724147698	47
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724081749	1608802724081758	9	-1	-1
global_norm/L2Loss_126	1608802724081761	1608802724081826	3	1608802724147748	5
gradients/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724081829	1608802724082469	3	1608802724147755	5
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724082473	1608802724083103	4	1608802724147762	27
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724083112	1608802724083149	9	1608802724147790	52
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724083154	1608802724083170	5	-1	-1
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724083173	1608802724083210	3	1608802724147844	54
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724083220	1608802724083253	10	1608802724147900	52
gradients/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724083257	1608802724083310	4	1608802724147953	72
gradients/AddN_37	1608802724083314	1608802724083349	4	1608802724148027	96
gradients/bert/encoder/layer_7/attention/output/dropout/mul_1_grad/Mul	1608802724083359	1608802724083395	10	1608802724148125	52
gradients/bert/encoder/layer_7/attention/output/dropout/mul_grad/Mul	1608802724083404	1608802724083447	9	1608802724148178	73
gradients/bert/encoder/layer_7/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724083452	1608802724083510	5	1608802724148259	55
gradients/bert/encoder/layer_7/attention/output/dense/MatMul_grad/MatMul	1608802724083514	1608802724083559	4	1608802724148315	643
gradients/bert/encoder/layer_7/attention/output/dense/MatMul_grad/MatMul_1	1608802724083568	1608802724083641	9	1608802724148961	616
global_norm/L2Loss_124	1608802724083649	1608802724083693	8	1608802724149579	5
gradients/bert/encoder/layer_7/attention/self/Reshape_3_grad/Reshape	1608802724083697	1608802724083706	4	-1	-1
global_norm/L2Loss_123	1608802724083710	1608802724083795	4	1608802724149586	13
gradients/bert/encoder/layer_7/attention/self/transpose_3_grad/transpose	1608802724083798	1608802724083846	3	1608802724149601	189
gradients/bert/encoder/layer_7/attention/self/MatMul_1_grad/MatMul	1608802724083856	1608802724085007	10	1608802724149792	162
gradients/bert/encoder/layer_7/attention/self/MatMul_1_grad/MatMul_1	1608802724085018	1608802724085729	11	1608802724149956	231
gradients/bert/encoder/layer_7/attention/self/dropout/mul_1_grad/Mul	1608802724085739	1608802724085781	10	1608802724150188	99
gradients/bert/encoder/layer_7/attention/self/transpose_2_grad/transpose	1608802724085788	1608802724085830	7	1608802724150289	190
gradients/bert/encoder/layer_7/attention/self/dropout/mul_grad/Mul	1608802724085839	1608802724085942	9	1608802724150480	141
gradients/bert/encoder/layer_7/attention/self/Reshape_2_grad/Reshape	1608802724085946	1608802724085955	4	-1	-1
gradients/bert/encoder/layer_7/attention/self/Softmax_grad/mul	1608802724085959	1608802724085989	4	1608802724150623	141
gradients/bert/encoder/layer_7/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724085993	1608802724086039	4	1608802724150771	55
gradients/bert/encoder/layer_7/attention/self/value/MatMul_grad/MatMul	1608802724086042	1608802724086083	3	1608802724150828	641
gradients/bert/encoder/layer_7/attention/self/value/MatMul_grad/MatMul_1	1608802724086094	1608802724086154	11	1608802724151477	611
gradients/bert/encoder/layer_7/attention/self/Softmax_grad/Sum	1608802724086161	1608802724086205	7	1608802724152090	54
global_norm/L2Loss_122	1608802724086213	1608802724086249	8	1608802724152147	5
global_norm/L2Loss_121	1608802724086252	1608802724086325	3	1608802724152154	15
gradients/bert/encoder/layer_7/attention/self/Softmax_grad/sub	1608802724086328	1608802724086429	3	1608802724152171	99
gradients/bert/encoder/layer_7/attention/self/Mul_grad/Mul	1608802724086434	1608802724086618	5	1608802724152272	142
gradients/bert/encoder/layer_7/attention/self/MatMul_grad/MatMul	1608802724086622	1608802724088200	4	1608802724152416	233
gradients/bert/encoder/layer_7/attention/self/MatMul_grad/MatMul_1	1608802724088211	1608802724089514	11	1608802724152651	229
gradients/bert/encoder/layer_7/attention/self/transpose_grad/transpose	1608802724089525	1608802724089573	11	1608802724152883	190
gradients/bert/encoder/layer_7/attention/self/transpose_1_grad/transpose	1608802724089581	1608802724089618	8	1608802724153074	190
gradients/bert/encoder/layer_7/attention/self/Reshape_grad/Reshape	1608802724089625	1608802724089634	7	-1	-1
gradients/bert/encoder/layer_7/attention/self/Reshape_1_grad/Reshape	1608802724089639	1608802724089644	5	-1	-1
gradients/bert/encoder/layer_7/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724089710	1608802724089793	66	1608802724153269	55
gradients/bert/encoder/layer_7/attention/self/query/MatMul_grad/MatMul	1608802724089800	1608802724089846	7	1608802724153326	638
gradients/bert/encoder/layer_7/attention/self/query/MatMul_grad/MatMul_1	1608802724089856	1608802724089915	10	1608802724153971	611
gradients/bert/encoder/layer_7/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724089923	1608802724089963	8	1608802724154588	54
gradients/bert/encoder/layer_7/attention/self/key/MatMul_grad/MatMul	1608802724089967	1608802724090096	4	1608802724154644	637
gradients/bert/encoder/layer_7/attention/self/key/MatMul_grad/MatMul_1	1608802724090104	1608802724090157	8	1608802724155291	613
global_norm/L2Loss_118	1608802724090165	1608802724090196	8	1608802724155906	7
global_norm/L2Loss_117	1608802724090200	1608802724090261	4	1608802724155915	16
global_norm/L2Loss_120	1608802724090264	1608802724090287	3	1608802724155933	5
gradients/AddN_38	1608802724090290	1608802724090320	3	1608802724155940	120
global_norm/L2Loss_119	1608802724090325	1608802724090379	5	1608802724156061	17
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724090382	1608802724090410	3	1608802724156080	72
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724090417	1608802724090442	7	1608802724156153	73
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724090448	1608802724090474	6	1608802724156228	51
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724090480	1608802724090515	6	1608802724156280	74
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724090519	1608802724090543	4	1608802724156357	69
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724090547	1608802724090571	4	1608802724156427	53
global_norm/L2Loss_115	1608802724090575	1608802724090601	4	1608802724156482	5
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724090604	1608802724090631	3	1608802724156489	32
gradients/AddN_39	1608802724090634	1608802724090660	3	1608802724156522	69
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724090664	1608802724090669	4	-1	-1
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724090672	1608802724090698	3	1608802724156593	55
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724090707	1608802724090731	9	1608802724156650	53
gradients/bert/encoder/layer_6/output/LayerNorm/moments/mean_grad/Tile	1608802724090735	1608802724090763	4	1608802724156705	28
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724090770	1608802724090798	7	1608802724156734	32
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724090803	1608802724090829	5	1608802724156769	66
gradients/bert/encoder/layer_6/output/LayerNorm/moments/mean_grad/truediv	1608802724090832	1608802724090857	3	1608802724156836	47
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724090860	1608802724090865	3	-1	-1
global_norm/L2Loss_116	1608802724090868	1608802724090973	3	1608802724156885	5
gradients/bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724090976	1608802724093210	3	1608802724156892	5
gradients/bert/encoder/layer_6/output/LayerNorm/moments/variance_grad/Tile	1608802724093222	1608802724095676	12	1608802724156899	28
gradients/bert/encoder/layer_6/output/LayerNorm/moments/variance_grad/truediv	1608802724095690	1608802724095734	14	1608802724156928	52
gradients/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724095739	1608802724095750	5	-1	-1
gradients/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724095754	1608802724095965	4	1608802724156982	54
gradients/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724095970	1608802724096243	5	1608802724157038	51
gradients/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724096248	1608802724096287	5	1608802724157091	73
gradients/AddN_40	1608802724096292	1608802724096334	5	1608802724157165	96
gradients/bert/encoder/layer_6/output/dropout/mul_1_grad/Mul	1608802724096339	1608802724096556	5	1608802724157263	51
gradients/bert/encoder/layer_6/output/dropout/mul_grad/Mul	1608802724096567	1608802724096755	11	1608802724157316	73
gradients/bert/encoder/layer_6/output/dense/BiasAdd_grad/BiasAddGrad	1608802724096760	1608802724096821	5	1608802724157393	55
gradients/bert/encoder/layer_6/output/dense/MatMul_grad/MatMul	1608802724096825	1608802724097065	4	1608802724157449	2222
gradients/bert/encoder/layer_6/output/dense/MatMul_grad/MatMul_1	1608802724097079	1608802724097528	14	1608802724159673	2469
global_norm/L2Loss_114	1608802724097538	1608802724100028	10	1608802724162143	5
gradients/bert/encoder/layer_6/intermediate/dense/mul_3_grad/Mul	1608802724100032	1608802724102503	4	1608802724162150	280
gradients/bert/encoder/layer_6/intermediate/dense/mul_2_grad/Mul_1	1608802724102508	1608802724102559	5	1608802724162432	281
global_norm/L2Loss_113	1608802724102564	1608802724102665	5	1608802724162715	33
gradients/bert/encoder/layer_6/intermediate/dense/Tanh_grad/TanhGrad	1608802724102676	1608802724102719	11	1608802724162750	275
gradients/bert/encoder/layer_6/intermediate/dense/mul_1_grad/Mul_1	1608802724102723	1608802724102772	4	1608802724163026	194
gradients/bert/encoder/layer_6/intermediate/dense/Pow_grad/mul_1	1608802724102777	1608802724102815	5	1608802724163222	281
gradients/AddN_41	1608802724102828	1608802724102875	13	1608802724163505	365
gradients/bert/encoder/layer_6/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724102883	1608802724102957	8	1608802724163878	108
gradients/bert/encoder/layer_6/intermediate/dense/MatMul_grad/MatMul	1608802724102963	1608802724103016	6	1608802724163988	2501
gradients/bert/encoder/layer_6/intermediate/dense/MatMul_grad/MatMul_1	1608802724103036	1608802724103092	20	1608802724166492	2467
global_norm/L2Loss_112	1608802724103102	1608802724103153	10	1608802724168962	9
gradients/AddN_42	1608802724103157	1608802724103200	4	1608802724168973	72
global_norm/L2Loss_111	1608802724103211	1608802724103304	11	1608802724169047	33
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724103308	1608802724103359	4	1608802724169081	69
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724103369	1608802724103416	10	1608802724169152	73
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724103425	1608802724103468	9	1608802724169226	51
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724103476	1608802724103534	8	1608802724169279	75
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724103540	1608802724103597	6	1608802724169356	69
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724103603	1608802724103643	6	1608802724169428	53
global_norm/L2Loss_109	1608802724103655	1608802724103695	12	1608802724169482	6
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724103699	1608802724103749	4	1608802724169490	32
gradients/AddN_43	1608802724103754	1608802724103800	5	1608802724169523	69
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724103813	1608802724103823	13	-1	-1
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724103827	1608802724103875	4	1608802724169594	55
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724103886	1608802724103927	11	1608802724169651	53
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724103938	1608802724103985	11	1608802724169706	28
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724103995	1608802724104050	10	1608802724169735	33
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724104056	1608802724104105	6	1608802724169770	65
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724104112	1608802724104155	7	1608802724169837	47
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724104159	1608802724104174	4	-1	-1
global_norm/L2Loss_110	1608802724104178	1608802724104218	4	1608802724169886	5
gradients/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724104222	1608802724104629	4	1608802724169893	5
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724104635	1608802724105260	6	1608802724169900	27
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724105271	1608802724105313	11	1608802724169929	52
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724105318	1608802724105334	5	-1	-1
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724105338	1608802724105380	4	1608802724169983	54
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724105391	1608802724105429	11	1608802724170038	51
gradients/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724105433	1608802724105476	4	1608802724170091	73
gradients/AddN_44	1608802724105482	1608802724105524	6	1608802724170166	95
gradients/bert/encoder/layer_6/attention/output/dropout/mul_1_grad/Mul	1608802724105537	1608802724105578	13	1608802724170263	51
gradients/bert/encoder/layer_6/attention/output/dropout/mul_grad/Mul	1608802724105586	1608802724105632	8	1608802724170316	73
gradients/bert/encoder/layer_6/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724105637	1608802724105699	5	1608802724170395	55
gradients/bert/encoder/layer_6/attention/output/dense/MatMul_grad/MatMul	1608802724105704	1608802724105754	5	1608802724170452	639
gradients/bert/encoder/layer_6/attention/output/dense/MatMul_grad/MatMul_1	1608802724105765	1608802724105847	11	1608802724171096	617
global_norm/L2Loss_108	1608802724105858	1608802724105907	11	1608802724171714	8
gradients/bert/encoder/layer_6/attention/self/Reshape_3_grad/Reshape	1608802724105911	1608802724105921	4	-1	-1
global_norm/L2Loss_107	1608802724105925	1608802724106023	4	1608802724171724	12
gradients/bert/encoder/layer_6/attention/self/transpose_3_grad/transpose	1608802724106027	1608802724106082	4	1608802724171738	189
gradients/bert/encoder/layer_6/attention/self/MatMul_1_grad/MatMul	1608802724106093	1608802724107165	11	1608802724171929	162
gradients/bert/encoder/layer_6/attention/self/MatMul_1_grad/MatMul_1	1608802724107180	1608802724107893	15	1608802724172094	242
gradients/bert/encoder/layer_6/attention/self/dropout/mul_1_grad/Mul	1608802724107909	1608802724107963	16	1608802724172338	99
gradients/bert/encoder/layer_6/attention/self/transpose_2_grad/transpose	1608802724107968	1608802724108016	5	1608802724172439	189
gradients/bert/encoder/layer_6/attention/self/dropout/mul_grad/Mul	1608802724108026	1608802724108099	10	1608802724172630	141
gradients/bert/encoder/layer_6/attention/self/Reshape_2_grad/Reshape	1608802724108104	1608802724108114	5	-1	-1
gradients/bert/encoder/layer_6/attention/self/Softmax_grad/mul	1608802724108121	1608802724108158	7	1608802724172773	142
gradients/bert/encoder/layer_6/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724108163	1608802724108218	5	1608802724172921	55
gradients/bert/encoder/layer_6/attention/self/value/MatMul_grad/MatMul	1608802724108223	1608802724108271	5	1608802724172977	640
gradients/bert/encoder/layer_6/attention/self/value/MatMul_grad/MatMul_1	1608802724108281	1608802724108378	10	1608802724173624	661
gradients/bert/encoder/layer_6/attention/self/Softmax_grad/Sum	1608802724108388	1608802724108443	10	1608802724174287	54
global_norm/L2Loss_106	1608802724108452	1608802724108495	9	1608802724174343	5
global_norm/L2Loss_105	1608802724108500	1608802724108588	5	1608802724174350	15
gradients/bert/encoder/layer_6/attention/self/Softmax_grad/sub	1608802724108593	1608802724108637	5	1608802724174367	99
gradients/bert/encoder/layer_6/attention/self/Mul_grad/Mul	1608802724108642	1608802724108778	5	1608802724174468	142
gradients/bert/encoder/layer_6/attention/self/MatMul_grad/MatMul	1608802724108783	1608802724110371	5	1608802724174612	244
gradients/bert/encoder/layer_6/attention/self/MatMul_grad/MatMul_1	1608802724110385	1608802724111688	14	1608802724174857	241
gradients/bert/encoder/layer_6/attention/self/transpose_grad/transpose	1608802724111700	1608802724111756	12	1608802724175100	189
gradients/bert/encoder/layer_6/attention/self/transpose_1_grad/transpose	1608802724111766	1608802724111810	10	1608802724175291	189
gradients/bert/encoder/layer_6/attention/self/Reshape_grad/Reshape	1608802724111818	1608802724111829	8	-1	-1
gradients/bert/encoder/layer_6/attention/self/Reshape_1_grad/Reshape	1608802724111833	1608802724111843	4	-1	-1
gradients/bert/encoder/layer_6/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724111847	1608802724111904	4	1608802724175487	55
gradients/bert/encoder/layer_6/attention/self/query/MatMul_grad/MatMul	1608802724111909	1608802724111956	5	1608802724175544	644
gradients/bert/encoder/layer_6/attention/self/query/MatMul_grad/MatMul_1	1608802724111966	1608802724112036	10	1608802724176193	610
gradients/bert/encoder/layer_6/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724112045	1608802724112101	9	1608802724176810	54
gradients/bert/encoder/layer_6/attention/self/key/MatMul_grad/MatMul	1608802724112105	1608802724112149	4	1608802724176866	640
gradients/bert/encoder/layer_6/attention/self/key/MatMul_grad/MatMul_1	1608802724112157	1608802724112224	8	1608802724177515	615
global_norm/L2Loss_102	1608802724112234	1608802724112277	10	1608802724178132	5
global_norm/L2Loss_101	1608802724112284	1608802724112385	7	1608802724178139	18
global_norm/L2Loss_104	1608802724112389	1608802724112426	4	1608802724178159	5
gradients/AddN_45	1608802724112430	1608802724112471	4	1608802724178166	119
global_norm/L2Loss_103	1608802724112476	1608802724112557	5	1608802724178286	16
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724112571	1608802724112615	14	1608802724178304	72
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724112628	1608802724112676	13	1608802724178378	73
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724112684	1608802724112724	8	1608802724178452	51
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724112739	1608802724112798	15	1608802724178505	73
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724112804	1608802724112849	6	1608802724178580	69
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724112854	1608802724112897	5	1608802724178651	52
global_norm/L2Loss_99	1608802724112904	1608802724112942	7	1608802724178705	5
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724112946	1608802724112995	4	1608802724178712	31
gradients/AddN_46	1608802724113000	1608802724113039	5	1608802724178745	69
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724113050	1608802724113059	11	-1	-1
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724113063	1608802724113111	4	1608802724178815	56
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724113121	1608802724113161	10	1608802724178874	53
gradients/bert/encoder/layer_5/output/LayerNorm/moments/mean_grad/Tile	1608802724113165	1608802724113217	4	1608802724178928	27
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724113234	1608802724113281	17	1608802724178957	33
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724113285	1608802724113333	4	1608802724178992	66
gradients/bert/encoder/layer_5/output/LayerNorm/moments/mean_grad/truediv	1608802724113338	1608802724113378	5	1608802724179059	47
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724113388	1608802724113397	10	-1	-1
global_norm/L2Loss_100	1608802724113400	1608802724113437	3	1608802724179108	5
gradients/bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724113448	1608802724115360	11	1608802724179115	5
gradients/bert/encoder/layer_5/output/LayerNorm/moments/variance_grad/Tile	1608802724115364	1608802724117833	4	1608802724179122	28
gradients/bert/encoder/layer_5/output/LayerNorm/moments/variance_grad/truediv	1608802724117851	1608802724117896	18	1608802724179152	52
gradients/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724117905	1608802724117916	9	-1	-1
gradients/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724117925	1608802724118120	9	1608802724179205	54
gradients/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724118125	1608802724118399	5	1608802724179261	51
gradients/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724118404	1608802724118465	5	1608802724179313	73
gradients/AddN_47	1608802724118469	1608802724118511	4	1608802724179388	95
gradients/bert/encoder/layer_5/output/dropout/mul_1_grad/Mul	1608802724118518	1608802724118719	7	1608802724179485	51
gradients/bert/encoder/layer_5/output/dropout/mul_grad/Mul	1608802724118730	1608802724118924	11	1608802724179538	73
gradients/bert/encoder/layer_5/output/dense/BiasAdd_grad/BiasAddGrad	1608802724118931	1608802724118989	7	1608802724179617	55
gradients/bert/encoder/layer_5/output/dense/MatMul_grad/MatMul	1608802724118993	1608802724119218	4	1608802724179674	2222
gradients/bert/encoder/layer_5/output/dense/MatMul_grad/MatMul_1	1608802724119228	1608802724119692	10	1608802724181898	2471
global_norm/L2Loss_98	1608802724119701	1608802724122185	9	1608802724184371	5
gradients/bert/encoder/layer_5/intermediate/dense/mul_3_grad/Mul	1608802724122192	1608802724124655	7	1608802724184378	279
gradients/bert/encoder/layer_5/intermediate/dense/mul_2_grad/Mul_1	1608802724124659	1608802724124705	4	1608802724184659	280
global_norm/L2Loss_97	1608802724124710	1608802724124798	5	1608802724184940	33
gradients/bert/encoder/layer_5/intermediate/dense/Tanh_grad/TanhGrad	1608802724124810	1608802724124848	12	1608802724184974	275
gradients/bert/encoder/layer_5/intermediate/dense/mul_1_grad/Mul_1	1608802724124852	1608802724124896	4	1608802724185251	197
gradients/bert/encoder/layer_5/intermediate/dense/Pow_grad/mul_1	1608802724124900	1608802724124940	4	1608802724185450	280
gradients/AddN_48	1608802724124944	1608802724124985	4	1608802724185731	367
gradients/bert/encoder/layer_5/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724124990	1608802724125053	5	1608802724186106	109
gradients/bert/encoder/layer_5/intermediate/dense/MatMul_grad/MatMul	1608802724125057	1608802724125111	4	1608802724186217	2502
gradients/bert/encoder/layer_5/intermediate/dense/MatMul_grad/MatMul_1	1608802724125124	1608802724125174	13	1608802724188720	2470
global_norm/L2Loss_96	1608802724125182	1608802724125228	8	1608802724191192	9
gradients/AddN_49	1608802724125232	1608802724125268	4	1608802724191202	73
global_norm/L2Loss_95	1608802724125279	1608802724125361	11	1608802724191277	33
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724125365	1608802724125418	4	1608802724191311	68
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724125427	1608802724125471	9	1608802724191381	73
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724125479	1608802724125519	8	1608802724191456	52
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724125532	1608802724125578	13	1608802724191509	73
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724125583	1608802724125625	5	1608802724191585	70
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724125632	1608802724125669	7	1608802724191656	52
global_norm/L2Loss_93	1608802724125679	1608802724125714	10	1608802724191710	5
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724125718	1608802724125766	4	1608802724191717	32
gradients/AddN_50	1608802724125771	1608802724125809	5	1608802724191751	69
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724125819	1608802724125828	10	-1	-1
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724125831	1608802724125874	3	1608802724191822	55
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724125884	1608802724125922	10	1608802724191878	53
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724125931	1608802724125973	9	1608802724191932	27
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724125982	1608802724126033	9	1608802724191962	33
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724126038	1608802724126084	5	1608802724191996	66
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724126089	1608802724126127	5	1608802724192063	47
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724126133	1608802724126145	6	-1	-1
global_norm/L2Loss_94	1608802724126149	1608802724126184	4	1608802724192112	5
gradients/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724126188	1608802724126773	4	1608802724192119	5
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724126780	1608802724127410	7	1608802724192126	28
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724127420	1608802724127462	10	1608802724192155	52
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724127466	1608802724127483	4	-1	-1
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724127486	1608802724127526	3	1608802724192208	53
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724127537	1608802724127574	11	1608802724192263	52
gradients/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724127578	1608802724127620	4	1608802724192317	73
gradients/AddN_51	1608802724127625	1608802724127663	5	1608802724192392	96
gradients/bert/encoder/layer_5/attention/output/dropout/mul_1_grad/Mul	1608802724127685	1608802724127726	22	1608802724192490	52
gradients/bert/encoder/layer_5/attention/output/dropout/mul_grad/Mul	1608802724127735	1608802724127782	9	1608802724192543	73
gradients/bert/encoder/layer_5/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724127787	1608802724127846	5	1608802724192622	55
gradients/bert/encoder/layer_5/attention/output/dense/MatMul_grad/MatMul	1608802724127850	1608802724127898	4	1608802724192679	639
gradients/bert/encoder/layer_5/attention/output/dense/MatMul_grad/MatMul_1	1608802724127908	1608802724127987	10	1608802724193322	613
global_norm/L2Loss_92	1608802724127996	1608802724128047	9	1608802724193937	5
gradients/bert/encoder/layer_5/attention/self/Reshape_3_grad/Reshape	1608802724128050	1608802724128060	3	-1	-1
global_norm/L2Loss_91	1608802724128064	1608802724128154	4	1608802724193944	15
gradients/bert/encoder/layer_5/attention/self/transpose_3_grad/transpose	1608802724128158	1608802724128211	4	1608802724193961	190
gradients/bert/encoder/layer_5/attention/self/MatMul_1_grad/MatMul	1608802724128221	1608802724129302	10	1608802724194152	162
gradients/bert/encoder/layer_5/attention/self/MatMul_1_grad/MatMul_1	1608802724129315	1608802724130033	13	1608802724194315	243
gradients/bert/encoder/layer_5/attention/self/dropout/mul_1_grad/Mul	1608802724130045	1608802724130092	12	1608802724194560	99
gradients/bert/encoder/layer_5/attention/self/transpose_2_grad/transpose	1608802724130097	1608802724130142	5	1608802724194661	189
gradients/bert/encoder/layer_5/attention/self/dropout/mul_grad/Mul	1608802724130154	1608802724130241	12	1608802724194852	141
gradients/bert/encoder/layer_5/attention/self/Reshape_2_grad/Reshape	1608802724130246	1608802724130255	5	-1	-1
gradients/bert/encoder/layer_5/attention/self/Softmax_grad/mul	1608802724130259	1608802724130292	4	1608802724194995	141
gradients/bert/encoder/layer_5/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724130296	1608802724130349	4	1608802724195141	55
gradients/bert/encoder/layer_5/attention/self/value/MatMul_grad/MatMul	1608802724130354	1608802724130398	5	1608802724195198	639
gradients/bert/encoder/layer_5/attention/self/value/MatMul_grad/MatMul_1	1608802724130408	1608802724130472	10	1608802724195846	618
gradients/bert/encoder/layer_5/attention/self/Softmax_grad/Sum	1608802724130481	1608802724130530	9	1608802724196465	54
global_norm/L2Loss_90	1608802724130541	1608802724130582	11	1608802724196521	5
global_norm/L2Loss_89	1608802724130586	1608802724130673	4	1608802724196528	15
gradients/bert/encoder/layer_5/attention/self/Softmax_grad/sub	1608802724130679	1608802724130729	6	1608802724196545	100
gradients/bert/encoder/layer_5/attention/self/Mul_grad/Mul	1608802724130734	1608802724130921	5	1608802724196646	142
gradients/bert/encoder/layer_5/attention/self/MatMul_grad/MatMul	1608802724130925	1608802724132508	4	1608802724196790	245
gradients/bert/encoder/layer_5/attention/self/MatMul_grad/MatMul_1	1608802724132521	1608802724133868	13	1608802724197037	242
gradients/bert/encoder/layer_5/attention/self/transpose_grad/transpose	1608802724133879	1608802724133931	11	1608802724197281	189
gradients/bert/encoder/layer_5/attention/self/transpose_1_grad/transpose	1608802724133941	1608802724133981	10	1608802724197472	192
gradients/bert/encoder/layer_5/attention/self/Reshape_grad/Reshape	1608802724133989	1608802724133999	8	-1	-1
gradients/bert/encoder/layer_5/attention/self/Reshape_1_grad/Reshape	1608802724134004	1608802724134010	5	-1	-1
gradients/bert/encoder/layer_5/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724134013	1608802724134067	3	1608802724197670	55
gradients/bert/encoder/layer_5/attention/self/query/MatMul_grad/MatMul	1608802724134071	1608802724134116	4	1608802724197727	639
gradients/bert/encoder/layer_5/attention/self/query/MatMul_grad/MatMul_1	1608802724134124	1608802724134189	8	1608802724198372	612
gradients/bert/encoder/layer_5/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724134198	1608802724134284	9	1608802724198991	56
gradients/bert/encoder/layer_5/attention/self/key/MatMul_grad/MatMul	1608802724134288	1608802724134331	4	1608802724199049	641
gradients/bert/encoder/layer_5/attention/self/key/MatMul_grad/MatMul_1	1608802724134340	1608802724134404	9	1608802724199696	615
global_norm/L2Loss_86	1608802724134413	1608802724134456	9	1608802724200313	5
global_norm/L2Loss_85	1608802724134461	1608802724134542	5	1608802724200319	16
global_norm/L2Loss_88	1608802724134546	1608802724134579	4	1608802724200337	5
gradients/AddN_52	1608802724134582	1608802724134620	3	1608802724200344	119
global_norm/L2Loss_87	1608802724134628	1608802724134704	8	1608802724200464	17
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724134715	1608802724134757	11	1608802724200482	71
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724134767	1608802724134811	10	1608802724200555	72
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724134819	1608802724134855	8	1608802724200629	51
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724134869	1608802724134916	14	1608802724200682	74
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724134921	1608802724134964	5	1608802724200758	69
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724134969	1608802724135008	5	1608802724200828	53
global_norm/L2Loss_83	1608802724135016	1608802724135051	8	1608802724200883	6
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724135054	1608802724135100	3	1608802724200890	32
gradients/AddN_53	1608802724135105	1608802724135144	5	1608802724200924	69
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724135155	1608802724135164	11	-1	-1
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724135168	1608802724135212	4	1608802724200994	54
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724135223	1608802724135261	11	1608802724201050	53
gradients/bert/encoder/layer_4/output/LayerNorm/moments/mean_grad/Tile	1608802724135265	1608802724135310	4	1608802724201105	27
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724135325	1608802724135368	15	1608802724201134	33
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724135373	1608802724135417	5	1608802724201168	65
gradients/bert/encoder/layer_4/output/LayerNorm/moments/mean_grad/truediv	1608802724135422	1608802724135459	5	1608802724201235	47
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724135468	1608802724135477	9	-1	-1
global_norm/L2Loss_84	1608802724135482	1608802724135519	5	1608802724201284	5
gradients/bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724135524	1608802724137559	5	1608802724201291	5
gradients/bert/encoder/layer_4/output/LayerNorm/moments/variance_grad/Tile	1608802724137565	1608802724140019	6	1608802724201297	27
gradients/bert/encoder/layer_4/output/LayerNorm/moments/variance_grad/truediv	1608802724140030	1608802724140077	11	1608802724201326	52
gradients/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724140082	1608802724140091	5	-1	-1
gradients/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724140102	1608802724140309	11	1608802724201379	53
gradients/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724140314	1608802724140589	5	1608802724201434	51
gradients/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724140596	1608802724140644	7	1608802724201486	72
gradients/AddN_54	1608802724140666	1608802724140706	22	1608802724201561	95
gradients/bert/encoder/layer_4/output/dropout/mul_1_grad/Mul	1608802724140713	1608802724140899	7	1608802724201657	51
gradients/bert/encoder/layer_4/output/dropout/mul_grad/Mul	1608802724140909	1608802724141104	10	1608802724201710	73
gradients/bert/encoder/layer_4/output/dense/BiasAdd_grad/BiasAddGrad	1608802724141110	1608802724141166	6	1608802724201789	55
gradients/bert/encoder/layer_4/output/dense/MatMul_grad/MatMul	1608802724141170	1608802724141399	4	1608802724201846	2223
gradients/bert/encoder/layer_4/output/dense/MatMul_grad/MatMul_1	1608802724141410	1608802724141867	11	1608802724204071	2468
global_norm/L2Loss_82	1608802724141879	1608802724144373	12	1608802724206540	5
gradients/bert/encoder/layer_4/intermediate/dense/mul_3_grad/Mul	1608802724144379	1608802724146835	6	1608802724206547	279
gradients/bert/encoder/layer_4/intermediate/dense/mul_2_grad/Mul_1	1608802724146839	1608802724146879	4	1608802724206828	282
global_norm/L2Loss_81	1608802724146883	1608802724146967	4	1608802724207112	33
gradients/bert/encoder/layer_4/intermediate/dense/Tanh_grad/TanhGrad	1608802724146976	1608802724147013	9	1608802724207147	275
gradients/bert/encoder/layer_4/intermediate/dense/mul_1_grad/Mul_1	1608802724147020	1608802724147061	7	1608802724207424	194
gradients/bert/encoder/layer_4/intermediate/dense/Pow_grad/mul_1	1608802724147067	1608802724147104	6	1608802724207620	280
gradients/AddN_55	1608802724147108	1608802724147155	4	1608802724207902	366
gradients/bert/encoder/layer_4/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724147160	1608802724147222	5	1608802724208271	109
gradients/bert/encoder/layer_4/intermediate/dense/MatMul_grad/MatMul	1608802724147228	1608802724147279	6	1608802724208382	2501
gradients/bert/encoder/layer_4/intermediate/dense/MatMul_grad/MatMul_1	1608802724147291	1608802724147339	12	1608802724210885	2470
global_norm/L2Loss_80	1608802724147347	1608802724147393	8	1608802724213357	11
gradients/AddN_56	1608802724147397	1608802724147434	4	1608802724213369	72
global_norm/L2Loss_79	1608802724147446	1608802724147524	12	1608802724213444	33
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724147527	1608802724147584	3	1608802724213478	69
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724147593	1608802724147635	9	1608802724213548	73
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724147643	1608802724147681	8	1608802724213624	52
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724147696	1608802724147744	15	1608802724213677	74
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724147749	1608802724147790	5	1608802724213753	68
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724147795	1608802724147830	5	1608802724213823	53
global_norm/L2Loss_77	1608802724147840	1608802724147875	10	1608802724213878	5
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724147878	1608802724147925	3	1608802724213885	32
gradients/AddN_57	1608802724147930	1608802724147966	5	1608802724213918	69
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724147976	1608802724147984	10	-1	-1
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724147988	1608802724148030	4	1608802724213989	55
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724148039	1608802724148079	9	1608802724214046	53
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724148084	1608802724148123	5	1608802724214101	27
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724148132	1608802724148179	9	1608802724214130	33
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724148183	1608802724148227	4	1608802724214165	66
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724148231	1608802724148267	4	1608802724214232	47
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724148278	1608802724148286	11	-1	-1
global_norm/L2Loss_78	1608802724148290	1608802724148323	4	1608802724214281	5
gradients/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724148327	1608802724148970	4	1608802724214288	5
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724148975	1608802724149602	5	1608802724214295	27
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724149612	1608802724149650	10	1608802724214324	52
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724149655	1608802724149669	5	-1	-1
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724149673	1608802724149711	4	1608802724214377	53
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724149720	1608802724149755	9	1608802724214432	52
gradients/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724149759	1608802724149807	4	1608802724214486	73
gradients/AddN_58	1608802724149812	1608802724149853	5	1608802724214561	96
gradients/bert/encoder/layer_4/attention/output/dropout/mul_1_grad/Mul	1608802724149864	1608802724149902	11	1608802724214658	51
gradients/bert/encoder/layer_4/attention/output/dropout/mul_grad/Mul	1608802724149910	1608802724149954	8	1608802724214711	73
gradients/bert/encoder/layer_4/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724149961	1608802724150021	7	1608802724214790	55
gradients/bert/encoder/layer_4/attention/output/dense/MatMul_grad/MatMul	1608802724150026	1608802724150072	5	1608802724214846	641
gradients/bert/encoder/layer_4/attention/output/dense/MatMul_grad/MatMul_1	1608802724150082	1608802724150157	10	1608802724215496	613
global_norm/L2Loss_76	1608802724150166	1608802724150212	9	1608802724216113	7
gradients/bert/encoder/layer_4/attention/self/Reshape_3_grad/Reshape	1608802724150216	1608802724150225	4	-1	-1
global_norm/L2Loss_75	1608802724150228	1608802724150314	3	1608802724216122	13
gradients/bert/encoder/layer_4/attention/self/transpose_3_grad/transpose	1608802724150319	1608802724150366	5	1608802724216136	189
gradients/bert/encoder/layer_4/attention/self/MatMul_1_grad/MatMul	1608802724150377	1608802724151492	11	1608802724216327	161
gradients/bert/encoder/layer_4/attention/self/MatMul_1_grad/MatMul_1	1608802724151505	1608802724152222	13	1608802724216490	230
gradients/bert/encoder/layer_4/attention/self/dropout/mul_1_grad/Mul	1608802724152233	1608802724152279	11	1608802724216722	99
gradients/bert/encoder/layer_4/attention/self/transpose_2_grad/transpose	1608802724152284	1608802724152330	5	1608802724216824	189
gradients/bert/encoder/layer_4/attention/self/dropout/mul_grad/Mul	1608802724152339	1608802724152436	9	1608802724217014	142
gradients/bert/encoder/layer_4/attention/self/Reshape_2_grad/Reshape	1608802724152441	1608802724152451	5	-1	-1
gradients/bert/encoder/layer_4/attention/self/Softmax_grad/mul	1608802724152466	1608802724152511	15	1608802724217158	141
gradients/bert/encoder/layer_4/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724152516	1608802724152564	5	1608802724217305	55
gradients/bert/encoder/layer_4/attention/self/value/MatMul_grad/MatMul	1608802724152568	1608802724152614	4	1608802724217361	641
gradients/bert/encoder/layer_4/attention/self/value/MatMul_grad/MatMul_1	1608802724152623	1608802724152687	9	1608802724218009	615
gradients/bert/encoder/layer_4/attention/self/Softmax_grad/Sum	1608802724152696	1608802724152741	9	1608802724218626	54
global_norm/L2Loss_74	1608802724152750	1608802724152783	9	1608802724218682	8
global_norm/L2Loss_73	1608802724152788	1608802724152861	5	1608802724218691	17
gradients/bert/encoder/layer_4/attention/self/Softmax_grad/sub	1608802724152865	1608802724152909	4	1608802724218710	101
gradients/bert/encoder/layer_4/attention/self/Mul_grad/Mul	1608802724152914	1608802724153100	5	1608802724218813	141
gradients/bert/encoder/layer_4/attention/self/MatMul_grad/MatMul	1608802724153108	1608802724154683	8	1608802724218959	234
gradients/bert/encoder/layer_4/attention/self/MatMul_grad/MatMul_1	1608802724154694	1608802724155990	11	1608802724219194	229
gradients/bert/encoder/layer_4/attention/self/transpose_grad/transpose	1608802724156000	1608802724156048	10	1608802724219425	189
gradients/bert/encoder/layer_4/attention/self/transpose_1_grad/transpose	1608802724156057	1608802724156096	9	1608802724219617	192
gradients/bert/encoder/layer_4/attention/self/Reshape_grad/Reshape	1608802724156104	1608802724156113	8	-1	-1
gradients/bert/encoder/layer_4/attention/self/Reshape_1_grad/Reshape	1608802724156117	1608802724156122	4	-1	-1
gradients/bert/encoder/layer_4/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724156126	1608802724156175	4	1608802724219814	55
gradients/bert/encoder/layer_4/attention/self/query/MatMul_grad/MatMul	1608802724156179	1608802724156221	4	1608802724219871	642
gradients/bert/encoder/layer_4/attention/self/query/MatMul_grad/MatMul_1	1608802724156230	1608802724156291	9	1608802724220520	612
gradients/bert/encoder/layer_4/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724156300	1608802724156351	9	1608802724221137	56
gradients/bert/encoder/layer_4/attention/self/key/MatMul_grad/MatMul	1608802724156355	1608802724156407	4	1608802724221195	638
gradients/bert/encoder/layer_4/attention/self/key/MatMul_grad/MatMul_1	1608802724156416	1608802724156475	9	1608802724221841	615
global_norm/L2Loss_70	1608802724156484	1608802724156522	9	1608802724222460	5
global_norm/L2Loss_69	1608802724156527	1608802724156602	5	1608802724222467	15
global_norm/L2Loss_72	1608802724156605	1608802724156636	3	1608802724222484	5
gradients/AddN_59	1608802724156639	1608802724156675	3	1608802724222491	119
global_norm/L2Loss_71	1608802724156683	1608802724156752	8	1608802724222611	17
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724156764	1608802724156803	12	1608802724222630	72
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724156812	1608802724156853	9	1608802724222703	73
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724156860	1608802724156893	7	1608802724222777	51
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724156907	1608802724156951	14	1608802724222830	74
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724156957	1608802724156998	6	1608802724222906	68
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724157003	1608802724157037	5	1608802724222976	52
global_norm/L2Loss_67	1608802724157046	1608802724157081	9	1608802724223030	5
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724157084	1608802724157127	3	1608802724223037	32
gradients/AddN_60	1608802724157131	1608802724157164	4	1608802724223070	69
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724157176	1608802724157184	12	-1	-1
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724157190	1608802724157230	6	1608802724223141	54
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724157239	1608802724157275	9	1608802724223197	52
gradients/bert/encoder/layer_3/output/LayerNorm/moments/mean_grad/Tile	1608802724157279	1608802724157322	4	1608802724223251	27
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724157336	1608802724157377	14	1608802724223280	33
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724157381	1608802724157426	4	1608802724223315	65
gradients/bert/encoder/layer_3/output/LayerNorm/moments/mean_grad/truediv	1608802724157431	1608802724157466	5	1608802724223382	47
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724157471	1608802724157484	5	-1	-1
global_norm/L2Loss_68	1608802724157488	1608802724157519	4	1608802724223431	5
gradients/bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724157522	1608802724159688	3	1608802724223438	6
gradients/bert/encoder/layer_3/output/LayerNorm/moments/variance_grad/Tile	1608802724159693	1608802724162152	5	1608802724223445	27
gradients/bert/encoder/layer_3/output/LayerNorm/moments/variance_grad/truediv	1608802724162161	1608802724162217	9	1608802724223473	52
gradients/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724162222	1608802724162230	5	-1	-1
gradients/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724162239	1608802724162441	9	1608802724223527	54
gradients/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724162445	1608802724162720	4	1608802724223582	51
gradients/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724162725	1608802724162763	5	1608802724223635	73
gradients/AddN_61	1608802724162771	1608802724162805	8	1608802724223709	96
gradients/bert/encoder/layer_3/output/dropout/mul_1_grad/Mul	1608802724162809	1608802724163033	4	1608802724223806	52
gradients/bert/encoder/layer_3/output/dropout/mul_grad/Mul	1608802724163041	1608802724163235	8	1608802724223860	73
gradients/bert/encoder/layer_3/output/dense/BiasAdd_grad/BiasAddGrad	1608802724163240	1608802724163290	5	1608802724223937	55
gradients/bert/encoder/layer_3/output/dense/MatMul_grad/MatMul	1608802724163294	1608802724163529	4	1608802724223993	2221
gradients/bert/encoder/layer_3/output/dense/MatMul_grad/MatMul_1	1608802724163538	1608802724164004	9	1608802724226216	2468
global_norm/L2Loss_66	1608802724164013	1608802724166497	9	1608802724228686	6
gradients/bert/encoder/layer_3/intermediate/dense/mul_3_grad/Mul	1608802724166500	1608802724168970	3	1608802724228693	278
gradients/bert/encoder/layer_3/intermediate/dense/mul_2_grad/Mul_1	1608802724168974	1608802724169014	4	1608802724228973	282
global_norm/L2Loss_65	1608802724169021	1608802724169093	7	1608802724229259	33
gradients/bert/encoder/layer_3/intermediate/dense/Tanh_grad/TanhGrad	1608802724169102	1608802724169136	9	1608802724229294	276
gradients/bert/encoder/layer_3/intermediate/dense/mul_1_grad/Mul_1	1608802724169140	1608802724169178	4	1608802724229571	195
gradients/bert/encoder/layer_3/intermediate/dense/Pow_grad/mul_1	1608802724169182	1608802724169235	4	1608802724229768	280
gradients/AddN_62	1608802724169240	1608802724169288	5	1608802724230049	366
gradients/bert/encoder/layer_3/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724169293	1608802724169349	5	1608802724230426	108
gradients/bert/encoder/layer_3/intermediate/dense/MatMul_grad/MatMul	1608802724169353	1608802724169399	4	1608802724230537	2502
gradients/bert/encoder/layer_3/intermediate/dense/MatMul_grad/MatMul_1	1608802724169408	1608802724169454	9	1608802724233040	2470
global_norm/L2Loss_64	1608802724169462	1608802724169505	8	1608802724235512	9
gradients/AddN_63	1608802724169511	1608802724169544	6	1608802724235522	72
global_norm/L2Loss_63	1608802724169555	1608802724169630	11	1608802724235596	33
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724169634	1608802724169676	4	1608802724235631	69
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724169683	1608802724169731	7	1608802724235702	72
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724169738	1608802724169773	7	1608802724235776	52
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724169784	1608802724169829	11	1608802724235829	74
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724169833	1608802724169870	4	1608802724235905	69
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724169875	1608802724169907	5	1608802724235976	53
global_norm/L2Loss_61	1608802724169915	1608802724169946	8	1608802724236030	5
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724169950	1608802724169990	4	1608802724236037	32
gradients/AddN_64	1608802724169996	1608802724170028	6	1608802724236071	69
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724170038	1608802724170045	10	-1	-1
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724170049	1608802724170085	4	1608802724236142	55
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724170093	1608802724170124	8	1608802724236198	53
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724170133	1608802724170169	9	1608802724236253	27
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724170177	1608802724170221	8	1608802724236282	33
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724170224	1608802724170292	3	1608802724236316	66
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724170297	1608802724170335	5	1608802724236384	47
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724170344	1608802724170351	9	-1	-1
global_norm/L2Loss_62	1608802724170356	1608802724170455	5	1608802724236432	5
gradients/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724170459	1608802724171104	4	1608802724236439	5
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724171110	1608802724171740	6	1608802724236446	27
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724171751	1608802724171786	11	1608802724236475	52
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724171790	1608802724171802	4	-1	-1
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724171805	1608802724171849	3	1608802724236528	53
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724171858	1608802724171889	9	1608802724236583	52
gradients/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724171894	1608802724171942	5	1608802724236637	73
gradients/AddN_65	1608802724171946	1608802724171978	4	1608802724236712	95
gradients/bert/encoder/layer_3/attention/output/dropout/mul_1_grad/Mul	1608802724171989	1608802724172023	11	1608802724236808	51
gradients/bert/encoder/layer_3/attention/output/dropout/mul_grad/Mul	1608802724172031	1608802724172068	8	1608802724236861	72
gradients/bert/encoder/layer_3/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724172073	1608802724172124	5	1608802724236939	55
gradients/bert/encoder/layer_3/attention/output/dense/MatMul_grad/MatMul	1608802724172128	1608802724172169	4	1608802724236996	639
gradients/bert/encoder/layer_3/attention/output/dense/MatMul_grad/MatMul_1	1608802724172178	1608802724172246	9	1608802724237644	660
global_norm/L2Loss_60	1608802724172254	1608802724172294	8	1608802724238308	5
gradients/bert/encoder/layer_3/attention/self/Reshape_3_grad/Reshape	1608802724172298	1608802724172306	4	-1	-1
global_norm/L2Loss_59	1608802724172309	1608802724172398	3	1608802724238315	12
gradients/bert/encoder/layer_3/attention/self/transpose_3_grad/transpose	1608802724172401	1608802724172467	3	1608802724238329	189
gradients/bert/encoder/layer_3/attention/self/MatMul_1_grad/MatMul	1608802724172477	1608802724173640	10	1608802724238520	160
gradients/bert/encoder/layer_3/attention/self/MatMul_1_grad/MatMul_1	1608802724173653	1608802724174408	13	1608802724238682	229
gradients/bert/encoder/layer_3/attention/self/dropout/mul_1_grad/Mul	1608802724174420	1608802724174462	12	1608802724238913	99
gradients/bert/encoder/layer_3/attention/self/transpose_2_grad/transpose	1608802724174466	1608802724174504	4	1608802724239014	189
gradients/bert/encoder/layer_3/attention/self/dropout/mul_grad/Mul	1608802724174515	1608802724174626	11	1608802724239205	141
gradients/bert/encoder/layer_3/attention/self/Reshape_2_grad/Reshape	1608802724174630	1608802724174638	4	-1	-1
gradients/bert/encoder/layer_3/attention/self/Softmax_grad/mul	1608802724174642	1608802724174670	4	1608802724239347	141
gradients/bert/encoder/layer_3/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724174674	1608802724174719	4	1608802724239494	55
gradients/bert/encoder/layer_3/attention/self/value/MatMul_grad/MatMul	1608802724174724	1608802724174762	5	1608802724239551	642
gradients/bert/encoder/layer_3/attention/self/value/MatMul_grad/MatMul_1	1608802724174769	1608802724174826	7	1608802724240199	617
gradients/bert/encoder/layer_3/attention/self/Softmax_grad/Sum	1608802724174834	1608802724174881	8	1608802724240817	54
global_norm/L2Loss_58	1608802724174891	1608802724174924	10	1608802724240873	5
global_norm/L2Loss_57	1608802724174927	1608802724174996	3	1608802724240879	16
gradients/bert/encoder/layer_3/attention/self/Softmax_grad/sub	1608802724175000	1608802724175122	4	1608802724240896	99
gradients/bert/encoder/layer_3/attention/self/Mul_grad/Mul	1608802724175127	1608802724175313	5	1608802724240997	142
gradients/bert/encoder/layer_3/attention/self/MatMul_grad/MatMul	1608802724175318	1608802724176901	5	1608802724241141	243
gradients/bert/encoder/layer_3/attention/self/MatMul_grad/MatMul_1	1608802724176911	1608802724178206	10	1608802724241386	242
gradients/bert/encoder/layer_3/attention/self/transpose_grad/transpose	1608802724178219	1608802724178263	13	1608802724241630	189
gradients/bert/encoder/layer_3/attention/self/transpose_1_grad/transpose	1608802724178270	1608802724178305	7	1608802724241821	189
gradients/bert/encoder/layer_3/attention/self/Reshape_grad/Reshape	1608802724178311	1608802724178320	6	-1	-1
gradients/bert/encoder/layer_3/attention/self/Reshape_1_grad/Reshape	1608802724178325	1608802724178330	5	-1	-1
gradients/bert/encoder/layer_3/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724178333	1608802724178378	3	1608802724242016	55
gradients/bert/encoder/layer_3/attention/self/query/MatMul_grad/MatMul	1608802724178382	1608802724178419	4	1608802724242073	642
gradients/bert/encoder/layer_3/attention/self/query/MatMul_grad/MatMul_1	1608802724178428	1608802724178484	9	1608802724242720	611
gradients/bert/encoder/layer_3/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724178491	1608802724178535	7	1608802724243336	54
gradients/bert/encoder/layer_3/attention/self/key/MatMul_grad/MatMul	1608802724178539	1608802724178574	4	1608802724243392	638
gradients/bert/encoder/layer_3/attention/self/key/MatMul_grad/MatMul_1	1608802724178581	1608802724178638	7	1608802724244038	617
global_norm/L2Loss_54	1608802724178647	1608802724178682	9	1608802724244657	5
global_norm/L2Loss_53	1608802724178686	1608802724178752	4	1608802724244664	16
global_norm/L2Loss_56	1608802724178758	1608802724178785	6	1608802724244682	5
gradients/AddN_66	1608802724178788	1608802724178820	3	1608802724244688	118
global_norm/L2Loss_55	1608802724178828	1608802724178888	8	1608802724244808	17
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724178901	1608802724178936	13	1608802724244827	72
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724178944	1608802724178981	8	1608802724244901	74
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724178988	1608802724179020	7	1608802724244977	51
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724179031	1608802724179071	11	1608802724245030	74
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724179075	1608802724179113	4	1608802724245106	69
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724179118	1608802724179153	5	1608802724245177	53
global_norm/L2Loss_51	1608802724179158	1608802724179187	5	1608802724245231	5
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724179191	1608802724179228	4	1608802724245238	32
gradients/AddN_67	1608802724179233	1608802724179264	5	1608802724245271	69
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724179274	1608802724179282	10	-1	-1
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724179286	1608802724179323	4	1608802724245342	54
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724179332	1608802724179364	9	1608802724245397	53
gradients/bert/encoder/layer_2/output/LayerNorm/moments/mean_grad/Tile	1608802724179368	1608802724179408	4	1608802724245452	28
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724179422	1608802724179459	14	1608802724245481	33
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724179462	1608802724179512	3	1608802724245515	66
gradients/bert/encoder/layer_2/output/LayerNorm/moments/mean_grad/truediv	1608802724179515	1608802724179557	3	1608802724245583	47
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724179565	1608802724179572	8	-1	-1
global_norm/L2Loss_52	1608802724179576	1608802724179678	4	1608802724245631	5
gradients/bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724179685	1608802724181906	7	1608802724245638	7
gradients/bert/encoder/layer_2/output/LayerNorm/moments/variance_grad/Tile	1608802724181910	1608802724184379	4	1608802724245646	27
gradients/bert/encoder/layer_2/output/LayerNorm/moments/variance_grad/truediv	1608802724184393	1608802724184430	14	1608802724245675	52
gradients/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724184434	1608802724184441	4	-1	-1
gradients/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724184449	1608802724184665	8	1608802724245729	53
gradients/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724184669	1608802724184944	4	1608802724245784	51
gradients/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724184947	1608802724184985	3	1608802724245837	73
gradients/AddN_68	1608802724184989	1608802724185021	4	1608802724245911	96
gradients/bert/encoder/layer_2/output/dropout/mul_1_grad/Mul	1608802724185025	1608802724185256	4	1608802724246008	51
gradients/bert/encoder/layer_2/output/dropout/mul_grad/Mul	1608802724185264	1608802724185460	8	1608802724246061	73
gradients/bert/encoder/layer_2/output/dense/BiasAdd_grad/BiasAddGrad	1608802724185467	1608802724185514	7	1608802724246137	55
gradients/bert/encoder/layer_2/output/dense/MatMul_grad/MatMul	1608802724185519	1608802724185753	5	1608802724246194	2219
gradients/bert/encoder/layer_2/output/dense/MatMul_grad/MatMul_1	1608802724185763	1608802724186226	10	1608802724248415	2470
global_norm/L2Loss_50	1608802724186233	1608802724188725	7	1608802724250887	6
gradients/bert/encoder/layer_2/intermediate/dense/mul_3_grad/Mul	1608802724188728	1608802724191197	3	1608802724250894	279
gradients/bert/encoder/layer_2/intermediate/dense/mul_2_grad/Mul_1	1608802724191200	1608802724191233	3	1608802724251175	280
global_norm/L2Loss_49	1608802724191236	1608802724191312	3	1608802724251457	33
gradients/bert/encoder/layer_2/intermediate/dense/Tanh_grad/TanhGrad	1608802724191320	1608802724191352	8	1608802724251491	275
gradients/bert/encoder/layer_2/intermediate/dense/mul_1_grad/Mul_1	1608802724191355	1608802724191391	3	1608802724251768	194
gradients/bert/encoder/layer_2/intermediate/dense/Pow_grad/mul_1	1608802724191395	1608802724191464	4	1608802724251965	279
gradients/AddN_69	1608802724191468	1608802724191517	4	1608802724252245	366
gradients/bert/encoder/layer_2/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724191520	1608802724191580	3	1608802724252616	110
gradients/bert/encoder/layer_2/intermediate/dense/MatMul_grad/MatMul	1608802724191584	1608802724191625	4	1608802724252727	2502
gradients/bert/encoder/layer_2/intermediate/dense/MatMul_grad/MatMul_1	1608802724191633	1608802724191679	8	1608802724255231	2470
global_norm/L2Loss_48	1608802724191686	1608802724191728	7	1608802724257703	9
gradients/AddN_70	1608802724191732	1608802724191760	4	1608802724257713	73
global_norm/L2Loss_47	1608802724191770	1608802724191838	10	1608802724257787	33
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724191841	1608802724191895	3	1608802724257822	69
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724191903	1608802724191954	8	1608802724257893	73
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724191960	1608802724191990	6	1608802724257967	52
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724192000	1608802724192036	10	1608802724258021	74
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724192041	1608802724192085	5	1608802724258096	69
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724192091	1608802724192128	6	1608802724258167	53
global_norm/L2Loss_45	1608802724192135	1608802724192164	7	1608802724258221	5
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724192167	1608802724192204	3	1608802724258228	31
gradients/AddN_71	1608802724192208	1608802724192237	4	1608802724258261	69
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724192247	1608802724192254	10	-1	-1
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724192258	1608802724192292	4	1608802724258331	57
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724192300	1608802724192332	8	1608802724258390	53
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724192337	1608802724192381	5	1608802724258445	27
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724192388	1608802724192430	7	1608802724258474	33
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724192434	1608802724192514	4	1608802724258509	65
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724192518	1608802724192561	4	1608802724258575	47
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724192568	1608802724192575	7	-1	-1
global_norm/L2Loss_46	1608802724192578	1608802724192682	3	1608802724258623	5
gradients/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724192685	1608802724193327	3	1608802724258630	5
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724193331	1608802724193956	4	1608802724258637	27
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724193963	1608802724193996	7	1608802724258666	52
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724194000	1608802724194012	4	-1	-1
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724194015	1608802724194046	3	1608802724258719	54
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724194054	1608802724194082	8	1608802724258774	52
gradients/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724194086	1608802724194163	4	1608802724258828	73
gradients/AddN_72	1608802724194169	1608802724194200	6	1608802724258902	96
gradients/bert/encoder/layer_2/attention/output/dropout/mul_1_grad/Mul	1608802724194209	1608802724194239	9	1608802724259000	51
gradients/bert/encoder/layer_2/attention/output/dropout/mul_grad/Mul	1608802724194247	1608802724194283	8	1608802724259053	73
gradients/bert/encoder/layer_2/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724194288	1608802724194336	5	1608802724259132	56
gradients/bert/encoder/layer_2/attention/output/dense/MatMul_grad/MatMul	1608802724194339	1608802724194376	3	1608802724259189	641
gradients/bert/encoder/layer_2/attention/output/dense/MatMul_grad/MatMul_1	1608802724194384	1608802724194446	8	1608802724259840	613
global_norm/L2Loss_44	1608802724194455	1608802724194492	9	1608802724260454	5
gradients/bert/encoder/layer_2/attention/self/Reshape_3_grad/Reshape	1608802724194495	1608802724194503	3	-1	-1
global_norm/L2Loss_43	1608802724194507	1608802724194576	4	1608802724260461	12
gradients/bert/encoder/layer_2/attention/self/transpose_3_grad/transpose	1608802724194579	1608802724194685	3	1608802724260475	189
gradients/bert/encoder/layer_2/attention/self/MatMul_1_grad/MatMul	1608802724194694	1608802724195856	9	1608802724260666	160
gradients/bert/encoder/layer_2/attention/self/MatMul_1_grad/MatMul_1	1608802724195866	1608802724196582	10	1608802724260828	229
gradients/bert/encoder/layer_2/attention/self/dropout/mul_1_grad/Mul	1608802724196591	1608802724196629	9	1608802724261059	99
gradients/bert/encoder/layer_2/attention/self/transpose_2_grad/transpose	1608802724196633	1608802724196668	4	1608802724261159	190
gradients/bert/encoder/layer_2/attention/self/dropout/mul_grad/Mul	1608802724196675	1608802724196802	7	1608802724261350	142
gradients/bert/encoder/layer_2/attention/self/Reshape_2_grad/Reshape	1608802724196806	1608802724196813	4	-1	-1
gradients/bert/encoder/layer_2/attention/self/Softmax_grad/mul	1608802724196817	1608802724196843	4	1608802724261494	141
gradients/bert/encoder/layer_2/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724196846	1608802724196887	3	1608802724261641	55
gradients/bert/encoder/layer_2/attention/self/value/MatMul_grad/MatMul	1608802724196891	1608802724196927	4	1608802724261697	640
gradients/bert/encoder/layer_2/attention/self/value/MatMul_grad/MatMul_1	1608802724196935	1608802724196986	8	1608802724262345	614
gradients/bert/encoder/layer_2/attention/self/Softmax_grad/Sum	1608802724196993	1608802724197058	7	1608802724262963	54
global_norm/L2Loss_42	1608802724197067	1608802724197099	9	1608802724263019	5
global_norm/L2Loss_41	1608802724197102	1608802724197165	3	1608802724263025	17
gradients/bert/encoder/layer_2/attention/self/Softmax_grad/sub	1608802724197168	1608802724197300	3	1608802724263044	99
gradients/bert/encoder/layer_2/attention/self/Mul_grad/Mul	1608802724197304	1608802724197491	4	1608802724263146	143
gradients/bert/encoder/layer_2/attention/self/MatMul_grad/MatMul	1608802724197497	1608802724199079	6	1608802724263290	244
gradients/bert/encoder/layer_2/attention/self/MatMul_grad/MatMul_1	1608802724199088	1608802724200390	9	1608802724263536	241
gradients/bert/encoder/layer_2/attention/self/transpose_grad/transpose	1608802724200400	1608802724200440	10	1608802724263779	190
gradients/bert/encoder/layer_2/attention/self/transpose_1_grad/transpose	1608802724200448	1608802724200479	8	1608802724263970	189
gradients/bert/encoder/layer_2/attention/self/Reshape_grad/Reshape	1608802724200485	1608802724200493	6	-1	-1
gradients/bert/encoder/layer_2/attention/self/Reshape_1_grad/Reshape	1608802724200496	1608802724200501	3	-1	-1
gradients/bert/encoder/layer_2/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724200507	1608802724200550	6	1608802724264167	54
gradients/bert/encoder/layer_2/attention/self/query/MatMul_grad/MatMul	1608802724200553	1608802724200599	3	1608802724264223	643
gradients/bert/encoder/layer_2/attention/self/query/MatMul_grad/MatMul_1	1608802724200606	1608802724200655	7	1608802724264874	660
gradients/bert/encoder/layer_2/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724200662	1608802724200699	7	1608802724265539	54
gradients/bert/encoder/layer_2/attention/self/key/MatMul_grad/MatMul	1608802724200704	1608802724200738	5	1608802724265594	639
gradients/bert/encoder/layer_2/attention/self/key/MatMul_grad/MatMul_1	1608802724200745	1608802724200795	7	1608802724266243	611
global_norm/L2Loss_38	1608802724200804	1608802724200835	9	1608802724266858	5
global_norm/L2Loss_37	1608802724200839	1608802724200898	4	1608802724266865	16
global_norm/L2Loss_40	1608802724200902	1608802724200927	4	1608802724266883	6
gradients/AddN_73	1608802724200930	1608802724200959	3	1608802724266890	119
global_norm/L2Loss_39	1608802724200965	1608802724201027	6	1608802724267011	17
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724201035	1608802724201067	8	1608802724267029	71
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724201076	1608802724201128	9	1608802724267102	73
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724201134	1608802724201162	6	1608802724267176	51
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724201171	1608802724201207	9	1608802724267229	74
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724201210	1608802724201252	3	1608802724267305	69
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724201257	1608802724201300	5	1608802724267375	53
global_norm/L2Loss_35	1608802724201310	1608802724201338	10	1608802724267430	5
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724201341	1608802724201378	3	1608802724267437	32
gradients/AddN_74	1608802724201382	1608802724201410	4	1608802724267470	68
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724201419	1608802724201425	9	-1	-1
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724201428	1608802724201464	3	1608802724267541	55
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724201471	1608802724201499	7	1608802724267598	54
gradients/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/Tile	1608802724201502	1608802724201538	3	1608802724267653	27
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724201557	1608802724201591	19	1608802724267682	34
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724201596	1608802724201680	5	1608802724267717	65
gradients/bert/encoder/layer_1/output/LayerNorm/moments/mean_grad/truediv	1608802724201684	1608802724201726	4	1608802724267784	47
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724201734	1608802724201740	8	-1	-1
global_norm/L2Loss_36	1608802724201744	1608802724201848	4	1608802724267833	5
gradients/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724201851	1608802724204085	3	1608802724267840	5
gradients/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/Tile	1608802724204089	1608802724206549	4	1608802724267847	28
gradients/bert/encoder/layer_1/output/LayerNorm/moments/variance_grad/truediv	1608802724206557	1608802724206597	8	1608802724267876	51
gradients/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724206601	1608802724206607	4	-1	-1
gradients/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724206615	1608802724206834	8	1608802724267929	54
gradients/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724206837	1608802724207116	3	1608802724267985	52
gradients/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724207119	1608802724207154	3	1608802724268038	73
gradients/AddN_75	1608802724207160	1608802724207191	6	1608802724268113	95
gradients/bert/encoder/layer_1/output/dropout/mul_1_grad/Mul	1608802724207194	1608802724207427	3	1608802724268210	51
gradients/bert/encoder/layer_1/output/dropout/mul_grad/Mul	1608802724207436	1608802724207629	9	1608802724268263	73
gradients/bert/encoder/layer_1/output/dense/BiasAdd_grad/BiasAddGrad	1608802724207634	1608802724207676	5	1608802724268340	55
gradients/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul	1608802724207680	1608802724207921	4	1608802724268397	2220
gradients/bert/encoder/layer_1/output/dense/MatMul_grad/MatMul_1	1608802724207929	1608802724208391	8	1608802724270619	2468
global_norm/L2Loss_34	1608802724208401	1608802724210905	10	1608802724273088	7
gradients/bert/encoder/layer_1/intermediate/dense/mul_3_grad/Mul	1608802724210908	1608802724213361	3	1608802724273097	279
gradients/bert/encoder/layer_1/intermediate/dense/mul_2_grad/Mul_1	1608802724213365	1608802724213397	4	1608802724273378	279
global_norm/L2Loss_33	1608802724213402	1608802724213477	5	1608802724273659	33
gradients/bert/encoder/layer_1/intermediate/dense/Tanh_grad/TanhGrad	1608802724213485	1608802724213513	8	1608802724273694	275
gradients/bert/encoder/layer_1/intermediate/dense/mul_1_grad/Mul_1	1608802724213516	1608802724213551	3	1608802724273970	195
gradients/bert/encoder/layer_1/intermediate/dense/Pow_grad/mul_1	1608802724213556	1608802724213630	5	1608802724274167	280
gradients/AddN_76	1608802724213634	1608802724213683	4	1608802724274449	369
gradients/bert/encoder/layer_1/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724213687	1608802724213732	4	1608802724274824	109
gradients/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul	1608802724213736	1608802724213775	4	1608802724274934	2501
gradients/bert/encoder/layer_1/intermediate/dense/MatMul_grad/MatMul_1	1608802724213782	1608802724213844	7	1608802724277437	2469
global_norm/L2Loss_32	1608802724213850	1608802724213894	6	1608802724279908	9
gradients/AddN_77	1608802724213898	1608802724213923	4	1608802724279919	72
global_norm/L2Loss_31	1608802724213931	1608802724214003	8	1608802724279993	34
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724214006	1608802724214061	3	1608802724280029	69
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724214068	1608802724214119	7	1608802724280100	73
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724214125	1608802724214152	6	1608802724280175	51
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724214159	1608802724214197	7	1608802724280227	74
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724214201	1608802724214252	4	1608802724280303	68
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724214256	1608802724214294	4	1608802724280373	52
global_norm/L2Loss_29	1608802724214302	1608802724214329	8	1608802724280426	5
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724214331	1608802724214368	2	1608802724280433	31
gradients/AddN_78	1608802724214372	1608802724214399	4	1608802724280466	69
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724214407	1608802724214413	8	-1	-1
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724214415	1608802724214447	2	1608802724280537	55
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724214454	1608802724214479	7	1608802724280594	53
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724214487	1608802724214517	8	1608802724280649	27
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724214524	1608802724214578	7	1608802724280678	32
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724214582	1608802724214688	4	1608802724280711	66
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724214693	1608802724214726	5	1608802724280779	47
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724214733	1608802724214739	7	-1	-1
global_norm/L2Loss_30	1608802724214742	1608802724214848	3	1608802724280828	5
gradients/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724214850	1608802724215493	2	1608802724280835	6
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724215496	1608802724216126	3	1608802724280842	28
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724216196	1608802724216227	70	1608802724280871	52
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724216231	1608802724216237	4	-1	-1
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724216240	1608802724216268	3	1608802724280925	53
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724216272	1608802724216296	4	1608802724280980	52
gradients/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724216299	1608802724216336	3	1608802724281033	73
gradients/AddN_79	1608802724216339	1608802724216374	3	1608802724281108	95
gradients/bert/encoder/layer_1/attention/output/dropout/mul_1_grad/Mul	1608802724216377	1608802724216405	3	1608802724281205	51
gradients/bert/encoder/layer_1/attention/output/dropout/mul_grad/Mul	1608802724216412	1608802724216438	7	1608802724281257	73
gradients/bert/encoder/layer_1/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724216444	1608802724216494	6	1608802724281334	55
gradients/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul	1608802724216498	1608802724216531	4	1608802724281390	638
gradients/bert/encoder/layer_1/attention/output/dense/MatMul_grad/MatMul_1	1608802724216538	1608802724216589	7	1608802724282034	663
global_norm/L2Loss_28	1608802724216595	1608802724216623	6	1608802724282699	5
gradients/bert/encoder/layer_1/attention/self/Reshape_3_grad/Reshape	1608802724216626	1608802724216633	3	-1	-1
global_norm/L2Loss_27	1608802724216636	1608802724216739	3	1608802724282706	13
gradients/bert/encoder/layer_1/attention/self/transpose_3_grad/transpose	1608802724216742	1608802724216845	3	1608802724282721	189
gradients/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul	1608802724216853	1608802724218018	8	1608802724282911	161
gradients/bert/encoder/layer_1/attention/self/MatMul_1_grad/MatMul_1	1608802724218026	1608802724218736	8	1608802724283074	241
gradients/bert/encoder/layer_1/attention/self/dropout/mul_1_grad/Mul	1608802724218746	1608802724218780	10	1608802724283316	99
gradients/bert/encoder/layer_1/attention/self/transpose_2_grad/transpose	1608802724218784	1608802724218823	4	1608802724283417	189
gradients/bert/encoder/layer_1/attention/self/dropout/mul_grad/Mul	1608802724218830	1608802724218969	7	1608802724283609	141
gradients/bert/encoder/layer_1/attention/self/Reshape_2_grad/Reshape	1608802724218973	1608802724218980	4	-1	-1
gradients/bert/encoder/layer_1/attention/self/Softmax_grad/mul	1608802724218983	1608802724219008	3	1608802724283752	141
gradients/bert/encoder/layer_1/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724219011	1608802724219049	3	1608802724283899	56
gradients/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul	1608802724219051	1608802724219088	2	1608802724283956	636
gradients/bert/encoder/layer_1/attention/self/value/MatMul_grad/MatMul_1	1608802724219095	1608802724219143	7	1608802724284600	611
gradients/bert/encoder/layer_1/attention/self/Softmax_grad/Sum	1608802724219149	1608802724219212	6	1608802724285213	55
global_norm/L2Loss_26	1608802724219219	1608802724219246	7	1608802724285269	6
global_norm/L2Loss_25	1608802724219249	1608802724219306	3	1608802724285276	15
gradients/bert/encoder/layer_1/attention/self/Softmax_grad/sub	1608802724219309	1608802724219442	3	1608802724285293	100
gradients/bert/encoder/layer_1/attention/self/Mul_grad/Mul	1608802724219446	1608802724219632	4	1608802724285394	142
gradients/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul	1608802724219636	1608802724221223	4	1608802724285538	234
gradients/bert/encoder/layer_1/attention/self/MatMul_grad/MatMul_1	1608802724221232	1608802724222521	9	1608802724285773	228
gradients/bert/encoder/layer_1/attention/self/transpose_grad/transpose	1608802724222530	1608802724222567	9	1608802724286003	189
gradients/bert/encoder/layer_1/attention/self/transpose_1_grad/transpose	1608802724222574	1608802724222615	7	1608802724286193	190
gradients/bert/encoder/layer_1/attention/self/Reshape_grad/Reshape	1608802724222622	1608802724222629	7	-1	-1
gradients/bert/encoder/layer_1/attention/self/Reshape_1_grad/Reshape	1608802724222632	1608802724222637	3	-1	-1
gradients/bert/encoder/layer_1/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724222642	1608802724222683	5	1608802724286389	55
gradients/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul	1608802724222686	1608802724222721	3	1608802724286446	638
gradients/bert/encoder/layer_1/attention/self/query/MatMul_grad/MatMul_1	1608802724222728	1608802724222777	7	1608802724287089	617
gradients/bert/encoder/layer_1/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724222783	1608802724222820	6	1608802724287711	54
gradients/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul	1608802724222824	1608802724222854	4	1608802724287768	637
gradients/bert/encoder/layer_1/attention/self/key/MatMul_grad/MatMul_1	1608802724222860	1608802724222906	6	1608802724288409	661
global_norm/L2Loss_22	1608802724222915	1608802724222945	9	1608802724289072	5
global_norm/L2Loss_21	1608802724222968	1608802724223025	23	1608802724289078	17
global_norm/L2Loss_24	1608802724223029	1608802724223052	4	1608802724289096	5
gradients/AddN_80	1608802724223057	1608802724223086	5	1608802724289102	119
global_norm/L2Loss_23	1608802724223091	1608802724223154	5	1608802724289223	16
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724223163	1608802724223212	9	1608802724289241	71
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724223219	1608802724223271	7	1608802724289314	73
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724223277	1608802724223304	6	1608802724289389	51
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724223313	1608802724223347	9	1608802724289442	74
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724223351	1608802724223397	4	1608802724289518	68
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724223401	1608802724223449	4	1608802724289587	53
global_norm/L2Loss_19	1608802724223453	1608802724223479	4	1608802724289642	6
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724223481	1608802724223515	2	1608802724289650	32
gradients/AddN_81	1608802724223518	1608802724223545	3	1608802724289683	69
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724223552	1608802724223558	7	-1	-1
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724223561	1608802724223591	3	1608802724289754	56
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724223599	1608802724223625	8	1608802724289811	52
gradients/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/Tile	1608802724223629	1608802724223662	4	1608802724289866	27
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724223674	1608802724223738	12	1608802724289895	32
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724223741	1608802724223827	3	1608802724289929	65
gradients/bert/encoder/layer_0/output/LayerNorm/moments/mean_grad/truediv	1608802724223831	1608802724223874	4	1608802724289996	47
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724223883	1608802724223890	9	-1	-1
global_norm/L2Loss_20	1608802724223894	1608802724223994	4	1608802724290044	5
gradients/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724224001	1608802724226221	7	1608802724290051	5
gradients/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/Tile	1608802724226225	1608802724228690	4	1608802724290058	27
gradients/bert/encoder/layer_0/output/LayerNorm/moments/variance_grad/truediv	1608802724228703	1608802724228733	13	1608802724290087	52
gradients/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724228737	1608802724228743	4	-1	-1
gradients/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724228751	1608802724228977	8	1608802724290140	54
gradients/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724228980	1608802724229261	3	1608802724290195	51
gradients/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724229265	1608802724229294	4	1608802724290248	73
gradients/AddN_82	1608802724229297	1608802724229325	3	1608802724290323	96
gradients/bert/encoder/layer_0/output/dropout/mul_1_grad/Mul	1608802724229328	1608802724229574	3	1608802724290420	51
gradients/bert/encoder/layer_0/output/dropout/mul_grad/Mul	1608802724229581	1608802724229775	7	1608802724290473	73
gradients/bert/encoder/layer_0/output/dense/BiasAdd_grad/BiasAddGrad	1608802724229780	1608802724229818	5	1608802724290552	55
gradients/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul	1608802724229822	1608802724230066	4	1608802724290609	2223
gradients/bert/encoder/layer_0/output/dense/MatMul_grad/MatMul_1	1608802724230073	1608802724230548	7	1608802724292834	2467
global_norm/L2Loss_18	1608802724230554	1608802724233043	6	1608802724295303	7
gradients/bert/encoder/layer_0/intermediate/dense/mul_3_grad/Mul	1608802724233046	1608802724235515	3	1608802724295312	279
gradients/bert/encoder/layer_0/intermediate/dense/mul_2_grad/Mul_1	1608802724235518	1608802724235556	3	1608802724295592	279
global_norm/L2Loss_17	1608802724235559	1608802724235629	3	1608802724295873	33
gradients/bert/encoder/layer_0/intermediate/dense/Tanh_grad/TanhGrad	1608802724235637	1608802724235664	8	1608802724295908	274
gradients/bert/encoder/layer_0/intermediate/dense/mul_1_grad/Mul_1	1608802724235667	1608802724235704	3	1608802724296183	195
gradients/bert/encoder/layer_0/intermediate/dense/Pow_grad/mul_1	1608802724235708	1608802724235784	4	1608802724296380	279
gradients/AddN_83	1608802724235787	1608802724235834	3	1608802724296661	365
gradients/bert/encoder/layer_0/intermediate/dense/BiasAdd_grad/BiasAddGrad	1608802724235837	1608802724235879	3	1608802724297030	109
gradients/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul	1608802724235882	1608802724235924	3	1608802724297140	2501
gradients/bert/encoder/layer_0/intermediate/dense/MatMul_grad/MatMul_1	1608802724235931	1608802724235996	7	1608802724299643	2469
global_norm/L2Loss_16	1608802724236019	1608802724236049	23	1608802724302114	9
gradients/AddN_84	1608802724236052	1608802724236077	3	1608802724302125	72
global_norm/L2Loss_15	1608802724236084	1608802724236154	7	1608802724302199	33
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724236157	1608802724236213	3	1608802724302233	69
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724236219	1608802724236270	6	1608802724302304	73
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Neg	1608802724236276	1608802724236302	6	1608802724302379	51
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub_grad/Sum	1608802724236313	1608802724236345	11	1608802724302432	74
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724236350	1608802724236404	5	1608802724302507	69
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724236409	1608802724236445	5	1608802724302577	53
global_norm/L2Loss_13	1608802724236452	1608802724236477	7	1608802724302632	5
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724236480	1608802724236513	3	1608802724302639	32
gradients/AddN_85	1608802724236516	1608802724236541	3	1608802724302672	69
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724236549	1608802724236555	8	-1	-1
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul	1608802724236559	1608802724236589	4	1608802724302743	54
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724236596	1608802724236637	7	1608802724302799	54
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/Tile	1608802724236640	1608802724236668	3	1608802724302854	27
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum	1608802724236674	1608802724236728	6	1608802724302883	33
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724236731	1608802724236828	3	1608802724302918	65
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean_grad/truediv	1608802724236832	1608802724236875	4	1608802724302985	47
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_grad/Reshape	1608802724236882	1608802724236888	7	-1	-1
global_norm/L2Loss_14	1608802724236893	1608802724236996	5	1608802724303034	5
gradients/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724236999	1608802724237640	3	1608802724303041	5
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/Tile	1608802724237645	1608802724238321	5	1608802724303047	27
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance_grad/truediv	1608802724238328	1608802724238355	7	1608802724303075	52
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724238358	1608802724238368	3	-1	-1
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/sub	1608802724238371	1608802724238397	3	1608802724303129	53
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724238404	1608802724238427	7	1608802724303183	51
gradients/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724238430	1608802724238527	3	1608802724303236	73
gradients/AddN_86	1608802724238530	1608802724238556	3	1608802724303311	95
gradients/bert/encoder/layer_0/attention/output/dropout/mul_1_grad/Mul	1608802724238565	1608802724238591	9	1608802724303407	51
gradients/bert/encoder/layer_0/attention/output/dropout/mul_grad/Mul	1608802724238598	1608802724238626	7	1608802724303460	73
gradients/bert/encoder/layer_0/attention/output/dense/BiasAdd_grad/BiasAddGrad	1608802724238630	1608802724238689	4	1608802724303537	55
gradients/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul	1608802724238692	1608802724238724	3	1608802724303593	643
gradients/bert/encoder/layer_0/attention/output/dense/MatMul_grad/MatMul_1	1608802724238731	1608802724238781	7	1608802724304243	614
global_norm/L2Loss_12	1608802724238787	1608802724238819	6	1608802724304859	6
gradients/bert/encoder/layer_0/attention/self/Reshape_3_grad/Reshape	1608802724238822	1608802724238828	3	-1	-1
global_norm/L2Loss_11	1608802724238831	1608802724238926	3	1608802724304866	14
gradients/bert/encoder/layer_0/attention/self/transpose_3_grad/transpose	1608802724238928	1608802724239032	2	1608802724304882	189
gradients/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul	1608802724239039	1608802724240207	7	1608802724305073	159
gradients/bert/encoder/layer_0/attention/self/MatMul_1_grad/MatMul_1	1608802724240214	1608802724240923	7	1608802724305234	241
gradients/bert/encoder/layer_0/attention/self/dropout/mul_1_grad/Mul	1608802724240931	1608802724240962	8	1608802724305477	99
gradients/bert/encoder/layer_0/attention/self/transpose_2_grad/transpose	1608802724240965	1608802724241005	3	1608802724305577	190
gradients/bert/encoder/layer_0/attention/self/dropout/mul_grad/Mul	1608802724241012	1608802724241150	7	1608802724305768	142
gradients/bert/encoder/layer_0/attention/self/Reshape_2_grad/Reshape	1608802724241153	1608802724241159	3	-1	-1
gradients/bert/encoder/layer_0/attention/self/Softmax_grad/mul	1608802724241162	1608802724241185	3	1608802724305912	141
gradients/bert/encoder/layer_0/attention/self/value/BiasAdd_grad/BiasAddGrad	1608802724241188	1608802724241224	3	1608802724306056	55
gradients/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul	1608802724241227	1608802724241257	3	1608802724306113	637
gradients/bert/encoder/layer_0/attention/self/value/MatMul_grad/MatMul_1	1608802724241263	1608802724241309	6	1608802724306755	664
gradients/bert/encoder/layer_0/attention/self/Softmax_grad/Sum	1608802724241316	1608802724241403	7	1608802724307421	55
global_norm/L2Loss_10	1608802724241409	1608802724241434	6	1608802724307477	5
global_norm/L2Loss_9	1608802724241439	1608802724241492	5	1608802724307484	15
gradients/bert/encoder/layer_0/attention/self/Softmax_grad/sub	1608802724241496	1608802724241646	4	1608802724307501	101
gradients/bert/encoder/layer_0/attention/self/Mul_grad/Mul	1608802724241650	1608802724241835	4	1608802724307603	142
gradients/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul	1608802724241838	1608802724243416	3	1608802724307746	243
gradients/bert/encoder/layer_0/attention/self/MatMul_grad/MatMul_1	1608802724243424	1608802724244716	8	1608802724307990	231
gradients/bert/encoder/layer_0/attention/self/transpose_grad/transpose	1608802724244725	1608802724244761	9	1608802724308223	189
gradients/bert/encoder/layer_0/attention/self/transpose_1_grad/transpose	1608802724244767	1608802724244811	6	1608802724308414	190
gradients/bert/encoder/layer_0/attention/self/Reshape_grad/Reshape	1608802724244816	1608802724244823	5	-1	-1
gradients/bert/encoder/layer_0/attention/self/Reshape_1_grad/Reshape	1608802724244827	1608802724244831	4	-1	-1
gradients/bert/encoder/layer_0/attention/self/query/BiasAdd_grad/BiasAddGrad	1608802724244833	1608802724244870	2	1608802724308607	55
gradients/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul	1608802724244873	1608802724244903	3	1608802724308663	643
gradients/bert/encoder/layer_0/attention/self/query/MatMul_grad/MatMul_1	1608802724244908	1608802724244953	5	1608802724309313	611
gradients/bert/encoder/layer_0/attention/self/key/BiasAdd_grad/BiasAddGrad	1608802724244960	1608802724244994	7	1608802724309929	56
gradients/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul	1608802724244997	1608802724245024	3	1608802724309987	636
gradients/bert/encoder/layer_0/attention/self/key/MatMul_grad/MatMul_1	1608802724245030	1608802724245071	6	1608802724310629	613
global_norm/L2Loss_6	1608802724245080	1608802724245107	9	1608802724311243	5
global_norm/L2Loss_5	1608802724245110	1608802724247206	3	1608802724311250	18
global_norm/L2Loss_8	1608802724247211	1608802724247249	5	1608802724311270	5
gradients/AddN_87	1608802724247253	1608802724247282	4	1608802724311276	119
global_norm/L2Loss_7	1608802724247293	1608802724247349	11	1608802724311397	17
gradients/bert/encoder/Reshape_1_grad/Reshape	1608802724247352	1608802724247360	3	-1	-1
gradients/bert/embeddings/dropout/mul_grad/Mul	1608802724247368	1608802724247397	8	1608802724311415	72
gradients/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul	1608802724247404	1608802724247435	7	1608802724311488	73
gradients/bert/embeddings/LayerNorm/batchnorm/mul_1_grad/Mul_1	1608802724247445	1608802724247472	10	1608802724311563	73
gradients/bert/embeddings/LayerNorm/batchnorm/sub_grad/Neg	1608802724247482	1608802724247508	10	1608802724311638	51
gradients/bert/embeddings/LayerNorm/batchnorm/sub_grad/Sum	1608802724247514	1608802724247552	6	1608802724311691	75
gradients/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul	1608802724247556	1608802724247580	4	1608802724311767	68
gradients/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Mul_1	1608802724247587	1608802724247612	7	1608802724311837	53
global_norm/L2Loss_3	1608802724247617	1608802724247644	5	1608802724311892	5
gradients/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Sum	1608802724247646	1608802724247677	2	1608802724311899	32
gradients/AddN_88	1608802724247681	1608802724247707	4	1608802724311932	69
gradients/bert/embeddings/LayerNorm/batchnorm/mul_2_grad/Reshape	1608802724247710	1608802724247720	3	-1	-1
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul	1608802724247723	1608802724247749	3	1608802724312003	55
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Mul_1	1608802724247756	1608802724247784	7	1608802724312059	52
gradients/bert/embeddings/LayerNorm/moments/mean_grad/Tile	1608802724247787	1608802724247822	3	1608802724312113	32
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum	1608802724247829	1608802724247856	7	1608802724312147	32
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Sum_1	1608802724247864	1608802724247891	8	1608802724312181	66
gradients/bert/embeddings/LayerNorm/moments/mean_grad/truediv	1608802724247895	1608802724247925	4	1608802724312248	47
gradients/bert/embeddings/LayerNorm/batchnorm/mul_grad/Reshape	1608802724247928	1608802724247933	3	-1	-1
global_norm/L2Loss_4	1608802724247939	1608802724248419	6	1608802724312296	5
gradients/bert/embeddings/LayerNorm/batchnorm/Rsqrt_grad/RsqrtGrad	1608802724248423	1608802724250890	4	1608802724312303	5
gradients/bert/embeddings/LayerNorm/moments/variance_grad/Tile	1608802724250898	1608802724250928	8	1608802724312310	33
gradients/bert/embeddings/LayerNorm/moments/variance_grad/truediv	1608802724250935	1608802724251177	7	1608802724312344	51
gradients/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/scalar	1608802724251181	1608802724251187	4	-1	-1
gradients/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/sub	1608802724251190	1608802724251460	3	1608802724312397	53
gradients/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/Mul	1608802724251464	1608802724251495	4	1608802724312453	52
gradients/bert/embeddings/LayerNorm/moments/SquaredDifference_grad/mul_1	1608802724251499	1608802724251523	4	1608802724312506	73
gradients/AddN_89	1608802724251531	1608802724251772	8	1608802724312581	96
gradients/bert/embeddings/add_1_grad/Sum	1608802724251775	1608802724251968	3	1608802724312679	34
gradients/bert/embeddings/Reshape_1_grad/Reshape	1608802724251974	1608802724251980	6	-1	-1
gradients/bert/embeddings/Slice_grad/Pad	1608802724251984	1608802724252250	4	1608802724312714	8
gradients/bert/embeddings/MatMul_grad/MatMul_1	1608802724252256	1608802724252315	6	1608802724312732	105
gradients/AddN_90/inputs_1	1608802724252318	1608802724255235	3	1608802724312838	334
global_norm/L2Loss_2	1608802724255247	1608802724257724	12	1608802724313173	14
global_norm/L2Loss_1	1608802724257727	1608802724257789	3	1608802724313189	6
gradients/AddN_90	1608802724257791	1608802724257819	2	1608802724313197	517
global_norm/L2Loss	1608802724257838	1608802724257896	19	1608802724313717	176
global_norm/stack	1608802724257899	1608802724258163	3	1608802724313895	13
global_norm/Sum	1608802724258214	1608802724258250	51	1608802724313910	5
global_norm/mul	1608802724258254	1608802724258280	4	1608802724313916	5
global_norm/global_norm	1608802724258283	1608802724258312	3	1608802724313922	5
clip_by_global_norm/IsFinite	1608802724258315	1608802724258342	3	1608802724313929	4
clip_by_global_norm/truediv	1608802724258345	1608802724258368	3	1608802724313934	5
clip_by_global_norm/Minimum	1608802724258370	1608802724258393	2	1608802724313941	4
clip_by_global_norm/mul	1608802724258396	1608802724258400	3	-1	-1
clip_by_global_norm/Select	1608802724258402	1608802724258456	2	1608802724313947	4
clip_by_global_norm/mul_72	1608802724258498	1608802724258527	42	1608802724313953	9
clip_by_global_norm/mul_76	1608802724258533	1608802724258556	6	1608802724313964	13
clip_by_global_norm/mul_73	1608802724258561	1608802724258582	5	1608802724313978	4
clip_by_global_norm/mul_65	1608802724258586	1608802724258606	4	1608802724313984	4
clip_by_global_norm/mul_88	1608802724258608	1608802724258630	2	1608802724313990	13
clip_by_global_norm/mul_84	1608802724258634	1608802724258655	4	1608802724314005	4
clip_by_global_norm/mul_62	1608802724258658	1608802724258680	3	1608802724314010	5
clip_by_global_norm/mul_66	1608802724258684	1608802724258710	4	1608802724314017	39
clip_by_global_norm/mul_70	1608802724258714	1608802724258736	4	1608802724314058	13
clip_by_global_norm/mul_89	1608802724258739	1608802724258766	3	1608802724314073	4
clip_by_global_norm/mul_77	1608802724258769	1608802724258790	3	1608802724314079	4
clip_by_global_norm/mul_80	1608802724258794	1608802724258830	4	1608802724314085	40
clip_by_global_norm/mul_85	1608802724258836	1608802724258904	6	1608802724314126	4
clip_by_global_norm/mul_90	1608802724258907	1608802724259002	3	1608802724314132	13
clip_by_global_norm/mul_74	1608802724259009	1608802724259054	7	1608802724314147	12
clip_by_global_norm/mul_78	1608802724259057	1608802724259128	3	1608802724314160	4
clip_by_global_norm/mul_81	1608802724259131	1608802724259195	3	1608802724314166	4
clip_by_global_norm/mul_63	1608802724259198	1608802724259853	3	1608802724314172	4
clip_by_global_norm/mul_67	1608802724259857	1608802724260470	4	1608802724314178	4
clip_by_global_norm/mul_92	1608802724260474	1608802724260502	4	1608802724314183	12
clip_by_global_norm/mul_96	1608802724260505	1608802724260533	3	1608802724314197	39
clip_by_global_norm/mul_79	1608802724260536	1608802724260559	3	1608802724314238	4
clip_by_global_norm/mul_82	1608802724260562	1608802724260679	3	1608802724314243	40
clip_by_global_norm/mul_86	1608802724260683	1608802724260704	4	1608802724314285	12
clip_by_global_norm/mul_91	1608802724260711	1608802724260733	7	1608802724314299	5
clip_by_global_norm/mul_93	1608802724260736	1608802724260760	3	1608802724314305	4
clip_by_global_norm/mul_71	1608802724260771	1608802724260840	11	1608802724314311	4
clip_by_global_norm/mul_75	1608802724260843	1608802724260865	3	1608802724314316	4
clip_by_global_norm/mul_104	1608802724260868	1608802724260889	3	1608802724314322	13
clip_by_global_norm/mul_83	1608802724260894	1608802724260914	5	1608802724314336	4
clip_by_global_norm/mul_87	1608802724260921	1608802724261070	7	1608802724314342	4
clip_by_global_norm/mul_1	1608802724261074	1608802724261174	4	1608802724314348	362
clip_by_global_norm/mul_3	1608802724261178	1608802724261362	4	1608802724314711	9
clip_by_global_norm/mul_4	1608802724261366	1608802724261506	4	1608802724314722	4
clip_by_global_norm/mul_7	1608802724261508	1608802724261703	2	1608802724314728	4
clip_by_global_norm/mul_5	1608802724261706	1608802724262343	3	1608802724314734	4
clip_by_global_norm/mul_8	1608802724262346	1608802724262968	3	1608802724314739	13
clip_by_global_norm/mul_11	1608802724262971	1608802724263024	3	1608802724314754	4
clip_by_global_norm/mul_6	1608802724263037	1608802724263060	13	1608802724314759	13
clip_by_global_norm/mul_9	1608802724263063	1608802724263088	3	1608802724314774	4
clip_by_global_norm/mul_12	1608802724263093	1608802724263116	5	1608802724314780	13
clip_by_global_norm/mul_15	1608802724263122	1608802724263152	6	1608802724314794	4
clip_by_global_norm/mul_100	1608802724263157	1608802724263302	5	1608802724314800	4
clip_by_global_norm/mul_10	1608802724263306	1608802724263328	4	1608802724314806	13
clip_by_global_norm/mul_13	1608802724263334	1608802724263356	6	1608802724314820	4
clip_by_global_norm/mul_16	1608802724263361	1608802724263386	5	1608802724314826	40
clip_by_global_norm/mul_40	1608802724263389	1608802724263542	3	1608802724314867	13
clip_by_global_norm/mul_119	1608802724263547	1608802724263573	5	1608802724314881	4
clip_by_global_norm/mul_123	1608802724263578	1608802724263603	5	1608802724314887	4
clip_by_global_norm/mul_14	1608802724263607	1608802724263628	4	1608802724314892	4
clip_by_global_norm/mul_17	1608802724263631	1608802724263785	3	1608802724314898	4
clip_by_global_norm/mul_103	1608802724263787	1608802724263979	2	1608802724314904	4
clip_by_global_norm/mul_24	1608802724263982	1608802724264172	3	1608802724314909	13
clip_by_global_norm/mul_107	1608802724264177	1608802724264235	5	1608802724314923	4
clip_by_global_norm/mul_32	1608802724264238	1608802724265545	3	1608802724314929	40
clip_by_global_norm/mul_115	1608802724265548	1608802724265600	3	1608802724314971	4
clip_by_global_norm/mul_18	1608802724265603	1608802724266248	3	1608802724314977	40
clip_by_global_norm/mul_124	1608802724266251	1608802724266872	3	1608802724315019	12
clip_by_global_norm/mul_127	1608802724266875	1608802724266899	3	1608802724315032	4
clip_by_global_norm/mul_94	1608802724266902	1608802724266928	3	1608802724315038	4
clip_by_global_norm/mul_54	1608802724266931	1608802724266953	3	1608802724315044	12
clip_by_global_norm/mul_57	1608802724266960	1608802724266983	7	1608802724315057	4
clip_by_global_norm/mul_105	1608802724266986	1608802724267026	3	1608802724315063	4
clip_by_global_norm/mul_108	1608802724267029	1608802724267050	3	1608802724315069	13
clip_by_global_norm/mul_111	1608802724267056	1608802724267080	6	1608802724315083	4
clip_by_global_norm/mul_116	1608802724267083	1608802724267117	3	1608802724315089	4
clip_by_global_norm/mul_120	1608802724267123	1608802724267187	6	1608802724315095	12
clip_by_global_norm/mul_35	1608802724267193	1608802724267240	6	1608802724315109	4
clip_by_global_norm/mul_37	1608802724267243	1608802724267320	3	1608802724315114	4
clip_by_global_norm/mul_131	1608802724267323	1608802724267386	3	1608802724315120	4
clip_by_global_norm/mul_95	1608802724267389	1608802724267441	3	1608802724315125	5
clip_by_global_norm/mul_97	1608802724267444	1608802724267470	3	1608802724315132	4
clip_by_global_norm/mul_55	1608802724267473	1608802724267496	3	1608802724315138	5
clip_by_global_norm/mul_58	1608802724267499	1608802724267552	3	1608802724315144	12
clip_by_global_norm/mul_151	1608802724267557	1608802724267613	5	1608802724315158	4
clip_by_global_norm/mul_112	1608802724267617	1608802724267664	4	1608802724315163	39
clip_by_global_norm/mul_117	1608802724267668	1608802724267694	4	1608802724315205	4
clip_by_global_norm/mul_121	1608802724267696	1608802724267727	2	1608802724315211	4
clip_by_global_norm/mul_125	1608802724267735	1608802724267795	8	1608802724315216	4
clip_by_global_norm/mul_128	1608802724267800	1608802724267846	5	1608802724315222	40
clip_by_global_norm/mul_132	1608802724267851	1608802724267878	5	1608802724315263	4
clip_by_global_norm/mul_38	1608802724267886	1608802724267909	8	1608802724315269	12
clip_by_global_norm/mul_139	1608802724267912	1608802724267938	3	1608802724315284	4
clip_by_global_norm/mul_98	1608802724267943	1608802724267964	5	1608802724315289	40
clip_by_global_norm/mul_101	1608802724267972	1608802724267997	8	1608802724315331	4
clip_by_global_norm/mul_152	1608802724268002	1608802724268052	5	1608802724315336	12
clip_by_global_norm/mul_59	1608802724268055	1608802724268124	3	1608802724315350	4
clip_by_global_norm/mul_113	1608802724268127	1608802724268221	3	1608802724315356	4
clip_by_global_norm/mul_118	1608802724268224	1608802724268278	3	1608802724315362	13
clip_by_global_norm/mul_122	1608802724268280	1608802724268400	2	1608802724315376	13
clip_by_global_norm/mul_126	1608802724268403	1608802724270622	3	1608802724315390	4
clip_by_global_norm/mul_129	1608802724270626	1608802724273428	4	1608802724315396	4
clip_by_global_norm/mul_133	1608802724273438	1608802724273480	10	1608802724315402	4
clip_by_global_norm/mul_135	1608802724273484	1608802724273516	4	1608802724315408	4
clip_by_global_norm/mul_140	1608802724273519	1608802724273667	3	1608802724315413	12
clip_by_global_norm/mul_39	1608802724273672	1608802724273703	5	1608802724315427	4
clip_by_global_norm/mul_99	1608802724273706	1608802724273734	3	1608802724315433	4
clip_by_global_norm/mul_102	1608802724273737	1608802724273972	3	1608802724315438	13
clip_by_global_norm/mul_48	1608802724273979	1608802724274169	7	1608802724315453	39
clip_by_global_norm/mul_109	1608802724274172	1608802724274451	3	1608802724315494	4
clip_by_global_norm/mul_114	1608802724274454	1608802724274821	3	1608802724315499	40
clip_by_global_norm/mul_166	1608802724274828	1608802724274941	7	1608802724315541	12
clip_by_global_norm/mul_170	1608802724274946	1608802724277449	5	1608802724315555	12
clip_by_global_norm/mul_174	1608802724277453	1608802724279915	4	1608802724315569	4
clip_by_global_norm/mul_130	1608802724279922	1608802724279946	7	1608802724315575	40
clip_by_global_norm/mul_182	1608802724279951	1608802724280004	5	1608802724315616	12
clip_by_global_norm/mul_136	1608802724280007	1608802724280033	3	1608802724315629	12
clip_by_global_norm/mul_141	1608802724280040	1608802724280065	7	1608802724315643	4
clip_by_global_norm/mul_143	1608802724280068	1608802724280111	3	1608802724315649	4
clip_by_global_norm/mul_147	1608802724280114	1608802724280182	3	1608802724315654	4
clip_by_global_norm/mul_153	1608802724280186	1608802724280235	4	1608802724315660	4
clip_by_global_norm/mul_154	1608802724280240	1608802724280313	5	1608802724315666	12
clip_by_global_norm/mul_44	1608802724280317	1608802724280380	4	1608802724315680	12
clip_by_global_norm/mul_110	1608802724280383	1608802724280434	3	1608802724315693	4
clip_by_global_norm/mul_167	1608802724280437	1608802724280464	3	1608802724315699	4
clip_by_global_norm/mul_171	1608802724280467	1608802724280494	3	1608802724315705	4
clip_by_global_norm/mul_175	1608802724280497	1608802724280544	3	1608802724315710	4
clip_by_global_norm/mul_178	1608802724280547	1608802724280603	3	1608802724315716	40
clip_by_global_norm/mul_183	1608802724280606	1608802724280655	3	1608802724315757	4
clip_by_global_norm/mul_187	1608802724280659	1608802724280685	4	1608802724315763	4
clip_by_global_norm/mul_137	1608802724280688	1608802724280717	3	1608802724315769	4
clip_by_global_norm/mul_142	1608802724280726	1608802724280785	9	1608802724315774	4
clip_by_global_norm/mul_144	1608802724280788	1608802724280834	3	1608802724315780	40
clip_by_global_norm/mul_148	1608802724280837	1608802724280862	3	1608802724315821	4
clip_by_global_norm/mul_29	1608802724280868	1608802724280894	6	1608802724315827	4
clip_by_global_norm/mul_155	1608802724280897	1608802724280932	3	1608802724315832	4
clip_by_global_norm/mul_158	1608802724280935	1608802724280961	3	1608802724315838	4
clip_by_global_norm/mul_41	1608802724280967	1608802724280995	6	1608802724315843	4
clip_by_global_norm/mul_168	1608802724280998	1608802724281043	3	1608802724315849	12
clip_by_global_norm/mul_172	1608802724281046	1608802724281114	3	1608802724315863	12
clip_by_global_norm/mul_176	1608802724281119	1608802724281211	5	1608802724315876	39
clip_by_global_norm/mul_179	1608802724281215	1608802724281267	4	1608802724315917	4
clip_by_global_norm/mul_185	1608802724281270	1608802724281339	3	1608802724315923	4
clip_by_global_norm/mul_188	1608802724281342	1608802724281402	3	1608802724315929	12
clip_by_global_norm/mul_134	1608802724281405	1608802724282704	3	1608802724315942	12
clip_by_global_norm/mul_138	1608802724282707	1608802724282735	3	1608802724315956	13
clip_by_global_norm/mul_199	1608802724282738	1608802724282767	3	1608802724315971	4
clip_by_global_norm/mul_145	1608802724282771	1608802724282798	4	1608802724315976	4
clip_by_global_norm/mul_149	1608802724282801	1608802724282914	3	1608802724315982	4
clip_by_global_norm/mul_21	1608802724282917	1608802724282945	3	1608802724315988	4
clip_by_global_norm/mul_156	1608802724282948	1608802724282971	3	1608802724315993	13
clip_by_global_norm/mul_159	1608802724282977	1608802724283005	6	1608802724316007	4
clip_by_global_norm/mul_162	1608802724283008	1608802724283077	3	1608802724316013	39
clip_by_global_norm/mul_106	1608802724283080	1608802724283106	3	1608802724316054	12
clip_by_global_norm/mul_42	1608802724283114	1608802724283140	8	1608802724316068	13
clip_by_global_norm/mul_177	1608802724283143	1608802724283170	3	1608802724316082	4
clip_by_global_norm/mul_180	1608802724283174	1608802724283318	4	1608802724316088	4
clip_by_global_norm/mul_186	1608802724283324	1608802724283419	6	1608802724316093	12
clip_by_global_norm/mul_189	1608802724283422	1608802724283610	3	1608802724316109	4
clip_by_global_norm/mul_191	1608802724283613	1608802724283755	3	1608802724316115	4
clip_by_global_norm/mul_195	1608802724283758	1608802724283897	3	1608802724316121	4
clip_by_global_norm/mul_200	1608802724283901	1608802724283966	4	1608802724316127	12
clip_by_global_norm/mul_203	1608802724283969	1608802724284607	3	1608802724316141	4
clip_by_global_norm/mul_146	1608802724284611	1608802724285227	4	1608802724316146	39
clip_by_global_norm/mul_150	1608802724285245	1608802724285283	18	1608802724316187	12
clip_by_global_norm/mul_157	1608802724285286	1608802724285310	3	1608802724316201	4
clip_by_global_norm/mul_160	1608802724285313	1608802724285335	3	1608802724316206	40
clip_by_global_norm/mul_163	1608802724285338	1608802724285363	3	1608802724316248	4
clip_by_global_norm/mul_169	1608802724285366	1608802724285407	3	1608802724316254	4
clip_by_global_norm/mul_173	1608802724285410	1608802724285549	3	1608802724316259	4
clip_by_global_norm/mul_181	1608802724285553	1608802724285578	4	1608802724316265	4
clip_by_global_norm/mul_45	1608802724285585	1608802724285609	7	1608802724316271	4
clip_by_global_norm/mul_190	1608802724285612	1608802724285643	3	1608802724316276	4
clip_by_global_norm/mul_192	1608802724285646	1608802724285785	3	1608802724316282	40
clip_by_global_norm/mul_196	1608802724285791	1608802724285820	6	1608802724316324	4
clip_by_global_norm/mul_201	1608802724285824	1608802724285855	4	1608802724316329	4
clip_by_global_norm/mul_204	1608802724285858	1608802724285883	3	1608802724316335	5
clip_by_global_norm/mul_2	1608802724285886	1608802724286015	3	1608802724316341	4
clip_by_global_norm/mul_161	1608802724286018	1608802724286211	3	1608802724316347	5
clip_by_global_norm/mul_164	1608802724286215	1608802724286448	4	1608802724316353	4
clip_by_global_norm/mul_25	1608802724286452	1608802724287090	4	1608802724316359	4
clip_by_global_norm/mul_36	1608802724287093	1608802724287720	3	1608802724316365	4
clip_by_global_norm/mul_43	1608802724287723	1608802724287779	3	1608802724316370	4
clip_by_global_norm/mul_193	1608802724287782	1608802724289078	3	1608802724316376	4
clip_by_global_norm/mul_197	1608802724289083	1608802724289111	5	1608802724316382	4
clip_by_global_norm/mul_202	1608802724289119	1608802724289143	8	1608802724316388	4
clip_by_global_norm/mul_205	1608802724289146	1608802724289173	3	1608802724316394	4
clip_by_global_norm/mul_60	1608802724289176	1608802724289199	3	1608802724316400	12
clip_by_global_norm/mul_165	1608802724289206	1608802724289234	7	1608802724316413	4
clip_by_global_norm/mul_20	1608802724289237	1608802724289265	3	1608802724316419	4
clip_by_global_norm/mul_33	1608802724289268	1608802724289294	3	1608802724316425	4
clip_by_global_norm/mul_194	1608802724289297	1608802724289324	3	1608802724316430	39
clip_by_global_norm/mul_198	1608802724289327	1608802724289396	3	1608802724316471	13
clip_by_global_norm/mul_46	1608802724289400	1608802724289443	4	1608802724316486	4
clip_by_global_norm/mul_206	1608802724289449	1608802724289522	6	1608802724316492	4
clip_by_global_norm/mul_52	1608802724289525	1608802724289592	3	1608802724316497	4
clip_by_global_norm/mul_56	1608802724289595	1608802724289643	3	1608802724316503	13
clip_by_global_norm/mul_184	1608802724289646	1608802724289677	3	1608802724316518	12
clip_by_global_norm/mul_49	1608802724289681	1608802724289708	4	1608802724316532	4
clip_by_global_norm/mul_50	1608802724289711	1608802724289756	3	1608802724316538	40
clip_by_global_norm/mul_51	1608802724289759	1608802724289812	3	1608802724316579	4
clip_by_global_norm/mul_19	1608802724289817	1608802724289867	5	1608802724316585	4
clip_by_global_norm/mul_22	1608802724289873	1608802724289897	6	1608802724316591	12
clip_by_global_norm/mul_26	1608802724289900	1608802724289930	3	1608802724316605	12
clip_by_global_norm/mul_30	1608802724289933	1608802724289996	3	1608802724316618	4
clip_by_global_norm/mul_23	1608802724290003	1608802724290045	7	1608802724316624	4
clip_by_global_norm/mul_27	1608802724290048	1608802724290078	3	1608802724316630	4
clip_by_global_norm/mul_31	1608802724290082	1608802724290106	4	1608802724316635	4
clip_by_global_norm/mul_47	1608802724290109	1608802724290140	3	1608802724316641	4
clip_by_global_norm/mul_28	1608802724290143	1608802724290171	3	1608802724316647	12
clip_by_global_norm/mul_53	1608802724290175	1608802724290198	4	1608802724316661	4
clip_by_global_norm/mul_34	1608802724290201	1608802724290249	3	1608802724316666	40
clip_by_global_norm/mul_61	1608802724290252	1608802724290327	3	1608802724316707	4
clip_by_global_norm/mul_64	1608802724290331	1608802724290421	4	1608802724316713	40
clip_by_global_norm/mul_68	1608802724290425	1608802724290475	4	1608802724316754	4
clip_by_global_norm/mul_69	1608802724290478	1608802724290558	3	1608802724316760	4
Square_71	1608802724290563	1608802724290616	5	1608802724316766	13
Mul_388	1608802724290624	1608802724292840	8	1608802724316780	12
Square_75	1608802724292845	1608802724295310	5	1608802724316793	13
Mul_410	1608802724295320	1608802724295344	10	1608802724316807	11
Square_72	1608802724295347	1608802724295601	3	1608802724316820	4
Mul_394	1608802724295604	1608802724295881	3	1608802724316826	4
Square_64	1608802724295884	1608802724295910	3	1608802724316831	4
Mul_351	1608802724295913	1608802724295935	3	1608802724316837	4
Square_87	1608802724295941	1608802724296189	6	1608802724316843	13
Mul_474	1608802724296195	1608802724296401	6	1608802724316857	11
Square_83	1608802724296404	1608802724296666	3	1608802724316870	4
Mul_453	1608802724296669	1608802724297036	3	1608802724316876	4
Square_61	1608802724297041	1608802724297157	5	1608802724316881	5
Mul_335	1608802724297160	1608802724299657	3	1608802724316887	4
Square_65	1608802724299660	1608802724302133	3	1608802724316893	41
Mul_356	1608802724302139	1608802724302166	6	1608802724316935	39
Square_69	1608802724302170	1608802724302211	4	1608802724316976	13
Mul_377	1608802724302216	1608802724302245	5	1608802724316990	12
Square_88	1608802724302248	1608802724302275	3	1608802724317004	4
Mul_480	1608802724302277	1608802724302317	2	1608802724317009	4
Square_76	1608802724302320	1608802724302392	3	1608802724317015	4
Mul_416	1608802724302399	1608802724302443	7	1608802724317020	4
Square_79	1608802724302446	1608802724302522	3	1608802724317026	40
Mul_431	1608802724302527	1608802724302591	5	1608802724317067	40
Square_84	1608802724302594	1608802724302643	3	1608802724317108	4
Mul_458	1608802724302645	1608802724302670	2	1608802724317114	4
Square_89	1608802724302672	1608802724302696	2	1608802724317120	12
Mul_485	1608802724302701	1608802724302763	5	1608802724317134	12
Square_73	1608802724302767	1608802724302815	4	1608802724317147	13
Mul_399	1608802724302821	1608802724302868	6	1608802724317162	11
Square_77	1608802724302871	1608802724302898	3	1608802724317175	5
Mul_421	1608802724302901	1608802724302931	3	1608802724317181	4
Square_80	1608802724302935	1608802724302995	4	1608802724317187	4
Mul_437	1608802724302998	1608802724303047	3	1608802724317193	4
Square_62	1608802724303054	1608802724303082	7	1608802724317198	4
Mul_340	1608802724303084	1608802724303110	2	1608802724317204	4
Square_66	1608802724303113	1608802724303135	3	1608802724317210	4
Mul_362	1608802724303137	1608802724303166	2	1608802724317215	4
Square_91	1608802724303169	1608802724303197	3	1608802724317221	12
Mul_496	1608802724303202	1608802724303247	5	1608802724317235	11
Mul_517	1608802724303251	1608802724303327	4	1608802724317247	39
Square_95	1608802724303333	1608802724303419	6	1608802724317288	40
Square_78	1608802724303421	1608802724303471	2	1608802724317330	4
Mul_426	1608802724303473	1608802724303598	2	1608802724317336	4
Square_81	1608802724303601	1608802724304241	3	1608802724317342	40
Mul_442	1608802724304246	1608802724304866	5	1608802724317384	39
Square_85	1608802724304869	1608802724304895	3	1608802724317424	13
Mul_463	1608802724304902	1608802724304928	7	1608802724317439	12
Square_90	1608802724304931	1608802724304961	3	1608802724317452	4
Mul_491	1608802724304965	1608802724305078	4	1608802724317458	4
Square_92	1608802724305081	1608802724305110	3	1608802724317463	4
Mul_502	1608802724305113	1608802724305141	3	1608802724317469	4
Square_70	1608802724305144	1608802724305169	3	1608802724317474	4
Mul_383	1608802724305171	1608802724305239	2	1608802724317480	4
Square_74	1608802724305242	1608802724305268	3	1608802724317485	4
Mul_405	1608802724305272	1608802724305296	4	1608802724317491	4
Mul_560	1608802724305299	1608802724305330	3	1608802724317496	13
Square_103	1608802724305336	1608802724305482	6	1608802724317511	12
Square_82	1608802724305484	1608802724305582	2	1608802724317524	4
Mul_448	1608802724305585	1608802724305773	3	1608802724317530	4
Square_86	1608802724305780	1608802724305918	7	1608802724317535	4
Mul_469	1608802724305922	1608802724306066	4	1608802724317541	4
Square	1608802724306069	1608802724306124	3	1608802724317546	364
Mul_5	1608802724306130	1608802724307423	6	1608802724317912	363
Square_2	1608802724307426	1608802724307482	3	1608802724318276	9
Mul_17	1608802724307486	1608802724307510	4	1608802724318287	7
Square_3	1608802724307514	1608802724307541	4	1608802724318295	4
Mul_23	1608802724307543	1608802724307569	2	1608802724318301	4
Square_6	1608802724307572	1608802724307603	3	1608802724318306	4
Mul_39	1608802724307606	1608802724307752	3	1608802724318312	4
Square_4	1608802724307754	1608802724307779	2	1608802724318317	4
Mul_28	1608802724307781	1608802724307810	2	1608802724318323	4
Square_7	1608802724307813	1608802724307837	3	1608802724318328	13
Mul_44	1608802724307846	1608802724307991	9	1608802724318343	12
Square_10	1608802724307994	1608802724308022	3	1608802724318356	4
Mul_61	1608802724308024	1608802724308049	2	1608802724318362	4
Square_5	1608802724308051	1608802724308080	2	1608802724318367	13
Mul_33	1608802724308084	1608802724308228	4	1608802724318382	11
Square_8	1608802724308230	1608802724308416	2	1608802724318395	5
Mul_50	1608802724308418	1608802724308607	2	1608802724318401	4
Square_11	1608802724308610	1608802724308668	3	1608802724318406	12
Mul_66	1608802724308677	1608802724309317	9	1608802724318420	12
Square_14	1608802724309321	1608802724309991	4	1608802724318434	4
Mul_82	1608802724309994	1608802724310629	3	1608802724318440	4
Square_99	1608802724310636	1608802724311248	7	1608802724318445	4
Mul_539	1608802724311251	1608802724311274	3	1608802724318451	4
Square_9	1608802724311280	1608802724311306	6	1608802724318456	13
Mul_55	1608802724311310	1608802724311340	4	1608802724318470	11
Square_12	1608802724311343	1608802724311366	3	1608802724318483	4
Mul_72	1608802724311368	1608802724311403	2	1608802724318489	4
Square_15	1608802724311406	1608802724311433	3	1608802724318495	40
Mul_87	1608802724311438	1608802724311460	5	1608802724318536	39
Square_39	1608802724311463	1608802724311493	3	1608802724318577	12
Mul_216	1608802724311498	1608802724311569	5	1608802724318591	11
Mul_641	1608802724311576	1608802724311643	7	1608802724318604	5
Square_118	1608802724311646	1608802724311699	3	1608802724318610	4
Mul_663	1608802724311702	1608802724311772	3	1608802724318616	4
Square_122	1608802724311775	1608802724311842	3	1608802724318621	4
Square_13	1608802724311845	1608802724311898	3	1608802724318627	4
Mul_77	1608802724311903	1608802724311929	5	1608802724318632	4
Square_16	1608802724311932	1608802724311958	3	1608802724318638	4
Mul_93	1608802724311960	1608802724312007	2	1608802724318644	4
Mul_555	1608802724312011	1608802724312066	4	1608802724318649	4
Square_102	1608802724312069	1608802724312121	3	1608802724318655	4
Square_23	1608802724312124	1608802724312152	3	1608802724318660	12
Mul_130	1608802724312158	1608802724312188	6	1608802724318674	12
Mul_577	1608802724312191	1608802724312253	3	1608802724318688	4
Square_106	1608802724312271	1608802724312301	18	1608802724318693	4
Square_31	1608802724312304	1608802724312335	3	1608802724318699	40
Mul_173	1608802724312341	1608802724312370	6	1608802724318741	39
Mul_620	1608802724312373	1608802724312403	3	1608802724318781	5
Square_114	1608802724312408	1608802724312434	5	1608802724318788	4
Square_17	1608802724312436	1608802724312464	2	1608802724318793	40
Mul_98	1608802724312470	1608802724312518	6	1608802724318835	40
Mul_668	1608802724312520	1608802724312586	2	1608802724318876	13
Square_123	1608802724312594	1608802724312684	8	1608802724318890	11
Mul_684	1608802724312686	1608802724312723	2	1608802724318903	4
Square_126	1608802724312725	1608802724312752	2	1608802724318908	4
Mul_507	1608802724312755	1608802724312851	3	1608802724318914	4
Square_93	1608802724312853	1608802724313030	2	1608802724318919	4
Square_53	1608802724313036	1608802724313183	6	1608802724318925	13
Mul_291	1608802724313188	1608802724313215	5	1608802724318939	11
Square_56	1608802724313218	1608802724313241	3	1608802724318951	4
Mul_308	1608802724313245	1608802724313271	4	1608802724318957	4
Mul_566	1608802724313274	1608802724313732	3	1608802724318962	5
Square_104	1608802724313735	1608802724313898	3	1608802724318969	4
Mul_582	1608802724313900	1608802724313937	2	1608802724318974	14
Square_107	1608802724313941	1608802724313966	4	1608802724318990	11
Mul_598	1608802724313969	1608802724314012	3	1608802724319002	5
Square_110	1608802724314015	1608802724314037	3	1608802724319009	4
Mul_625	1608802724314044	1608802724314070	7	1608802724319014	5
Square_115	1608802724314072	1608802724314095	2	1608802724319021	4
Mul_646	1608802724314098	1608802724314122	3	1608802724319026	13
Square_119	1608802724314128	1608802724314158	6	1608802724319040	11
Square_34	1608802724314161	1608802724314188	3	1608802724319053	4
Mul_190	1608802724314190	1608802724314216	2	1608802724319058	4
Square_36	1608802724314218	1608802724314246	2	1608802724319064	4
Mul_200	1608802724314249	1608802724314271	3	1608802724319069	4
Mul_706	1608802724314276	1608802724314300	5	1608802724319075	4
Square_130	1608802724314303	1608802724314327	3	1608802724319080	4
Mul_512	1608802724314329	1608802724314353	2	1608802724319086	4
Square_94	1608802724314356	1608802724314380	3	1608802724319091	4
Mul_523	1608802724314383	1608802724314406	3	1608802724319097	4
Square_96	1608802724314411	1608802724314434	5	1608802724319102	4
Square_54	1608802724314436	1608802724314463	2	1608802724319108	5
Mul_297	1608802724314466	1608802724314486	3	1608802724319114	4
Square_57	1608802724314489	1608802724314516	3	1608802724319120	13
Mul_313	1608802724314521	1608802724314547	5	1608802724319134	11
Mul_813	1608802724314550	1608802724314574	3	1608802724319147	4
Square_150	1608802724314578	1608802724314605	4	1608802724319153	4
Mul_603	1608802724314608	1608802724314634	3	1608802724319158	40
Square_111	1608802724314642	1608802724314666	8	1608802724319200	39
Mul_630	1608802724314670	1608802724314698	4	1608802724319241	4
Square_116	1608802724314701	1608802724314725	3	1608802724319247	4
Mul_652	1608802724314728	1608802724314755	3	1608802724319252	4
Square_120	1608802724314757	1608802724314789	2	1608802724319258	4
Mul_674	1608802724314791	1608802724314819	2	1608802724319263	4
Square_124	1608802724314821	1608802724314845	2	1608802724319269	4
Mul_689	1608802724314848	1608802724314871	3	1608802724319274	40
Square_127	1608802724314876	1608802724314903	5	1608802724319315	39
Mul_711	1608802724314906	1608802724314934	3	1608802724319356	5
Square_131	1608802724314937	1608802724314959	3	1608802724319363	4
Square_37	1608802724314961	1608802724314991	2	1608802724319369	13
Mul_205	1608802724314995	1608802724315017	4	1608802724319383	12
Mul_749	1608802724315023	1608802724315048	6	1608802724319396	4
Square_138	1608802724315051	1608802724315078	3	1608802724319402	4
Square_97	1608802724315081	1608802724315102	3	1608802724319408	40
Mul_528	1608802724315107	1608802724315135	5	1608802724319449	39
Mul_544	1608802724315138	1608802724315165	3	1608802724319489	4
Square_100	1608802724315168	1608802724315190	3	1608802724319495	4
Mul_818	1608802724315192	1608802724315221	2	1608802724319500	12
Square_151	1608802724315226	1608802724315248	5	1608802724319514	11
Square_58	1608802724315256	1608802724315282	8	1608802724319526	4
Mul_319	1608802724315285	1608802724315310	3	1608802724319532	4
Mul_609	1608802724315314	1608802724315337	4	1608802724319537	4
Square_112	1608802724315340	1608802724315365	3	1608802724319543	4
Mul_635	1608802724315367	1608802724315393	2	1608802724319549	14
Square_117	1608802724315401	1608802724315426	8	1608802724319564	11
Mul_657	1608802724315428	1608802724315455	2	1608802724319577	13
Square_121	1608802724315460	1608802724315483	5	1608802724319592	12
Mul_679	1608802724315491	1608802724315515	8	1608802724319605	4
Square_125	1608802724315517	1608802724315542	2	1608802724319611	4
Mul_695	1608802724315544	1608802724315567	2	1608802724319616	4
Square_128	1608802724315570	1608802724315598	3	1608802724319622	4
Mul_716	1608802724315600	1608802724315626	2	1608802724319628	4
Square_132	1608802724315631	1608802724315653	5	1608802724319633	4
Mul_727	1608802724315655	1608802724315682	2	1608802724319639	4
Square_134	1608802724315684	1608802724315704	2	1608802724319644	4
Mul_754	1608802724315707	1608802724315733	3	1608802724319650	12
Square_139	1608802724315738	1608802724315763	5	1608802724319664	11
Square_38	1608802724315766	1608802724315789	3	1608802724319677	4
Mul_211	1608802724315791	1608802724315819	2	1608802724319682	4
Square_98	1608802724315822	1608802724315844	3	1608802724319688	5
Mul_534	1608802724315846	1608802724315872	2	1608802724319694	4
Mul_549	1608802724315875	1608802724315903	3	1608802724319699	14
Square_101	1608802724315908	1608802724315930	5	1608802724319714	11
Square_47	1608802724315932	1608802724315960	2	1608802724319727	40
Mul_259	1608802724315965	1608802724315988	5	1608802724319769	39
Mul_588	1608802724315995	1608802724316018	7	1608802724319810	4
Square_108	1608802724316021	1608802724316048	3	1608802724319815	4
Mul_614	1608802724316050	1608802724316073	2	1608802724319821	39
Square_113	1608802724316078	1608802724316104	5	1608802724319863	39
Mul_893	1608802724316106	1608802724316132	2	1608802724319904	13
Square_165	1608802724316138	1608802724316161	6	1608802724319918	11
Square_169	1608802724316163	1608802724316190	2	1608802724319931	13
Mul_915	1608802724316196	1608802724316220	6	1608802724319945	11
Square_173	1608802724316237	1608802724316263	17	1608802724319958	4
Mul_937	1608802724316265	1608802724316294	2	1608802724319964	4
Mul_700	1608802724316296	1608802724316324	2	1608802724319969	40
Square_129	1608802724316329	1608802724316358	5	1608802724320011	39
Square_181	1608802724316365	1608802724316399	7	1608802724320052	13
Mul_979	1608802724316405	1608802724316429	6	1608802724320067	12
Mul_732	1608802724316435	1608802724316464	6	1608802724320080	13
Square_135	1608802724316468	1608802724316489	4	1608802724320094	11
Mul_760	1608802724316496	1608802724316520	7	1608802724320107	4
Square_140	1608802724316522	1608802724316551	2	1608802724320113	4
Mul_770	1608802724316554	1608802724316578	3	1608802724320118	4
Square_142	1608802724316581	1608802724316607	3	1608802724320123	4
Mul_792	1608802724316610	1608802724316635	3	1608802724320129	4
Square_146	1608802724316638	1608802724316661	3	1608802724320134	4
Mul_824	1608802724316664	1608802724316689	3	1608802724320140	4
Square_152	1608802724316692	1608802724316715	3	1608802724320145	4
Mul_829	1608802724316718	1608802724316745	3	1608802724320151	13
Square_153	1608802724316750	1608802724316774	5	1608802724320165	12
Square_43	1608802724316777	1608802724316800	3	1608802724320178	13
Mul_238	1608802724316805	1608802724316831	5	1608802724320193	12
Mul_593	1608802724316834	1608802724316861	3	1608802724320207	5
Square_109	1608802724316864	1608802724316887	3	1608802724320213	4
Mul_899	1608802724316889	1608802724316915	2	1608802724320218	4
Square_166	1608802724316917	1608802724316937	2	1608802724320224	4
Square_170	1608802724316940	1608802724316968	3	1608802724320230	4
Mul_921	1608802724316970	1608802724316998	2	1608802724320235	4
Square_174	1608802724317001	1608802724317023	3	1608802724320240	4
Mul_942	1608802724317025	1608802724317052	2	1608802724320246	4
Square_177	1608802724317054	1608802724317078	2	1608802724320251	40
Mul_958	1608802724317086	1608802724317109	8	1608802724320293	39
Square_182	1608802724317112	1608802724317138	3	1608802724320334	4
Mul_985	1608802724317140	1608802724317161	2	1608802724320340	4
Mul_1007	1608802724317164	1608802724317191	3	1608802724320345	4
Square_186	1608802724317194	1608802724317220	3	1608802724320351	4
Mul_738	1608802724317223	1608802724317246	3	1608802724320356	5
Square_136	1608802724317248	1608802724317272	2	1608802724320362	4
Mul_765	1608802724317274	1608802724317298	2	1608802724320367	6
Square_141	1608802724317301	1608802724317328	3	1608802724320375	4
Mul_775	1608802724317330	1608802724317356	2	1608802724320380	40
Square_143	1608802724317361	1608802724317384	5	1608802724320421	39
Mul_797	1608802724317387	1608802724317414	3	1608802724320462	4
Square_147	1608802724317416	1608802724317438	2	1608802724320468	4
Square_28	1608802724317443	1608802724317466	5	1608802724320473	4
Mul_158	1608802724317469	1608802724317493	3	1608802724320479	4
Mul_835	1608802724317495	1608802724317517	2	1608802724320484	4
Square_154	1608802724317519	1608802724317544	2	1608802724320490	4
Mul_851	1608802724317546	1608802724317583	2	1608802724320495	4
Square_157	1608802724317586	1608802724317607	3	1608802724320501	4
Square_40	1608802724317609	1608802724317636	2	1608802724320506	4
Mul_222	1608802724317638	1608802724317660	2	1608802724320512	4
Mul_904	1608802724317664	1608802724317691	4	1608802724320517	12
Square_167	1608802724317696	1608802724317722	5	1608802724320531	11
Square_171	1608802724317725	1608802724317750	3	1608802724320544	13
Mul_926	1608802724317756	1608802724317783	6	1608802724320559	12
Square_175	1608802724317786	1608802724317807	3	1608802724320572	41
Mul_947	1608802724317816	1608802724317838	9	1608802724320614	39
Square_178	1608802724317841	1608802724317868	3	1608802724320655	5
Mul_964	1608802724317870	1608802724317893	2	1608802724320661	4
Square_184	1608802724317896	1608802724317922	3	1608802724320667	4
Mul_996	1608802724317924	1608802724317949	2	1608802724320672	4
Mul_1012	1608802724317953	1608802724317978	4	1608802724320678	12
Square_187	1608802724317983	1608802724318009	5	1608802724320691	11
Mul_721	1608802724318012	1608802724318036	3	1608802724320703	13
Square_133	1608802724318043	1608802724318066	7	1608802724320718	11
Mul_743	1608802724318069	1608802724318095	3	1608802724320731	13
Square_137	1608802724318099	1608802724318123	4	1608802724320745	11
Mul_1071	1608802724318126	1608802724318152	3	1608802724320758	4
Square_198	1608802724318156	1608802724318182	4	1608802724320764	4
Mul_781	1608802724318185	1608802724318208	3	1608802724320770	4
Square_144	1608802724318211	1608802724318237	3	1608802724320775	4
Mul_802	1608802724318240	1608802724318262	3	1608802724320781	5
Square_148	1608802724318267	1608802724318288	5	1608802724320787	4
Square_20	1608802724318291	1608802724318318	3	1608802724320792	5
Mul_114	1608802724318320	1608802724318341	2	1608802724320799	4
Mul_840	1608802724318344	1608802724318370	3	1608802724320804	13
Square_155	1608802724318375	1608802724318402	5	1608802724320818	11
Mul_856	1608802724318404	1608802724318430	2	1608802724320831	4
Square_158	1608802724318433	1608802724318457	3	1608802724320837	4
Mul_872	1608802724318460	1608802724318483	3	1608802724320842	40
Square_161	1608802724318487	1608802724318516	4	1608802724320884	39
Mul_571	1608802724318519	1608802724318547	3	1608802724320924	13
Square_105	1608802724318551	1608802724318576	4	1608802724320939	11
Square_41	1608802724318578	1608802724318604	2	1608802724320952	13
Mul_227	1608802724318608	1608802724318629	4	1608802724320966	11
Square_176	1608802724318635	1608802724318658	6	1608802724320979	4
Mul_953	1608802724318660	1608802724318687	2	1608802724320985	4
Square_179	1608802724318690	1608802724318715	3	1608802724320990	5
Mul_969	1608802724318719	1608802724318744	4	1608802724320997	4
Mul_1001	1608802724318746	1608802724318774	2	1608802724321002	13
Square_185	1608802724318779	1608802724318802	5	1608802724321017	11
Mul_1018	1608802724318805	1608802724318834	3	1608802724321029	4
Square_188	1608802724318837	1608802724318857	3	1608802724321035	4
Mul_1028	1608802724318863	1608802724318886	6	1608802724321040	4
Square_190	1608802724318889	1608802724318915	3	1608802724321046	4
Mul_1050	1608802724318918	1608802724318943	3	1608802724321051	5
Square_194	1608802724318946	1608802724318982	3	1608802724321057	4
Square_199	1608802724318984	1608802724319011	2	1608802724321063	13
Mul_1076	1608802724319015	1608802724319040	4	1608802724321077	11
Square_202	1608802724319043	1608802724319070	3	1608802724321090	4
Mul_1092	1608802724319072	1608802724319093	2	1608802724321095	4
Mul_786	1608802724319097	1608802724319125	4	1608802724321101	40
Square_145	1608802724319130	1608802724319157	5	1608802724321142	40
Mul_807	1608802724319160	1608802724319184	3	1608802724321183	13
Square_149	1608802724319189	1608802724319213	5	1608802724321198	11
Mul_846	1608802724319216	1608802724319239	3	1608802724321211	5
Square_156	1608802724319244	1608802724319267	5	1608802724321217	4
Mul_861	1608802724319270	1608802724319295	3	1608802724321223	39
Square_159	1608802724319300	1608802724319321	5	1608802724321264	39
Mul_878	1608802724319324	1608802724319351	3	1608802724321305	4
Square_162	1608802724319354	1608802724319381	3	1608802724321311	4
Square_168	1608802724319384	1608802724319408	3	1608802724321316	4
Mul_910	1608802724319410	1608802724319435	2	1608802724321322	4
Square_172	1608802724319437	1608802724319462	2	1608802724321327	4
Mul_932	1608802724319468	1608802724319489	6	1608802724321333	4
Square_180	1608802724319492	1608802724319517	3	1608802724321338	4
Mul_974	1608802724319520	1608802724319543	3	1608802724321344	4
Square_44	1608802724319546	1608802724319571	3	1608802724321349	4
Mul_244	1608802724319573	1608802724319598	2	1608802724321355	4
Mul_1023	1608802724319600	1608802724319624	2	1608802724321360	5
Square_189	1608802724319627	1608802724319653	3	1608802724321366	4
Mul_1033	1608802724319655	1608802724319682	2	1608802724321372	41
Square_191	1608802724319686	1608802724319712	4	1608802724321414	40
Mul_1055	1608802724319715	1608802724319743	3	1608802724321455	4
Square_195	1608802724319746	1608802724319767	3	1608802724321461	4
Square_200	1608802724319769	1608802724319794	2	1608802724321467	4
Mul_1082	1608802724319796	1608802724319816	2	1608802724321473	4
Mul_1097	1608802724319822	1608802724319845	6	1608802724321478	7
Square_203	1608802724319850	1608802724319875	5	1608802724321486	4
Square_1	1608802724319878	1608802724319900	3	1608802724321492	4
Mul_11	1608802724319902	1608802724319927	2	1608802724321498	4
Mul_867	1608802724319929	1608802724319954	2	1608802724321503	5
Square_160	1608802724319957	1608802724319979	3	1608802724321509	4
Mul_883	1608802724319982	1608802724320007	3	1608802724321515	4
Square_163	1608802724320009	1608802724320029	2	1608802724321520	4
Square_24	1608802724320032	1608802724320059	3	1608802724321526	5
Mul_136	1608802724320062	1608802724320086	3	1608802724321532	4
Square_35	1608802724320089	1608802724320111	3	1608802724321537	5
Mul_195	1608802724320113	1608802724320139	2	1608802724321544	4
Square_42	1608802724320142	1608802724320164	3	1608802724321549	4
Mul_233	1608802724320169	1608802724320193	5	1608802724321555	4
Mul_1039	1608802724320196	1608802724320225	3	1608802724321560	4
Square_192	1608802724320227	1608802724320250	2	1608802724321566	4
Mul_1060	1608802724320252	1608802724320281	2	1608802724321572	4
Square_196	1608802724320284	1608802724320306	3	1608802724321577	4
Square_201	1608802724320312	1608802724320336	6	1608802724321583	4
Mul_1087	1608802724320338	1608802724320379	2	1608802724321588	4
Mul_1102	1608802724320382	1608802724320406	3	1608802724321594	4
Square_204	1608802724320408	1608802724320435	2	1608802724321599	4
Square_59	1608802724320438	1608802724320464	3	1608802724321605	13
Mul_324	1608802724320470	1608802724320495	6	1608802724321619	11
Mul_888	1608802724320497	1608802724320524	2	1608802724321632	5
Square_164	1608802724320526	1608802724320546	2	1608802724321638	4
Square_19	1608802724320552	1608802724320575	6	1608802724321644	5
Mul_109	1608802724320578	1608802724320603	3	1608802724321650	4
Square_32	1608802724320605	1608802724320630	2	1608802724321655	4
Mul_179	1608802724320632	1608802724320657	2	1608802724321661	4
Mul_1044	1608802724320660	1608802724320683	3	1608802724321667	40
Square_193	1608802724320690	1608802724320711	7	1608802724321708	39
Mul_1065	1608802724320714	1608802724320740	3	1608802724321749	13
Square_197	1608802724320745	1608802724320766	5	1608802724321763	12
Square_45	1608802724320771	1608802724320794	5	1608802724321777	4
Mul_249	1608802724320796	1608802724320820	2	1608802724321783	4
Square_205	1608802724320823	1608802724320845	3	1608802724321788	4
Mul_1108	1608802724320848	1608802724320873	3	1608802724321794	4
Square_51	1608802724320876	1608802724320900	3	1608802724321799	4
Mul_281	1608802724320907	1608802724320930	7	1608802724321805	4
Square_55	1608802724320933	1608802724320958	3	1608802724321810	14
Mul_302	1608802724320964	1608802724320986	6	1608802724321825	12
Square_183	1608802724320989	1608802724321017	3	1608802724321839	13
Mul_990	1608802724321021	1608802724321049	4	1608802724321854	11
Square_48	1608802724321052	1608802724321076	3	1608802724321867	4
Mul_265	1608802724321078	1608802724321103	2	1608802724321872	4
Square_49	1608802724321105	1608802724321126	2	1608802724321878	40
Mul_270	1608802724321133	1608802724321159	7	1608802724321919	39
Square_50	1608802724321161	1608802724321188	2	1608802724321960	4
Mul_276	1608802724321191	1608802724321214	3	1608802724321966	4
Square_18	1608802724321217	1608802724321243	3	1608802724321972	4
Mul_104	1608802724321245	1608802724321269	2	1608802724321977	4
Square_21	1608802724321274	1608802724321299	5	1608802724321983	12
Mul_119	1608802724321303	1608802724321329	4	1608802724321997	12
Square_25	1608802724321331	1608802724321358	2	1608802724322010	13
Mul_141	1608802724321362	1608802724321389	4	1608802724322024	11
Square_29	1608802724321392	1608802724321417	3	1608802724322037	4
Mul_163	1608802724321419	1608802724321442	2	1608802724322043	4
Square_22	1608802724321446	1608802724321472	4	1608802724322048	4
Mul_125	1608802724321474	1608802724321494	2	1608802724322054	4
Square_26	1608802724321503	1608802724321526	9	1608802724322060	4
Mul_147	1608802724321528	1608802724321554	2	1608802724322065	4
Square_30	1608802724321556	1608802724321578	2	1608802724322071	4
Mul_168	1608802724321581	1608802724321607	3	1608802724322076	4
Square_46	1608802724321610	1608802724321633	3	1608802724322082	5
Mul_254	1608802724321640	1608802724321663	7	1608802724322088	4
Square_27	1608802724321666	1608802724321691	3	1608802724322093	13
Mul_152	1608802724321696	1608802724321718	5	1608802724322108	11
Square_52	1608802724321721	1608802724321758	3	1608802724322121	4
Mul_286	1608802724321760	1608802724321784	2	1608802724322127	4
Square_33	1608802724321787	1608802724321811	3	1608802724322132	40
Mul_184	1608802724321816	1608802724321845	5	1608802724322174	39
Square_60	1608802724321848	1608802724321873	3	1608802724322215	4
Mul_330	1608802724321879	1608802724321902	6	1608802724322220	4
Square_63	1608802724321904	1608802724321930	2	1608802724322226	40
Mul_345	1608802724321956	1608802724321982	26	1608802724322267	39
Square_67	1608802724321984	1608802724322009	2	1608802724322308	4
Mul_367	1608802724322012	1608802724322034	3	1608802724322314	4
Square_68	1608802724322036	1608802724322056	2	1608802724322319	4
Mul_372	1608802724322059	1608802724322079	3	1608802724322325	4
Mul_390	1608802724322081	1608802724322103	2	1608802724322330	13
add_244	1608802724322106	1608802724322134	3	1608802724322345	18
Mul_412	1608802724322137	1608802724322161	3	1608802724322364	14
add_258	1608802724322164	1608802724322188	3	1608802724322380	17
Mul_396	1608802724322190	1608802724322212	2	1608802724322398	4
add_248	1608802724322214	1608802724322238	2	1608802724322404	4
Mul_353	1608802724322241	1608802724322264	3	1608802724322409	4
add_221	1608802724322268	1608802724322292	4	1608802724322415	5
Mul_476	1608802724322295	1608802724322317	3	1608802724322422	12
add_298	1608802724322321	1608802724322351	4	1608802724322435	17
Mul_455	1608802724322354	1608802724322377	3	1608802724322454	4
add_285	1608802724322379	1608802724322406	2	1608802724322460	4
Mul_337	1608802724322409	1608802724322430	3	1608802724322465	4
add_211	1608802724322438	1608802724322462	8	1608802724322471	4
Mul_358	1608802724322465	1608802724322491	3	1608802724322481	44
add_224	1608802724322493	1608802724322516	2	1608802724322527	56
Mul_379	1608802724322519	1608802724322546	3	1608802724322584	13
add_237	1608802724322549	1608802724322576	3	1608802724322598	17
Mul_482	1608802724322579	1608802724322601	3	1608802724322617	5
add_302	1608802724322604	1608802724322631	3	1608802724322623	12
Mul_418	1608802724322634	1608802724322656	3	1608802724322651	11
add_262	1608802724322658	1608802724322690	2	1608802724322681	13
Mul_433	1608802724322693	1608802724322714	3	1608802724322710	44
add_271	1608802724322721	1608802724322745	7	1608802724322756	56
Mul_460	1608802724322747	1608802724322774	2	1608802724322813	4
add_288	1608802724322777	1608802724322801	3	1608802724322819	4
Mul_487	1608802724322803	1608802724322829	2	1608802724322825	17
add_305	1608802724322832	1608802724322856	3	1608802724322849	23
Mul_401	1608802724322863	1608802724322886	7	1608802724322880	19
add_251	1608802724322889	1608802724322915	3	1608802724322905	22
Mul_423	1608802724322918	1608802724322939	3	1608802724322934	11
add_265	1608802724322942	1608802724322968	3	1608802724322961	11
Mul_439	1608802724322971	1608802724322995	3	1608802724322988	12
add_275	1608802724323000	1608802724323023	5	1608802724323017	11
Mul_342	1608802724323026	1608802724323051	3	1608802724323043	10
add_214	1608802724323054	1608802724323078	3	1608802724323070	11
Mul_364	1608802724323081	1608802724323106	3	1608802724323100	11
add_228	1608802724323108	1608802724323130	2	1608802724323125	10
Mul_498	1608802724323147	1608802724323172	17	1608802724323166	18
add_312	1608802724323174	1608802724323202	2	1608802724323191	23
add_325	1608802724323205	1608802724323229	3	1608802724323223	61
Mul_519	1608802724323231	1608802724323256	2	1608802724323285	39
Mul_428	1608802724323260	1608802724323283	4	1608802724323326	4
add_268	1608802724323289	1608802724323314	6	1608802724323332	4
Mul_444	1608802724323317	1608802724323341	3	1608802724323337	40
add_278	1608802724323344	1608802724323367	3	1608802724323379	56
Mul_465	1608802724323370	1608802724323398	3	1608802724323437	12
add_291	1608802724323400	1608802724323425	2	1608802724323451	17
Mul_493	1608802724323432	1608802724323454	7	1608802724323470	5
add_309	1608802724323458	1608802724323487	4	1608802724323477	9
Mul_504	1608802724323489	1608802724323514	2	1608802724323506	14
add_316	1608802724323517	1608802724323544	3	1608802724323534	13
Mul_385	1608802724323546	1608802724323568	2	1608802724323563	10
add_241	1608802724323570	1608802724323597	2	1608802724323590	10
Mul_407	1608802724323599	1608802724323620	2	1608802724323616	10
add_255	1608802724323626	1608802724323649	6	1608802724323643	10
add_352	1608802724323652	1608802724323678	3	1608802724323669	21
Mul_562	1608802724323681	1608802724323702	3	1608802724323698	17
Mul_450	1608802724323704	1608802724323732	2	1608802724323724	14
add_282	1608802724323735	1608802724323762	3	1608802724323752	14
Mul_471	1608802724323770	1608802724323794	8	1608802724323787	12
add_295	1608802724323796	1608802724323824	2	1608802724323814	10
Mul_7	1608802724323827	1608802724323849	3	1608802724323844	368
add_3	1608802724323851	1608802724323877	2	1608802724324214	521
Mul_19	1608802724323880	1608802724323902	3	1608802724324737	10
add_11	1608802724323909	1608802724323935	7	1608802724324748	13
Mul_25	1608802724323937	1608802724323964	2	1608802724324763	4
add_15	1608802724323967	1608802724323991	3	1608802724324768	4
Mul_41	1608802724323993	1608802724324018	2	1608802724324774	4
add_25	1608802724324021	1608802724324043	3	1608802724324780	4
Mul_30	1608802724324052	1608802724324076	9	1608802724324785	4
add_18	1608802724324078	1608802724324106	2	1608802724324791	4
Mul_46	1608802724324109	1608802724324130	3	1608802724324797	12
add_28	1608802724324132	1608802724324160	2	1608802724324810	17
Mul_63	1608802724324163	1608802724324183	3	1608802724324829	4
add_39	1608802724324190	1608802724324216	7	1608802724324836	4
Mul_35	1608802724324218	1608802724324245	2	1608802724324842	13
add_21	1608802724324247	1608802724324270	2	1608802724324856	17
Mul_52	1608802724324273	1608802724324298	3	1608802724324875	4
add_32	1608802724324300	1608802724324322	2	1608802724324881	4
Mul_68	1608802724324328	1608802724324350	6	1608802724324886	13
add_42	1608802724324354	1608802724324389	4	1608802724324901	17
Mul_84	1608802724324392	1608802724324415	3	1608802724324919	4
add_52	1608802724324418	1608802724324445	3	1608802724324925	4
Mul_541	1608802724324449	1608802724324470	4	1608802724324931	4
add_339	1608802724324480	1608802724324504	10	1608802724324936	4
Mul_57	1608802724324507	1608802724324536	3	1608802724324942	12
add_35	1608802724324539	1608802724324564	3	1608802724324955	17
Mul_74	1608802724324566	1608802724324594	2	1608802724324974	4
add_46	1608802724324596	1608802724324620	2	1608802724324980	4
Mul_89	1608802724324622	1608802724324649	2	1608802724324986	39
add_55	1608802724324652	1608802724324679	3	1608802724325026	56
Mul_218	1608802724324682	1608802724324706	3	1608802724325084	12
add_136	1608802724324709	1608802724324737	3	1608802724325098	17
add_403	1608802724324739	1608802724324764	2	1608802724325116	4
Mul_643	1608802724324768	1608802724324794	4	1608802724325122	4
add_417	1608802724324797	1608802724324822	3	1608802724325128	5
Mul_665	1608802724324827	1608802724324849	5	1608802724325134	4
Mul_79	1608802724324851	1608802724324876	2	1608802724325140	5
add_49	1608802724324879	1608802724324903	3	1608802724325146	4
Mul_95	1608802724324906	1608802724324931	3	1608802724325151	4
add_59	1608802724324933	1608802724324961	2	1608802724325157	5
add_349	1608802724324964	1608802724324987	3	1608802724325163	4
Mul_557	1608802724324989	1608802724325013	2	1608802724325169	4
Mul_132	1608802724325017	1608802724325038	4	1608802724325175	12
add_82	1608802724325042	1608802724325071	4	1608802724325189	17
add_363	1608802724325074	1608802724325098	3	1608802724325207	4
Mul_579	1608802724325104	1608802724325127	6	1608802724325213	4
Mul_175	1608802724325131	1608802724325156	4	1608802724325219	39
add_109	1608802724325158	1608802724325182	2	1608802724325260	56
add_390	1608802724325185	1608802724325213	3	1608802724325317	4
Mul_622	1608802724325216	1608802724325238	3	1608802724325323	4
Mul_100	1608802724325245	1608802724325267	7	1608802724325329	39
add_62	1608802724325270	1608802724325297	3	1608802724325369	56
add_420	1608802724325300	1608802724325324	3	1608802724325427	18
Mul_670	1608802724325326	1608802724325354	2	1608802724325446	12
add_430	1608802724325357	1608802724325381	3	1608802724325459	4
Mul_686	1608802724325387	1608802724325410	6	1608802724325465	4
add_319	1608802724325412	1608802724325438	2	1608802724325471	4
Mul_509	1608802724325440	1608802724325463	2	1608802724325477	4
Mul_293	1608802724325466	1608802724325491	3	1608802724325485	18
add_183	1608802724325494	1608802724325519	3	1608802724325512	24
Mul_310	1608802724325526	1608802724325550	7	1608802724325544	13
add_194	1608802724325553	1608802724325580	3	1608802724325570	13
add_356	1608802724325583	1608802724325608	3	1608802724325600	12
Mul_568	1608802724325611	1608802724325636	3	1608802724325631	11
add_366	1608802724325639	1608802724325662	3	1608802724325656	21
Mul_584	1608802724325669	1608802724325692	7	1608802724325686	19
add_376	1608802724325695	1608802724325720	3	1608802724325712	13
Mul_600	1608802724325723	1608802724325745	3	1608802724325740	11
add_393	1608802724325747	1608802724325774	2	1608802724325768	11
Mul_627	1608802724325777	1608802724325798	3	1608802724325794	10
add_406	1608802724325804	1608802724325831	6	1608802724325822	25
Mul_648	1608802724325834	1608802724325859	3	1608802724325850	17
Mul_192	1608802724325861	1608802724325883	2	1608802724325879	11
add_120	1608802724325886	1608802724325912	3	1608802724325906	11
Mul_202	1608802724325914	1608802724325935	2	1608802724325931	10
add_126	1608802724325950	1608802724325974	15	1608802724325968	11
add_444	1608802724325977	1608802724326003	3	1608802724325994	10
Mul_708	1608802724326006	1608802724326027	3	1608802724326023	10
add_322	1608802724326030	1608802724326060	3	1608802724326050	13
Mul_514	1608802724326063	1608802724326084	3	1608802724326080	10
add_329	1608802724326090	1608802724326114	6	1608802724326106	10
Mul_525	1608802724326117	1608802724326142	3	1608802724326134	11
Mul_299	1608802724326145	1608802724326168	3	1608802724326162	12
add_187	1608802724326170	1608802724326200	2	1608802724326191	12
Mul_315	1608802724326203	1608802724326224	3	1608802724326219	18
add_197	1608802724326226	1608802724326255	2	1608802724326247	23
add_511	1608802724326258	1608802724326285	3	1608802724326275	12
Mul_815	1608802724326289	1608802724326312	4	1608802724326306	12
add_379	1608802724326314	1608802724326342	2	1608802724326332	64
Mul_605	1608802724326345	1608802724326369	3	1608802724326398	39
add_396	1608802724326374	1608802724326399	5	1608802724326439	4
Mul_632	1608802724326402	1608802724326426	3	1608802724326445	4
add_410	1608802724326429	1608802724326452	3	1608802724326450	7
Mul_654	1608802724326454	1608802724326480	2	1608802724326471	14
add_424	1608802724326483	1608802724326508	3	1608802724326501	11
Mul_676	1608802724326511	1608802724326537	3	1608802724326531	11
add_433	1608802724326539	1608802724326568	2	1608802724326556	62
Mul_691	1608802724326571	1608802724326594	3	1608802724326619	39
add_447	1608802724326597	1608802724326622	3	1608802724326660	4
Mul_713	1608802724326625	1608802724326646	3	1608802724326666	4
Mul_207	1608802724326648	1608802724326673	2	1608802724326672	13
add_129	1608802724326677	1608802724326705	4	1608802724326694	22
add_471	1608802724326707	1608802724326733	2	1608802724326724	13
Mul_751	1608802724326735	1608802724326760	2	1608802724326751	14
Mul_530	1608802724326763	1608802724326787	3	1608802724326780	47
add_332	1608802724326789	1608802724326817	2	1608802724326828	56
add_342	1608802724326820	1608802724326846	3	1608802724326886	4
Mul_546	1608802724326848	1608802724326870	2	1608802724326891	4
add_514	1608802724326873	1608802724326899	3	1608802724326897	17
Mul_820	1608802724326901	1608802724326923	2	1608802724326918	17
Mul_321	1608802724326925	1608802724326951	2	1608802724326944	12
add_201	1608802724326953	1608802724326979	2	1608802724326970	10
add_383	1608802724326982	1608802724327005	3	1608802724326998	11
Mul_611	1608802724327008	1608802724327033	3	1608802724327024	14
add_399	1608802724327035	1608802724327058	2	1608802724327052	22
Mul_637	1608802724327061	1608802724327088	3	1608802724327081	20
add_413	1608802724327091	1608802724327117	3	1608802724327107	22
Mul_659	1608802724327119	1608802724327145	2	1608802724327136	20
add_427	1608802724327147	1608802724327174	2	1608802724327164	14
Mul_681	1608802724327177	1608802724327199	3	1608802724327194	11
add_437	1608802724327201	1608802724327230	2	1608802724327223	11
Mul_697	1608802724327233	1608802724327254	3	1608802724327249	11
add_450	1608802724327261	1608802724327284	7	1608802724327278	10
Mul_718	1608802724327287	1608802724327315	3	1608802724327303	17
add_457	1608802724327318	1608802724327343	3	1608802724327334	13
Mul_729	1608802724327345	1608802724327379	2	1608802724327373	11
add_474	1608802724327382	1608802724327407	3	1608802724327399	24
Mul_756	1608802724327414	1608802724327438	7	1608802724327431	20
Mul_213	1608802724327441	1608802724327465	3	1608802724327457	11
add_133	1608802724327467	1608802724327495	2	1608802724327486	13
Mul_536	1608802724327497	1608802724327523	2	1608802724327518	11
add_336	1608802724327526	1608802724327548	3	1608802724327542	10
add_345	1608802724327555	1608802724327581	7	1608802724327573	23
Mul_551	1608802724327585	1608802724327609	4	1608802724327601	17
Mul_261	1608802724327612	1608802724327634	3	1608802724327629	44
add_163	1608802724327636	1608802724327665	2	1608802724327675	56
add_370	1608802724327668	1608802724327690	3	1608802724327733	4
Mul_590	1608802724327696	1608802724327720	6	1608802724327738	4
add_386	1608802724327723	1608802724327750	3	1608802724327744	56
Mul_616	1608802724327753	1608802724327774	3	1608802724327802	39
add_561	1608802724327778	1608802724327805	4	1608802724327843	17
Mul_895	1608802724327809	1608802724327830	4	1608802724327862	12
Mul_917	1608802724327836	1608802724327859	6	1608802724327875	13
add_575	1608802724327861	1608802724327890	2	1608802724327890	17
Mul_939	1608802724327892	1608802724327914	2	1608802724327909	11
add_589	1608802724327916	1608802724327942	2	1608802724327935	11
add_440	1608802724327944	1608802724327965	2	1608802724327960	61
Mul_702	1608802724327971	1608802724327994	6	1608802724328023	39
Mul_981	1608802724327997	1608802724328021	3	1608802724328064	12
add_615	1608802724328023	1608802724328045	2	1608802724328078	17
add_460	1608802724328047	1608802724328075	2	1608802724328096	17
Mul_734	1608802724328078	1608802724328104	3	1608802724328115	12
add_478	1608802724328106	1608802724328129	2	1608802724328128	6
Mul_762	1608802724328132	1608802724328156	3	1608802724328148	13
add_484	1608802724328160	1608802724328184	4	1608802724328177	10
Mul_772	1608802724328186	1608802724328212	2	1608802724328206	11
add_498	1608802724328214	1608802724328237	2	1608802724328230	11
Mul_794	1608802724328243	1608802724328266	6	1608802724328260	12
add_518	1608802724328269	1608802724328296	3	1608802724328286	13
Mul_826	1608802724328298	1608802724328321	2	1608802724328315	12
add_521	1608802724328324	1608802724328352	3	1608802724328343	24
Mul_831	1608802724328356	1608802724328384	4	1608802724328378	18
Mul_240	1608802724328390	1608802724328414	6	1608802724328408	18
add_150	1608802724328418	1608802724328446	4	1608802724328435	22
add_373	1608802724328448	1608802724328474	2	1608802724328465	13
Mul_595	1608802724328477	1608802724328505	3	1608802724328499	11
add_565	1608802724328507	1608802724328530	2	1608802724328524	10
Mul_901	1608802724328536	1608802724328561	6	1608802724328553	13
Mul_923	1608802724328563	1608802724328591	2	1608802724328579	14
add_579	1608802724328593	1608802724328617	2	1608802724328610	11
Mul_944	1608802724328620	1608802724328646	3	1608802724328640	11
add_592	1608802724328648	1608802724328671	2	1608802724328665	10
Mul_960	1608802724328678	1608802724328705	7	1608802724328696	47
add_602	1608802724328708	1608802724328749	3	1608802724328747	56
Mul_987	1608802724328751	1608802724328775	2	1608802724328805	4
add_619	1608802724328778	1608802724328804	3	1608802724328810	4
add_633	1608802724328806	1608802724328828	2	1608802724328822	11
Mul_1009	1608802724328832	1608802724328858	4	1608802724328853	11
add_464	1608802724328861	1608802724328887	3	1608802724328878	10
Mul_740	1608802724328890	1608802724328913	3	1608802724328908	11
add_481	1608802724328916	1608802724328942	3	1608802724328932	13
Mul_767	1608802724328945	1608802724328968	3	1608802724328961	12
add_487	1608802724328971	1608802724328998	3	1608802724328992	60
Mul_777	1608802724329001	1608802724329025	3	1608802724329054	40
add_501	1608802724329027	1608802724329053	2	1608802724329096	5
Mul_799	1608802724329055	1608802724329082	2	1608802724329102	4
Mul_160	1608802724329085	1608802724329108	3	1608802724329107	7
add_100	1608802724329111	1608802724329140	3	1608802724329133	10
add_525	1608802724329142	1608802724329165	2	1608802724329159	11
Mul_837	1608802724329171	1608802724329194	6	1608802724329189	11
add_535	1608802724329197	1608802724329222	3	1608802724329212	13
Mul_853	1608802724329224	1608802724329245	2	1608802724329241	10
Mul_224	1608802724329248	1608802724329274	3	1608802724329267	12
add_140	1608802724329276	1608802724329299	2	1608802724329292	11
add_568	1608802724329306	1608802724329332	7	1608802724329324	23
Mul_906	1608802724329335	1608802724329361	3	1608802724329352	17
Mul_928	1608802724329363	1608802724329385	2	1608802724329381	18
add_582	1608802724329388	1608802724329415	3	1608802724329409	22
Mul_949	1608802724329418	1608802724329443	3	1608802724329435	48
add_595	1608802724329449	1608802724329473	6	1608802724329484	56
Mul_966	1608802724329475	1608802724329499	2	1608802724329542	4
add_606	1608802724329502	1608802724329524	3	1608802724329548	4
Mul_998	1608802724329526	1608802724329551	2	1608802724329554	5
add_626	1608802724329554	1608802724329576	3	1608802724329570	10
add_636	1608802724329582	1608802724329606	6	1608802724329599	21
Mul_1014	1608802724329609	1608802724329634	3	1608802724329625	18
add_453	1608802724329637	1608802724329661	3	1608802724329654	23
Mul_723	1608802724329664	1608802724329691	3	1608802724329685	17
add_467	1608802724329694	1608802724329719	3	1608802724329711	23
Mul_745	1608802724329724	1608802724329748	5	1608802724329742	19
add_673	1608802724329751	1608802724329777	3	1608802724329767	14
Mul_1073	1608802724329781	1608802724329803	4	1608802724329798	11
add_491	1608802724329806	1608802724329831	3	1608802724329825	11
Mul_783	1608802724329834	1608802724329855	3	1608802724329850	10
add_504	1608802724329861	1608802724329887	6	1608802724329878	13
Mul_804	1608802724329890	1608802724329918	3	1608802724329906	13
Mul_116	1608802724329921	1608802724329944	3	1608802724329938	12
add_72	1608802724329947	1608802724329975	3	1608802724329966	12
add_528	1608802724329978	1608802724330002	3	1608802724329996	22
Mul_842	1608802724330008	1608802724330031	6	1608802724330026	18
add_538	1608802724330034	1608802724330063	3	1608802724330051	11
Mul_858	1608802724330066	1608802724330088	3	1608802724330083	11
add_548	1608802724330091	1608802724330119	3	1608802724330110	64
Mul_874	1608802724330123	1608802724330144	4	1608802724330176	39
add_359	1608802724330149	1608802724330173	5	1608802724330217	17
Mul_573	1608802724330176	1608802724330211	3	1608802724330236	12
Mul_229	1608802724330214	1608802724330235	3	1608802724330249	12
add_143	1608802724330238	1608802724330265	3	1608802724330263	17
Mul_955	1608802724330267	1608802724330288	2	1608802724330284	11
add_599	1608802724330294	1608802724330319	6	1608802724330311	12
Mul_971	1608802724330321	1608802724330347	2	1608802724330338	10
add_609	1608802724330349	1608802724330374	2	1608802724330367	11
add_629	1608802724330376	1608802724330403	2	1608802724330397	23
Mul_1003	1608802724330406	1608802724330426	3	1608802724330422	17
add_640	1608802724330434	1608802724330457	8	1608802724330451	10
Mul_1020	1608802724330460	1608802724330484	3	1608802724330476	10
add_646	1608802724330486	1608802724330511	2	1608802724330504	11
Mul_1030	1608802724330513	1608802724330538	2	1608802724330533	11
add_660	1608802724330541	1608802724330568	3	1608802724330560	12
Mul_1052	1608802724330570	1608802724330595	2	1608802724330590	11
Mul_1078	1608802724330598	1608802724330624	3	1608802724330616	17
add_676	1608802724330626	1608802724330649	2	1608802724330643	22
Mul_1094	1608802724330652	1608802724330678	3	1608802724330672	11
add_686	1608802724330680	1608802724330702	2	1608802724330697	10
add_494	1608802724330707	1608802724330732	5	1608802724330725	62
Mul_788	1608802724330735	1608802724330759	3	1608802724330789	39
add_507	1608802724330761	1608802724330786	2	1608802724330830	17
Mul_809	1608802724330789	1608802724330814	3	1608802724330848	12
add_532	1608802724330816	1608802724330839	2	1608802724330862	4
Mul_848	1608802724330846	1608802724330870	7	1608802724330868	7
add_541	1608802724330872	1608802724330899	2	1608802724330890	61
Mul_863	1608802724330902	1608802724330926	3	1608802724330953	39
add_552	1608802724330929	1608802724330957	3	1608802724330994	5
Mul_880	1608802724330959	1608802724330984	2	1608802724331000	4
Mul_912	1608802724330990	1608802724331011	6	1608802724331006	11
add_572	1608802724331014	1608802724331047	3	1608802724331032	11
Mul_934	1608802724331050	1608802724331072	3	1608802724331067	11
add_586	1608802724331074	1608802724331104	2	1608802724331092	15
Mul_976	1608802724331106	1608802724331127	2	1608802724331123	10
add_612	1608802724331130	1608802724331158	3	1608802724331152	10
Mul_246	1608802724331161	1608802724331186	3	1608802724331177	11
add_154	1608802724331188	1608802724331212	2	1608802724331205	10
add_643	1608802724331215	1608802724331241	3	1608802724331231	13
Mul_1025	1608802724331243	1608802724331265	2	1608802724331260	11
add_649	1608802724331268	1608802724331294	3	1608802724331287	61
Mul_1035	1608802724331296	1608802724331324	2	1608802724331350	40
add_663	1608802724331326	1608802724331350	2	1608802724331391	5
Mul_1057	1608802724331352	1608802724331377	2	1608802724331398	4
Mul_1084	1608802724331379	1608802724331400	2	1608802724331403	5
add_680	1608802724331403	1608802724331429	3	1608802724331422	10
add_689	1608802724331431	1608802724331454	2	1608802724331448	11
Mul_1099	1608802724331460	1608802724331483	6	1608802724331477	11
Mul_13	1608802724331485	1608802724331510	2	1608802724331502	10
add_7	1608802724331512	1608802724331537	2	1608802724331530	10
add_545	1608802724331540	1608802724331566	3	1608802724331559	11
Mul_869	1608802724331568	1608802724331589	2	1608802724331585	10
add_555	1608802724331602	1608802724331627	13	1608802724331620	10
Mul_885	1608802724331630	1608802724331654	3	1608802724331646	10
Mul_138	1608802724331657	1608802724331678	3	1608802724331673	10
add_86	1608802724331680	1608802724331711	2	1608802724331702	13
Mul_197	1608802724331714	1608802724331737	3	1608802724331731	13
add_123	1608802724331743	1608802724331768	6	1608802724331761	11
Mul_235	1608802724331770	1608802724331794	2	1608802724331786	10
add_147	1608802724331798	1608802724331822	4	1608802724331815	11
add_653	1608802724331824	1608802724331851	2	1608802724331842	14
Mul_1041	1608802724331854	1608802724331876	3	1608802724331871	11
add_666	1608802724331878	1608802724331905	2	1608802724331899	11
Mul_1062	1608802724331908	1608802724331934	3	1608802724331925	12
Mul_1089	1608802724331937	1608802724331960	3	1608802724331954	12
add_683	1608802724331962	1608802724331988	2	1608802724331978	13
add_692	1608802724331990	1608802724332015	2	1608802724332007	13
Mul_1104	1608802724332020	1608802724332048	5	1608802724332041	12
Mul_326	1608802724332050	1608802724332075	2	1608802724332067	17
add_204	1608802724332077	1608802724332104	2	1608802724332095	24
add_558	1608802724332106	1608802724332134	2	1608802724332124	13
Mul_890	1608802724332136	1608802724332158	2	1608802724332153	11
Mul_111	1608802724332160	1608802724332185	2	1608802724332180	11
add_69	1608802724332187	1608802724332211	2	1608802724332205	10
Mul_181	1608802724332217	1608802724332881	6	1608802724332234	649
add_113	1608802724332884	1608802724332912	3	1608802724332903	11
add_656	1608802724332915	1608802724332937	3	1608802724332932	60
Mul_1046	1608802724332939	1608802724332961	2	1608802724332993	39
add_669	1608802724332963	1608802724332985	2	1608802724333034	17
Mul_1067	1608802724332988	1608802724333008	3	1608802724333052	12
Mul_251	1608802724333012	1608802724333033	4	1608802724333066	4
add_157	1608802724333036	1608802724333057	3	1608802724333072	4
Mul_1110	1608802724333060	1608802724333080	3	1608802724333077	9
add_696	1608802724333082	1608802724333103	2	1608802724333098	10
Mul_283	1608802724333106	1608802724333127	3	1608802724333123	10
add_177	1608802724333129	1608802724333150	2	1608802724333145	10
Mul_304	1608802724333152	1608802724333179	2	1608802724333169	17
add_190	1608802724333183	1608802724333207	4	1608802724333200	22
Mul_992	1608802724333209	1608802724333239	2	1608802724333226	25
add_622	1608802724333244	1608802724333268	5	1608802724333261	22
Mul_267	1608802724333271	1608802724333304	3	1608802724333298	11
add_167	1608802724333306	1608802724333332	2	1608802724333322	10
Mul_272	1608802724333335	1608802724333358	3	1608802724333353	45
add_170	1608802724333361	1608802724333386	3	1608802724333400	56
Mul_278	1608802724333389	1608802724333410	3	1608802724333458	4
add_174	1608802724333412	1608802724333439	2	1608802724333464	4
Mul_106	1608802724333442	1608802724333466	3	1608802724333470	4
add_66	1608802724333468	1608802724333493	2	1608802724333486	10
Mul_121	1608802724333495	1608802724333521	2	1608802724333512	17
add_75	1608802724333523	1608802724333545	2	1608802724333540	22
Mul_143	1608802724333548	1608802724333574	3	1608802724333569	18
add_89	1608802724333576	1608802724333598	2	1608802724333592	22
Mul_165	1608802724333605	1608802724333628	7	1608802724333623	11
add_103	1608802724333630	1608802724333657	2	1608802724333647	14
Mul_127	1608802724333660	1608802724333681	3	1608802724333676	11
add_79	1608802724333684	1608802724333711	3	1608802724333704	10
Mul_149	1608802724333715	1608802724333736	4	1608802724333732	10
add_93	1608802724333742	1608802724333765	6	1608802724333759	10
Mul_170	1608802724333768	1608802724333792	3	1608802724333784	10
add_106	1608802724333795	1608802724333817	3	1608802724333811	10
Mul_256	1608802724333820	1608802724333846	3	1608802724333840	11
add_160	1608802724333848	1608802724333870	2	1608802724333864	10
Mul_154	1608802724333873	1608802724333900	3	1608802724333895	17
add_96	1608802724333903	1608802724333929	3	1608802724333919	21
Mul_288	1608802724333931	1608802724333952	2	1608802724333948	11
add_180	1608802724333955	1608802724333984	3	1608802724333971	16
Mul_186	1608802724333986	1608802724334008	2	1608802724334004	44
add_116	1608802724334011	1608802724334038	3	1608802724334050	56
Mul_332	1608802724334041	1608802724334065	3	1608802724334107	5
add_208	1608802724334068	1608802724334091	3	1608802724334114	4
Mul_347	1608802724334093	1608802724334119	2	1608802724334120	39
add_217	1608802724334122	1608802724334144	3	1608802724334162	56
Mul_369	1608802724334147	1608802724334172	3	1608802724334219	4
add_231	1608802724334174	1608802724334200	2	1608802724334225	4
Mul_374	1608802724334202	1608802724334225	2	1608802724334230	4
add_234	1608802724334227	1608802724334252	2	1608802724334243	13
add_245	1608802724334255	1608802724334277	3	1608802724334271	21
Assign_214	1608802724334281	1608802724334335	4	1608802724334308	36
add_259	1608802724334338	1608802724334364	3	1608802724334356	23
Assign_226	1608802724334372	1608802724334403	8	1608802724334391	24
add_249	1608802724334406	1608802724334435	3	1608802724334423	15
Assign_217	1608802724334438	1608802724334467	3	1608802724334454	18
add_222	1608802724334470	1608802724334501	3	1608802724334491	13
Assign_193	1608802724334504	1608802724334535	3	1608802724334524	17
add_299	1608802724334543	1608802724334570	8	1608802724334562	23
Assign_262	1608802724334575	1608802724334623	5	1608802724334593	24
add_286	1608802724334626	1608802724334653	3	1608802724334644	12
Assign_250	1608802724334656	1608802724334690	3	1608802724334678	17
add_212	1608802724334693	1608802724334727	3	1608802724334710	12
Assign_184	1608802724334731	1608802724334761	4	1608802724334749	16
add_225	1608802724334763	1608802724334794	2	1608802724334781	61
Assign_196	1608802724334796	1608802724334825	2	1608802724334844	41
add_238	1608802724334828	1608802724334857	3	1608802724334887	18
Assign_208	1608802724334860	1608802724334891	3	1608802724334906	13
add_303	1608802724334893	1608802724334919	2	1608802724334921	5
Assign_265	1608802724334921	1608802724334961	2	1608802724334940	19
add_263	1608802724334965	1608802724334991	4	1608802724334983	12
Assign_229	1608802724334993	1608802724335028	2	1608802724335015	16
add_272	1608802724335030	1608802724335059	2	1608802724335048	61
Assign_238	1608802724335062	1608802724335089	3	1608802724335111	41
add_289	1608802724335091	1608802724335130	2	1608802724335153	5
Assign_253	1608802724335132	1608802724335160	2	1608802724335160	6
add_306	1608802724335167	1608802724335192	7	1608802724335185	23
Assign_268	1608802724335195	1608802724335225	3	1608802724335211	23
add_252	1608802724335228	1608802724335253	3	1608802724335246	23
Assign_220	1608802724335255	1608802724335286	2	1608802724335275	23
add_266	1608802724335288	1608802724335312	2	1608802724335305	11
Assign_232	1608802724335318	1608802724335350	6	1608802724335338	16
add_276	1608802724335352	1608802724335381	2	1608802724335370	14
Assign_241	1608802724335384	1608802724335412	3	1608802724335402	16
add_215	1608802724335415	1608802724335445	3	1608802724335438	12
Assign_187	1608802724335448	1608802724335477	3	1608802724335466	15
add_229	1608802724335483	1608802724335509	6	1608802724335502	11
Assign_199	1608802724335512	1608802724335541	3	1608802724335528	15
add_313	1608802724335544	1608802724335570	3	1608802724335562	23
Assign_274	1608802724335575	1608802724335608	5	1608802724335597	23
Assign_286	1608802724335611	1608802724335637	3	1608802724335628	49
add_326	1608802724335643	1608802724335668	6	1608802724335679	56
add_269	1608802724335671	1608802724335697	3	1608802724335737	5
Assign_235	1608802724335700	1608802724335727	3	1608802724335744	4
add_279	1608802724335730	1608802724335760	3	1608802724335752	62
Assign_244	1608802724335764	1608802724335792	4	1608802724335816	41
add_292	1608802724335798	1608802724335825	6	1608802724335859	17
Assign_256	1608802724335827	1608802724335861	2	1608802724335878	14
add_310	1608802724335863	1608802724335888	2	1608802724335893	4
Assign_271	1608802724335891	1608802724335921	3	1608802724335911	15
add_317	1608802724335924	1608802724335952	3	1608802724335941	11
Assign_277	1608802724335955	1608802724335985	3	1608802724335973	16
add_242	1608802724335988	1608802724336017	3	1608802724336006	14
Assign_211	1608802724336020	1608802724336066	3	1608802724336037	34
add_256	1608802724336069	1608802724336094	3	1608802724336087	11
Assign_223	1608802724336097	1608802724336125	3	1608802724336115	15
Assign_310	1608802724336128	1608802724336155	3	1608802724336146	22
add_353	1608802724336157	1608802724336182	2	1608802724336174	23
add_283	1608802724336187	1608802724336210	5	1608802724336203	11
Assign_247	1608802724336212	1608802724336240	2	1608802724336229	16
add_296	1608802724336252	1608802724336280	12	1608802724336272	12
Assign_259	1608802724336283	1608802724336313	3	1608802724336299	15
add_4	1608802724336316	1608802724336343	3	1608802724336334	527
Assign_1	1608802724336345	1608802724336390	2	1608802724336864	369
add_12	1608802724336393	1608802724336419	3	1608802724337235	14
Assign_7	1608802724336426	1608802724336455	7	1608802724337250	10
add_16	1608802724336457	1608802724336485	2	1608802724337261	4
Assign_10	1608802724336489	1608802724336517	4	1608802724337267	4
add_26	1608802724336520	1608802724336551	3	1608802724337272	4
Assign_19	1608802724336556	1608802724336584	5	1608802724337278	4
add_19	1608802724336590	1608802724336616	6	1608802724337283	4
Assign_13	1608802724336619	1608802724336650	3	1608802724337289	4
add_29	1608802724336652	1608802724336677	2	1608802724337294	17
Assign_22	1608802724336680	1608802724336710	3	1608802724337313	14
add_40	1608802724336712	1608802724336736	2	1608802724337328	5
Assign_31	1608802724336742	1608802724336768	6	1608802724337334	4
add_22	1608802724336771	1608802724336799	3	1608802724337340	17
Assign_16	1608802724336802	1608802724336829	3	1608802724337359	13
add_33	1608802724336832	1608802724336860	3	1608802724337374	4
Assign_25	1608802724336863	1608802724336888	3	1608802724337380	4
add_43	1608802724336896	1608802724336921	8	1608802724337386	17
Assign_34	1608802724336925	1608802724336955	4	1608802724337404	13
add_53	1608802724336958	1608802724336983	3	1608802724337419	5
Assign_43	1608802724336986	1608802724337017	3	1608802724337426	4
add_340	1608802724337020	1608802724337044	3	1608802724337431	4
Assign_298	1608802724337050	1608802724337076	6	1608802724337437	4
add_36	1608802724337079	1608802724337107	3	1608802724337442	17
Assign_28	1608802724337109	1608802724337135	2	1608802724337461	13
add_47	1608802724337137	1608802724337166	2	1608802724337476	4
Assign_37	1608802724337168	1608802724337193	2	1608802724337482	4
add_56	1608802724337203	1608802724337230	10	1608802724337487	56
Assign_46	1608802724337232	1608802724337262	2	1608802724337545	40
add_137	1608802724337265	1608802724337291	3	1608802724337587	17
Assign_118	1608802724337296	1608802724337326	5	1608802724337605	13
Assign_355	1608802724337329	1608802724337358	3	1608802724337620	4
add_404	1608802724337361	1608802724337389	3	1608802724337626	4
Assign_367	1608802724337393	1608802724337425	4	1608802724337631	4
add_418	1608802724337427	1608802724337452	2	1608802724337637	4
add_50	1608802724337455	1608802724337483	3	1608802724337643	5
Assign_40	1608802724337485	1608802724337511	2	1608802724337649	4
add_60	1608802724337517	1608802724337542	6	1608802724337654	5
Assign_49	1608802724337544	1608802724337576	2	1608802724337661	4
Assign_307	1608802724337579	1608802724337604	3	1608802724337666	4
add_350	1608802724337606	1608802724337635	2	1608802724337671	4
add_83	1608802724337638	1608802724337660	3	1608802724337677	17
Assign_70	1608802724337666	1608802724337694	6	1608802724337696	14
Assign_319	1608802724337696	1608802724337725	2	1608802724337712	18
add_364	1608802724337728	1608802724337753	3	1608802724337745	11
add_110	1608802724337755	1608802724337783	2	1608802724337776	61
Assign_94	1608802724337786	1608802724337813	3	1608802724337838	40
Assign_343	1608802724337829	1608802724337856	16	1608802724337880	4
add_391	1608802724337858	1608802724337887	2	1608802724337886	4
add_63	1608802724337890	1608802724337914	3	1608802724337907	61
Assign_52	1608802724337917	1608802724337949	3	1608802724337971	41
Assign_370	1608802724337952	1608802724337982	3	1608802724338014	14
add_421	1608802724337985	1608802724338010	3	1608802724338030	17
Assign_379	1608802724338012	1608802724338043	2	1608802724338048	4
add_431	1608802724338045	1608802724338070	2	1608802724338062	11
Assign_280	1608802724338072	1608802724338103	2	1608802724338093	15
add_320	1608802724338105	1608802724338136	2	1608802724338123	11
add_184	1608802724338138	1608802724338164	2	1608802724338157	23
Assign_160	1608802724338167	1608802724338200	3	1608802724338185	24
add_195	1608802724338203	1608802724338228	3	1608802724338220	11
Assign_169	1608802724338231	1608802724338263	3	1608802724338252	16
Assign_313	1608802724338266	1608802724338296	3	1608802724338283	14
add_357	1608802724338298	1608802724338326	2	1608802724338317	12
Assign_322	1608802724338328	1608802724338359	2	1608802724338344	26
add_367	1608802724338361	1608802724338386	2	1608802724338379	22
Assign_331	1608802724338388	1608802724338420	2	1608802724338408	16
add_377	1608802724338423	1608802724338451	3	1608802724338440	11
Assign_346	1608802724338454	1608802724338481	3	1608802724338471	15
add_394	1608802724338483	1608802724338512	2	1608802724338502	14
Assign_358	1608802724338516	1608802724338542	4	1608802724338532	23
add_407	1608802724338545	1608802724338574	3	1608802724338566	23
add_121	1608802724338578	1608802724338605	4	1608802724338594	11
Assign_103	1608802724338608	1608802724338635	3	1608802724338625	16
add_127	1608802724338638	1608802724338669	3	1608802724338657	15
Assign_109	1608802724338672	1608802724338698	3	1608802724338688	16
Assign_391	1608802724338700	1608802724338731	2	1608802724338722	15
add_445	1608802724338734	1608802724338764	3	1608802724338751	11
Assign_283	1608802724338768	1608802724338795	4	1608802724338785	15
add_323	1608802724338797	1608802724338826	2	1608802724338818	11
Assign_289	1608802724338829	1608802724338856	3	1608802724338846	15
add_330	1608802724338858	1608802724338889	2	1608802724338881	11
add_188	1608802724338891	1608802724338918	2	1608802724338908	10
Assign_163	1608802724338921	1608802724338948	3	1608802724338938	15
add_198	1608802724338950	1608802724338981	2	1608802724338968	23
Assign_172	1608802724338984	1608802724339011	3	1608802724339000	23
Assign_451	1608802724339013	1608802724339045	2	1608802724339036	15
add_512	1608802724339048	1608802724339080	3	1608802724339066	14
Assign_334	1608802724339082	1608802724339109	2	1608802724339099	50
add_380	1608802724339111	1608802724339140	2	1608802724339151	56
Assign_349	1608802724339142	1608802724339168	2	1608802724339209	4
add_397	1608802724339171	1608802724339200	3	1608802724339214	4
Assign_361	1608802724339202	1608802724339232	2	1608802724339220	13
add_411	1608802724339235	1608802724339261	3	1608802724339253	11
Assign_373	1608802724339264	1608802724339293	3	1608802724339280	18
add_425	1608802724339296	1608802724339321	3	1608802724339314	11
Assign_382	1608802724339324	1608802724339358	3	1608802724339347	50
add_434	1608802724339360	1608802724339389	2	1608802724339399	55
Assign_394	1608802724339392	1608802724339419	3	1608802724339456	5
add_448	1608802724339421	1608802724339461	2	1608802724339463	4
add_130	1608802724339464	1608802724339487	3	1608802724339481	23
Assign_112	1608802724339490	1608802724339520	3	1608802724339510	23
Assign_415	1608802724339523	1608802724339553	3	1608802724339540	14
add_472	1608802724339555	1608802724339582	2	1608802724339573	12
add_333	1608802724339584	1608802724339611	2	1608802724339601	60
Assign_292	1608802724339614	1608802724339641	3	1608802724339663	41
Assign_301	1608802724339643	1608802724339675	2	1608802724339705	4
add_343	1608802724339677	1608802724339705	2	1608802724339710	4
Assign_454	1608802724339708	1608802724339734	3	1608802724339724	23
add_515	1608802724339736	1608802724339764	2	1608802724339753	23
add_202	1608802724339767	1608802724339790	3	1608802724339784	10
Assign_175	1608802724339792	1608802724339825	2	1608802724339814	16
Assign_337	1608802724339827	1608802724339856	2	1608802724339843	14
add_384	1608802724339858	1608802724339883	2	1608802724339876	11
Assign_352	1608802724339886	1608802724339916	3	1608802724339902	23
add_400	1608802724339918	1608802724339943	2	1608802724339937	22
Assign_364	1608802724339945	1608802724339977	2	1608802724339968	23
add_414	1608802724339980	1608802724340009	3	1608802724339997	23
Assign_376	1608802724340011	1608802724340037	2	1608802724340027	15
add_428	1608802724340039	1608802724340071	2	1608802724340063	12
Assign_385	1608802724340074	1608802724340100	3	1608802724340090	15
add_438	1608802724340107	1608802724340133	7	1608802724340126	11
Assign_397	1608802724340136	1608802724340168	3	1608802724340154	15
add_451	1608802724340172	1608802724340198	4	1608802724340190	11
Assign_403	1608802724340200	1608802724340232	2	1608802724340217	20
add_458	1608802724340235	1608802724340259	3	1608802724340252	11
Assign_418	1608802724340262	1608802724340293	3	1608802724340283	22
add_475	1608802724340296	1608802724340326	3	1608802724340313	23
add_134	1608802724340330	1608802724340354	4	1608802724340347	11
Assign_115	1608802724340357	1608802724340397	3	1608802724340379	22
add_337	1608802724340399	1608802724340425	2	1608802724340418	11
Assign_295	1608802724340428	1608802724340458	3	1608802724340448	16
Assign_304	1608802724340461	1608802724340489	3	1608802724340477	21
add_346	1608802724340492	1608802724340517	3	1608802724340510	23
add_164	1608802724340519	1608802724340549	2	1608802724340542	61
Assign_142	1608802724340554	1608802724340581	5	1608802724340604	41
Assign_325	1608802724340588	1608802724340613	7	1608802724340646	4
add_371	1608802724340616	1608802724340647	3	1608802724340652	4
Assign_340	1608802724340650	1608802724340676	3	1608802724340666	50
add_387	1608802724340679	1608802724340709	3	1608802724340719	56
Assign_496	1608802724340712	1608802724340738	3	1608802724340776	13
add_562	1608802724340744	1608802724340770	6	1608802724340791	17
add_576	1608802724340774	1608802724340801	4	1608802724340810	17
Assign_508	1608802724340805	1608802724340832	4	1608802724340829	16
add_590	1608802724340835	1608802724340864	3	1608802724340856	11
Assign_520	1608802724340867	1608802724340893	3	1608802724340883	15
Assign_388	1608802724340904	1608802724340931	11	1608802724340920	50
add_441	1608802724340933	1608802724340961	2	1608802724340972	56
add_616	1608802724340964	1608802724340987	3	1608802724341030	17
Assign_544	1608802724340990	1608802724341020	3	1608802724341048	13
Assign_406	1608802724341023	1608802724341047	3	1608802724341063	14
add_461	1608802724341054	1608802724341081	7	1608802724341079	18
Assign_421	1608802724341083	1608802724341114	2	1608802724341099	19
add_479	1608802724341116	1608802724341142	2	1608802724341134	11
Assign_427	1608802724341144	1608802724341176	2	1608802724341165	16
add_485	1608802724341178	1608802724341204	2	1608802724341196	12
Assign_439	1608802724341211	1608802724341239	7	1608802724341228	16
add_499	1608802724341242	1608802724341271	3	1608802724341260	14
Assign_457	1608802724341274	1608802724341300	3	1608802724341290	16
add_519	1608802724341303	1608802724341334	3	1608802724341325	12
Assign_460	1608802724341338	1608802724341364	4	1608802724341354	23
add_522	1608802724341372	1608802724341398	8	1608802724341390	23
add_151	1608802724341401	1608802724341428	3	1608802724341417	22
Assign_130	1608802724341431	1608802724341457	3	1608802724341447	23
Assign_328	1608802724341459	1608802724341490	2	1608802724341480	15
add_374	1608802724341492	1608802724341517	2	1608802724341510	11
Assign_499	1608802724341524	1608802724341551	7	1608802724341541	15
add_566	1608802724341555	1608802724341584	4	1608802724341573	14
add_580	1608802724341587	1608802724341612	3	1608802724341605	12
Assign_511	1608802724341614	1608802724341646	2	1608802724341635	16
add_593	1608802724341649	1608802724341673	3	1608802724341666	11
Assign_523	1608802724341681	1608802724341709	8	1608802724341699	16
add_603	1608802724341712	1608802724341742	3	1608802724341730	61
Assign_532	1608802724341745	1608802724341771	3	1608802724341792	41
add_620	1608802724341773	1608802724341801	2	1608802724341835	4
Assign_547	1608802724341805	1608802724341832	4	1608802724341840	4
Assign_559	1608802724341839	1608802724341866	7	1608802724341856	15
add_634	1608802724341868	1608802724341897	2	1608802724341886	14
Assign_409	1608802724341900	1608802724341927	3	1608802724341917	15
add_465	1608802724341929	1608802724341959	2	1608802724341950	12
Assign_424	1608802724341962	1608802724341987	3	1608802724341978	15
add_482	1608802724341993	1608802724342019	6	1608802724342011	11
Assign_430	1608802724342021	1608802724342051	2	1608802724342038	49
add_488	1608802724342053	1608802724342080	2	1608802724342089	56
Assign_442	1608802724342083	1608802724342116	3	1608802724342146	5
add_502	1608802724342118	1608802724342143	2	1608802724342153	4
add_101	1608802724342150	1608802724342174	7	1608802724342167	11
Assign_85	1608802724342177	1608802724342207	3	1608802724342193	16
Assign_463	1608802724342210	1608802724342236	3	1608802724342227	15
add_526	1608802724342238	1608802724342268	2	1608802724342260	11
Assign_472	1608802724342271	1608802724342296	3	1608802724342287	15
add_536	1608802724342303	1608802724342330	7	1608802724342323	11
add_141	1608802724342332	1608802724342359	2	1608802724342349	10
Assign_121	1608802724342361	1608802724342388	2	1608802724342378	16
Assign_502	1608802724342391	1608802724342423	3	1608802724342409	26
add_569	1608802724342425	1608802724342451	2	1608802724342443	23
add_583	1608802724342458	1608802724342482	7	1608802724342476	22
Assign_514	1608802724342485	1608802724342521	3	1608802724342500	22
add_596	1608802724342524	1608802724342552	3	1608802724342544	61
Assign_526	1608802724342554	1608802724342585	2	1608802724342608	41
add_607	1608802724342588	1608802724342612	3	1608802724342650	5
Assign_535	1608802724342618	1608802724342644	6	1608802724342656	4
add_627	1608802724342647	1608802724342675	3	1608802724342664	11
Assign_553	1608802724342678	1608802724342704	3	1608802724342694	16
Assign_562	1608802724342707	1608802724342736	3	1608802724342726	22
add_637	1608802724342738	1608802724342763	2	1608802724342756	23
Assign_400	1608802724342770	1608802724342796	7	1608802724342786	22
add_454	1608802724342799	1608802724342829	3	1608802724342816	23
Assign_412	1608802724342831	1608802724342857	2	1608802724342848	22
add_468	1608802724342860	1608802724342889	3	1608802724342881	22
Assign_595	1608802724342892	1608802724342918	3	1608802724342908	15
add_674	1608802724342925	1608802724342952	7	1608802724342943	12
Assign_433	1608802724342957	1608802724342988	5	1608802724342973	20
add_492	1608802724342991	1608802724343016	3	1608802724343009	12
Assign_445	1608802724343019	1608802724343049	3	1608802724343039	16
add_505	1608802724343052	1608802724343076	3	1608802724343070	11
add_73	1608802724343083	1608802724343109	7	1608802724343102	11
Assign_61	1608802724343112	1608802724343142	3	1608802724343128	15
Assign_466	1608802724343145	1608802724343170	3	1608802724343161	23
add_529	1608802724343173	1608802724343202	3	1608802724343194	23
Assign_475	1608802724343205	1608802724343231	3	1608802724343221	15
add_539	1608802724343237	1608802724343263	6	1608802724343255	11
Assign_484	1608802724343265	1608802724343296	2	1608802724343282	50
add_549	1608802724343298	1608802724343324	2	1608802724343334	56
Assign_316	1608802724343327	1608802724343358	3	1608802724343392	13
add_360	1608802724343361	1608802724343385	3	1608802724343407	17
add_144	1608802724343394	1608802724343418	9	1608802724343425	17
Assign_124	1608802724343421	1608802724343450	3	1608802724343444	15
add_600	1608802724343453	1608802724343477	3	1608802724343471	11
Assign_529	1608802724343480	1608802724343510	3	1608802724343500	15
add_610	1608802724343513	1608802724343537	3	1608802724343530	11
Assign_538	1608802724343546	1608802724343573	9	1608802724343563	16
Assign_556	1608802724343576	1608802724343604	3	1608802724343592	21
add_630	1608802724343607	1608802724343632	3	1608802724343624	23
Assign_565	1608802724343634	1608802724343666	2	1608802724343655	16
add_641	1608802724343668	1608802724343692	2	1608802724343686	11
Assign_571	1608802724343701	1608802724343728	9	1608802724343718	16
add_647	1608802724343730	1608802724343760	2	1608802724343748	14
Assign_583	1608802724343762	1608802724343788	2	1608802724343779	15
add_661	1608802724343792	1608802724343822	4	1608802724343814	11
add_677	1608802724343825	1608802724343849	3	1608802724343843	22
Assign_598	1608802724343855	1608802724343882	6	1608802724343872	23
add_687	1608802724343884	1608802724343913	2	1608802724343902	15
Assign_607	1608802724343918	1608802724343944	5	1608802724343934	16
Assign_436	1608802724343947	1608802724343976	3	1608802724343966	50
add_495	1608802724343978	1608802724344004	2	1608802724344018	56
Assign_448	1608802724344012	1608802724344039	8	1608802724344075	14
add_508	1608802724344041	1608802724344070	2	1608802724344091	17
Assign_469	1608802724344073	1608802724344098	3	1608802724344110	5
add_533	1608802724344100	1608802724344139	2	1608802724344130	12
Assign_478	1608802724344142	1608802724344168	3	1608802724344159	50
add_542	1608802724344174	1608802724344200	6	1608802724344210	56
Assign_487	1608802724344202	1608802724344233	2	1608802724344268	4
add_553	1608802724344236	1608802724344260	3	1608802724344274	4
add_573	1608802724344263	1608802724344291	3	1608802724344284	11
Assign_505	1608802724344293	1608802724344320	2	1608802724344310	16
add_587	1608802724344327	1608802724344353	7	1608802724344345	12
Assign_517	1608802724344355	1608802724344398	2	1608802724344378	17
add_613	1608802724344401	1608802724344429	3	1608802724344421	12
Assign_541	1608802724344431	1608802724344461	2	1608802724344451	16
add_155	1608802724344464	1608802724344489	3	1608802724344482	10
Assign_133	1608802724344495	1608802724344522	6	1608802724344512	16
Assign_568	1608802724344525	1608802724344554	3	1608802724344541	18
add_644	1608802724344556	1608802724344582	2	1608802724344574	11
Assign_574	1608802724344587	1608802724344617	5	1608802724344606	50
add_650	1608802724344619	1608802724344645	2	1608802724344659	55
Assign_586	1608802724344652	1608802724344679	7	1608802724344716	4
add_664	1608802724344681	1608802724344710	2	1608802724344721	4
add_681	1608802724344715	1608802724344739	5	1608802724344731	11
Assign_601	1608802724344743	1608802724344773	4	1608802724344763	16
Assign_610	1608802724344776	1608802724344801	3	1608802724344792	15
add_690	1608802724344807	1608802724344833	6	1608802724344825	11
add_8	1608802724344835	1608802724344862	2	1608802724344852	10
Assign_4	1608802724344866	1608802724344894	4	1608802724344883	16
Assign_481	1608802724344896	1608802724344930	2	1608802724344916	19
add_546	1608802724344933	1608802724344957	3	1608802724344950	11
Assign_490	1608802724344963	1608802724344990	6	1608802724344980	15
add_556	1608802724344993	1608802724345022	3	1608802724345010	14
add_87	1608802724345025	1608802724345047	3	1608802724345041	11
Assign_73	1608802724345051	1608802724345081	4	1608802724345071	15
add_124	1608802724345084	1608802724345108	3	1608802724345101	11
Assign_106	1608802724345116	1608802724345142	8	1608802724345133	16
add_148	1608802724345145	1608802724345174	3	1608802724345162	11
Assign_127	1608802724345177	1608802724345204	3	1608802724345194	16
Assign_577	1608802724345207	1608802724345236	3	1608802724345227	15
add_654	1608802724345239	1608802724345264	3	1608802724345257	11
Assign_589	1608802724345270	1608802724345297	6	1608802724345287	16
add_667	1608802724345300	1608802724345328	3	1608802724345318	10
add_684	1608802724345331	1608802724345355	3	1608802724345349	11
Assign_604	1608802724345358	1608802724345389	3	1608802724345374	19
Assign_613	1608802724345391	1608802724345417	2	1608802724345408	14
add_693	1608802724345424	1608802724345450	7	1608802724345443	11
add_205	1608802724345453	1608802724345480	3	1608802724345470	22
Assign_178	1608802724345483	1608802724345512	3	1608802724345502	23
Assign_493	1608802724345514	1608802724345543	2	1608802724345534	15
add_559	1608802724345546	1608802724345570	3	1608802724345564	11
add_70	1608802724345573	1608802724345600	3	1608802724345594	10
Assign_58	1608802724345603	1608802724345641	3	1608802724345619	15
add_114	1608802724345644	1608802724345671	3	1608802724345663	12
Assign_97	1608802724345674	1608802724345704	3	1608802724345690	19
Assign_580	1608802724345707	1608802724345732	3	1608802724345724	49
add_657	1608802724345738	1608802724345764	6	1608802724345775	56
Assign_592	1608802724345767	1608802724345797	3	1608802724345832	14
add_670	1608802724345800	1608802724345825	3	1608802724345848	17
add_158	1608802724345829	1608802724345856	4	1608802724345867	5
Assign_136	1608802724345858	1608802724345884	2	1608802724345875	15
add_697	1608802724345891	1608802724345917	7	1608802724345910	11
Assign_616	1608802724345919	1608802724345949	2	1608802724345936	16
add_178	1608802724345953	1608802724345979	4	1608802724345972	11
Assign_154	1608802724345982	1608802724346012	3	1608802724345999	18
add_191	1608802724346015	1608802724346041	3	1608802724346033	22
Assign_166	1608802724346048	1608802724346075	7	1608802724346065	23
add_623	1608802724346077	1608802724346105	2	1608802724346094	22
Assign_550	1608802724346109	1608802724346136	4	1608802724346126	23
add_168	1608802724346138	1608802724346167	2	1608802724346160	11
Assign_145	1608802724346169	1608802724346195	2	1608802724346186	15
add_171	1608802724346202	1608802724346228	7	1608802724346221	61
Assign_148	1608802724346231	1608802724346261	3	1608802724346284	41
add_175	1608802724346264	1608802724346290	3	1608802724346326	5
Assign_151	1608802724346293	1608802724346323	3	1608802724346332	4
add_67	1608802724346325	1608802724346350	2	1608802724346343	11
Assign_55	1608802724346358	1608802724346386	8	1608802724346375	15
add_76	1608802724346388	1608802724346417	2	1608802724346406	22
Assign_64	1608802724346419	1608802724346445	2	1608802724346435	23
add_90	1608802724346448	1608802724346477	3	1608802724346470	23
Assign_76	1608802724346479	1608802724346504	2	1608802724346495	22
add_104	1608802724346511	1608802724346535	7	1608802724346529	11
Assign_88	1608802724346538	1608802724346568	3	1608802724346554	18
add_80	1608802724346570	1608802724346595	2	1608802724346588	12
Assign_67	1608802724346597	1608802724346629	2	1608802724346619	16
add_94	1608802724346632	1608802724346656	3	1608802724346650	11
Assign_79	1608802724346663	1608802724346689	7	1608802724346680	15
add_107	1608802724346692	1608802724346720	3	1608802724346710	14
Assign_91	1608802724346722	1608802724346749	2	1608802724346739	16
add_161	1608802724346751	1608802724346781	2	1608802724346774	12
Assign_139	1608802724346784	1608802724346811	3	1608802724346801	16
add_97	1608802724346817	1608802724346844	6	1608802724346837	22
Assign_82	1608802724346847	1608802724346878	3	1608802724346863	22
add_181	1608802724346881	1608802724346905	3	1608802724346899	11
Assign_157	1608802724346908	1608802724346938	3	1608802724346928	16
add_117	1608802724346941	1608802724346970	3	1608802724346958	61
Assign_100	1608802724346973	1608802724346999	3	1608802724347021	42
add_209	1608802724347001	1608802724347028	2	1608802724347065	4
Assign_181	1608802724347031	1608802724347057	3	1608802724347070	4
add_218	1608802724347060	1608802724347091	3	1608802724347084	62
Assign_190	1608802724347094	1608802724347124	3	1608802724347147	41
add_232	1608802724347128	1608802724347153	4	1608802724347190	4
Assign_202	1608802724347156	1608802724347185	3	1608802724347196	4
add_235	1608802724347188	1608802724347213	3	1608802724347205	12
Assign_205	1608802724347215	1608802724347253	2	1608802724347243	16
Sqrt_71	1608802724347256	1608802724347287	3	1608802724347276	19
Assign_215	1608802724347293	1608802724347322	6	1608802724347310	23
Sqrt_75	1608802724347324	1608802724347354	2	1608802724347344	23
Assign_227	1608802724347360	1608802724347387	6	1608802724347377	22
Sqrt_72	1608802724347394	1608802724347419	7	1608802724347414	11
Assign_218	1608802724347423	1608802724347453	4	1608802724347439	16
Sqrt_64	1608802724347456	1608802724347480	3	1608802724347475	11
Assign_194	1608802724347483	1608802724347513	3	1608802724347502	15
Sqrt_87	1608802724347515	1608802724347730	2	1608802724347534	206
Assign_263	1608802724347739	1608802724347769	9	1608802724347757	24
Sqrt_83	1608802724347772	1608802724347796	3	1608802724347791	11
Assign_251	1608802724347798	1608802724347824	2	1608802724347814	15
Sqrt_61	1608802724347827	1608802724347849	3	1608802724347844	11
Assign_185	1608802724347854	1608802724347880	5	1608802724347870	16
Sqrt_65	1608802724347883	1608802724347906	3	1608802724347901	46
Assign_197	1608802724347912	1608802724347939	6	1608802724347949	42
Sqrt_69	1608802724347941	1608802724347964	2	1608802724347992	13
Assign_209	1608802724347968	1608802724347995	4	1608802724348008	14
Sqrt_88	1608802724347997	1608802724348020	2	1608802724348023	5
Assign_266	1608802724348023	1608802724348050	3	1608802724348040	15
Sqrt_76	1608802724348052	1608802724348076	2	1608802724348071	12
Assign_230	1608802724348078	1608802724348104	2	1608802724348094	15
Sqrt_79	1608802724348106	1608802724348128	2	1608802724348123	46
Assign_239	1608802724348133	1608802724348159	5	1608802724348171	41
Sqrt_84	1608802724348162	1608802724348185	3	1608802724348214	5
Assign_254	1608802724348187	1608802724348212	2	1608802724348220	4
Sqrt_89	1608802724348214	1608802724348237	2	1608802724348232	17
Assign_269	1608802724348242	1608802724348268	5	1608802724348258	21
Sqrt_73	1608802724348270	1608802724348293	2	1608802724348288	18
Assign_221	1608802724348298	1608802724348324	5	1608802724348314	22
Sqrt_77	1608802724348327	1608802724348351	3	1608802724348345	11
Assign_233	1608802724348353	1608802724348387	2	1608802724348376	16
Sqrt_80	1608802724348390	1608802724348414	3	1608802724348409	11
Assign_242	1608802724348418	1608802724348445	4	1608802724348435	15
Sqrt_62	1608802724348448	1608802724348471	3	1608802724348466	11
Assign_188	1608802724348474	1608802724348499	3	1608802724348490	14
Sqrt_66	1608802724348501	1608802724348524	2	1608802724348519	11
Assign_200	1608802724348528	1608802724348560	4	1608802724348544	18
Sqrt_91	1608802724348563	1608802724348589	3	1608802724348582	18
Assign_275	1608802724348595	1608802724348623	6	1608802724348612	22
Sqrt_95	1608802724348626	1608802724348648	3	1608802724348644	46
Assign_287	1608802724348655	1608802724348681	7	1608802724348691	40
Sqrt_78	1608802724348684	1608802724348708	3	1608802724348733	5
Assign_236	1608802724348710	1608802724348738	2	1608802724348739	4
Sqrt_81	1608802724348740	1608802724348763	2	1608802724348758	48
Assign_245	1608802724348769	1608802724348796	6	1608802724348807	41
Sqrt_85	1608802724348798	1608802724348822	2	1608802724348850	12
Assign_257	1608802724348826	1608802724348852	4	1608802724348864	13
Sqrt_90	1608802724348854	1608802724348877	2	1608802724348878	5
Assign_272	1608802724348880	1608802724348908	3	1608802724348897	15
Sqrt_92	1608802724348910	1608802724348934	2	1608802724348929	11
Assign_278	1608802724348936	1608802724348964	2	1608802724348954	15
Sqrt_70	1608802724348966	1608802724348989	2	1608802724348984	11
Assign_212	1608802724348991	1608802724349018	2	1608802724349009	15
Sqrt_74	1608802724349021	1608802724349044	3	1608802724349039	11
Assign_224	1608802724349046	1608802724349071	2	1608802724349061	15
Sqrt_103	1608802724349074	1608802724349097	3	1608802724349092	18
Assign_311	1608802724349101	1608802724349127	4	1608802724349117	22
Sqrt_82	1608802724349130	1608802724349158	3	1608802724349148	16
Assign_248	1608802724349162	1608802724349188	4	1608802724349178	15
Sqrt_86	1608802724349190	1608802724349213	2	1608802724349208	11
Assign_260	1608802724349215	1608802724349240	2	1608802724349231	14
Sqrt	1608802724349242	1608802724349265	2	1608802724349261	374
Assign_2	1608802724349270	1608802724349302	5	1608802724349638	369
Sqrt_2	1608802724349304	1608802724349327	2	1608802724350009	10
Assign_8	1608802724349331	1608802724349357	4	1608802724350020	8
Sqrt_3	1608802724349360	1608802724349382	3	1608802724350030	5
Assign_11	1608802724349384	1608802724349411	2	1608802724350036	4
Sqrt_6	1608802724349414	1608802724349436	3	1608802724350041	5
Assign_20	1608802724349440	1608802724349465	4	1608802724350048	4
Sqrt_4	1608802724349468	1608802724349491	3	1608802724350053	4
Assign_14	1608802724349493	1608802724349518	2	1608802724350058	4
Sqrt_7	1608802724349520	1608802724349543	2	1608802724350064	12
Assign_23	1608802724349548	1608802724349574	5	1608802724350077	13
Sqrt_10	1608802724349576	1608802724349599	2	1608802724350092	4
Assign_32	1608802724349603	1608802724349629	4	1608802724350098	4
Sqrt_5	1608802724349631	1608802724349653	2	1608802724350104	12
Assign_17	1608802724349658	1608802724349684	5	1608802724350117	13
Sqrt_8	1608802724349686	1608802724349709	2	1608802724350132	5
Assign_26	1608802724349711	1608802724349736	2	1608802724350138	4
Sqrt_11	1608802724349738	1608802724349760	2	1608802724350143	14
Assign_35	1608802724349767	1608802724349794	7	1608802724350158	14
Sqrt_14	1608802724349797	1608802724349820	3	1608802724350173	5
Assign_44	1608802724349822	1608802724349847	2	1608802724350181	4
Sqrt_99	1608802724349851	1608802724349874	4	1608802724350186	5
Assign_299	1608802724349876	1608802724349904	2	1608802724350192	4
Sqrt_9	1608802724349906	1608802724349929	2	1608802724350197	12
Assign_29	1608802724349934	1608802724349960	5	1608802724350211	14
Sqrt_12	1608802724349968	1608802724349993	8	1608802724350226	4
Assign_38	1608802724349995	1608802724350027	2	1608802724350232	4
Sqrt_15	1608802724350029	1608802724350053	2	1608802724350238	41
Assign_47	1608802724350059	1608802724350092	6	1608802724350280	41
Sqrt_39	1608802724350095	1608802724350119	3	1608802724350322	12
Assign_119	1608802724350129	1608802724350157	10	1608802724350336	14
Sqrt_118	1608802724350160	1608802724350187	3	1608802724350351	5
Assign_356	1608802724350191	1608802724350217	4	1608802724350358	4
Sqrt_122	1608802724350219	1608802724350257	2	1608802724350363	5
Assign_368	1608802724350259	1608802724350290	2	1608802724350369	4
Sqrt_13	1608802724350292	1608802724350316	2	1608802724350375	5
Assign_41	1608802724350318	1608802724350348	2	1608802724350381	4
Sqrt_16	1608802724350351	1608802724350375	3	1608802724350386	5
Assign_50	1608802724350377	1608802724350408	2	1608802724350397	15
Sqrt_102	1608802724350411	1608802724350439	3	1608802724350430	11
Assign_308	1608802724350441	1608802724350468	2	1608802724350458	15
Sqrt_23	1608802724350471	1608802724350501	3	1608802724350489	24
Assign_71	1608802724350507	1608802724350534	6	1608802724350523	22
Sqrt_106	1608802724350541	1608802724350565	7	1608802724350560	12
Assign_320	1608802724350569	1608802724350600	4	1608802724350585	15
Sqrt_31	1608802724350602	1608802724350626	2	1608802724350621	46
Assign_95	1608802724350631	1608802724350664	5	1608802724350669	40
Sqrt_114	1608802724350666	1608802724350690	2	1608802724350711	4
Assign_344	1608802724350697	1608802724350724	7	1608802724350717	12
Sqrt_17	1608802724350727	1608802724350755	3	1608802724350745	47
Assign_53	1608802724350760	1608802724350788	5	1608802724350795	41
Sqrt_123	1608802724350791	1608802724350820	3	1608802724350838	14
Assign_371	1608802724350825	1608802724350857	5	1608802724350854	13
Sqrt_126	1608802724350860	1608802724350884	3	1608802724350879	12
Assign_380	1608802724350888	1608802724350917	4	1608802724350904	18
Sqrt_93	1608802724350920	1608802724350944	3	1608802724350938	11
Assign_281	1608802724350946	1608802724350977	2	1608802724350967	15
Sqrt_53	1608802724350980	1608802724351010	3	1608802724350998	18
Assign_161	1608802724351016	1608802724351043	6	1608802724351032	23
Sqrt_56	1608802724351046	1608802724351074	3	1608802724351068	11
Assign_170	1608802724351078	1608802724351105	4	1608802724351095	15
Sqrt_104	1608802724351111	1608802724351135	6	1608802724351130	12
Assign_314	1608802724351137	1608802724351167	2	1608802724351153	14
Sqrt_107	1608802724351170	1608802724351194	3	1608802724351188	18
Assign_323	1608802724351199	1608802724351231	5	1608802724351220	22
Sqrt_110	1608802724351234	1608802724351258	3	1608802724351253	11
Assign_332	1608802724351265	1608802724351292	7	1608802724351282	15
Sqrt_115	1608802724351295	1608802724351322	3	1608802724351313	15
Assign_347	1608802724351325	1608802724351351	3	1608802724351341	15
Sqrt_119	1608802724351354	1608802724351383	3	1608802724351378	18
Assign_359	1608802724351389	1608802724351421	6	1608802724351406	23
Sqrt_34	1608802724351424	1608802724351449	3	1608802724351443	11
Assign_104	1608802724351453	1608802724351483	4	1608802724351469	18
Sqrt_36	1608802724351485	1608802724351510	2	1608802724351504	12
Assign_110	1608802724351512	1608802724351543	2	1608802724351533	15
Sqrt_130	1608802724351545	1608802724351573	2	1608802724351564	11
Assign_392	1608802724351577	1608802724351604	4	1608802724351594	15
Sqrt_94	1608802724351607	1608802724351635	3	1608802724351625	16
Assign_284	1608802724351638	1608802724351666	3	1608802724351656	14
Sqrt_96	1608802724351669	1608802724351696	3	1608802724351691	11
Assign_290	1608802724351699	1608802724351728	3	1608802724351715	14
Sqrt_54	1608802724351731	1608802724351755	3	1608802724351749	12
Assign_164	1608802724351757	1608802724351790	2	1608802724351773	21
Sqrt_57	1608802724351793	1608802724351816	3	1608802724351811	18
Assign_173	1608802724351832	1608802724351860	16	1608802724351849	23
Sqrt_150	1608802724351863	1608802724351891	3	1608802724351881	12
Assign_452	1608802724351894	1608802724351921	3	1608802724351911	15
Sqrt_111	1608802724351924	1608802724351954	3	1608802724351948	47
Assign_335	1608802724351960	1608802724351987	6	1608802724351997	41
Sqrt_116	1608802724351994	1608802724352019	7	1608802724352039	4
Assign_350	1608802724352021	1608802724352069	2	1608802724352045	28
Sqrt_120	1608802724352073	1608802724352097	4	1608802724352091	11
Assign_362	1608802724352099	1608802724352125	2	1608802724352115	15
Sqrt_124	1608802724352127	1608802724352150	2	1608802724352145	11
Assign_374	1608802724352152	1608802724352177	2	1608802724352167	14
Sqrt_127	1608802724352179	1608802724352204	2	1608802724352199	46
Assign_383	1608802724352209	1608802724352236	5	1608802724352247	41
Sqrt_131	1608802724352239	1608802724352262	3	1608802724352289	5
Assign_395	1608802724352264	1608802724352291	2	1608802724352297	4
Sqrt_37	1608802724352293	1608802724352315	2	1608802724352311	18
Assign_113	1608802724352320	1608802724352349	5	1608802724352336	25
Sqrt_138	1608802724352352	1608802724352383	3	1608802724352376	13
Assign_416	1608802724352388	1608802724352420	5	1608802724352409	16
Sqrt_97	1608802724352423	1608802724352452	3	1608802724352442	47
Assign_293	1608802724352457	1608802724352486	5	1608802724352490	41
Sqrt_100	1608802724352488	1608802724352518	2	1608802724352533	4
Assign_302	1608802724352521	1608802724352548	3	1608802724352539	14
Sqrt_151	1608802724352557	1608802724352582	9	1608802724352577	18
Assign_455	1608802724352587	1608802724352619	5	1608802724352604	22
Sqrt_58	1608802724352623	1608802724352647	4	1608802724352641	12
Assign_176	1608802724352649	1608802724352679	2	1608802724352668	15
Sqrt_112	1608802724352681	1608802724352704	2	1608802724352700	11
Assign_338	1608802724352710	1608802724352738	6	1608802724352727	15
Sqrt_117	1608802724352740	1608802724352769	2	1608802724352759	18
Assign_353	1608802724352776	1608802724352803	7	1608802724352792	23
Sqrt_121	1608802724352805	1608802724352834	2	1608802724352829	18
Assign_365	1608802724352838	1608802724352869	4	1608802724352855	22
Sqrt_125	1608802724352871	1608802724352895	2	1608802724352890	12
Assign_377	1608802724352897	1608802724352927	2	1608802724352914	18
Sqrt_128	1608802724352930	1608802724352953	3	1608802724352948	11
Assign_386	1608802724352958	1608802724352985	5	1608802724352975	15
Sqrt_132	1608802724352989	1608802724353018	4	1608802724353007	11
Assign_398	1608802724353021	1608802724353048	3	1608802724353037	15
Sqrt_134	1608802724353050	1608802724353078	2	1608802724353073	11
Assign_404	1608802724353082	1608802724353108	4	1608802724353098	15
Sqrt_139	1608802724353115	1608802724353139	7	1608802724353133	19
Assign_419	1608802724353144	1608802724353175	5	1608802724353161	22
Sqrt_38	1608802724353178	1608802724353202	3	1608802724353196	11
Assign_116	1608802724353204	1608802724353235	2	1608802724353225	15
Sqrt_98	1608802724353238	1608802724353262	3	1608802724353256	12
Assign_296	1608802724353268	1608802724353294	6	1608802724353284	15
Sqrt_101	1608802724353297	1608802724353333	3	1608802724353315	23
Assign_305	1608802724353339	1608802724353367	6	1608802724353356	23
Sqrt_47	1608802724353370	1608802724353400	3	1608802724353393	47
Assign_143	1608802724353405	1608802724353436	5	1608802724353443	42
Sqrt_108	1608802724353439	1608802724353465	3	1608802724353486	5
Assign_326	1608802724353467	1608802724353500	2	1608802724353492	12
Sqrt_113	1608802724353502	1608802724353525	2	1608802724353520	46
Assign_341	1608802724353535	1608802724353562	10	1608802724353568	41
Sqrt_165	1608802724353565	1608802724353593	3	1608802724353611	12
Assign_497	1608802724353597	1608802724353625	4	1608802724353625	13
Sqrt_169	1608802724353628	1608802724353660	3	1608802724353653	19
Assign_509	1608802724353665	1608802724353698	5	1608802724353682	23
Sqrt_173	1608802724353700	1608802724353727	2	1608802724353721	12
Assign_521	1608802724353730	1608802724353761	3	1608802724353746	19
Sqrt_129	1608802724353764	1608802724353787	3	1608802724353782	47
Assign_389	1608802724353792	1608802724353825	5	1608802724353830	41
Sqrt_181	1608802724353828	1608802724353856	3	1608802724353873	12
Assign_545	1608802724353862	1608802724353890	6	1608802724353886	15
Sqrt_135	1608802724353892	1608802724353921	2	1608802724353915	18
Assign_407	1608802724353925	1608802724353952	4	1608802724353941	23
Sqrt_140	1608802724353959	1608802724353983	7	1608802724353977	11
Assign_422	1608802724353985	1608802724354016	2	1608802724354001	19
Sqrt_142	1608802724354019	1608802724354042	3	1608802724354038	12
Assign_428	1608802724354045	1608802724354075	3	1608802724354064	15
Sqrt_146	1608802724354077	1608802724354105	2	1608802724354096	11
Assign_440	1608802724354107	1608802724354135	2	1608802724354125	15
Sqrt_152	1608802724354137	1608802724354164	2	1608802724354155	15
Assign_458	1608802724354166	1608802724354192	2	1608802724354182	15
Sqrt_153	1608802724354194	1608802724354222	2	1608802724354216	18
Assign_461	1608802724354229	1608802724354260	7	1608802724354245	23
Sqrt_43	1608802724354263	1608802724354288	3	1608802724354282	19
Assign_131	1608802724354293	1608802724354325	5	1608802724354314	23
Sqrt_109	1608802724354328	1608802724354351	3	1608802724354347	11
Assign_329	1608802724354358	1608802724354384	7	1608802724354374	15
Sqrt_166	1608802724354387	1608802724354417	3	1608802724354405	17
Assign_500	1608802724354419	1608802724354446	2	1608802724354435	16
Sqrt_170	1608802724354449	1608802724354478	3	1608802724354472	12
Assign_512	1608802724354481	1608802724354508	3	1608802724354498	15
Sqrt_174	1608802724354514	1608802724354539	6	1608802724354533	12
Assign_524	1608802724354541	1608802724354573	2	1608802724354557	19
Sqrt_177	1608802724354575	1608802724354599	2	1608802724354593	48
Assign_533	1608802724354604	1608802724354635	5	1608802724354643	41
Sqrt_182	1608802724354638	1608802724354666	3	1608802724354685	5
Assign_548	1608802724354669	1608802724354697	3	1608802724354692	10
Sqrt_186	1608802724354700	1608802724354729	3	1608802724354719	15
Assign_560	1608802724354733	1608802724354759	4	1608802724354749	15
Sqrt_136	1608802724354763	1608802724354790	4	1608802724354785	11
Assign_410	1608802724354792	1608802724354822	2	1608802724354808	15
Sqrt_141	1608802724354825	1608802724354849	3	1608802724354843	12
Assign_425	1608802724354851	1608802724354890	2	1608802724354867	27
Sqrt_143	1608802724354893	1608802724354917	3	1608802724354911	47
Assign_431	1608802724354926	1608802724354954	9	1608802724354960	41
Sqrt_147	1608802724354958	1608802724354986	4	1608802724355003	4
Assign_443	1608802724354988	1608802724355014	2	1608802724355009	10
Sqrt_28	1608802724355016	1608802724355044	2	1608802724355038	12
Assign_86	1608802724355047	1608802724355075	3	1608802724355064	15
Sqrt_154	1608802724355081	1608802724355106	6	1608802724355100	12
Assign_464	1608802724355108	1608802724355138	2	1608802724355124	18
Sqrt_157	1608802724355140	1608802724355164	2	1608802724355159	11
Assign_473	1608802724355166	1608802724355196	2	1608802724355186	15
Sqrt_40	1608802724355199	1608802724355226	3	1608802724355217	11
Assign_122	1608802724355228	1608802724355256	2	1608802724355245	15
Sqrt_167	1608802724355258	1608802724355286	2	1608802724355276	19
Assign_503	1608802724355292	1608802724355319	6	1608802724355309	22
Sqrt_171	1608802724355322	1608802724355353	3	1608802724355347	18
Assign_515	1608802724355357	1608802724355390	4	1608802724355374	21
Sqrt_175	1608802724355392	1608802724355417	2	1608802724355411	47
Assign_527	1608802724355423	1608802724355456	6	1608802724355460	42
Sqrt_178	1608802724355459	1608802724355482	3	1608802724355504	4
Assign_536	1608802724355488	1608802724355515	6	1608802724355510	10
Sqrt_184	1608802724355518	1608802724355545	3	1608802724355536	14
Assign_554	1608802724355547	1608802724355574	2	1608802724355564	16
Sqrt_187	1608802724355576	1608802724355606	2	1608802724355600	18
Assign_563	1608802724355611	1608802724355642	5	1608802724355628	22
Sqrt_133	1608802724355644	1608802724355670	2	1608802724355664	18
Assign_401	1608802724355674	1608802724355706	4	1608802724355691	23
Sqrt_137	1608802724355708	1608802724355732	2	1608802724355727	18
Assign_413	1608802724355737	1608802724355769	5	1608802724355758	22
Sqrt_198	1608802724355771	1608802724355799	2	1608802724355790	11
Assign_596	1608802724355803	1608802724355830	4	1608802724355819	15
Sqrt_144	1608802724355833	1608802724355861	3	1608802724355855	11
Assign_434	1608802724355863	1608802724355889	2	1608802724355879	15
Sqrt_148	1608802724355896	1608802724355921	7	1608802724355916	11
Assign_446	1608802724355924	1608802724355954	3	1608802724355940	14
Sqrt_20	1608802724355957	1608802724355981	3	1608802724355975	12
Assign_62	1608802724355983	1608802724356015	2	1608802724356004	15
Sqrt_155	1608802724356017	1608802724356040	2	1608802724356036	17
Assign_467	1608802724356049	1608802724356077	9	1608802724356066	23
Sqrt_158	1608802724356079	1608802724356107	2	1608802724356097	15
Assign_476	1608802724356111	1608802724356138	4	1608802724356128	15
Sqrt_161	1608802724356141	1608802724356170	3	1608802724356164	47
Assign_485	1608802724356177	1608802724356208	7	1608802724356213	41
Sqrt_105	1608802724356211	1608802724356235	3	1608802724356256	13
Assign_317	1608802724356240	1608802724356272	5	1608802724356271	14
Sqrt_41	1608802724356274	1608802724356298	2	1608802724356293	18
Assign_125	1608802724356307	1608802724356335	9	1608802724356324	23
Sqrt_176	1608802724356337	1608802724356372	2	1608802724356356	11
Assign_530	1608802724356374	1608802724356404	2	1608802724356392	16
Sqrt_179	1608802724356406	1608802724356442	2	1608802724356436	12
Assign_539	1608802724356445	1608802724356471	3	1608802724356461	14
Sqrt_185	1608802724356479	1608802724356504	8	1608802724356499	19
Assign_557	1608802724356509	1608802724356540	5	1608802724356525	22
Sqrt_188	1608802724356543	1608802724356567	3	1608802724356562	12
Assign_566	1608802724356569	1608802724356600	2	1608802724356589	15
Sqrt_190	1608802724356602	1608802724356631	2	1608802724356621	11
Assign_572	1608802724356633	1608802724356661	2	1608802724356651	15
Sqrt_194	1608802724356664	1608802724356691	3	1608802724356682	15
Assign_584	1608802724356693	1608802724356719	2	1608802724356709	15
Sqrt_199	1608802724356721	1608802724356749	2	1608802724356744	18
Assign_599	1608802724356754	1608802724356786	5	1608802724356770	22
Sqrt_202	1608802724356788	1608802724356813	2	1608802724356808	12
Assign_608	1608802724356816	1608802724356848	3	1608802724356833	20
Sqrt_145	1608802724356851	1608802724356874	3	1608802724356870	46
Assign_437	1608802724356883	1608802724356912	9	1608802724356918	41
Sqrt_149	1608802724356914	1608802724356942	2	1608802724356960	13
Assign_449	1608802724356947	1608802724356976	5	1608802724356975	14
Sqrt_156	1608802724356978	1608802724357007	2	1608802724357001	11
Assign_470	1608802724357009	1608802724357035	2	1608802724357025	15
Sqrt_159	1608802724357042	1608802724357067	7	1608802724357062	46
Assign_479	1608802724357072	1608802724357104	5	1608802724357110	41
Sqrt_162	1608802724357107	1608802724357130	3	1608802724357152	5
Assign_488	1608802724357133	1608802724357163	3	1608802724357159	10
Sqrt_168	1608802724357167	1608802724357195	4	1608802724357185	12
Assign_506	1608802724357197	1608802724357223	2	1608802724357214	15
Sqrt_172	1608802724357225	1608802724357254	2	1608802724357244	16
Assign_518	1608802724357256	1608802724357282	2	1608802724357272	15
Sqrt_180	1608802724357289	1608802724357313	7	1608802724357307	11
Assign_542	1608802724357316	1608802724357346	3	1608802724357332	15
Sqrt_44	1608802724357350	1608802724357375	4	1608802724357369	11
Assign_134	1608802724357377	1608802724357408	2	1608802724357393	19
Sqrt_189	1608802724357411	1608802724357434	3	1608802724357429	11
Assign_569	1608802724357441	1608802724357468	7	1608802724357457	15
Sqrt_191	1608802724357471	1608802724357499	3	1608802724357489	47
Assign_575	1608802724357505	1608802724357533	6	1608802724357538	41
Sqrt_195	1608802724357536	1608802724357565	3	1608802724357580	4
Assign_587	1608802724357567	1608802724357593	2	1608802724357587	10
Sqrt_200	1608802724357599	1608802724357624	6	1608802724357619	12
Assign_602	1608802724357627	1608802724357658	3	1608802724357643	19
Sqrt_203	1608802724357661	1608802724357685	3	1608802724357679	11
Assign_611	1608802724357689	1608802724357722	4	1608802724357711	16
Sqrt_1	1608802724357725	1608802724357753	3	1608802724357744	11
Assign_5	1608802724357757	1608802724357784	4	1608802724357774	15
Sqrt_160	1608802724357786	1608802724357815	2	1608802724357805	15
Assign_482	1608802724357818	1608802724357843	3	1608802724357834	15
Sqrt_163	1608802724357846	1608802724357875	3	1608802724357869	11
Assign_491	1608802724357877	1608802724357907	2	1608802724357893	15
Sqrt_24	1608802724357909	1608802724357935	2	1608802724357929	11
Assign_74	1608802724357938	1608802724357976	3	1608802724357954	26
Sqrt_35	1608802724357979	1608802724358004	3	1608802724357998	12
Assign_107	1608802724358006	1608802724358037	2	1608802724358027	15
Sqrt_42	1608802724358040	1608802724358067	3	1608802724358058	11
Assign_128	1608802724358070	1608802724358097	3	1608802724358087	15
Sqrt_192	1608802724358099	1608802724358129	2	1608802724358119	15
Assign_578	1608802724358131	1608802724358158	2	1608802724358147	15
Sqrt_196	1608802724358165	1608802724358189	7	1608802724358184	11
Assign_590	1608802724358191	1608802724358222	2	1608802724358208	15
Sqrt_201	1608802724358225	1608802724358249	3	1608802724358244	11
Assign_605	1608802724358251	1608802724358280	2	1608802724358270	15
Sqrt_204	1608802724358283	1608802724358305	3	1608802724358301	10
Assign_614	1608802724358311	1608802724358337	6	1608802724358328	15
Sqrt_59	1608802724358340	1608802724358368	3	1608802724358358	18
Assign_179	1608802724358373	1608802724358400	5	1608802724358389	22
Sqrt_164	1608802724358403	1608802724358431	3	1608802724358425	12
Assign_494	1608802724358433	1608802724358463	2	1608802724358449	15
Sqrt_19	1608802724358466	1608802724358490	3	1608802724358485	12
Assign_59	1608802724358494	1608802724358523	4	1608802724358510	18
Sqrt_32	1608802724358525	1608802724358549	2	1608802724358544	11
Assign_98	1608802724358552	1608802724358582	3	1608802724358571	15
Sqrt_193	1608802724358584	1608802724358612	2	1608802724358603	45
Assign_581	1608802724358617	1608802724358644	5	1608802724358650	41
Sqrt_197	1608802724358647	1608802724358676	3	1608802724358693	12
Assign_593	1608802724358681	1608802724358707	5	1608802724358706	14
Sqrt_45	1608802724358710	1608802724358740	3	1608802724358734	12
Assign_137	1608802724358742	1608802724358775	2	1608802724358760	16
Sqrt_205	1608802724358778	1608802724358803	3	1608802724358797	12
Assign_617	1608802724358805	1608802724358835	2	1608802724358825	15
Sqrt_51	1608802724358838	1608802724358862	3	1608802724358857	11
Assign_155	1608802724358870	1608802724358898	8	1608802724358887	15
Sqrt_55	1608802724358901	1608802724358929	3	1608802724358919	18
Assign_167	1608802724358934	1608802724358962	5	1608802724358951	22
Sqrt_183	1608802724358964	1608802724358992	2	1608802724358986	17
Assign_551	1608802724358996	1608802724359023	4	1608802724359013	22
Sqrt_48	1608802724359029	1608802724359054	6	1608802724359048	12
Assign_146	1608802724359057	1608802724359088	3	1608802724359073	19
Sqrt_49	1608802724359090	1608802724359114	2	1608802724359109	47
Assign_149	1608802724359119	1608802724359152	5	1608802724359157	41
Sqrt_50	1608802724359155	1608802724359183	3	1608802724359200	5
Assign_152	1608802724359186	1608802724359213	3	1608802724359206	11
Sqrt_18	1608802724359216	1608802724359244	3	1608802724359234	15
Assign_56	1608802724359247	1608802724359274	3	1608802724359264	15
Sqrt_21	1608802724359277	1608802724359306	3	1608802724359300	18
Assign_65	1608802724359310	1608802724359342	4	1608802724359327	23
Sqrt_25	1608802724359345	1608802724359370	3	1608802724359364	18
Assign_77	1608802724359374	1608802724359406	4	1608802724359394	22
Sqrt_29	1608802724359408	1608802724359432	2	1608802724359427	11
Assign_89	1608802724359486	1608802724359518	54	1608802724359505	16
Sqrt_22	1608802724359521	1608802724359545	3	1608802724359540	11
Assign_68	1608802724359547	1608802724359575	2	1608802724359565	14
Sqrt_26	1608802724359578	1608802724359600	3	1608802724359596	11
Assign_80	1608802724359603	1608802724359628	3	1608802724359619	14
Sqrt_30	1608802724359630	1608802724359652	2	1608802724359648	11
Assign_92	1608802724359655	1608802724359680	3	1608802724359671	14
Sqrt_46	1608802724359683	1608802724359707	3	1608802724359702	11
Assign_140	1608802724359709	1608802724359734	2	1608802724359725	14
Sqrt_27	1608802724359736	1608802724359759	2	1608802724359755	18
Assign_83	1608802724359764	1608802724359790	5	1608802724359781	21
Sqrt_52	1608802724359793	1608802724359820	3	1608802724359811	16
Assign_158	1608802724359822	1608802724359849	2	1608802724359840	15
Sqrt_33	1608802724359852	1608802724359875	3	1608802724359870	47
Assign_101	1608802724359882	1608802724359909	7	1608802724359918	41
Sqrt_60	1608802724359912	1608802724359934	3	1608802724359961	4
Assign_182	1608802724359937	1608802724359961	3	1608802724359967	4
Sqrt_63	1608802724359964	1608802724359988	3	1608802724359983	46
Assign_191	1608802724359992	1608802724360019	4	1608802724360031	40
Sqrt_67	1608802724360022	1608802724360045	3	1608802724360073	4
Assign_203	1608802724360047	1608802724360072	2	1608802724360079	4
Sqrt_68	1608802724360074	1608802724360097	2	1608802724360092	11
Assign_206	1608802724360100	1608802724360124	3	1608802724360116	14
add_246	1608802724360127	1608802724360152	3	1608802724360146	18
add_260	1608802724360156	1608802724360177	4	1608802724360173	18
add_250	1608802724360180	1608802724360200	3	1608802724360197	10
add_223	1608802724360202	1608802724360229	2	1608802724360219	15
add_300	1608802724360232	1608802724360253	3	1608802724360249	18
add_287	1608802724360255	1608802724360281	2	1608802724360277	11
add_213	1608802724360283	1608802724360306	2	1608802724360300	10
add_226	1608802724360310	1608802724360332	4	1608802724360328	44
add_239	1608802724360337	1608802724360367	5	1608802724360374	13
add_304	1608802724360370	1608802724360392	3	1608802724360388	11
add_264	1608802724360396	1608802724360420	4	1608802724360416	10
add_273	1608802724360423	1608802724360447	3	1608802724360439	44
add_290	1608802724360450	1608802724360471	3	1608802724360485	4
add_307	1608802724360476	1608802724360500	5	1608802724360492	21
add_253	1608802724360502	1608802724360523	2	1608802724360519	17
add_267	1608802724360525	1608802724360549	2	1608802724360545	10
add_277	1608802724360551	1608802724360573	2	1608802724360567	10
add_216	1608802724360576	1608802724360597	3	1608802724360594	10
add_230	1608802724360600	1608802724360624	3	1608802724360617	13
add_314	1608802724360626	1608802724360646	2	1608802724360643	17
add_327	1608802724360651	1608802724360672	5	1608802724360668	44
add_270	1608802724360674	1608802724360698	2	1608802724360714	4
add_280	1608802724360700	1608802724360721	2	1608802724360720	42
add_293	1608802724360723	1608802724360749	2	1608802724360763	12
add_311	1608802724360751	1608802724360771	2	1608802724360778	4
add_318	1608802724360776	1608802724360797	5	1608802724360793	10
add_243	1608802724360799	1608802724360828	2	1608802724360816	9
add_257	1608802724360830	1608802724360851	2	1608802724360847	10
add_354	1608802724360853	1608802724360877	2	1608802724360873	17
add_284	1608802724360881	1608802724360901	4	1608802724360898	10
add_297	1608802724360907	1608802724360928	6	1608802724360924	10
add_5	1608802724360930	1608802724360954	2	1608802724360947	368
add_13	1608802724360957	1608802724360978	3	1608802724361318	9
add_17	1608802724360981	1608802724361005	3	1608802724361328	4
add_27	1608802724361008	1608802724361027	3	1608802724361333	4
add_20	1608802724361032	1608802724361054	5	1608802724361339	4
add_30	1608802724361057	1608802724361081	3	1608802724361345	12
add_41	1608802724361085	1608802724361105	4	1608802724361359	4
add_23	1608802724361109	1608802724361132	4	1608802724361364	12
add_34	1608802724361135	1608802724361154	3	1608802724361378	4
add_44	1608802724361160	1608802724361181	6	1608802724361384	12
add_54	1608802724361184	1608802724361207	3	1608802724361398	4
add_341	1608802724361211	1608802724361231	4	1608802724361403	4
add_37	1608802724361235	1608802724361259	4	1608802724361409	13
add_48	1608802724361262	1608802724361286	3	1608802724361423	5
add_57	1608802724361288	1608802724361309	2	1608802724361430	40
add_138	1608802724361311	1608802724361336	2	1608802724361471	13
add_405	1608802724361338	1608802724361358	2	1608802724361486	4
add_419	1608802724361362	1608802724361386	4	1608802724361491	4
add_51	1608802724361389	1608802724361413	3	1608802724361497	4
add_61	1608802724361416	1608802724361435	3	1608802724361503	5
add_351	1608802724361439	1608802724361461	4	1608802724361509	4
add_84	1608802724361464	1608802724361484	3	1608802724361514	12
add_365	1608802724361487	1608802724361512	3	1608802724361528	4
add_111	1608802724361514	1608802724361537	2	1608802724361534	41
add_392	1608802724361540	1608802724361560	3	1608802724361576	4
add_64	1608802724361563	1608802724361586	3	1608802724361582	41
add_422	1608802724361589	1608802724361608	3	1608802724361625	12
add_432	1608802724361612	1608802724361635	4	1608802724361639	4
add_321	1608802724361637	1608802724361660	2	1608802724361654	9
add_185	1608802724361663	1608802724361684	3	1608802724361680	17
add_196	1608802724361688	1608802724361711	4	1608802724361704	13
add_358	1608802724361714	1608802724361735	3	1608802724361731	10
add_368	1608802724361738	1608802724361763	3	1608802724361758	18
add_378	1608802724361766	1608802724361790	3	1608802724361783	11
add_395	1608802724361793	1608802724361815	3	1608802724361811	11
add_408	1608802724361817	1608802724361841	2	1608802724361834	16
add_122	1608802724361844	1608802724361864	3	1608802724361861	10
add_128	1608802724361867	1608802724361891	3	1608802724361887	11
add_446	1608802724361894	1608802724361919	3	1608802724361910	10
add_324	1608802724361922	1608802724361942	3	1608802724361939	10
add_331	1608802724361945	1608802724361968	3	1608802724361961	13
add_189	1608802724361970	1608802724361990	2	1608802724361986	10
add_199	1608802724361992	1608802724362016	2	1608802724362012	17
add_513	1608802724362018	1608802724362041	2	1608802724362035	10
add_381	1608802724362045	1608802724362067	4	1608802724362063	45
add_398	1608802724362069	1608802724362092	2	1608802724362109	5
add_412	1608802724362094	1608802724362115	2	1608802724362115	6
add_426	1608802724362117	1608802724362150	2	1608802724362146	10
add_435	1608802724362152	1608802724362178	2	1608802724362169	47
add_449	1608802724362181	1608802724362202	3	1608802724362218	4
add_131	1608802724362205	1608802724362228	3	1608802724362223	18
add_473	1608802724362232	1608802724362252	4	1608802724362249	10
add_334	1608802724362254	1608802724362278	2	1608802724362274	44
add_344	1608802724362282	1608802724362304	4	1608802724362320	4
add_516	1608802724362307	1608802724362328	3	1608802724362326	16
add_203	1608802724362331	1608802724362356	3	1608802724362348	14
add_385	1608802724362359	1608802724362379	3	1608802724362376	10
add_401	1608802724362383	1608802724362407	4	1608802724362403	18
add_415	1608802724362410	1608802724362433	3	1608802724362426	17
add_429	1608802724362435	1608802724362456	2	1608802724362452	10
add_439	1608802724362458	1608802724362484	2	1608802724362480	10
add_452	1608802724362486	1608802724362506	2	1608802724362503	10
add_459	1608802724362513	1608802724362534	7	1608802724362530	10
add_476	1608802724362537	1608802724362560	3	1608802724362553	17
add_135	1608802724362562	1608802724362583	2	1608802724362579	10
add_338	1608802724362585	1608802724362609	2	1608802724362605	11
add_347	1608802724362612	1608802724362631	3	1608802724362628	17
add_165	1608802724362637	1608802724362658	6	1608802724362654	44
add_372	1608802724362662	1608802724362686	4	1608802724362700	4
add_388	1608802724362688	1608802724362709	2	1608802724362706	44
add_563	1608802724362711	1608802724362735	2	1608802724362751	13
add_577	1608802724362738	1608802724362758	3	1608802724362765	13
add_591	1608802724362765	1608802724362787	7	1608802724362783	10
add_442	1608802724362791	1608802724362814	4	1608802724362807	45
add_617	1608802724362817	1608802724362837	3	1608802724362854	12
add_462	1608802724362840	1608802724362864	3	1608802724362868	13
add_480	1608802724362867	1608802724362891	3	1608802724362883	10
add_486	1608802724362893	1608802724362914	2	1608802724362910	11
add_500	1608802724362917	1608802724362940	3	1608802724362934	12
add_520	1608802724362943	1608802724362964	3	1608802724362960	10
add_523	1608802724362966	1608802724362992	2	1608802724362987	18
add_152	1608802724362994	1608802724363017	2	1608802724363011	18
add_375	1608802724363020	1608802724363040	3	1608802724363037	10
add_567	1608802724363043	1608802724363067	3	1608802724363059	13
add_581	1608802724363069	1608802724363090	2	1608802724363086	10
add_594	1608802724363094	1608802724363119	4	1608802724363114	12
add_604	1608802724363121	1608802724363145	2	1608802724363138	44
add_621	1608802724363148	1608802724363168	3	1608802724363184	5
add_635	1608802724363173	1608802724363196	5	1608802724363190	12
add_466	1608802724363199	1608802724363220	3	1608802724363216	11
add_483	1608802724363223	1608802724363247	3	1608802724363243	10
add_489	1608802724363249	1608802724363273	2	1608802724363266	44
add_503	1608802724363275	1608802724363296	2	1608802724363312	4
add_102	1608802724363301	1608802724363323	5	1608802724363318	12
add_527	1608802724363327	1608802724363348	4	1608802724363344	10
add_537	1608802724363351	1608802724363384	3	1608802724363379	10
add_142	1608802724363386	1608802724363410	2	1608802724363403	10
add_570	1608802724363413	1608802724363434	3	1608802724363430	17
add_584	1608802724363436	1608802724363461	2	1608802724363453	17
add_597	1608802724363463	1608802724363484	2	1608802724363480	44
add_608	1608802724363486	1608802724363510	2	1608802724363526	4
add_628	1608802724363512	1608802724363535	2	1608802724363532	7
add_638	1608802724363537	1608802724363558	2	1608802724363554	17
add_455	1608802724363560	1608802724363584	2	1608802724363577	16
add_469	1608802724363587	1608802724363607	3	1608802724363604	17
add_675	1608802724363610	1608802724363636	3	1608802724363632	11
add_493	1608802724363640	1608802724363664	4	1608802724363657	10
add_506	1608802724363667	1608802724363687	3	1608802724363683	10
add_74	1608802724363690	1608802724363712	3	1608802724363706	12
add_530	1608802724363716	1608802724363736	4	1608802724363733	18
add_540	1608802724363739	1608802724363764	3	1608802724363760	10
add_550	1608802724363767	1608802724363790	3	1608802724363783	44
add_361	1608802724363792	1608802724363813	2	1608802724363829	12
add_145	1608802724363816	1608802724365491	3	1608802724365468	26
add_601	1608802724365497	1608802724365530	6	1608802724365523	13
add_611	1608802724365534	1608802724365560	4	1608802724365556	11
add_631	1608802724365564	1608802724365586	4	1608802724365582	18
add_642	1608802724365594	1608802724365617	8	1608802724365612	12
add_648	1608802724365620	1608802724365644	3	1608802724365636	10
add_662	1608802724365647	1608802724365669	3	1608802724365665	10
add_678	1608802724365673	1608802724365697	4	1608802724365693	18
add_688	1608802724365700	1608802724365720	3	1608802724365717	10
add_496	1608802724365728	1608802724365750	8	1608802724365746	45
add_509	1608802724365752	1608802724365777	2	1608802724365792	13
add_534	1608802724365779	1608802724365800	2	1608802724365807	4
add_543	1608802724365803	1608802724365837	3	1608802724365831	45
add_554	1608802724365840	1608802724365862	3	1608802724365879	4
add_574	1608802724365868	1608802724365889	6	1608802724365885	11
add_588	1608802724365892	1608802724365915	3	1608802724365908	13
add_614	1608802724365918	1608802724365940	3	1608802724365935	12
add_156	1608802724365942	1608802724365966	2	1608802724365962	11
add_645	1608802724365969	1608802724365989	3	1608802724365986	10
add_651	1608802724365995	1608802724366016	6	1608802724366012	45
add_665	1608802724366019	1608802724366046	3	1608802724366058	4
add_682	1608802724366048	1608802724366069	2	1608802724366066	11
add_691	1608802724366073	1608802724366097	4	1608802724366093	11
add_9	1608802724366101	1608802724366123	4	1608802724366118	10
add_547	1608802724366129	1608802724366151	6	1608802724366147	10
add_557	1608802724366153	1608802724366179	2	1608802724366170	15
add_88	1608802724366181	1608802724366203	2	1608802724366199	11
add_125	1608802724366205	1608802724366230	2	1608802724366226	10
add_149	1608802724366233	1608802724366254	3	1608802724366250	11
add_655	1608802724366259	1608802724366281	5	1608802724366276	11
add_668	1608802724366284	1608802724366307	3	1608802724366301	12
add_685	1608802724366309	1608802724366330	2	1608802724366326	11
add_694	1608802724366332	1608802724366357	2	1608802724366353	11
add_206	1608802724366360	1608802724366385	3	1608802724366377	17
add_560	1608802724366388	1608802724366409	3	1608802724366405	11
add_71	1608802724366412	1608802724366436	3	1608802724366428	14
add_115	1608802724366439	1608802724366460	3	1608802724366456	11
add_658	1608802724366463	1608802724366488	3	1608802724366483	45
add_671	1608802724366490	1608802724366514	2	1608802724366530	13
add_159	1608802724366516	1608802724366538	2	1608802724366545	4
add_698	1608802724366541	1608802724366564	3	1608802724366558	12
add_179	1608802724366567	1608802724366588	3	1608802724366584	11
add_192	1608802724366590	1608802724366616	2	1608802724366612	18
add_624	1608802724366619	1608802724366643	3	1608802724366636	18
add_169	1608802724366647	1608802724366669	4	1608802724366665	11
add_172	1608802724366671	1608802724366696	2	1608802724366688	44
add_176	1608802724366699	1608802724366719	3	1608802724366734	4
add_68	1608802724366722	1608802724366747	3	1608802724366743	10
add_77	1608802724366749	1608802724366775	2	1608802724366766	17
add_91	1608802724366778	1608802724366799	3	1608802724366795	18
add_105	1608802724366802	1608802724366825	3	1608802724366818	13
add_81	1608802724366827	1608802724366848	2	1608802724366844	10
add_95	1608802724366850	1608802724366876	2	1608802724366872	11
add_108	1608802724366879	1608802724366903	3	1608802724366896	10
add_162	1608802724366905	1608802724366927	2	1608802724366923	11
add_98	1608802724366930	1608802724366954	3	1608802724366946	17
add_182	1608802724366957	1608802724366977	3	1608802724366974	11
add_118	1608802724366980	1608802724367004	3	1608802724367000	45
add_210	1608802724367007	1608802724367031	3	1608802724367047	4
add_219	1608802724367034	1608802724367056	3	1608802724367053	44
add_233	1608802724367059	1608802724367083	3	1608802724367098	4
add_236	1608802724367085	1608802724367106	2	1608802724367104	9
truediv_72	1608802724367109	1608802724367148	3	1608802724367138	27
truediv_76	1608802724367152	1608802724367179	4	1608802724367170	22
truediv_73	1608802724367182	1608802724367205	3	1608802724367200	11
truediv_65	1608802724367209	1608802724367237	4	1608802724367229	11
truediv_88	1608802724367242	1608802724367266	5	1608802724367260	23
truediv_84	1608802724367269	1608802724367297	3	1608802724367292	11
truediv_62	1608802724367301	1608802724367327	4	1608802724367318	11
truediv_66	1608802724367331	1608802724367353	4	1608802724367348	65
truediv_70	1608802724367356	1608802724367383	3	1608802724367415	17
truediv_89	1608802724367387	1608802724367409	4	1608802724367434	4
truediv_77	1608802724367416	1608802724367438	7	1608802724367440	5
truediv_80	1608802724367441	1608802724367467	3	1608802724367458	63
truediv_85	1608802724367471	1608802724367494	4	1608802724367523	5
truediv_90	1608802724367496	1608802724367522	2	1608802724367529	17
truediv_74	1608802724367525	1608802724367548	3	1608802724367548	17
truediv_78	1608802724367551	1608802724367578	3	1608802724367572	10
truediv_81	1608802724367581	1608802724367606	3	1608802724367598	10
truediv_63	1608802724367608	1608802724367631	2	1608802724367625	10
truediv_67	1608802724367633	1608802724367659	2	1608802724367651	14
truediv_92	1608802724367661	1608802724367683	2	1608802724367679	22
truediv_96	1608802724367688	1608802724367715	5	1608802724367709	63
truediv_79	1608802724367719	1608802724367745	4	1608802724367774	5
truediv_82	1608802724367747	1608802724367770	2	1608802724367781	57
truediv_86	1608802724367773	1608802724367799	3	1608802724367839	18
truediv_91	1608802724367801	1608802724367822	2	1608802724367859	4
truediv_93	1608802724367829	1608802724367851	7	1608802724367865	5
truediv_71	1608802724367853	1608802724367878	2	1608802724367871	9
truediv_75	1608802724367881	1608802724367904	3	1608802724367899	10
truediv_104	1608802724367906	1608802724367932	2	1608802724367927	23
truediv_83	1608802724367936	1608802724367958	4	1608802724367953	10
truediv_87	1608802724367962	1608802724367987	4	1608802724367981	12
truediv_1	1608802724367990	1608802724368018	3	1608802724368009	532
truediv_3	1608802724368021	1608802724368043	3	1608802724368545	15
truediv_4	1608802724368046	1608802724368076	3	1608802724368561	4
truediv_7	1608802724368078	1608802724368100	2	1608802724368567	5
truediv_5	1608802724368107	1608802724368130	7	1608802724368573	4
truediv_8	1608802724368133	1608802724368158	3	1608802724368579	18
truediv_11	1608802724368161	1608802724368183	3	1608802724368599	4
truediv_6	1608802724368185	1608802724368212	2	1608802724368605	18
truediv_9	1608802724368214	1608802724368235	2	1608802724368624	5
truediv_12	1608802724368237	1608802724368263	2	1608802724368630	17
truediv_15	1608802724368267	1608802724368292	4	1608802724368649	5
truediv_100	1608802724368295	1608802724368317	3	1608802724368655	5
truediv_10	1608802724368319	1608802724368346	2	1608802724368661	18
truediv_13	1608802724368349	1608802724368394	3	1608802724368680	5
truediv_16	1608802724368396	1608802724368427	2	1608802724368687	58
truediv_40	1608802724368433	1608802724368460	6	1608802724368747	17
truediv_119	1608802724368465	1608802724368488	5	1608802724368765	5
truediv_123	1608802724368491	1608802724368525	3	1608802724368772	5
truediv_14	1608802724368528	1608802724368550	3	1608802724368778	5
truediv_17	1608802724368552	1608802724368578	2	1608802724368784	5
truediv_103	1608802724368581	1608802724368608	3	1608802724368791	4
truediv_24	1608802724368610	1608802724368635	2	1608802724368797	18
truediv_107	1608802724368638	1608802724368665	3	1608802724368817	5
truediv_32	1608802724368668	1608802724368690	3	1608802724368823	58
truediv_115	1608802724368694	1608802724368720	4	1608802724368883	5
truediv_18	1608802724368724	1608802724368751	4	1608802724368890	58
truediv_124	1608802724368754	1608802724368777	3	1608802724368950	17
truediv_127	1608802724368780	1608802724368806	3	1608802724368969	4
truediv_94	1608802724368810	1608802724368832	4	1608802724368975	4
truediv_54	1608802724368834	1608802724368862	2	1608802724368981	18
truediv_57	1608802724368866	1608802724368891	4	1608802724369000	5
truediv_105	1608802724368894	1608802724368917	3	1608802724369007	5
truediv_108	1608802724368919	1608802724368946	2	1608802724369013	17
truediv_111	1608802724368949	1608802724368971	3	1608802724369032	5
truediv_116	1608802724368974	1608802724369001	3	1608802724369038	4
truediv_120	1608802724369005	1608802724369030	4	1608802724369044	18
truediv_35	1608802724369033	1608802724369055	3	1608802724369063	4
truediv_37	1608802724369058	1608802724369085	3	1608802724369075	14
truediv_131	1608802724369088	1608802724369112	3	1608802724369105	11
truediv_95	1608802724369116	1608802724369143	4	1608802724369137	11
truediv_97	1608802724369146	1608802724369170	3	1608802724369163	10
truediv_55	1608802724369174	1608802724369196	4	1608802724369191	11
truediv_58	1608802724369199	1608802724369224	3	1608802724369216	23
truediv_151	1608802724369228	1608802724369250	4	1608802724369245	11
truediv_112	1608802724369254	1608802724369281	4	1608802724369276	63
truediv_117	1608802724369284	1608802724369310	3	1608802724369341	5
truediv_121	1608802724369313	1608802724369335	3	1608802724369347	4
truediv_125	1608802724369337	1608802724369362	2	1608802724369354	13
truediv_128	1608802724369365	1608802724369387	3	1608802724369382	63
truediv_132	1608802724369389	1608802724369416	2	1608802724369447	5
truediv_38	1608802724369419	1608802724369444	3	1608802724369453	17
truediv_139	1608802724369448	1608802724369470	4	1608802724369472	5
truediv_98	1608802724369473	1608802724369499	3	1608802724369489	66
truediv_101	1608802724369501	1608802724369522	2	1608802724369558	5
truediv_152	1608802724369524	1608802724369552	2	1608802724369564	17
truediv_59	1608802724369555	1608802724369581	3	1608802724369583	5
truediv_113	1608802724369584	1608802724369608	3	1608802724369603	11
truediv_118	1608802724369611	1608802724369636	3	1608802724369628	22
truediv_122	1608802724369639	1608802724369661	3	1608802724369656	23
truediv_126	1608802724369663	1608802724369689	2	1608802724369683	11
truediv_129	1608802724369692	1608802724369718	3	1608802724369709	10
truediv_133	1608802724369721	1608802724369745	3	1608802724369740	10
truediv_135	1608802724369748	1608802724369773	3	1608802724369765	13
truediv_140	1608802724369775	1608802724369797	2	1608802724369793	22
truediv_39	1608802724369799	1608802724369826	2	1608802724369820	11
truediv_99	1608802724369828	1608802724369854	2	1608802724369845	10
truediv_102	1608802724369857	1608802724369880	3	1608802724369874	22
truediv_48	1608802724369882	1608802724369908	2	1608802724369899	62
truediv_109	1608802724369911	1608802724369933	3	1608802724369964	5
truediv_114	1608802724369936	1608802724369972	3	1608802724369970	60
truediv_166	1608802724369975	1608802724370000	3	1608802724370031	17
truediv_170	1608802724370004	1608802724370028	4	1608802724370050	17
truediv_174	1608802724370032	1608802724370059	4	1608802724370069	5
truediv_130	1608802724370063	1608802724370086	4	1608802724370080	63
truediv_182	1608802724370088	1608802724370115	2	1608802724370145	17
truediv_136	1608802724370118	1608802724370143	3	1608802724370164	17
truediv_141	1608802724370146	1608802724370169	3	1608802724370183	5
truediv_143	1608802724370173	1608802724370198	4	1608802724370190	13
truediv_147	1608802724370201	1608802724370222	3	1608802724370217	11
truediv_153	1608802724370225	1608802724370251	3	1608802724370246	11
truediv_154	1608802724370254	1608802724370279	3	1608802724370271	22
truediv_44	1608802724370283	1608802724370305	4	1608802724370300	23
truediv_110	1608802724370308	1608802724370333	3	1608802724370325	13
truediv_167	1608802724370336	1608802724370358	3	1608802724370353	11
truediv_171	1608802724370360	1608802724370388	2	1608802724370382	11
truediv_175	1608802724370390	1608802724370415	2	1608802724370408	10
truediv_178	1608802724370418	1608802724370442	3	1608802724370436	64
truediv_183	1608802724370444	1608802724370470	2	1608802724370502	5
truediv_187	1608802724370474	1608802724370497	4	1608802724370508	5
truediv_137	1608802724370499	1608802724370525	2	1608802724370520	11
truediv_142	1608802724370528	1608802724370549	3	1608802724370545	10
truediv_144	1608802724370556	1608802724370578	7	1608802724370573	63
truediv_148	1608802724370580	1608802724370607	2	1608802724370637	5
truediv_29	1608802724370611	1608802724370633	4	1608802724370644	5
truediv_155	1608802724370636	1608802724370662	3	1608802724370656	11
truediv_158	1608802724370665	1608802724370686	3	1608802724370681	11
truediv_41	1608802724370694	1608802724370717	8	1608802724370712	11
truediv_168	1608802724370720	1608802724370747	3	1608802724370737	22
truediv_172	1608802724370750	1608802724370776	3	1608802724370768	25
truediv_176	1608802724370779	1608802724370806	3	1608802724370800	64
truediv_179	1608802724370808	1608802724370831	2	1608802724370866	5
truediv_185	1608802724370838	1608802724370861	7	1608802724370872	5
truediv_188	1608802724370864	1608802724370890	3	1608802724370881	22
truediv_134	1608802724370894	1608802724370918	4	1608802724370913	23
truediv_138	1608802724370921	1608802724370947	3	1608802724370941	23
truediv_199	1608802724370950	1608802724370972	3	1608802724370966	10
truediv_145	1608802724370979	1608802724371003	7	1608802724370997	10
truediv_149	1608802724371005	1608802724371031	2	1608802724371023	11
truediv_21	1608802724371034	1608802724371057	3	1608802724371052	10
truediv_156	1608802724371061	1608802724371088	4	1608802724371081	23
truediv_159	1608802724371091	1608802724371113	3	1608802724371109	10
truediv_162	1608802724371119	1608802724371141	6	1608802724371136	63
truediv_106	1608802724371144	1608802724371170	3	1608802724371201	17
truediv_42	1608802724371173	1608802724371196	3	1608802724371220	18
truediv_177	1608802724371198	1608802724371228	2	1608802724371239	5
truediv_180	1608802724371230	1608802724371252	2	1608802724371247	11
truediv_186	1608802724371259	1608802724371283	7	1608802724371278	23
truediv_189	1608802724371286	1608802724371311	3	1608802724371303	10
truediv_191	1608802724371313	1608802724371336	2	1608802724371330	10
truediv_195	1608802724371339	1608802724371373	3	1608802724371367	12
truediv_200	1608802724371375	1608802724371397	2	1608802724371392	22
truediv_203	1608802724371403	1608802724371426	6	1608802724371420	10
truediv_146	1608802724371430	1608802724371456	4	1608802724371447	64
truediv_150	1608802724371459	1608802724371482	3	1608802724371512	17
truediv_157	1608802724371484	1608802724371511	2	1608802724371531	5
truediv_160	1608802724371514	1608802724371536	3	1608802724371537	58
truediv_163	1608802724371538	1608802724371565	2	1608802724371597	5
truediv_169	1608802724371568	1608802724371594	3	1608802724371603	4
truediv_173	1608802724371596	1608802724371621	2	1608802724371615	11
truediv_181	1608802724371623	1608802724371647	2	1608802724371640	13
truediv_45	1608802724371650	1608802724371672	3	1608802724371667	11
truediv_190	1608802724371676	1608802724371703	4	1608802724371697	11
truediv_192	1608802724371706	1608802724371731	3	1608802724371723	62
truediv_196	1608802724371735	1608802724371758	4	1608802724371787	5
truediv_201	1608802724371760	1608802724371787	2	1608802724371794	5
truediv_204	1608802724371790	1608802724371812	3	1608802724371807	11
truediv_2	1608802724371815	1608802724371842	3	1608802724371836	11
truediv_161	1608802724371845	1608802724371866	3	1608802724371862	10
truediv_164	1608802724371874	1608802724371897	8	1608802724371891	11
truediv_25	1608802724371902	1608802724371928	5	1608802724371919	10
truediv_36	1608802724371932	1608802724371954	4	1608802724371949	11
truediv_43	1608802724371957	1608802724371983	3	1608802724371977	11
truediv_193	1608802724371987	1608802724372009	4	1608802724372004	10
truediv_197	1608802724372015	1608802724372041	6	1608802724372035	10
truediv_202	1608802724372045	1608802724372070	4	1608802724372062	10
truediv_205	1608802724372073	1608802724372096	3	1608802724372091	11
truediv_60	1608802724372099	1608802724372128	3	1608802724372117	27
truediv_165	1608802724372130	1608802724372152	2	1608802724372147	11
truediv_20	1608802724372158	1608802724372183	6	1608802724372178	10
truediv_33	1608802724372186	1608802724372211	3	1608802724372203	10
truediv_194	1608802724372213	1608802724372235	2	1608802724372231	64
truediv_198	1608802724372238	1608802724372265	3	1608802724372296	17
truediv_46	1608802724372267	1608802724372289	2	1608802724372315	5
truediv_206	1608802724372292	1608802724372319	3	1608802724372322	4
truediv_52	1608802724372322	1608802724372350	3	1608802724372339	10
truediv_56	1608802724372354	1608802724372387	4	1608802724372379	24
truediv_184	1608802724372390	1608802724372416	3	1608802724372407	22
truediv_49	1608802724372420	1608802724372443	4	1608802724372438	10
truediv_50	1608802724372447	1608802724372475	4	1608802724372469	64
truediv_51	1608802724372477	1608802724372503	2	1608802724372535	5
truediv_19	1608802724372506	1608802724372530	3	1608802724372541	4
truediv_22	1608802724372533	1608802724372559	3	1608802724372550	22
truediv_26	1608802724372561	1608802724372583	2	1608802724372578	23
truediv_30	1608802724372587	1608802724372615	4	1608802724372609	11
truediv_23	1608802724372618	1608802724372640	3	1608802724372635	10
truediv_27	1608802724372647	1608802724372670	7	1608802724372665	10
truediv_31	1608802724372673	1608802724372699	3	1608802724372690	13
truediv_47	1608802724372701	1608802724372724	2	1608802724372719	10
truediv_28	1608802724372726	1608802724372761	2	1608802724372755	23
truediv_53	1608802724372764	1608802724372786	3	1608802724372781	10
truediv_34	1608802724372792	1608802724372818	6	1608802724372812	63
truediv_61	1608802724372821	1608802724372847	3	1608802724372877	5
truediv_64	1608802724372850	1608802724372873	3	1608802724372883	58
truediv_68	1608802724372875	1608802724372902	2	1608802724372943	5
truediv_69	1608802724372905	1608802724372927	3	1608802724372950	4
add_247	1608802724372930	1608802724372958	3	1608802724372956	18
add_261	1608802724372963	1608802724372991	5	1608802724372981	21
mul_397	1608802724372994	1608802724373018	3	1608802724373013	11
mul_354	1608802724373024	1608802724373049	6	1608802724373041	14
add_301	1608802724373052	1608802724373075	3	1608802724373070	22
mul_456	1608802724373080	1608802724373107	5	1608802724373103	11
mul_338	1608802724373111	1608802724373138	4	1608802724373128	11
add_227	1608802724373142	1608802724373165	4	1608802724373159	61
add_240	1608802724373169	1608802724373197	4	1608802724373222	17
mul_483	1608802724373200	1608802724373221	3	1608802724373241	4
mul_419	1608802724373223	1608802724373249	2	1608802724373246	10
add_274	1608802724373252	1608802724373278	3	1608802724373269	60
mul_461	1608802724373281	1608802724373304	3	1608802724373331	4
add_308	1608802724373306	1608802724373332	2	1608802724373337	17
add_254	1608802724373335	1608802724373361	3	1608802724373355	20
mul_424	1608802724373364	1608802724373392	3	1608802724373387	11
mul_440	1608802724373394	1608802724373419	2	1608802724373411	11
mul_343	1608802724373421	1608802724373443	2	1608802724373438	11
mul_365	1608802724373445	1608802724373469	2	1608802724373462	13
add_315	1608802724373471	1608802724373494	2	1608802724373489	22
add_328	1608802724373497	1608802724373524	3	1608802724373518	61
mul_429	1608802724373527	1608802724373551	3	1608802724373580	4
add_281	1608802724373554	1608802724373577	3	1608802724373586	55
add_294	1608802724373580	1608802724373606	3	1608802724373643	17
mul_494	1608802724373609	1608802724373631	3	1608802724373662	4
mul_505	1608802724373633	1608802724373658	2	1608802724373667	4
mul_386	1608802724373660	1608802724373681	2	1608802724373677	10
mul_408	1608802724373687	1608802724373708	6	1608802724373704	11
add_355	1608802724373711	1608802724373739	3	1608802724373728	21
mul_451	1608802724373743	1608802724373764	4	1608802724373760	11
mul_472	1608802724373767	1608802724373792	3	1608802724373788	11
add_6	1608802724373794	1608802724373817	2	1608802724373811	524
add_14	1608802724373824	1608802724373847	7	1608802724374339	13
mul_26	1608802724373851	1608802724373876	4	1608802724374353	4
mul_42	1608802724373879	1608802724373899	3	1608802724374359	4
mul_31	1608802724373901	1608802724373926	2	1608802724374364	4
add_31	1608802724373928	1608802724373951	2	1608802724374370	17
mul_64	1608802724373957	1608802724373980	6	1608802724374389	4
add_24	1608802724373984	1608802724374010	4	1608802724374394	17
mul_53	1608802724374013	1608802724374033	3	1608802724374413	4
add_45	1608802724374036	1608802724374062	3	1608802724374418	17
mul_85	1608802724374065	1608802724374086	3	1608802724374437	4
mul_542	1608802724374094	1608802724374116	8	1608802724374443	4
add_38	1608802724374119	1608802724374152	3	1608802724374449	17
mul_75	1608802724374155	1608802724374177	3	1608802724374467	4
add_58	1608802724374180	1608802724374207	3	1608802724374473	56
add_139	1608802724374210	1608802724374232	3	1608802724374530	16
mul_644	1608802724374240	1608802724374263	8	1608802724374548	4
mul_666	1608802724374267	1608802724374291	4	1608802724374554	4
mul_80	1608802724374295	1608802724374318	4	1608802724374560	4
mul_96	1608802724374320	1608802724374344	2	1608802724374565	4
mul_558	1608802724374347	1608802724374367	3	1608802724374571	4
add_85	1608802724374373	1608802724374397	6	1608802724374577	17
mul_580	1608802724374400	1608802724374425	3	1608802724374595	4
add_112	1608802724374427	1608802724374451	2	1608802724374601	56
mul_623	1608802724374454	1608802724374479	3	1608802724374658	4
add_65	1608802724374482	1608802724374504	3	1608802724374664	55
add_423	1608802724374510	1608802724374533	6	1608802724374721	17
mul_687	1608802724374535	1608802724374561	2	1608802724374739	4
mul_510	1608802724374565	1608802724374587	4	1608802724374745	4
add_186	1608802724374590	1608802724374616	3	1608802724374750	17
mul_311	1608802724374619	1608802724374640	3	1608802724374769	4
mul_569	1608802724374644	1608802724374669	4	1608802724374775	4
add_369	1608802724374671	1608802724374697	2	1608802724374780	17
mul_601	1608802724374700	1608802724374721	3	1608802724374799	4
mul_628	1608802724374724	1608802724374749	3	1608802724374805	4
add_409	1608802724374752	1608802724374773	3	1608802724374810	17
mul_193	1608802724374779	1608802724374802	6	1608802724374829	4
mul_203	1608802724374805	1608802724374830	3	1608802724374835	4
mul_709	1608802724374833	1608802724374854	3	1608802724374850	10
mul_515	1608802724374859	1608802724374883	5	1608802724374876	13
mul_526	1608802724374886	1608802724374907	3	1608802724374903	10
mul_300	1608802724374909	1608802724374934	2	1608802724374930	10
add_200	1608802724374936	1608802724374961	2	1608802724374953	21
mul_816	1608802724374964	1608802724374986	3	1608802724374982	10
add_382	1608802724374989	1608802724375018	3	1608802724375006	67
mul_633	1608802724375022	1608802724375043	4	1608802724375075	4
mul_655	1608802724375045	1608802724375070	2	1608802724375081	4
mul_677	1608802724375073	1608802724375097	3	1608802724375090	10
add_436	1608802724375100	1608802724375122	3	1608802724375117	61
mul_714	1608802724375125	1608802724375151	3	1608802724375180	4
add_132	1608802724375154	1608802724375177	3	1608802724375186	17
mul_752	1608802724375180	1608802724375204	3	1608802724375204	7
add_335	1608802724375207	1608802724375233	3	1608802724375224	61
mul_547	1608802724375236	1608802724375258	3	1608802724375287	4
add_517	1608802724375260	1608802724375286	2	1608802724375292	17
mul_322	1608802724375290	1608802724375311	4	1608802724375311	7
mul_612	1608802724375314	1608802724375338	3	1608802724375334	10
add_402	1608802724375341	1608802724375366	3	1608802724375358	22
add_416	1608802724375368	1608802724375392	2	1608802724375386	22
mul_682	1608802724375394	1608802724375419	2	1608802724375411	14
mul_698	1608802724375422	1608802724375442	3	1608802724375439	10
mul_719	1608802724375445	1608802724375469	3	1608802724375465	11
mul_730	1608802724375472	1608802724375495	3	1608802724375488	10
add_477	1608802724375498	1608802724375529	3	1608802724375516	29
mul_214	1608802724375533	1608802724375558	4	1608802724375551	14
mul_537	1608802724375564	1608802724375586	6	1608802724375581	11
add_348	1608802724375588	1608802724375616	2	1608802724375610	21
add_166	1608802724375618	1608802724375646	2	1608802724375635	61
mul_591	1608802724375649	1608802724375672	3	1608802724375698	4
add_389	1608802724375675	1608802724375701	3	1608802724375704	56
add_564	1608802724375704	1608802724375727	3	1608802724375761	17
add_578	1608802724375729	1608802724375756	2	1608802724375781	17
mul_940	1608802724375760	1608802724375782	4	1608802724375799	4
add_443	1608802724375788	1608802724375811	6	1608802724375805	61
add_618	1608802724375813	1608802724375839	2	1608802724375868	17
add_463	1608802724375842	1608802724375864	3	1608802724375886	17
mul_763	1608802724375866	1608802724375892	2	1608802724375905	4
mul_773	1608802724375894	1608802724375914	2	1608802724375911	10
mul_795	1608802724375920	1608802724375943	6	1608802724375938	11
mul_827	1608802724375947	1608802724375971	4	1608802724375964	13
add_524	1608802724375974	1608802724375996	3	1608802724375991	21
add_153	1608802724375999	1608802724376028	3	1608802724376020	23
mul_596	1608802724376032	1608802724376054	4	1608802724376050	11
mul_902	1608802724376060	1608802724376082	6	1608802724376078	10
mul_924	1608802724376084	1608802724376109	2	1608802724376101	10
mul_945	1608802724376112	1608802724376135	3	1608802724376131	11
add_605	1608802724376137	1608802724376165	2	1608802724376159	61
mul_988	1608802724376169	1608802724376190	4	1608802724376222	4
mul_1010	1608802724376197	1608802724376219	7	1608802724376227	4
mul_741	1608802724376222	1608802724376245	3	1608802724376238	10
mul_768	1608802724376248	1608802724376269	3	1608802724376265	11
add_490	1608802724376271	1608802724376296	2	1608802724376291	61
mul_800	1608802724376299	1608802724376320	3	1608802724376353	4
mul_161	1608802724376325	1608802724376348	5	1608802724376359	4
mul_838	1608802724376351	1608802724376386	3	1608802724376376	12
mul_854	1608802724376390	1608802724376412	4	1608802724376408	11
mul_225	1608802724376415	1608802724376439	3	1608802724376435	10
add_571	1608802724376442	1608802724376464	3	1608802724376459	22
add_585	1608802724376470	1608802724376495	6	1608802724376488	23
add_598	1608802724376498	1608802724376526	3	1608802724376515	61
mul_967	1608802724376528	1608802724376550	2	1608802724376579	4
mul_999	1608802724376553	1608802724376577	3	1608802724376585	4
add_639	1608802724376581	1608802724376603	4	1608802724376598	21
add_456	1608802724376609	1608802724376633	6	1608802724376627	22
add_470	1608802724376636	1608802724376662	3	1608802724376653	22
mul_1074	1608802724376665	1608802724376687	3	1608802724376683	11
mul_784	1608802724376691	1608802724376716	4	1608802724376709	14
mul_805	1608802724376719	1608802724376739	3	1608802724376737	10
mul_117	1608802724376742	1608802724376768	3	1608802724376764	11
add_531	1608802724376771	1608802724376797	3	1608802724376789	22
mul_859	1608802724376800	1608802724376822	3	1608802724376817	11
add_551	1608802724376826	1608802724376854	4	1608802724376843	60
add_362	1608802724376856	1608802724376879	2	1608802724376905	16
add_146	1608802724376882	1608802724376918	3	1608802724376923	17
mul_956	1608802724376921	1608802724376945	3	1608802724376943	6
mul_972	1608802724376948	1608802724376970	3	1608802724376966	10
add_632	1608802724376974	1608802724376999	4	1608802724376991	22
mul_1021	1608802724377002	1608802724377024	3	1608802724377020	11
mul_1031	1608802724377028	1608802724377053	4	1608802724377049	10
mul_1053	1608802724377056	1608802724377080	3	1608802724377074	10
add_679	1608802724377084	1608802724377109	4	1608802724377103	22
mul_1095	1608802724377111	1608802724377136	2	1608802724377129	13
add_497	1608802724377139	1608802724377162	3	1608802724377157	61
add_510	1608802724377164	1608802724377191	2	1608802724377219	17
mul_849	1608802724377194	1608802724377215	3	1608802724377237	4
add_544	1608802724377222	1608802724377246	7	1608802724377243	59
mul_881	1608802724377248	1608802724377273	2	1608802724377303	4
mul_913	1608802724377278	1608802724377299	5	1608802724377309	4
mul_935	1608802724377301	1608802724377325	2	1608802724377322	10
mul_977	1608802724377328	1608802724377349	3	1608802724377346	10
mul_247	1608802724377355	1608802724377378	6	1608802724377373	10
mul_1026	1608802724377380	1608802724377404	2	1608802724377397	13
add_652	1608802724377406	1608802724377429	2	1608802724377423	60
mul_1058	1608802724377431	1608802724377457	2	1608802724377486	4
mul_1085	1608802724377459	1608802724377480	2	1608802724377492	4
mul_1100	1608802724377487	1608802724377509	7	1608802724377504	11
add_10	1608802724377511	1608802724377538	2	1608802724377528	13
mul_870	1608802724377541	1608802724377562	3	1608802724377558	11
mul_886	1608802724377565	1608802724377589	3	1608802724377585	11
mul_139	1608802724377592	1608802724377612	3	1608802724377609	10
mul_198	1608802724377619	1608802724377641	7	1608802724377637	10
mul_236	1608802724377643	1608802724377667	2	1608802724377660	13
mul_1042	1608802724377669	1608802724377690	2	1608802724377686	10
mul_1063	1608802724377692	1608802724377717	2	1608802724377713	11
mul_1090	1608802724377719	1608802724377740	2	1608802724377736	10
add_695	1608802724377745	1608802724377769	5	1608802724377763	11
add_207	1608802724377771	1608802724377798	2	1608802724377788	21
mul_891	1608802724377800	1608802724377822	2	1608802724377818	11
mul_112	1608802724377825	1608802724377852	3	1608802724377845	13
mul_182	1608802724377855	1608802724377875	3	1608802724377872	11
add_659	1608802724377881	1608802724377904	6	1608802724377899	62
add_672	1608802724377907	1608802724377932	3	1608802724377962	16
mul_252	1608802724377935	1608802724377957	3	1608802724377980	4
mul_1111	1608802724377959	1608802724377985	2	1608802724377985	6
mul_284	1608802724377987	1608802724378008	2	1608802724378005	10
add_193	1608802724378014	1608802724378037	6	1608802724378031	22
add_625	1608802724378039	1608802724378066	2	1608802724378056	22
mul_268	1608802724378070	1608802724378093	4	1608802724378088	11
add_173	1608802724378095	1608802724378121	2	1608802724378113	64
mul_279	1608802724378124	1608802724378145	3	1608802724378179	5
mul_107	1608802724378147	1608802724378172	2	1608802724378185	4
add_78	1608802724378174	1608802724378201	2	1608802724378191	22
add_92	1608802724378203	1608802724378228	2	1608802724378221	21
mul_166	1608802724378231	1608802724378263	3	1608802724378248	21
mul_128	1608802724378265	1608802724378286	2	1608802724378283	11
mul_150	1608802724378289	1608802724378314	3	1608802724378310	11
mul_171	1608802724378316	1608802724378339	2	1608802724378333	10
mul_257	1608802724378341	1608802724378363	2	1608802724378359	10
add_99	1608802724378365	1608802724378391	2	1608802724378382	21
mul_289	1608802724378394	1608802724378415	3	1608802724378411	11
add_119	1608802724378417	1608802724378444	2	1608802724378439	60
mul_333	1608802724378446	1608802724378471	2	1608802724378501	4
add_220	1608802724378474	1608802724378497	3	1608802724378506	56
mul_370	1608802724378500	1608802724378524	3	1608802724378564	4
mul_375	1608802724378527	1608802724378547	3	1608802724378570	4
mul_392	1608802724378550	1608802724378575	3	1608802724378575	12
mul_414	1608802724378579	1608802724378602	4	1608802724378596	18
sub_73	1608802724378605	1608802724378628	3	1608802724378623	12
sub_65	1608802724378630	1608802724378655	2	1608802724378647	13
mul_478	1608802724378659	1608802724378681	4	1608802724378677	18
sub_84	1608802724378684	1608802724378713	3	1608802724378709	10
sub_62	1608802724378717	1608802724378743	4	1608802724378734	11
mul_360	1608802724378747	1608802724378769	4	1608802724378765	45
mul_381	1608802724378772	1608802724378796	3	1608802724378812	13
sub_89	1608802724378800	1608802724378821	4	1608802724378826	4
sub_77	1608802724378825	1608802724378849	4	1608802724378845	10
mul_435	1608802724378851	1608802724378876	2	1608802724378869	44
sub_85	1608802724378879	1608802724378900	3	1608802724378914	5
mul_489	1608802724378903	1608802724378929	3	1608802724378925	17
mul_403	1608802724378931	1608802724378952	2	1608802724378948	17
sub_78	1608802724378958	1608802724378980	6	1608802724378976	10
sub_81	1608802724378983	1608802724379007	3	1608802724379000	10
sub_63	1608802724379009	1608802724379031	2	1608802724379027	11
sub_67	1608802724379036	1608802724379061	5	1608802724379056	11
mul_500	1608802724379064	1608802724379085	3	1608802724379082	17
mul_521	1608802724379092	1608802724379113	7	1608802724379110	44
sub_79	1608802724379117	1608802724379141	4	1608802724379156	4
mul_446	1608802724379144	1608802724379165	3	1608802724379162	43
mul_467	1608802724379167	1608802724379192	2	1608802724379207	13
sub_91	1608802724379194	1608802724379218	2	1608802724379222	4
sub_93	1608802724379220	1608802724379241	2	1608802724379238	10
sub_71	1608802724379245	1608802724379270	4	1608802724379262	14
sub_75	1608802724379272	1608802724379293	2	1608802724379289	10
mul_564	1608802724379295	1608802724379321	2	1608802724379316	17
sub_83	1608802724379324	1608802724379349	3	1608802724379341	10
sub_87	1608802724379351	1608802724379372	2	1608802724379368	11
mul_9	1608802724379375	1608802724379399	3	1608802724379393	369
mul_21	1608802724379402	1608802724379423	3	1608802724379764	9
sub_4	1608802724379429	1608802724379451	6	1608802724379775	4
sub_7	1608802724379454	1608802724379477	3	1608802724379781	6
sub_5	1608802724379480	1608802724379501	3	1608802724379788	4
mul_48	1608802724379503	1608802724379529	2	1608802724379794	13
sub_11	1608802724379532	1608802724379553	3	1608802724379809	4
mul_37	1608802724379568	1608802724379589	15	1608802724379815	12
sub_9	1608802724379592	1608802724379616	3	1608802724379829	4
mul_70	1608802724379618	1608802724379639	2	1608802724379834	13
sub_15	1608802724379641	1608802724379666	2	1608802724379849	4
sub_100	1608802724379669	1608802724379694	3	1608802724379855	5
mul_59	1608802724379696	1608802724379717	2	1608802724379861	12
sub_13	1608802724379720	1608802724379743	3	1608802724379875	5
mul_91	1608802724379747	1608802724379768	4	1608802724379881	39
mul_220	1608802724379771	1608802724379796	3	1608802724379921	13
sub_119	1608802724379801	1608802724379825	5	1608802724379936	4
sub_123	1608802724379828	1608802724379848	3	1608802724379942	4
sub_14	1608802724379851	1608802724379877	3	1608802724379948	4
sub_17	1608802724379879	1608802724379899	2	1608802724379953	5
sub_103	1608802724379901	1608802724379925	2	1608802724379960	4
mul_134	1608802724379929	1608802724379953	4	1608802724379965	13
sub_107	1608802724379956	1608802724379977	3	1608802724379980	4
mul_177	1608802724379981	1608802724380006	4	1608802724380002	44
sub_115	1608802724380010	1608802724380032	4	1608802724380048	4
mul_102	1608802724380038	1608802724380060	6	1608802724380056	45
mul_672	1608802724380063	1608802724380088	3	1608802724380102	12
sub_127	1608802724380093	1608802724380116	5	1608802724380116	7
sub_94	1608802724380120	1608802724380144	4	1608802724380140	10
mul_295	1608802724380147	1608802724380168	3	1608802724380164	17
sub_57	1608802724380173	1608802724380194	5	1608802724380191	10
sub_105	1608802724380198	1608802724380222	4	1608802724380215	13
mul_586	1608802724380225	1608802724380245	3	1608802724380242	18
sub_111	1608802724380247	1608802724380273	2	1608802724380269	10
sub_116	1608802724380276	1608802724380300	3	1608802724380294	10
mul_650	1608802724380303	1608802724380325	3	1608802724380321	18
sub_35	1608802724380328	1608802724380352	3	1608802724380346	13
sub_37	1608802724380356	1608802724383633	4	1608802724383550	58
sub_131	1608802724383646	1608802724383735	13	1608802724383706	26
sub_95	1608802724383741	1608802724383799	6	1608802724383770	21
sub_97	1608802724383804	1608802724383855	5	1608802724383834	21
sub_55	1608802724383860	1608802724383915	5	1608802724383889	26
mul_317	1608802724383921	1608802724383973	6	1608802724383952	26
sub_151	1608802724383985	1608802724384039	12	1608802724384017	22
mul_607	1608802724384047	1608802724384102	8	1608802724384077	51
sub_117	1608802724384108	1608802724384158	6	1608802724384138	20
sub_121	1608802724384163	1608802724384217	5	1608802724384196	20
sub_125	1608802724384222	1608802724384269	5	1608802724384250	19
mul_693	1608802724384279	1608802724384329	10	1608802724384309	51
sub_132	1608802724384333	1608802724384411	4	1608802724384362	46
mul_209	1608802724384416	1608802724384470	5	1608802724384448	27
sub_139	1608802724384475	1608802724384530	5	1608802724384509	20
mul_532	1608802724384538	1608802724384592	8	1608802724384567	52
sub_101	1608802724384597	1608802724384646	5	1608802724384626	20
mul_822	1608802724384651	1608802724384704	5	1608802724384680	24
sub_59	1608802724384709	1608802724384759	5	1608802724384738	21
sub_113	1608802724384764	1608802724384818	5	1608802724384798	20
mul_639	1608802724384823	1608802724384877	5	1608802724384851	25
mul_661	1608802724384882	1608802724384932	5	1608802724384912	26
sub_126	1608802724384937	1608802724384993	5	1608802724384964	28
sub_129	1608802724384998	1608802724385044	5	1608802724385027	18
sub_133	1608802724385056	1608802724385104	12	1608802724385085	19
sub_135	1608802724385111	1608802724385164	7	1608802724385139	19
mul_758	1608802724385170	1608802724385220	6	1608802724385200	25
sub_39	1608802724385227	1608802724385281	7	1608802724385261	20
sub_99	1608802724385286	1608802724385333	5	1608802724385314	20
mul_553	1608802724385344	1608802724385394	11	1608802724385375	25
mul_263	1608802724385399	1608802724385452	5	1608802724385427	51
sub_109	1608802724385458	1608802724385507	6	1608802724385487	20
mul_618	1608802724385512	1608802724385566	5	1608802724385546	52
mul_897	1608802724385571	1608802724385623	5	1608802724385599	24
mul_919	1608802724385630	1608802724385680	7	1608802724385659	26
sub_174	1608802724385688	1608802724385742	8	1608802724385717	24
mul_704	1608802724385750	1608802724385799	8	1608802724385779	52
mul_983	1608802724385804	1608802724385867	5	1608802724385845	26
mul_736	1608802724385874	1608802724385927	7	1608802724385903	24
sub_141	1608802724385932	1608802724385982	5	1608802724385963	20
sub_143	1608802724385987	1608802724386041	5	1608802724386015	26
sub_147	1608802724386046	1608802724386095	5	1608802724386075	21
sub_153	1608802724386100	1608802724386155	5	1608802724386135	20
mul_833	1608802724386162	1608802724386215	7	1608802724386191	25
mul_242	1608802724386220	1608802724386270	5	1608802724386249	25
sub_110	1608802724386276	1608802724386332	6	1608802724386311	21
sub_167	1608802724386337	1608802724386384	5	1608802724386366	19
sub_171	1608802724386394	1608802724386442	10	1608802724386423	19
sub_175	1608802724386447	1608802724386497	5	1608802724386474	19
mul_962	1608802724386502	1608802724386551	5	1608802724386531	52
sub_183	1608802724386558	1608802724386611	7	1608802724386591	21
sub_187	1608802724386616	1608802724386663	5	1608802724386644	19
sub_137	1608802724386676	1608802724386726	13	1608802724386705	21
sub_142	1608802724386731	1608802724386782	5	1608802724386759	23
mul_779	1608802724386787	1608802724386834	5	1608802724386816	51
sub_148	1608802724386841	1608802724386898	7	1608802724386877	21
sub_29	1608802724386904	1608802724386958	6	1608802724386933	20
sub_155	1608802724386963	1608802724387013	5	1608802724386993	20
sub_158	1608802724387018	1608802724387070	5	1608802724387046	24
sub_41	1608802724387077	1608802724387126	7	1608802724387106	21
mul_908	1608802724387131	1608802724387186	5	1608802724387166	25
mul_930	1608802724387193	1608802724387245	7	1608802724387221	24
mul_951	1608802724387250	1608802724387298	5	1608802724387279	51
sub_179	1608802724387303	1608802724387356	5	1608802724387337	19
sub_185	1608802724387360	1608802724387408	4	1608802724387389	20
mul_1016	1608802724387418	1608802724387467	10	1608802724387447	25
mul_725	1608802724387472	1608802724387525	5	1608802724387500	26
mul_747	1608802724387531	1608802724387581	6	1608802724387561	26
sub_199	1608802724387586	1608802724387640	5	1608802724387620	20
sub_145	1608802724387649	1608802724387696	9	1608802724387678	18
sub_149	1608802724387706	1608802724387753	10	1608802724387735	20
sub_21	1608802724387759	1608802724387809	6	1608802724387787	22
mul_844	1608802724387815	1608802724387863	6	1608802724387844	24
sub_159	1608802724387868	1608802724387921	5	1608802724387900	20
mul_876	1608802724387926	1608802724387979	5	1608802724387955	52
mul_575	1608802724387987	1608802724388037	8	1608802724388017	25
mul_231	1608802724388042	1608802724388096	5	1608802724388070	28
sub_177	1608802724388101	1608802724388148	5	1608802724388129	19
sub_180	1608802724388155	1608802724388211	7	1608802724388188	23
mul_1005	1608802724388217	1608802724388270	6	1608802724388246	24
sub_189	1608802724388275	1608802724388330	5	1608802724388305	24
sub_191	1608802724388335	1608802724388403	5	1608802724388364	37
sub_195	1608802724388412	1608802724388460	9	1608802724388441	19
mul_1080	1608802724388468	1608802724388522	8	1608802724388501	26
sub_203	1608802724388529	1608802724388584	7	1608802724388558	19
mul_790	1608802724388589	1608802724388640	5	1608802724388618	54
mul_811	1608802724388645	1608802724388698	5	1608802724388678	25
sub_157	1608802724388703	1608802724388751	5	1608802724388731	20
mul_865	1608802724388761	1608802724388810	10	1608802724388790	52
sub_163	1608802724388814	1608802724388865	4	1608802724388844	21
sub_169	1608802724388870	1608802724388917	5	1608802724388899	19
sub_173	1608802724388922	1608802724388973	5	1608802724388953	19
sub_181	1608802724388978	1608802724389027	5	1608802724389006	20
sub_45	1608802724389034	1608802724389084	7	1608802724389064	19
sub_190	1608802724389088	1608802724389139	4	1608802724389116	23
mul_1037	1608802724389144	1608802724389192	5	1608802724389172	52
sub_196	1608802724389196	1608802724389250	4	1608802724389230	20
sub_201	1608802724389257	1608802724389308	7	1608802724389285	19
sub_204	1608802724389313	1608802724389363	5	1608802724389344	20
mul_15	1608802724389371	1608802724389423	8	1608802724389400	22
sub_161	1608802724389429	1608802724389478	6	1608802724389458	20
sub_164	1608802724389483	1608802724389535	5	1608802724389516	19
sub_25	1608802724389540	1608802724389592	5	1608802724389568	19
sub_36	1608802724389597	1608802724389646	5	1608802724389626	20
sub_43	1608802724389651	1608802724389704	5	1608802724389680	24
sub_193	1608802724389709	1608802724389756	5	1608802724389737	20
sub_197	1608802724389765	1608802724389812	9	1608802724389793	19
sub_202	1608802724389818	1608802724389868	6	1608802724389845	18
mul_1106	1608802724389873	1608802724389921	5	1608802724389902	19
mul_328	1608802724389926	1608802724389978	5	1608802724389958	25
sub_165	1608802724389983	1608802724390030	5	1608802724390011	20
sub_20	1608802724390040	1608802724390088	10	1608802724390069	20
sub_33	1608802724390093	1608802724390144	5	1608802724390121	22
mul_1048	1608802724390149	1608802724390197	5	1608802724390177	52
mul_1069	1608802724390201	1608802724390253	4	1608802724390233	24
sub_46	1608802724390258	1608802724390309	5	1608802724390286	20
sub_206	1608802724390314	1608802724390365	5	1608802724390345	21
sub_52	1608802724390370	1608802724390421	5	1608802724390399	22
mul_306	1608802724390428	1608802724390477	7	1608802724390457	26
mul_994	1608802724390483	1608802724390537	6	1608802724390516	27
sub_49	1608802724390542	1608802724390595	5	1608802724390571	20
mul_274	1608802724390600	1608802724390649	5	1608802724390629	52
sub_51	1608802724390654	1608802724390705	5	1608802724390683	23
sub_19	1608802724390711	1608802724390758	6	1608802724390739	20
mul_123	1608802724390763	1608802724390816	5	1608802724390797	25
mul_145	1608802724390821	1608802724390871	5	1608802724390849	24
sub_30	1608802724390878	1608802724390928	7	1608802724390908	20
sub_23	1608802724390933	1608802724390984	5	1608802724390965	19
sub_27	1608802724390989	1608802724391037	5	1608802724391018	20
sub_31	1608802724391046	1608802724391093	9	1608802724391074	19
sub_47	1608802724391099	1608802724391150	6	1608802724391126	19
mul_156	1608802724391154	1608802724391203	4	1608802724391183	25
sub_53	1608802724391208	1608802724391260	5	1608802724391241	20
mul_188	1608802724391265	1608802724391312	5	1608802724391294	51
sub_61	1608802724391322	1608802724391371	10	1608802724391352	20
mul_349	1608802724391376	1608802724391441	5	1608802724391405	52
sub_68	1608802724391447	1608802724391499	6	1608802724391477	22
sub_69	1608802724391505	1608802724391557	6	1608802724391537	20
sub_72	1608802724391562	1608802724391614	5	1608802724391591	28
sub_76	1608802724391622	1608802724391672	8	1608802724391652	30
Assign_216	1608802724391679	1608802724391767	7	1608802724391712	45
Assign_192	1608802724391773	1608802724391843	6	1608802724391802	31
sub_88	1608802724391848	1608802724391913	5	1608802724391888	33
Assign_249	1608802724391920	1608802724391991	7	1608802724391948	30
Assign_183	1608802724391996	1608802724392061	5	1608802724392027	29
sub_66	1608802724392066	1608802724392128	5	1608802724392104	71
sub_70	1608802724392137	1608802724392187	9	1608802724392176	20
Assign_264	1608802724392196	1608802724392260	9	1608802724392226	30
Assign_228	1608802724392265	1608802724392333	5	1608802724392293	27
sub_80	1608802724392338	1608802724392405	5	1608802724392378	72
Assign_252	1608802724392413	1608802724392484	8	1608802724392452	24
sub_90	1608802724392489	1608802724392544	5	1608802724392520	31
sub_74	1608802724392556	1608802724392607	12	1608802724392586	30
Assign_231	1608802724392612	1608802724392680	5	1608802724392638	33
Assign_240	1608802724392684	1608802724392748	4	1608802724392713	29
Assign_186	1608802724392753	1608802724392823	5	1608802724392788	29
Assign_198	1608802724392828	1608802724392888	5	1608802724392856	27
sub_92	1608802724392900	1608802724392959	12	1608802724392935	32
sub_96	1608802724392965	1608802724393018	6	1608802724392993	68
Assign_234	1608802724393025	1608802724393087	7	1608802724393063	18
sub_82	1608802724393092	1608802724393153	5	1608802724393130	70
sub_86	1608802724393158	1608802724393211	5	1608802724393201	17
Assign_270	1608802724393215	1608802724393280	4	1608802724393244	30
Assign_276	1608802724393285	1608802724393352	5	1608802724393313	33
Assign_210	1608802724393357	1608802724393417	5	1608802724393385	28
Assign_222	1608802724393422	1608802724393492	5	1608802724393457	29
sub_104	1608802724393497	1608802724393559	5	1608802724393529	32
Assign_246	1608802724393566	1608802724393628	7	1608802724393594	30
Assign_258	1608802724393633	1608802724393701	5	1608802724393660	33
sub_1	1608802724393705	1608802724393760	4	1608802724393737	534
sub_3	1608802724393768	1608802724393825	8	1608802724394274	13
Assign_9	1608802724393831	1608802724393908	6	1608802724394288	4
Assign_18	1608802724393913	1608802724393976	5	1608802724394293	4
Assign_12	1608802724393980	1608802724394048	4	1608802724394299	4
sub_8	1608802724394053	1608802724394108	5	1608802724394304	17
Assign_30	1608802724394115	1608802724394182	7	1608802724394322	4
sub_6	1608802724394187	1608802724394246	5	1608802724394327	17
Assign_24	1608802724394252	1608802724394316	6	1608802724394346	4
sub_12	1608802724394321	1608802724394383	5	1608802724394353	30
Assign_42	1608802724394391	1608802724394454	8	1608802724394419	29
Assign_297	1608802724394459	1608802724394530	5	1608802724394495	31
sub_10	1608802724394535	1608802724394594	5	1608802724394566	31
Assign_36	1608802724394600	1608802724394663	6	1608802724394628	28
sub_16	1608802724394667	1608802724394727	4	1608802724394699	70
sub_40	1608802724394735	1608802724394784	8	1608802724394770	24
Assign_354	1608802724394799	1608802724394866	15	1608802724394829	30
Assign_366	1608802724394871	1608802724394939	5	1608802724394900	27
Assign_39	1608802724394945	1608802724395007	6	1608802724394974	28
Assign_48	1608802724395012	1608802724395080	5	1608802724395045	29
Assign_306	1608802724395085	1608802724395146	5	1608802724395113	27
sub_24	1608802724395157	1608802724395215	11	1608802724395192	31
Assign_318	1608802724395222	1608802724395290	7	1608802724395250	29
sub_32	1608802724395295	1608802724395350	5	1608802724395327	70
Assign_342	1608802724395357	1608802724395424	7	1608802724395398	20
sub_18	1608802724395429	1608802724395489	5	1608802724395461	74
sub_124	1608802724395499	1608802724395553	10	1608802724395537	26
Assign_378	1608802724395561	1608802724395630	8	1608802724395589	34
Assign_279	1608802724395635	1608802724395699	5	1608802724395664	30
sub_54	1608802724395706	1608802724395770	7	1608802724395745	33
Assign_168	1608802724395777	1608802724395840	7	1608802724395805	27
Assign_312	1608802724395852	1608802724395916	12	1608802724395882	29
sub_108	1608802724395921	1608802724395982	5	1608802724395953	31
Assign_330	1608802724395990	1608802724396052	8	1608802724396018	29
Assign_345	1608802724396056	1608802724396126	4	1608802724396092	28
sub_120	1608802724396131	1608802724396184	5	1608802724396162	31
Assign_102	1608802724396197	1608802724396258	13	1608802724396225	28
Assign_108	1608802724396262	1608802724396329	4	1608802724396290	33
Assign_390	1608802724396333	1608802724396409	4	1608802724396361	40
Assign_282	1608802724396414	1608802724396491	5	1608802724396461	27
Assign_288	1608802724396496	1608802724396552	5	1608802724396523	26
Assign_162	1608802724396562	1608802724396620	10	1608802724396590	26
sub_58	1608802724396627	1608802724396685	7	1608802724396659	31
Assign_450	1608802724396692	1608802724396749	7	1608802724396718	27
sub_112	1608802724396753	1608802724396809	4	1608802724396789	69
Assign_348	1608802724396814	1608802724396877	5	1608802724396860	7
Assign_360	1608802724396881	1608802724396939	4	1608802724396908	27
Assign_372	1608802724396943	1608802724397003	4	1608802724396969	30
sub_128	1608802724397007	1608802724397058	4	1608802724397037	70
Assign_393	1608802724397062	1608802724397124	4	1608802724397109	12
sub_38	1608802724397128	1608802724397183	4	1608802724397158	29
Assign_414	1608802724397188	1608802724397245	5	1608802724397215	26
sub_98	1608802724397249	1608802724397307	4	1608802724397286	69
Assign_300	1608802724397312	1608802724397369	5	1608802724397357	8
sub_152	1608802724397379	1608802724397430	10	1608802724397409	30
Assign_174	1608802724397437	1608802724397499	7	1608802724397463	32
Assign_336	1608802724397503	1608802724397561	4	1608802724397530	28
sub_118	1608802724397566	1608802724397622	5	1608802724397601	31
sub_122	1608802724397629	1608802724397674	7	1608802724397657	28
Assign_375	1608802724397683	1608802724397741	9	1608802724397710	28
Assign_384	1608802724397745	1608802724397807	4	1608802724397771	29
Assign_396	1608802724397811	1608802724397867	4	1608802724397837	27
Assign_402	1608802724397871	1608802724397935	4	1608802724397905	27
sub_140	1608802724397940	1608802724397997	5	1608802724397969	30
Assign_114	1608802724398003	1608802724398061	6	1608802724398031	27
Assign_294	1608802724398066	1608802724398128	5	1608802724398092	30
sub_102	1608802724398132	1608802724398183	4	1608802724398162	31
sub_48	1608802724398190	1608802724398243	7	1608802724398223	69
Assign_324	1608802724398247	1608802724398309	4	1608802724398294	6
sub_114	1608802724398314	1608802724398364	5	1608802724398345	69
sub_166	1608802724398369	1608802724398420	5	1608802724398415	17
sub_170	1608802724398428	1608802724398472	8	1608802724398456	29
Assign_519	1608802724398485	1608802724398548	13	1608802724398514	28
sub_130	1608802724398552	1608802724398609	4	1608802724398582	69
sub_182	1608802724398615	1608802724398661	6	1608802724398652	20
sub_136	1608802724398666	1608802724398717	5	1608802724398699	29
Assign_420	1608802724398723	1608802724398787	6	1608802724398750	28
Assign_426	1608802724398792	1608802724398849	5	1608802724398820	26
Assign_438	1608802724398856	1608802724398919	7	1608802724398883	30
Assign_456	1608802724398923	1608802724398979	4	1608802724398950	26
sub_154	1608802724398983	1608802724399041	4	1608802724399019	31
sub_44	1608802724399046	1608802724399095	5	1608802724399074	28
Assign_327	1608802724399100	1608802724399157	5	1608802724399127	26
Assign_498	1608802724399161	1608802724399223	4	1608802724399188	31
Assign_510	1608802724399228	1608802724399283	5	1608802724399254	26
Assign_522	1608802724399287	1608802724399354	4	1608802724399322	27
sub_178	1608802724399358	1608802724399414	4	1608802724399388	69
Assign_546	1608802724399418	1608802724399476	4	1608802724399458	14
Assign_558	1608802724399480	1608802724399542	4	1608802724399507	31
Assign_408	1608802724399546	1608802724399629	4	1608802724399594	29
Assign_423	1608802724399633	1608802724399698	4	1608802724399666	28
sub_144	1608802724399702	1608802724399758	4	1608802724399732	69
Assign_441	1608802724399764	1608802724399824	6	1608802724399803	16
Assign_84	1608802724399828	1608802724399890	4	1608802724399855	30
Assign_462	1608802724399894	1608802724399952	4	1608802724399921	28
Assign_471	1608802724399956	1608802724400022	4	1608802724399991	27
Assign_120	1608802724400026	1608802724400082	4	1608802724400054	26
sub_168	1608802724400092	1608802724400143	10	1608802724400123	29
sub_172	1608802724400147	1608802724400199	4	1608802724400175	29
sub_176	1608802724400204	1608802724400248	5	1608802724400231	68
Assign_534	1608802724400253	1608802724400316	5	1608802724400301	11
Assign_552	1608802724400320	1608802724400393	4	1608802724400348	33
sub_188	1608802724400398	1608802724400451	5	1608802724400429	30
sub_134	1608802724400457	1608802724400507	6	1608802724400485	28
sub_138	1608802724400512	1608802724400556	5	1608802724400539	28
Assign_594	1608802724400561	1608802724400623	5	1608802724400592	27
Assign_432	1608802724400628	1608802724400690	5	1608802724400655	26
Assign_444	1608802724400694	1608802724400751	4	1608802724400722	26
Assign_60	1608802724400756	1608802724400818	5	1608802724400782	31
sub_156	1608802724400822	1608802724400873	4	1608802724400853	30
Assign_474	1608802724400880	1608802724400942	7	1608802724400911	27
sub_162	1608802724400946	1608802724401002	4	1608802724400975	69
sub_106	1608802724401007	1608802724401053	5	1608802724401046	17
sub_42	1608802724401058	1608802724401107	5	1608802724401089	28
Assign_528	1608802724401111	1608802724401168	4	1608802724401137	26
Assign_537	1608802724401181	1608802724401241	13	1608802724401209	26
sub_186	1608802724401246	1608802724401300	5	1608802724401275	29
Assign_564	1608802724401305	1608802724401362	5	1608802724401332	27
Assign_570	1608802724401367	1608802724401431	5	1608802724401399	27
Assign_582	1608802724401436	1608802724401490	5	1608802724401462	24
sub_200	1608802724401500	1608802724401554	10	1608802724401533	30
Assign_606	1608802724401562	1608802724401627	8	1608802724401589	27
sub_146	1608802724401632	1608802724401683	5	1608802724401662	70
sub_150	1608802724401690	1608802724401740	7	1608802724401733	17
Assign_468	1608802724401745	1608802724401801	5	1608802724401771	26
sub_160	1608802724401811	1608802724401864	10	1608802724401843	69
Assign_486	1608802724401868	1608802724401929	4	1608802724401913	11
Assign_504	1608802724401934	1608802724401991	5	1608802724401962	26
Assign_516	1608802724401995	1608802724402063	4	1608802724402028	29
Assign_540	1608802724402067	1608802724402124	4	1608802724402094	27
Assign_132	1608802724402133	1608802724402192	9	1608802724402161	27
Assign_567	1608802724402196	1608802724402257	4	1608802724402223	26
sub_192	1608802724402262	1608802724402314	5	1608802724402292	70
Assign_585	1608802724402321	1608802724402383	7	1608802724402364	15
Assign_600	1608802724402387	1608802724402442	4	1608802724402414	25
Assign_609	1608802724402452	1608802724402509	10	1608802724402479	26
sub_2	1608802724402514	1608802724402569	5	1608802724402543	21
Assign_480	1608802724402576	1608802724402633	7	1608802724402603	26
Assign_489	1608802724402637	1608802724402699	4	1608802724402669	26
Assign_72	1608802724402704	1608802724402758	5	1608802724402731	25
Assign_105	1608802724402768	1608802724402824	10	1608802724402795	25
Assign_126	1608802724402828	1608802724402888	4	1608802724402854	25
Assign_576	1608802724402893	1608802724402949	5	1608802724402920	26
Assign_588	1608802724402954	1608802724403019	5	1608802724402987	27
Assign_603	1608802724403024	1608802724403078	5	1608802724403051	25
sub_205	1608802724403082	1608802724403138	4	1608802724403118	20
sub_60	1608802724403143	1608802724403192	5	1608802724403170	28
Assign_492	1608802724403199	1608802724403255	7	1608802724403225	27
Assign_57	1608802724403260	1608802724403322	5	1608802724403292	26
Assign_96	1608802724403327	1608802724403383	5	1608802724403354	25
sub_194	1608802724403393	1608802724403446	10	1608802724403425	70
sub_198	1608802724403451	1608802724403499	5	1608802724403497	17
Assign_135	1608802724403504	1608802724403560	5	1608802724403530	26
Assign_615	1608802724403564	1608802724403627	4	1608802724403596	26
Assign_153	1608802724403631	1608802724403687	4	1608802724403659	25
sub_56	1608802724403691	1608802724403749	4	1608802724403727	31
sub_184	1608802724403754	1608802724403811	5	1608802724403781	28
Assign_144	1608802724403818	1608802724403879	7	1608802724403847	28
sub_50	1608802724403883	1608802724403939	4	1608802724403918	69
Assign_150	1608802724403944	1608802724404001	5	1608802724403989	8
Assign_54	1608802724404011	1608802724404070	10	1608802724404040	26
sub_22	1608802724404075	1608802724404130	5	1608802724404105	29
sub_26	1608802724404134	1608802724404180	4	1608802724404163	30
Assign_87	1608802724404187	1608802724404250	7	1608802724404218	27
Assign_66	1608802724404254	1608802724404310	4	1608802724404281	26
Assign_78	1608802724404321	1608802724404387	11	1608802724404348	34
Assign_90	1608802724404392	1608802724404455	5	1608802724404420	26
Assign_138	1608802724404460	1608802724404517	5	1608802724404488	26
sub_28	1608802724404522	1608802724404578	5	1608802724404557	30
Assign_156	1608802724404583	1608802724404639	5	1608802724404609	26
sub_34	1608802724404648	1608802724404700	9	1608802724404679	69
Assign_180	1608802724404705	1608802724404766	5	1608802724404750	8
sub_64	1608802724404771	1608802724404822	5	1608802724404802	69
Assign_201	1608802724404827	1608802724404888	5	1608802724404872	13
Assign_204	1608802724404893	1608802724404948	5	1608802724404920	25
Assign_213	1608802724404957	1608802724405020	9	1608802724404985	34
Assign_225	1608802724405024	1608802724405086	4	1608802724405051	31
Assign_261	1608802724405090	1608802724405147	4	1608802724405118	31
Assign_195	1608802724405151	1608802724405214	4	1608802724405183	60
Assign_207	1608802724405219	1608802724405273	5	1608802724405245	30
Assign_237	1608802724405283	1608802724405339	10	1608802724405310	58
Assign_267	1608802724405343	1608802724405403	4	1608802724405370	29
Assign_219	1608802724405408	1608802724405461	5	1608802724405434	30
Assign_273	1608802724405465	1608802724405524	4	1608802724405497	31
Assign_285	1608802724405528	1608802724405587	4	1608802724405555	57
Assign_243	1608802724405591	1608802724405648	4	1608802724405619	58
Assign_255	1608802724405652	1608802724405712	4	1608802724405678	29
Assign_309	1608802724405717	1608802724405771	5	1608802724405744	31
Assign	1608802724405781	1608802724405850	10	1608802724405811	385
Assign_6	1608802724405855	1608802724405917	5	1608802724406197	10
Assign_21	1608802724405922	1608802724405978	5	1608802724406208	14
Assign_15	1608802724405983	1608802724406042	5	1608802724406224	13
Assign_33	1608802724406046	1608802724406100	4	1608802724406239	13
Assign_27	1608802724406109	1608802724406164	9	1608802724406254	13
Assign_45	1608802724406168	1608802724406227	4	1608802724406269	41
Assign_117	1608802724406231	1608802724406289	4	1608802724406311	13
Assign_69	1608802724406293	1608802724406354	4	1608802724406326	29
Assign_93	1608802724406358	1608802724406412	4	1608802724406385	57
Assign_51	1608802724406421	1608802724406478	9	1608802724406449	58
Assign_369	1608802724406482	1608802724406541	4	1608802724406509	31
Assign_159	1608802724406546	1608802724406605	5	1608802724406575	31
Assign_321	1608802724406609	1608802724406672	4	1608802724406641	31
Assign_357	1608802724406676	1608802724406731	4	1608802724406704	30
Assign_171	1608802724406741	1608802724406799	10	1608802724406769	32
Assign_333	1608802724406803	1608802724406865	4	1608802724406830	58
Assign_381	1608802724406869	1608802724406926	4	1608802724406896	58
Assign_111	1608802724406930	1608802724406993	4	1608802724406964	32
Assign_291	1608802724406998	1608802724407053	5	1608802724407026	59
Assign_453	1608802724407062	1608802724407119	9	1608802724407090	32
Assign_351	1608802724407123	1608802724407182	4	1608802724407150	29
Assign_363	1608802724407186	1608802724407240	4	1608802724407213	30
Assign_417	1608802724407244	1608802724407306	4	1608802724407278	31
Assign_303	1608802724407311	1608802724407369	5	1608802724407337	30
Assign_141	1608802724407373	1608802724407432	4	1608802724407401	59
Assign_339	1608802724407437	1608802724407498	5	1608802724407463	57
Assign_495	1608802724407502	1608802724407561	4	1608802724407530	33
Assign_507	1608802724407567	1608802724407629	6	1608802724407600	32
Assign_387	1608802724407634	1608802724407692	5	1608802724407660	58
Assign_543	1608802724407697	1608802724407753	5	1608802724407724	31
Assign_405	1608802724407757	1608802724407818	4	1608802724407788	32
Assign_459	1608802724407823	1608802724407878	5	1608802724407849	30
Assign_129	1608802724407882	1608802724407945	4	1608802724407916	31
Assign_531	1608802724407950	1608802724408008	5	1608802724407976	58
Assign_429	1608802724408013	1608802724408068	5	1608802724408040	58
Assign_501	1608802724408072	1608802724408133	4	1608802724408103	32
Assign_513	1608802724408137	1608802724408191	4	1608802724408164	30
Assign_525	1608802724408200	1608802724408259	9	1608802724408230	58
Assign_561	1608802724408263	1608802724408324	4	1608802724408289	30
Assign_399	1608802724408328	1608802724408398	4	1608802724408356	42
Assign_411	1608802724408403	1608802724408480	5	1608802724408437	39
Assign_465	1608802724408485	1608802724408537	5	1608802724408511	29
Assign_483	1608802724408546	1608802724408599	9	1608802724408572	59
Assign_315	1608802724408603	1608802724408663	4	1608802724408632	27
Assign_123	1608802724408667	1608802724408720	4	1608802724408693	30
Assign_555	1608802724408724	1608802724408782	4	1608802724408756	30
Assign_597	1608802724408787	1608802724408837	5	1608802724408812	29
Assign_435	1608802724408845	1608802724408898	8	1608802724408872	57
Assign_447	1608802724408902	1608802724408957	4	1608802724408930	26
Assign_477	1608802724408961	1608802724409014	4	1608802724408988	57
Assign_573	1608802724409018	1608802724409074	4	1608802724409048	58
Assign_3	1608802724409078	1608802724409129	4	1608802724409107	21
Assign_612	1608802724409139	1608802724409192	10	1608802724409166	25
Assign_177	1608802724409196	1608802724409253	4	1608802724409222	29
Assign_579	1608802724409257	1608802724409309	4	1608802724409284	57
Assign_591	1608802724409314	1608802724409372	5	1608802724409345	31
Assign_165	1608802724409376	1608802724409426	4	1608802724409401	29
Assign_549	1608802724409437	1608802724409491	11	1608802724409463	30
Assign_147	1608802724409495	1608802724409553	4	1608802724409521	57
Assign_63	1608802724409557	1608802724409630	4	1608802724409583	50
Assign_75	1608802724409634	1608802724409694	4	1608802724409665	31
Assign_81	1608802724409698	1608802724409749	4	1608802724409724	29
Assign_99	1608802724409758	1608802724409816	9	1608802724409787	59
Assign_189	1608802724409823	1608802724409878	7	1608802724409851	57
group_deps_1	1608802724409885	1608802724410014	7	-1	-1
