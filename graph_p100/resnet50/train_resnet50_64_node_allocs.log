tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D
1608143244734019	12.25
1608143244734025	1.0
1608143244734071	0.001953125
1608143244734139	-0.001953125
1608143244734142	-1.0
1608143244785822	-12.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv36/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v113/conv46/conv2d/kernel/read
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg/mul
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg/mul
tower_0/v/l2_loss/L2Loss_2
1608143244706136	0.000244140625
1608143244706866	-0.000244140625
tower_0/v/gradients/tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/mul
v/cg/resnet_v14/conv15/conv2d/kernel
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/ShapeN-matshapes-0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v14/conv17/batchnorm17/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244846304	31.751953125
1608143244846309	0.25
1608143244846331	24.5
1608143244846344	0.006591796875
1608143244846412	-31.751953125
1608143244846414	-0.006591796875
1608143244846415	-0.25
1608143244849064	-24.5
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg/sub_1
v/cg/resnet_v19/conv31/batchnorm31/moving_mean
v/cg/resnet_v111/conv39/batchnorm39/moving_variance/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244768176	7.804931640625
1608143244768184	4.0
1608143244768216	9.00048828125
1608143244768242	0.00390625
1608143244768355	-7.804931640625
1608143244768358	-0.00390625
1608143244768369	-4.0
1608143244769593	-9.00048828125
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg_1/sub_1
gpu_compute_stage_ops_group
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg/sub_1
v/cg/resnet_v17/conv25/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/truediv
tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D
1608143244750311	24.5
1608143244750316	4.0
1608143244750421	0.00048828125
1608143244750920	-0.00048828125
1608143244750924	-4.0
1608143244768150	-24.5
v/cg/resnet_v14/conv15/batchnorm15/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244791329	1.0
1608143244791337	1.0
1608143244791354	0.00390625
1608143244791484	-0.00390625
1608143244791487	-1.0
1608143244792470	-1.0
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg_1/mul
v/cg/resnet_v15/conv20/conv2d/kernel/read
v/cg/resnet_v19/conv31/batchnorm31/beta/read
tower_0/v/l2_loss/L2Loss_27
1608143244699349	0.000244140625
1608143244699351	0.000244140625
1608143244699404	-0.000244140625
1608143244706873	-0.000244140625
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg
v/cg/resnet_v13/conv14/batchnorm14/moving_mean
v/cg/resnet_v12/conv8/batchnorm8/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/conv0/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/batchnorm39/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244787472	49.00390625
1608143244787473	0.00390625
1608143244787474	0.00439453125
1608143244787474	0.000244140625
1608143244787551	0.000244140625
1608143244787641	-0.000244140625
1608143244787641	-0.000244140625
1608143244787998	-49.00390625
1608143244788042	-0.00390625
1608143244788082	-0.00439453125
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D
1608143244713661	49.0
1608143244713668	0.0625
1608143244713721	0.01806640625
1608143244713800	-0.01806640625
1608143244713804	-0.0625
1608143244859160	-49.0
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg/mul
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v12/conv8/batchnorm8/gamma/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_40_grad/mul
1608143244698207	1.0
1608143244786805	-1.0
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg_1/sub_1
learning_rate/Cast
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_17_grad/mul
1608143244702702	0.25
1608143244838709	-0.25
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Merge
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg_1/sub_1
v/cg/resnet_v19/conv33/batchnorm33/moving_variance/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv45/batchnorm45/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv37/batchnorm37/gamma/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_36
1608143244699608	0.000244140625
1608143244699610	0.000244140625
1608143244699664	-0.000244140625
1608143244706881	-0.000244140625
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg
v/cg/resnet_v11/conv6/batchnorm6/gamma/read
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg_1/mul
v/cg/resnet_v110/conv36/batchnorm36/moving_variance
v/cg/resnet_v18/conv28/batchnorm28/moving_variance/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/batchnorm41/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244782355	12.25
1608143244782356	0.0009765625
1608143244782357	0.001220703125
1608143244782357	0.000244140625
1608143244782381	0.000244140625
1608143244782471	-0.000244140625
1608143244782471	-0.000244140625
1608143244783791	-12.25
1608143244783844	-0.0009765625
1608143244783883	-0.001220703125
tower_0/v/gradients/AddN_19
tower_0/v/gradients/AddN_48
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/Mul
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244814275	2.25
1608143244814282	2.250244140625
1608143244814305	81.0
1608143244819143	-81.0
1608143244819146	-2.250244140625
1608143244820270	-2.25
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg/mul
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/cond/Switch_1
edge_663_learning_rate/PiecewiseConstant/and_1@@MemcpyDtoH
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg/mul
v/cg/resnet_v14/conv17/batchnorm17/beta
tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D
1608143244718548	24.5
1608143244718554	0.25
1608143244718610	0.004638671875
1608143244718682	-0.004638671875
1608143244718685	-0.25
1608143244841879	-24.5
v/cg/resnet_v17/conv24/batchnorm24/gamma
tower_0/v/gradients/AddN_13
v/cg/resnet_v11/conv7/batchnorm7/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/Relu_grad/ReluGrad
tower_0/v/l2_loss/L2Loss_33
1608143244698814	0.000244140625
1608143244698816	0.000244140625
1608143244698873	-0.000244140625
1608143244706878	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v15/conv19/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv1/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v14/conv16/Relu
tower_0/v/cg/resnet_v10/Relu
v/cg/resnet_v16/conv23/batchnorm23/gamma/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_30_grad/mul
1608143244699561	1.0
1608143244804335	-1.0
tower_0/v/cg/resnet_v114/add
tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D
1608143244724341	12.25
1608143244724347	0.5
1608143244724407	0.001220703125
1608143244724480	-0.001220703125
1608143244724484	-0.5
1608143244820217	-12.25
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg_1/mul
v/cg/resnet_v111/conv38/batchnorm38/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/batchnorm42/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244781720	49.00390625
1608143244781721	0.00390625
1608143244781721	0.00439453125
1608143244781722	0.000244140625
1608143244781743	0.000244140625
1608143244781827	-0.000244140625
1608143244781828	-0.000244140625
1608143244782179	-49.00390625
1608143244782223	-0.00390625
1608143244782264	-0.00439453125
v/cg/resnet_v16/conv21/batchnorm21/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v10/conv2/batchnorm2/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/batchnorm49/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244767852	24.515625
1608143244767853	0.0078125
1608143244767854	0.0078125
1608143244767855	0.000244140625
1608143244767880	0.000244140625
1608143244768154	-0.000244140625
1608143244768155	-0.000244140625
1608143244769286	-24.515625
1608143244769343	-0.0078125
1608143244769384	-0.0078125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv41/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v111/conv39/batchnorm39/moving_mean
tower_0/v/l2_loss/L2Loss_47
1608143244700019	0.000244140625
1608143244700031	0.0087890625
1608143244700101	-0.0087890625
1608143244706890	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv3/conv2d/kernel/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v110/conv34/batchnorm34/moving_mean/read
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/Switch_1
tower_0/v/gradients/AddN_18
tower_0/v/l2_loss/L2Loss_11
1608143244705775	0.000244140625
1608143244705777	0.000244140625
1608143244705826	-0.000244140625
1608143244706859	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/conv0/Relu_grad/ReluGrad
v/cg/resnet_v18/conv28/batchnorm28/moving_mean
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg
v/cg/resnet_v15/conv20/batchnorm20/moving_mean
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg/mul
tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D
1608143244746478	6.125
1608143244746483	4.0
1608143244746534	0.00048828125
1608143244747329	-0.00048828125
1608143244747333	-4.0
1608143244771944	-6.125
tower_0/v/cg/resnet_v16/conv23/batchnorm23/FusedBatchNormV3
1608143244723875	98.0
1608143244723877	0.001953125
1608143244723878	0.001953125
1608143244723879	0.001953125
1608143244723880	0.001953125
1608143244724748	-0.001953125
1608143244724790	-0.001953125
1608143244821632	-98.0
1608143244821922	-0.001953125
1608143244821923	-0.001953125
tower_0/v/cg/resnet_v16/conv21/Relu
v/cg/resnet_v115/conv52/batchnorm52/beta/read
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg/mul
tower_0/v/cg/resnet_v15/conv18/Relu
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_6_grad/mul
1608143244705521	0.140625
1608143244869889	-0.140625
tower_0/v/gradients/AddN_64
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg/mul
tower_0/v/gradients/AddN_39
_SOURCE
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv37/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v16/conv21/batchnorm21/moving_mean/read
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg_1/sub_1
v/cg/resnet_v113/conv43/batchnorm43/moving_variance/read
tower_0/v/l2_loss/L2Loss_23
1608143244698259	0.000244140625
1608143244698261	0.000244140625
1608143244698315	-0.000244140625
1608143244706869	-0.000244140625
v/cg/resnet_v16/conv23/conv2d/kernel/read
tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D
1608143244719723	98.0
1608143244719729	0.25
1608143244719778	0.004638671875
1608143244719851	-0.004638671875
1608143244719873	-0.25
1608143244836720	-98.0
tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D
1608143244721689	98.0
1608143244721695	0.25
1608143244721750	0.004638671875
1608143244721823	-0.004638671875
1608143244721827	-0.25
1608143244831223	-98.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v111/conv38/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Reshape
v/cg/resnet_v110/conv35/batchnorm35/beta
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg_1/sub_1
v/cg/resnet_v13/conv13/conv2d/kernel
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg/mul
v/cg/resnet_v11/conv6/batchnorm6/beta
tower_0/v/cg/resnet_v111/conv38/batchnorm38/FusedBatchNormV3
1608143244733029	12.25
1608143244733031	0.0009765625
1608143244733033	0.0009765625
1608143244733037	0.0009765625
1608143244733038	0.0009765625
1608143244733726	-0.0009765625
1608143244733768	-0.0009765625
1608143244788706	-12.25
1608143244788961	-0.0009765625
1608143244788962	-0.0009765625
v/cg/resnet_v15/conv19/batchnorm19/moving_variance
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg_1/mul
tower_0/v/gradients/AddN_34
v/cg/resnet_v13/conv14/batchnorm14/gamma
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg_1/sub_1
v/cg/resnet_v16/conv21/batchnorm21/moving_variance
learning_rate/PiecewiseConstant/Greater_1
1608143244692256	0.000244140625
1608143244707062	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/ShapeN-matshapes-0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv15/batchnorm15/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_grad/mul
1608143244704814	0.035888671875
1608143244884324	-0.035888671875
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244878515	0.25
1608143244878521	0.140625
1608143244878535	0.00537109375
1608143244879255	-0.00537109375
1608143244879257	-0.140625
1608143244880416	-0.25
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244783303	4.0
1608143244783311	4.00048828125
1608143244783329	81.0
1608143244783779	-81.0
1608143244783782	-4.00048828125
1608143244786186	-4.0
v/cg/resnet_v19/conv33/batchnorm33/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244880426	61.21875
1608143244880432	0.015625
1608143244880455	49.0
1608143244880468	0.020263671875
1608143244880659	-61.21875
1608143244880661	-0.020263671875
1608143244880662	-0.015625
1608143244882663	-49.0
v/cg/resnet_v17/conv27/batchnorm27/gamma/read
v/cg/resnet_v16/conv23/batchnorm23/gamma
v/cg/resnet_v17/conv24/conv2d/kernel/read
tower_0/v/l2_loss/L2Loss_10
1608143244704085	0.000244140625
1608143244704087	0.000244140625
1608143244704140	-0.000244140625
1608143244706858	-0.000244140625
v/cg/resnet_v110/conv34/batchnorm34/beta/read
v/cg/resnet_v17/conv26/batchnorm26/moving_mean
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg
v/cg/resnet_v12/conv9/batchnorm9/gamma/read
tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D
1608143244712865	196.0
1608143244712878	0.0625
1608143244712937	0.01806640625
1608143244713016	-0.01806640625
1608143244713020	-0.0625
1608143244861424	-196.0
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244824162	24.5
1608143244824168	1.0
1608143244824199	31.751953125
1608143244824215	112.5
1608143244824888	-24.5
1608143244824891	-112.5
1608143244824892	-1.0
1608143244826657	-31.751953125
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg_1
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg_1/sub_1
v/cg/resnet_v15/conv19/batchnorm19/moving_mean
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244805449	19.501953125
1608143244805455	2.25
1608143244805490	12.25
1608143244805507	81.0
1608143244805687	-19.501953125
1608143244805690	-81.0
1608143244805692	-2.25
1608143244807214	-12.25
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/batchnorm24/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244809480	49.0
1608143244809480	0.00439453125
1608143244809481	0.00390625
1608143244809482	0.000244140625
1608143244809534	0.000244140625
1608143244809658	-0.000244140625
1608143244809658	-0.000244140625
1608143244810905	-49.0
1608143244810954	-0.00439453125
1608143244810986	-0.00390625
tower_0/v/gradients/AddN_37
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v16/conv22/batchnorm22/beta/read
tower_0/v/cg/resnet_v113/conv45/batchnorm45/FusedBatchNormV3
1608143244743967	6.125
1608143244743968	0.001953125
1608143244743969	0.001953125
1608143244743970	0.001953125
1608143244743971	0.001953125
1608143244746064	-0.001953125
1608143244746108	-0.001953125
1608143244780145	-6.125
1608143244780345	-0.001953125
1608143244780346	-0.001953125
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244845172	196.0
1608143244845177	0.5
1608143244845211	196.0
1608143244846021	-196.0
1608143244846023	-0.5
1608143244872456	-196.0
v/cg/resnet_v112/conv41/batchnorm41/moving_variance/read
v/cg/resnet_v10/conv3/batchnorm3/gamma/read
v/cg/resnet_v114/conv47/batchnorm47/moving_variance/read
v/cg/resnet_v14/conv17/batchnorm17/moving_variance
tower_0/v/cg/resnet_v12/conv9/Relu
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg_1/mul
v/cg/resnet_v110/conv35/conv2d/kernel
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv38/batchnorm38/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v17/Relu
tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D
1608143244734499	12.25
1608143244734504	2.25
1608143244734550	81.0
1608143244735945	-81.0
1608143244735949	-2.25
1608143244782467	-12.25
tower_0/v/cg/resnet_v15/conv20/batchnorm20/FusedBatchNormV3
1608143244721971	98.0
1608143244721972	0.001953125
1608143244721973	0.001953125
1608143244721974	0.001953125
1608143244721975	0.001953125
1608143244722640	-0.001953125
1608143244722680	-0.001953125
1608143244831078	-98.0
1608143244831224	-0.001953125
1608143244831225	-0.001953125
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/batchnorm52/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244762667	24.5078125
1608143244762667	0.009765625
1608143244762669	0.0078125
1608143244762669	0.000244140625
1608143244762704	0.000244140625
1608143244762801	-0.000244140625
1608143244762802	-0.000244140625
1608143244763340	-24.5078125
1608143244763400	-0.009765625
1608143244763672	-0.0078125
v/cg/resnet_v112/conv40/batchnorm40/moving_mean/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_49_grad/mul
1608143244702068	4.0
1608143244769474	-4.0
tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D
1608143244726742	12.25
1608143244726747	1.0
1608143244726797	0.001953125
1608143244726873	-0.001953125
1608143244726876	-1.0
1608143244807216	-12.25
v/cg/resnet_v110/conv35/batchnorm35/moving_mean/read
tower_0/v/cg/resnet_v110/conv34/batchnorm34/FusedBatchNormV3
1608143244730710	12.25
1608143244730711	0.0009765625
1608143244730711	0.0009765625
1608143244730712	0.0009765625
1608143244730713	0.0009765625
1608143244731374	-0.0009765625
1608143244731408	-0.0009765625
1608143244795310	-12.25
1608143244796269	-0.0009765625
1608143244796270	-0.0009765625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv26/batchnorm26/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv4/batchnorm4/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v114/conv49/batchnorm49/Const
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v111/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg/sub_1
tower_0/v/cg/affine0/xw_plus_b
tower_0/v/cg/resnet_v12/add
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg/mul
tower_0/v/cg/resnet_v114/conv48/Relu
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg_1/mul
v/cg/resnet_v17/conv24/batchnorm24/moving_variance/read
v/cg/resnet_v17/conv24/conv2d/kernel
v/cg/resnet_v111/conv38/batchnorm38/moving_variance/read
tower_0/v/cg/resnet_v12/conv8/Relu
v/cg/resnet_v113/conv43/batchnorm43/gamma/read
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg/sub_1
v/cg/resnet_v113/conv45/batchnorm45/gamma/read
tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D
1608143244709296	49.0
1608143244709302	0.140625
1608143244709362	85.046875
1608143244709783	-85.046875
1608143244709788	-0.140625
1608143244877564	-49.0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_3_grad/mul
1608143244704387	0.140625
1608143244880258	-0.140625
tower_0/v/gradients/AddN_5
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg_1/sub_1
tower_0/v/l2_loss/L2Loss_43
1608143244697605	0.000244140625
1608143244697641	0.0087890625
1608143244697718	-0.0087890625
1608143244706887	-0.000244140625
v/cg/resnet_v17/conv26/batchnorm26/beta
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_27_grad/mul
1608143244699428	1.0
1608143244813559	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244800609	49.0
1608143244800615	1.0
1608143244800704	49.0
1608143244800723	0.00390625
1608143244800794	-49.0
1608143244800797	-0.00390625
1608143244800797	-1.0
1608143244801767	-49.0
v/cg/resnet_v13/conv12/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244792869	1.0
1608143244792876	1.0
1608143244792905	0.00244140625
1608143244793024	-0.00244140625
1608143244793027	-1.0
1608143244794124	-1.0
edge_560_learning_rate/PiecewiseConstant/case/preds_c@@MemcpyDtoH
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/ShapeN-matshapes-0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244811000	12.25
1608143244811006	1.0
1608143244811030	19.501953125
1608143244811045	0.00390625
1608143244811997	-12.25
1608143244812000	-0.00390625
1608143244812001	-1.0
1608143244813713	-19.501953125
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg_1/mul
v/cg/resnet_v17/conv25/batchnorm25/gamma
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg/sub_1
v/cg/resnet_v17/conv26/conv2d/kernel
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/ShapeN-matshapes-0
main_fetch_group/_564
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg/mul
v/cg/resnet_v11/conv7/batchnorm7/beta/read
learning_rate/mul
tower_0/v/gradients/AddN_11
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Assert/Switch_1
tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D
1608143244723598	98.0
1608143244723611	0.25
1608143244723661	0.004638671875
1608143244723733	-0.004638671875
1608143244723736	-0.25
1608143244821921	-98.0
tower_0/v/gradients/AddN_28
v/cg/resnet_v112/conv40/conv2d/kernel
tower_0/v/gradients/AddN_44
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg_1/sub_1
v/cg/resnet_v113/conv45/batchnorm45/moving_variance/read
tower_0/v/l2_loss/L2Loss_39
1608143244699736	0.000244140625
1608143244699737	0.000244140625
1608143244699794	-0.000244140625
1608143244706883	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv41/batchnorm41/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244831829	24.5
1608143244831835	0.56298828125
1608143244831862	31.751953125
1608143244831877	112.5
1608143244832229	-24.5
1608143244832231	-112.5
1608143244832233	-0.56298828125
1608143244834287	-31.751953125
v/cg/resnet_v15/conv20/batchnorm20/gamma/read
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg_1
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v110/add
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv18/batchnorm18/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v19/conv32/batchnorm32/FusedBatchNormV3
1608143244729450	12.25
1608143244729451	0.0009765625
1608143244729452	0.0009765625
1608143244729453	0.0009765625
1608143244729454	0.0009765625
1608143244730142	-0.0009765625
1608143244730177	-0.0009765625
1608143244797565	-12.25
1608143244797726	-0.0009765625
1608143244797727	-0.0009765625
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/batchnorm1/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244872157	196.0
1608143244872158	0.001220703125
1608143244872158	0.0009765625
1608143244872163	0.000244140625
1608143244872225	0.000244140625
1608143244872297	-0.000244140625
1608143244872298	-0.000244140625
1608143244874253	-196.0
1608143244874288	-0.001220703125
1608143244874332	-0.0009765625
v/cg/conv0/batchnorm0/moving_mean
v/cg/resnet_v10/conv4/conv2d/kernel
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg/sub_1
v/cg/resnet_v19/conv32/batchnorm32/moving_variance
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg_1/sub_1
tower_0/v/gradients/AddN_14
tower_0/v/cg/resnet_v110/conv36/batchnorm36/FusedBatchNormV3
1608143244731809	49.0
1608143244731810	0.00390625
1608143244731811	0.00390625
1608143244731817	0.00390625
1608143244731818	0.00390625
1608143244732448	-0.00390625
1608143244732482	-0.00390625
1608143244792430	-49.0
1608143244792672	-0.00390625
1608143244792673	-0.00390625
tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D
1608143244730938	12.25
1608143244730943	2.25
1608143244730995	81.0
1608143244731098	-81.0
1608143244731102	-2.25
1608143244794074	-12.25
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244870051	196.0
1608143244870056	0.062744140625
1608143244870078	196.0
1608143244870091	0.020263671875
1608143244870926	-196.0
1608143244870929	-0.020263671875
1608143244870930	-0.062744140625
1608143244872037	-196.0
tower_0/v/gradients/tower_0/v/cg/conv0/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244882978	0.035888671875
1608143244882985	0.035888671875
1608143244882999	0.0341796875
1608143244883165	-0.0341796875
1608143244883167	-0.035888671875
1608143244884351	-0.035888671875
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg
tower_0/v/cg/resnet_v115/conv52/batchnorm52/FusedBatchNormV3
1608143244756548	24.5
1608143244756549	0.009765625
1608143244756550	0.0078125
1608143244756551	0.0078125
1608143244756552	0.0078125
1608143244758651	-0.009765625
1608143244758684	-0.0078125
1608143244762643	-24.5
1608143244762798	-0.0078125
1608143244762799	-0.0078125
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244789034	12.25
1608143244789040	3.00048828125
1608143244789105	12.25
1608143244789126	81.0
1608143244789225	-12.25
1608143244789228	-81.0
1608143244789230	-3.00048828125
1608143244790462	-12.25
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg_1/mul
v/cg/resnet_v18/conv29/batchnorm29/beta
tower_0/v/gradients/AddN_66
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg_1/mul
tower_0/v/l2_loss/L2Loss_7
1608143244702439	0.000244140625
1608143244702443	0.000244140625
1608143244702499	-0.000244140625
1608143244706898	-0.000244140625
tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D
1608143244722950	24.5
1608143244722956	0.5625
1608143244723004	112.5
1608143244723113	-112.5
1608143244723117	-0.5625
1608143244824099	-24.5
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv9/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv24/batchnorm24/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg_1
tower_0/v/cg/resnet_v18/conv29/Relu
tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D
1608143244742313	6.125
1608143244742318	9.0
1608143244742863	72.0
1608143244743470	-72.0
1608143244743474	-9.0
1608143244780344	-6.125
v/cg/resnet_v113/conv45/batchnorm45/moving_mean/read
v/cg/resnet_v19/conv32/batchnorm32/gamma/read
tower_0/v/cg/resnet_v112/conv41/Relu
v/cg/resnet_v114/conv49/batchnorm49/gamma
tower_0/v/gradients/tower_0/v/cg/affine0/xw_plus_b/MatMul_grad/MatMul
1608143244761608	0.5
1608143244762009	-0.5
tower_0/v/l2_loss/L2Loss_38
1608143244701823	0.000244140625
1608143244701836	0.0087890625
1608143244701893	-0.0087890625
1608143244706882	-0.000244140625
v/cg/resnet_v13/conv11/batchnorm11/moving_mean/read
tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D
1608143244710516	196.0
1608143244710523	0.0625
1608143244710582	0.01806640625
1608143244710663	-0.01806640625
1608143244710667	-0.0625
1608143244872458	-196.0
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D
1608143244724547	49.0
1608143244724552	2.0
1608143244724608	0.001220703125
1608143244724680	-0.001220703125
1608143244724684	-2.0
1608143244809653	-49.0
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244837655	0.25
1608143244837661	0.25048828125
1608143244837676	0.00244140625
1608143244838477	-0.00244140625
1608143244838480	-0.25048828125
1608143244838859	-0.25
v/cg/resnet_v17/conv26/conv2d/kernel/read
learning_rate/PiecewiseConstant/case/cond/cond/cond/Switch/Switch
tower_0/v/gradients/AddN_9
v/cg/resnet_v16/conv22/batchnorm22/gamma
v/cg/resnet_v15/conv18/batchnorm18/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244870950	0.062744140625
1608143244870956	0.0625
1608143244870970	0.0029296875
1608143244871927	-0.0029296875
1608143244871930	-0.0625
1608143244872149	-0.062744140625
tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D
1608143244752438	6.125
1608143244752443	4.0
1608143244752496	0.00048828125
1608143244753036	-0.00048828125
1608143244753040	-4.0
1608143244766350	-6.125
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv28/batchnorm28/gamma/ApplyGradientDescent
v/cg/resnet_v113/conv44/batchnorm44/gamma
v/cg/resnet_v110/conv35/batchnorm35/gamma/read
v/cg/resnet_v12/conv10/batchnorm10/beta/read
tower_0/v/gradients/AddN_29
append_apply_gradient_ops/GradientDescent/update_v/cg/affine0/biases/ApplyGradientDescent
v/cg/resnet_v17/conv27/batchnorm27/moving_variance
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg/sub_1
v/cg/resnet_v111/conv39/batchnorm39/gamma
v/cg/resnet_v11/conv5/batchnorm5/moving_mean
v/cg/resnet_v110/conv34/batchnorm34/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv21/batchnorm21/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/transpose
1608143244704227	36.75
1608143244706653	-36.75
v/cg/resnet_v114/conv49/batchnorm49/beta/read
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg_1
tower_0/v/gradients/AddN_25
v/cg/resnet_v15/conv19/batchnorm19/beta
v/cg/resnet_v111/conv38/batchnorm38/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv17/batchnorm17/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg_1
v/cg/conv0/batchnorm0/moving_mean/read
learning_rate/Cast_2
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg/mul
v/cg/resnet_v16/conv23/batchnorm23/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244792693	20.501708984375
1608143244792700	1.0
1608143244792731	12.25
1608143244792749	0.00341796875
1608143244792839	-20.501708984375
1608143244792842	-0.00341796875
1608143244792844	-1.0
1608143244794072	-12.25
tower_0/v/add
v/cg/resnet_v17/conv25/batchnorm25/moving_mean/read
tower_0/v/gradients/AddN_49
tower_0/v/l2_loss/L2Loss_41
1608143244701516	0.000244140625
1608143244701532	0.0087890625
1608143244701590	-0.0087890625
1608143244706885	-0.000244140625
v/cg/resnet_v16/conv22/batchnorm22/moving_variance/read
v/cg/resnet_v113/conv44/batchnorm44/moving_variance
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_2_grad/mul
1608143244706182	0.015625
1608143244882689	-0.015625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_15_grad/mul
1608143244705397	0.25
1608143244844082	-0.25
tower_0/v/cg/resnet_v14/add
tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D
1608143244717051	24.5
1608143244717057	0.5625
1608143244717107	112.5
1608143244717234	-112.5
1608143244717238	-0.5625
1608143244849066	-24.5
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg/mul
tower_0/v/gradients/AddN_27
tower_0/v/cg/resnet_v115/conv51/batchnorm51/FusedBatchNormV3
1608143244755308	6.125
1608143244755309	0.001953125
1608143244755310	0.001953125
1608143244755311	0.001953125
1608143244755312	0.001953125
1608143244756680	-0.001953125
1608143244756721	-0.001953125
1608143244763714	-6.125
1608143244764033	-0.001953125
1608143244764034	-0.001953125
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg_1
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v17/conv26/Relu
v/cg/resnet_v10/conv2/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv13/batchnorm13/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244762908	7.812744140625
1608143244762924	4.0
1608143244762970	6.125
1608143244762999	0.00439453125
1608143244763098	-7.812744140625
1608143244763102	-0.00439453125
1608143244763103	-4.0
1608143244764030	-6.125
average_loss/Mean/_568
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244822768	0.25
1608143244822775	0.25
1608143244822791	0.00244140625
1608143244823837	-0.00244140625
1608143244823839	-0.25
1608143244824152	-0.25
v/cg/resnet_v111/conv38/conv2d/kernel/read
v/cg/conv0/batchnorm0/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244805715	2.25
1608143244805722	4.0
1608143244805739	81.0
1608143244806095	-81.0
1608143244806099	-4.0
1608143244807270	-2.25
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_28_grad/mul
1608143244698465	1.0
1608143244808771	-1.0
v/cg/resnet_v16/conv22/batchnorm22/moving_variance
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv48/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v18/conv29/batchnorm29/gamma
ConstantFolding/average_loss/Mean/input_const_axis
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv19/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v17/conv27/batchnorm27/moving_mean/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_13_grad/mul
1608143244705967	0.5625
1608143244851569	-0.5625
v/cg/resnet_v115/conv52/conv2d/kernel
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg/mul
tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D
1608143244722424	24.5
1608143244722429	0.25
1608143244722478	0.004638671875
1608143244722552	-0.004638671875
1608143244722556	-0.25
1608143244826658	-24.5
tower_0/v/gradients/AddN_65
tower_0/v/l2_loss/L2Loss_31
1608143244697858	0.000244140625
1608143244697861	0.000244140625
1608143244697918	-0.000244140625
1608143244706877	-0.000244140625
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg_1/sub_1
v/cg/resnet_v113/conv46/batchnorm46/beta
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244770207	6.125
1608143244770214	9.00048828125
1608143244770301	7.820556640625
1608143244770320	131.619384765625
1608143244770419	-6.125
1608143244770423	-131.619384765625
1608143244770423	-9.00048828125
1608143244771943	-7.820556640625
v/cg/resnet_v115/conv51/batchnorm51/gamma/read
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg/mul
v/cg/resnet_v111/conv39/batchnorm39/gamma/read
v/cg/resnet_v13/conv12/batchnorm12/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv49/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244794134	12.25
1608143244794139	4.0
1608143244794173	20.501708984375
1608143244794190	81.0
1608143244794983	-12.25
1608143244794985	-81.0
1608143244794987	-4.0
1608143244796266	-20.501708984375
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv10/batchnorm10/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg/mul
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v112/conv40/batchnorm40/FusedBatchNormV3
1608143244734276	12.25
1608143244734276	0.0009765625
1608143244734277	0.0009765625
1608143244734278	0.0009765625
1608143244734279	0.0009765625
1608143244736789	-0.0009765625
1608143244736834	-0.0009765625
1608143244783918	-12.25
1608143244785822	-0.0009765625
1608143244785823	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv5/batchnorm5/beta/ApplyGradientDescent
v/cg/resnet_v115/conv52/batchnorm52/gamma/read
tower_0/v/gpu_cached_inputs/read
v/cg/resnet_v19/conv31/batchnorm31/moving_variance
v/cg/resnet_v17/conv24/batchnorm24/moving_variance
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg/sub_1
v/cg/resnet_v17/conv26/batchnorm26/moving_variance/read
tower_0/v/l2_loss/L2Loss_24
1608143244702762	0.000244140625
1608143244702776	0.0087890625
1608143244702834	-0.0087890625
1608143244706870	-0.000244140625
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244766654	4.00048828125
1608143244766663	7.820556640625
1608143244766684	0.00390625
1608143244766828	-0.00390625
1608143244766831	-7.820556640625
1608143244767839	-4.00048828125
tower_0/v/l2_loss/L2Loss_21
1608143244705086	0.000244140625
1608143244705088	0.000244140625
1608143244705138	-0.000244140625
1608143244706868	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244831243	31.751953125
1608143244831251	0.25
1608143244831278	24.5
1608143244831294	0.006591796875
1608143244831368	-31.751953125
1608143244831371	-0.006591796875
1608143244831372	-0.25
1608143244831776	-24.5
v/cg/resnet_v13/conv13/batchnorm13/gamma
tower_0/v/cg/resnet_v110/conv35/batchnorm35/FusedBatchNormV3
1608143244731234	12.25
1608143244731235	0.0009765625
1608143244731236	0.0009765625
1608143244731237	0.0009765625
1608143244731238	0.0009765625
1608143244731945	-0.0009765625
1608143244731985	-0.0009765625
1608143244793915	-12.25
1608143244794074	-0.0009765625
1608143244794075	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv44/conv2d/kernel/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v112/conv40/batchnorm40/moving_variance
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244790535	49.0
1608143244790542	1.0
1608143244790579	49.0
1608143244790604	0.00390625
1608143244791300	-49.0
1608143244791303	-0.00390625
1608143244791304	-1.0
1608143244791624	-49.0
tower_0/v/gradients/AddN_57
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_11_grad/mul
1608143244705844	0.5
1608143244848443	-0.5
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv13/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv27/batchnorm27/FusedBatchNormV3
1608143244726295	49.0
1608143244726297	0.00390625
1608143244726297	0.00390625
1608143244726298	0.00390625
1608143244726305	0.00390625
1608143244726519	-49.0
1608143244726956	-0.00390625
1608143244726999	-0.00390625
1608143244810377	-0.00390625
1608143244810378	-0.00390625
v/cg/resnet_v10/conv1/conv2d/kernel
v/cg/resnet_v10/conv1/batchnorm1/moving_mean
tower_0/v/cg/resnet_v18/conv29/batchnorm29/FusedBatchNormV3
1608143244727554	12.25
1608143244727555	0.0009765625
1608143244727556	0.0009765625
1608143244727557	0.0009765625
1608143244727558	0.0009765625
1608143244728319	-0.0009765625
1608143244728380	-0.0009765625
1608143244803462	-12.25
1608143244804470	-0.0009765625
1608143244804470	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv28/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/mpool0/MaxPool_grad/MaxPoolGrad
1608143244882706	196.0
1608143244882959	-196.0
v/cg/resnet_v17/conv24/batchnorm24/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv21/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244852606	0.125
1608143244852613	0.125
1608143244852627	0.00244140625
1608143244853600	-0.00244140625
1608143244853603	-0.125
1608143244853801	-0.125
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244798108	4.0
1608143244798114	4.00048828125
1608143244798131	81.0
1608143244798376	-81.0
1608143244798380	-4.00048828125
1608143244800596	-4.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv49/batchnorm49/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v14/conv17/batchnorm17/FusedBatchNormV3
1608143244720012	98.0
1608143244720014	0.001953125
1608143244720015	0.001953125
1608143244720015	0.001953125
1608143244720017	0.001953125
1608143244720706	-0.001953125
1608143244720749	-0.001953125
1608143244836499	-98.0
1608143244836722	-0.001953125
1608143244836722	-0.001953125
v/cg/resnet_v111/conv37/batchnorm37/moving_variance
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv11/batchnorm11/gamma/ApplyGradientDescent
tower_0/v/gradients/AddN_60
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg_1
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg/mul
v/cg/resnet_v12/conv8/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/batchnorm19/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244831681	24.5
1608143244831682	0.00048828125
1608143244831682	0.00048828125
1608143244831683	0.000244140625
1608143244831701	0.000244140625
1608143244831781	-0.000244140625
1608143244831781	-0.000244140625
1608143244833472	-24.5
1608143244833517	-0.00048828125
1608143244833776	-0.00048828125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv25/batchnorm25/beta/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_51
1608143244706223	0.000244140625
1608143244706235	0.0087890625
1608143244706294	-0.0087890625
1608143244706894	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244846052	0.5
1608143244846059	0.5
1608143244846074	0.00244140625
1608143244846168	-0.00244140625
1608143244846171	-0.5
1608143244848959	-0.5
v/cg/resnet_v15/conv19/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v13/conv12/batchnorm12/FusedBatchNormV3
1608143244716643	24.5
1608143244716644	0.00048828125
1608143244716645	0.00048828125
1608143244716646	0.00048828125
1608143244716647	0.000732421875
1608143244717630	-0.00048828125
1608143244717666	-0.00048828125
1608143244851539	-24.5
1608143244851728	-0.00048828125
1608143244851733	-0.000732421875
tower_0/v/gradients/AddN_41
tower_0/v/l2_loss/L2Loss_15
1608143244705329	0.000244140625
1608143244705331	0.000244140625
1608143244705381	-0.000244140625
1608143244706862	-0.000244140625
tower_0/v/cg/resnet_v112/conv42/batchnorm42/FusedBatchNormV3
1608143244739121	49.0
1608143244739122	0.00390625
1608143244739123	0.00390625
1608143244739124	0.00390625
1608143244739125	0.00390625
1608143244741111	-0.00390625
1608143244741155	-0.00390625
1608143244781678	-49.0
1608143244781825	-0.00390625
1608143244781825	-0.00390625
v/cg/resnet_v114/conv47/conv2d/kernel
tower_0/v/gradients/AddN_56
v/cg/resnet_v11/conv7/batchnorm7/beta
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/batchnorm45/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244780238	7.820556640625
1608143244780239	0.001953125
1608143244780239	0.001953125
1608143244780241	0.000244140625
1608143244780271	0.000244140625
1608143244780348	-0.000244140625
1608143244780349	-0.000244140625
1608143244780789	-7.820556640625
1608143244780835	-0.001953125
1608143244780875	-0.001953125
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_9_grad/mul
1608143244705283	0.140625
1608143244859059	-0.140625
v/cg/affine0/weights
tower_0/v/gradients/AddN_63
v/cg/resnet_v12/conv9/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv8/batchnorm8/beta/ApplyGradientDescent
v/cg/resnet_v10/conv3/conv2d/kernel
tower_0/v/cg/resnet_v111/conv37/Relu
v/cg/resnet_v17/conv25/batchnorm25/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv40/batchnorm40/beta/ApplyGradientDescent
v/cg/resnet_v14/conv15/batchnorm15/gamma/read
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg/mul
v/cg/resnet_v18/conv29/batchnorm29/beta/read
v/cg/resnet_v114/conv49/batchnorm49/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/batchnorm4/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244872313	196.0
1608143244872314	0.0009765625
1608143244872314	0.0009765625
1608143244872315	0.000244140625
1608143244872336	0.000244140625
1608143244872461	-0.000244140625
1608143244872461	-0.000244140625
1608143244875763	-196.0
1608143244875796	-0.0009765625
1608143244876304	-0.0009765625
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v113/Relu_grad/ReluGrad
v/cg/resnet_v19/conv31/batchnorm31/gamma/read
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_51_grad/mul
1608143244706315	9.0
1608143244765676	-9.0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_5_grad/mul
1608143244704540	0.0625
1608143244872067	-0.0625
tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D
1608143244748567	6.125
1608143244748572	9.0
1608143244748624	72.0
1608143244748986	-72.0
1608143244748990	-9.0
1608143244769594	-6.125
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244861442	49.0
1608143244861447	0.0625
1608143244861480	49.0
1608143244861494	0.020263671875
1608143244861560	-49.0
1608143244861562	-0.020263671875
1608143244861563	-0.0625
1608143244864186	-49.0
tower_0/v/cg/resnet_v111/conv39/batchnorm39/FusedBatchNormV3
1608143244733597	49.0
1608143244733598	0.00390625
1608143244733599	0.00390625
1608143244733600	0.00390625
1608143244733601	0.00390625
1608143244734222	-0.00390625
1608143244734263	-0.00390625
1608143244786846	-49.0
1608143244787638	-0.00390625
1608143244787638	-0.00390625
v/cg/resnet_v11/conv7/batchnorm7/moving_variance/read
tower_0/v/cg/resnet_v114/conv49/batchnorm49/FusedBatchNormV3
1608143244751187	24.5
1608143244751188	0.0078125
1608143244751189	0.0078125
1608143244751190	0.0078125
1608143244751191	0.0078125
1608143244753597	-0.0078125
1608143244753633	-0.0078125
1608143244767796	-24.5
1608143244768152	-0.0078125
1608143244768153	-0.0078125
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg_1/mul
edge_667_learning_rate/PiecewiseConstant/and_2@@MemcpyDtoH
tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D
1608143244714232	49.0
1608143244714239	0.140625
1608143244714297	85.046875
1608143244714666	-85.046875
1608143244714670	-0.140625
1608143244856631	-49.0
tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D
1608143244740198	24.5
1608143244740203	8.0
1608143244740256	0.00048828125
1608143244740731	-0.00048828125
1608143244740735	-8.0
1608143244778914	-24.5
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv52/batchnorm52/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244810755	2.25
1608143244810762	2.250244140625
1608143244810779	0.00244140625
1608143244810894	-0.00244140625
1608143244810897	-2.250244140625
1608143244813596	-2.25
tower_0/v/l2_loss/L2Loss_40
1608143244698131	0.000244140625
1608143244698133	0.000244140625
1608143244698183	-0.000244140625
1608143244706885	-0.000244140625
v/cg/resnet_v19/conv33/batchnorm33/moving_variance
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg
v/cg/resnet_v112/conv42/batchnorm42/gamma
v/cg/resnet_v111/conv38/batchnorm38/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/batchnorm50/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244765689	9.00048828125
1608143244765690	0.001953125
1608143244765691	0.001953125
1608143244765691	0.000244140625
1608143244765723	0.000244140625
1608143244766355	-0.000244140625
1608143244766356	-0.000244140625
1608143244766841	-9.00048828125
1608143244766890	-0.001953125
1608143244767508	-0.001953125
tower_0/v/gradients/tower_0/v/cg/conv0/batchnorm0/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244882873	245.0
1608143244882874	0.000244140625
1608143244882875	0.000244140625
1608143244882875	0.000244140625
1608143244882894	0.000244140625
1608143244882964	-0.000244140625
1608143244882964	-0.000244140625
1608143244883174	-245.0
1608143244884263	-0.000244140625
1608143244884294	-0.000244140625
v/cg/resnet_v14/conv16/batchnorm16/moving_variance
tower_0/v/gradients/AddN_7
tower_0/v/cg/resnet_v14/Relu
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_37_grad/mul
1608143244699020	1.0
1608143244791662	-1.0
tower_0/v/cg/resnet_v11/Relu
v/cg/resnet_v113/conv45/batchnorm45/moving_variance
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244864246	49.0
1608143244864251	0.25
1608143244864275	53.818115234375
1608143244864289	85.046875
1608143244864760	-49.0
1608143244864763	-85.046875
1608143244864764	-0.25
1608143244869993	-53.818115234375
v/cg/resnet_v13/conv14/conv2d/kernel/read
v/cg/resnet_v12/conv10/batchnorm10/beta
v/cg/resnet_v110/conv35/batchnorm35/beta/read
v/cg/conv0/batchnorm0/moving_variance/read
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent
v/cg/resnet_v16/conv23/batchnorm23/beta
v/cg/resnet_v112/conv41/conv2d/kernel
tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D
1608143244745130	24.5
1608143244745135	4.0
1608143244745181	0.00048828125
1608143244745249	-0.00048828125
1608143244745253	-4.0
1608143244779049	-24.5
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v14/conv17/batchnorm17/moving_mean/read
v/cg/resnet_v13/conv14/batchnorm14/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv12/batchnorm12/gamma/ApplyGradientDescent
tower_0/v/gradients/AddN_15
v/cg/resnet_v15/conv19/batchnorm19/gamma
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg
v/cg/resnet_v112/conv41/batchnorm41/beta
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg_1/sub_1
v/cg/resnet_v14/conv15/batchnorm15/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv36/batchnorm36/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/batchnorm34/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244795360	12.25
1608143244795361	0.0009765625
1608143244795361	0.001220703125
1608143244795362	0.000244140625
1608143244795384	0.000244140625
1608143244796271	-0.000244140625
1608143244796272	-0.000244140625
1608143244796665	-12.25
1608143244796717	-0.0009765625
1608143244796753	-0.001220703125
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg_1
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg/sub_1
v/cg/resnet_v16/conv21/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244795012	4.0
1608143244795019	4.00048828125
1608143244795037	81.0
1608143244795174	-81.0
1608143244795177	-4.00048828125
1608143244796324	-4.0
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg
v/cg/resnet_v11/conv5/conv2d/kernel/read
v/cg/resnet_v110/conv36/batchnorm36/moving_mean/read
v/cg/resnet_v13/conv14/batchnorm14/gamma/read
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv49/batchnorm49/beta/ApplyGradientDescent
learning_rate/PiecewiseConstant/and
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244772013	24.5078125
1608143244772019	7.820556640625
1608143244772053	24.5
1608143244772071	0.00439453125
1608143244772193	-24.5078125
1608143244772196	-0.00439453125
1608143244772197	-7.820556640625
1608143244773272	-24.5
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v18/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Tile
1608143244761972	24.5
1608143244779047	-24.5
v/cg/conv0/conv2d/kernel
v/cg/resnet_v114/conv48/batchnorm48/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/AddN_1
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/batchnorm33/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244797001	49.00390625
1608143244797002	0.00390625
1608143244797002	0.00439453125
1608143244797003	0.000244140625
1608143244797025	0.000244140625
1608143244797108	-0.000244140625
1608143244797108	-0.000244140625
1608143244797443	-49.00390625
1608143244797494	-0.00390625
1608143244797527	-0.00439453125
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244859216	196.0
1608143244859221	0.062744140625
1608143244859243	196.0
1608143244859257	0.020263671875
1608143244859407	-196.0
1608143244859409	-0.020263671875
1608143244859410	-0.062744140625
1608143244861233	-196.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v113/conv44/batchnorm44/gamma/read
v/cg/resnet_v110/conv34/batchnorm34/gamma
v/cg/resnet_v14/conv15/batchnorm15/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv23/batchnorm23/beta/ApplyGradientDescent
v/cg/resnet_v11/conv6/batchnorm6/moving_mean/read
v/cg/resnet_v10/conv2/conv2d/kernel
tower_0/v/cg/resnet_v113/conv46/batchnorm46/FusedBatchNormV3
1608143244745410	24.5
1608143244745411	0.009765625
1608143244745412	0.0078125
1608143244745413	0.0078125
1608143244745414	0.0078125
1608143244746249	-24.5
1608143244747411	-0.009765625
1608143244747911	-0.0078125
1608143244779050	-0.0078125
1608143244779051	-0.0078125
tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D
1608143244727245	12.25
1608143244727250	2.25
1608143244727298	81.0
1608143244727405	-81.0
1608143244727409	-2.25
1608143244804468	-12.25
v/cg/resnet_v111/conv37/batchnorm37/beta/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v10/conv4/batchnorm4/gamma
v/cg/resnet_v18/conv30/batchnorm30/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/batchnorm10/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244853815	196.0
1608143244853816	0.001220703125
1608143244853816	0.0009765625
1608143244853817	0.000244140625
1608143244853878	0.000244140625
1608143244853956	-0.000244140625
1608143244853957	-0.000244140625
1608143244855930	-196.0
1608143244855965	-0.001220703125
1608143244856214	-0.0009765625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/AddN_68
tower_0/v/cg/resnet_v13/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244789258	3.00048828125
1608143244789266	4.0
1608143244789284	81.0
1608143244790153	-81.0
1608143244790156	-4.0
1608143244790523	-3.00048828125
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg/mul
tower_0/v/l2_loss/L2Loss_42
1608143244699075	0.000244140625
1608143244699077	0.000244140625
1608143244699130	-0.000244140625
1608143244706886	-0.000244140625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_26_grad/mul
1608143244703406	2.25
1608143244819297	-2.25
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244787834	1.0
1608143244787842	1.0
1608143244787860	0.00244140625
1608143244787985	-0.00244140625
1608143244787989	-1.0
1608143244789021	-1.0
v/cg/resnet_v13/conv11/batchnorm11/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244854955	0.0625
1608143244854961	0.0625
1608143244854974	0.0029296875
1608143244855921	-0.0029296875
1608143244855923	-0.0625
1608143244856950	-0.0625
v/cg/resnet_v111/conv39/conv2d/kernel
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg_1
tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D
1608143244740766	6.125
1608143244740772	2.0
1608143244740967	0.00048828125
1608143244741037	-0.00048828125
1608143244741040	-2.0
1608143244781113	-6.125
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_25_grad/mul
1608143244698753	0.5
1608143244821599	-0.5
average_loss/Mean/input
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_48_grad/mul
1608143244700282	9.0
1608143244771636	-9.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv19/batchnorm19/beta/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_26
1608143244703304	0.000244140625
1608143244703319	0.0087890625
1608143244703378	-0.0087890625
1608143244706872	-0.000244140625
tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D
1608143244732734	12.25
1608143244732740	2.25
1608143244732786	81.0
1608143244732888	-81.0
1608143244732892	-2.25
1608143244788960	-12.25
tower_0/v/transpose/perm
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv42/batchnorm42/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D
1608143244733331	49.0
1608143244733337	1.0
1608143244733389	0.001220703125
1608143244733459	-0.001220703125
1608143244733463	-1.0
1608143244787636	-49.0
v/cg/resnet_v113/conv46/conv2d/kernel
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg_1
v/cg/resnet_v15/conv20/batchnorm20/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv50/batchnorm50/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_50_grad/mul
1608143244702234	4.0
1608143244767591	-4.0
tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D
1608143244711350	49.0
1608143244711356	0.0625
1608143244711409	0.01806640625
1608143244711504	-0.01806640625
1608143244711508	-0.0625
1608143244869994	-49.0
tower_0/v/l2_loss/L2Loss_13
1608143244705897	0.000244140625
1608143244705899	0.000244140625
1608143244705944	-0.000244140625
1608143244706861	-0.000244140625
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg/mul
tower_0/v/resnet50_synthetic_labels/min
v/cg/resnet_v10/conv2/batchnorm2/moving_variance/read
tower_0/v/cg/resnet_v17/conv25/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244782008	1.0
1608143244782016	1.000244140625
1608143244782033	0.00244140625
1608143244782166	-0.00244140625
1608143244782170	-1.000244140625
1608143244782948	-1.0
v/cg/resnet_v11/conv6/batchnorm6/moving_variance
v/cg/affine0/biases/read
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg_1
v/cg/resnet_v15/conv18/batchnorm18/beta/read
tower_0/v/cg/resnet_v113/conv44/batchnorm44/FusedBatchNormV3
1608143244741281	6.125
1608143244741282	0.001953125
1608143244741283	0.001953125
1608143244741284	0.001953125
1608143244741285	0.001953125
1608143244744107	-0.001953125
1608143244744818	-0.001953125
1608143244780926	-6.125
1608143244781114	-0.001953125
1608143244781115	-0.001953125
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/batchnorm12/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244851578	24.5
1608143244851579	0.00048828125
1608143244851580	0.000732421875
1608143244851580	0.000244140625
1608143244851645	0.000244140625
1608143244851735	-0.000244140625
1608143244851735	-0.000244140625
1608143244853610	-24.5
1608143244853652	-0.00048828125
1608143244853685	-0.000732421875
tower_0/v/cg/resnet_v110/conv35/Relu
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v114/conv48/batchnorm48/beta/read
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg/mul
v/cg/resnet_v10/conv3/batchnorm3/beta/read
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg
v/cg/resnet_v110/conv36/batchnorm36/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv3/batchnorm3/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/batchnorm21/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244826219	24.5
1608143244826220	0.00048828125
1608143244826220	0.000732421875
1608143244826221	0.000244140625
1608143244826241	0.000244140625
1608143244826661	-0.000244140625
1608143244826661	-0.000244140625
1608143244830889	-24.5
1608143244830946	-0.00048828125
1608143244830975	-0.000732421875
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244820282	98.0
1608143244820288	0.5
1608143244820317	98.0
1608143244821269	-98.0
1608143244821271	-0.5
1608143244821566	-98.0
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg_1/sub_1
v/cg/resnet_v13/conv12/batchnorm12/beta/read
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg_1/mul
v/cg/resnet_v18/conv28/batchnorm28/gamma/read
v/cg/resnet_v110/conv35/batchnorm35/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv20/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg
v/cg/resnet_v114/conv47/batchnorm47/moving_variance
tower_0/v/l2_loss/L2Loss_20
1608143244702913	0.000244140625
1608143244702915	0.000244140625
1608143244702970	-0.000244140625
1608143244706867	-0.000244140625
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv46/batchnorm46/gamma/ApplyGradientDescent
v/cg/conv0/batchnorm0/beta
v/cg/resnet_v10/conv4/batchnorm4/beta
v/cg/resnet_v11/conv6/batchnorm6/gamma
v/cg/resnet_v110/conv35/batchnorm35/moving_variance/read
tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D
1608143244728656	12.25
1608143244728662	1.0
1608143244728711	0.001953125
1608143244728794	-0.001953125
1608143244728797	-1.0
1608143244800540	-12.25
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_44_grad/mul
1608143244699969	2.0
1608143244781646	-2.0
learning_rate/PiecewiseConstant/case/cond/cond/cond/Switch_1
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/batchnorm43/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244778802	24.501953125
1608143244778803	0.009765625
1608143244778804	0.0078125
1608143244778805	0.000244140625
1608143244778832	0.000244140625
1608143244778919	-0.000244140625
1608143244778920	-0.000244140625
1608143244779531	-24.501953125
1608143244779587	-0.009765625
1608143244779623	-0.0078125
v/cg/resnet_v17/conv25/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_38_grad/mul
1608143244701919	2.25
1608143244790334	-2.25
tower_0/v/gradients/tower_0/v/cg/resnet_v17/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg/mul
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v14/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244877615	49.0
1608143244877619	0.25
1608143244877645	53.194580078125
1608143244877660	85.046875
1608143244878491	-49.0
1608143244878493	-85.046875
1608143244878494	-0.25
1608143244880355	-53.194580078125
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv43/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v13/conv11/batchnorm11/beta/read
v/cg/resnet_v18/conv28/batchnorm28/gamma
tower_0/v/cg/resnet_v10/conv3/batchnorm3/FusedBatchNormV3
1608143244710058	49.0
1608143244710059	0.000244140625
1608143244710060	0.000244140625
1608143244710061	0.000244140625
1608143244710062	0.000244140625
1608143244710989	-0.000244140625
1608143244711032	-0.000244140625
1608143244876372	-49.0
1608143244877565	-0.000244140625
1608143244877566	-0.000244140625
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg/sub_1
tower_0/v/cg/spatial_mean0
1608143244758705	0.5
1608143244761713	-0.5
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244763136	7.812744140625
1608143244763149	4.0
1608143244763173	0.00439453125
1608143244763326	-0.00439453125
1608143244763329	-4.0
1608143244764266	-7.812744140625
v/cg/resnet_v110/conv34/batchnorm34/moving_variance/read
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg_1/sub_1
v/cg/resnet_v114/conv48/batchnorm48/moving_mean
v/cg/resnet_v113/conv46/batchnorm46/moving_mean
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg_1/mul
v/cg/resnet_v14/conv16/batchnorm16/beta
tower_0/v/cg/resnet_v16/add
v/cg/resnet_v114/conv49/batchnorm49/moving_variance/read
v/cg/resnet_v19/conv33/batchnorm33/beta/read
v/cg/resnet_v10/conv3/batchnorm3/moving_mean
tower_0/v/gradients/AddN_45
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/batchnorm37/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244790353	20.501708984375
1608143244790353	0.0009765625
1608143244790354	0.001220703125
1608143244790355	0.000244140625
1608143244790378	0.000244140625
1608143244790468	-0.000244140625
1608143244790468	-0.000244140625
1608143244791495	-20.501708984375
1608143244791546	-0.0009765625
1608143244791583	-0.001220703125
tower_0/v/cg/resnet_v110/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv43/batchnorm43/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg_1
v/cg/resnet_v18/conv30/conv2d/kernel
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv15/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v14/conv17/conv2d/kernel
average_loss/Mean
v/cg/resnet_v19/conv31/batchnorm31/moving_mean/read
v/cg/resnet_v17/conv24/batchnorm24/gamma/read
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg_1
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg_1/sub_1
v/cg/resnet_v12/conv8/batchnorm8/gamma
v/cg/resnet_v14/conv16/batchnorm16/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv38/batchnorm38/beta/ApplyGradientDescent
v/cg/resnet_v16/conv21/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv39/batchnorm39/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244779351	9.000244140625
1608143244779360	9.00048828125
1608143244779381	0.00439453125
1608143244779518	-0.00439453125
1608143244779521	-9.00048828125
1608143244780226	-9.000244140625
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv33/batchnorm33/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v15/Relu_grad/ReluGrad
v/cg/resnet_v17/conv27/conv2d/kernel
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg/sub_1
v/cg/resnet_v18/conv29/conv2d/kernel
v/cg/resnet_v17/conv27/batchnorm27/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv26/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/batchnorm47/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244771654	9.000244140625
1608143244771655	0.001953125
1608143244771655	0.001953125
1608143244771656	0.000244140625
1608143244771680	0.000244140625
1608143244771947	-0.000244140625
1608143244771948	-0.000244140625
1608143244773124	-9.000244140625
1608143244773176	-0.001953125
1608143244773228	-0.001953125
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg_1/mul
v/cg/resnet_v13/conv11/batchnorm11/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv33/batchnorm33/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg_1
v/cg/resnet_v115/conv50/batchnorm50/moving_mean
v/cg/resnet_v19/conv32/batchnorm32/beta
learning_rate/PiecewiseConstant/case/n_true_conds
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244779073	49.0
1608143244779081	9.000244140625
1608143244779121	49.0
1608143244779308	-49.0
1608143244779311	-9.000244140625
1608143244810374	-49.0
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/batchnorm20/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244831123	98.001953125
1608143244831124	0.001953125
1608143244831125	0.001953125
1608143244831125	0.000244140625
1608143244831144	0.000244140625
1608143244831227	-0.000244140625
1608143244831227	-0.000244140625
1608143244831531	-98.001953125
1608143244831573	-0.001953125
1608143244831602	-0.001953125
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_10_grad/mul
1608143244704160	0.0625
1608143244856530	-0.0625
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244821941	31.751953125
1608143244821947	0.25
1608143244821974	24.5
1608143244821989	0.006591796875
1608143244822740	-31.751953125
1608143244822742	-0.006591796875
1608143244822743	-0.25
1608143244824096	-24.5
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_1_grad/mul
1608143244704035	0.0625
1608143244876335	-0.0625
tower_0/v/l2_loss/L2Loss_25
1608143244698685	0.000244140625
1608143244698687	0.000244140625
1608143244698736	-0.000244140625
1608143244706871	-0.000244140625
tower_0/v/cg/resnet_v19/conv32/Relu
v/cg/resnet_v14/conv16/batchnorm16/moving_mean/read
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_16_grad/mul
1608143244703663	0.5625
1608143244841456	-0.5625
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/batchnorm25/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244819307	12.25
1608143244819308	0.0009765625
1608143244819308	0.001220703125
1608143244819309	0.000244140625
1608143244819328	0.000244140625
1608143244820221	-0.000244140625
1608143244820222	-0.000244140625
1608143244821450	-12.25
1608143244821496	-0.0009765625
1608143244821536	-0.001220703125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv14/batchnorm14/gamma/ApplyGradientDescent
v/cg/resnet_v13/conv13/batchnorm13/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244803009	12.25
1608143244803015	1.0
1608143244803045	19.501953125
1608143244803062	0.00341796875
1608143244803144	-12.25
1608143244803147	-0.00341796875
1608143244803149	-1.0
1608143244804466	-19.501953125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv20/batchnorm20/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg
v/cg/resnet_v112/conv40/batchnorm40/moving_variance/read
v/cg/resnet_v18/conv29/batchnorm29/moving_mean
v/cg/resnet_v14/conv17/batchnorm17/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv8/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v113/conv45/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244781175	49.0
1608143244781182	2.0
1608143244781207	73.53125
1608143244781314	-49.0
1608143244781317	-2.0
1608143244781617	-73.53125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v11/conv7/batchnorm7/moving_mean/read
v/cg/resnet_v16/conv21/batchnorm21/moving_mean
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v115/conv52/batchnorm52/beta
tower_0/v/l2_loss/L2Loss_30
1608143244699482	0.000244140625
1608143244699484	0.000244140625
1608143244699534	-0.000244140625
1608143244706876	-0.000244140625
v/cg/resnet_v12/conv10/batchnorm10/moving_variance/read
tower_0/v/l2_loss/L2Loss_18
1608143244706016	0.000244140625
1608143244706017	0.000244140625
1608143244706062	-0.000244140625
1608143244706865	-0.000244140625
v/cg/resnet_v113/conv45/batchnorm45/gamma
learning_rate/Const_6
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg/mul
tower_0/v/l2_loss/L2Loss_34
1608143244697998	0.000244140625
1608143244698000	0.000244140625
1608143244698056	-0.000244140625
1608143244706879	-0.000244140625
tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D
1608143244711910	49.0
1608143244711916	0.140625
1608143244711967	85.046875
1608143244712302	-85.046875
1608143244712306	-0.140625
1608143244864188	-49.0
v/cg/resnet_v11/conv5/batchnorm5/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v12/conv9/batchnorm9/moving_mean/read
v/cg/resnet_v15/conv20/conv2d/kernel
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_52_grad/mul
1608143244702381	4.0
1608143244763756	-4.0
v/cg/resnet_v110/conv36/batchnorm36/gamma/read
v/cg/resnet_v11/conv6/batchnorm6/moving_mean
tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D
1608143244716026	98.0
1608143244716032	0.5
1608143244716090	0.004638671875
1608143244716167	-0.004638671875
1608143244716171	-0.5
1608143244844928	-98.0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_45_grad/mul
1608143244698616	9.0
1608143244780960	-9.0
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg_1/mul
v/cg/resnet_v12/conv10/batchnorm10/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244838872	24.5
1608143244838878	0.56298828125
1608143244838900	31.751953125
1608143244838914	112.5
1608143244840722	-24.5
1608143244840724	-112.5
1608143244840726	-0.56298828125
1608143244841878	-31.751953125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv50/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v13/conv12/batchnorm12/moving_mean
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/Const_1
main_fetch_group
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244779807	4.0
1608143244779815	7.820556640625
1608143244779833	0.00439453125
1608143244779966	-0.00439453125
1608143244779969	-7.820556640625
1608143244780420	-4.0
tower_0/v/cg/resnet_v18/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv44/batchnorm44/gamma/ApplyGradientDescent
v/cg/resnet_v18/conv30/batchnorm30/gamma
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv47/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv13/batchnorm13/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/batchnorm13/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244848968	31.751953125
1608143244848969	0.00048828125
1608143244848970	0.000732421875
1608143244848971	0.000244140625
1608143244848997	0.000244140625
1608143244849069	-0.000244140625
1608143244849069	-0.000244140625
1608143244851419	-31.751953125
1608143244851474	-0.00048828125
1608143244851507	-0.000732421875
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Switch
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg/sub_1
v/cg/resnet_v17/conv27/batchnorm27/moving_mean
v/cg/resnet_v17/conv26/batchnorm26/beta/read
v/cg/resnet_v115/conv52/batchnorm52/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v15/add
learning_rate/Cast_3
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv9/batchnorm9/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg_1/mul
learning_rate/PiecewiseConstant/case/preds_c
1608143244706393	0.000244140625
1608143244709691	-0.000244140625
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v19/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v13/conv13/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/Relu_grad/ReluGrad
v/cg/resnet_v15/conv19/batchnorm19/moving_variance/read
learning_rate/PiecewiseConstant/and_2
edge_641_learning_rate/PiecewiseConstant/LessEqual@@MemcpyDtoH
v/cg/resnet_v112/conv41/batchnorm41/moving_variance
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/batchnorm32/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244797613	12.25
1608143244797614	0.0009765625
1608143244797614	0.001220703125
1608143244797615	0.000244140625
1608143244797646	0.000244140625
1608143244797728	-0.000244140625
1608143244797729	-0.000244140625
1608143244798389	-12.25
1608143244799309	-0.0009765625
1608143244799348	-0.001220703125
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/Relu_grad/ReluGrad
v/cg/resnet_v12/conv9/batchnorm9/moving_variance/read
v/cg/resnet_v12/conv8/batchnorm8/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv8/batchnorm8/gamma/ApplyGradientDescent
v/cg/resnet_v111/conv39/batchnorm39/moving_mean/read
tower_0/v/gradients/AddN_40
tower_0/v/gradients/tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/ExpandDims
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg/sub_1
v/cg/resnet_v115/conv50/batchnorm50/moving_variance
v/cg/resnet_v113/conv43/conv2d/kernel
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v115/conv51/conv2d/kernel/read
tower_0/v/cg/resnet_v11/conv6/batchnorm6/FusedBatchNormV3
1608143244712475	49.0
1608143244712477	0.000244140625
1608143244712478	0.000244140625
1608143244712478	0.000244140625
1608143244712479	0.000244140625
1608143244713344	-0.000244140625
1608143244713386	-0.000244140625
1608143244863607	-49.0
1608143244864189	-0.000244140625
1608143244864190	-0.000244140625
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg
v/cg/resnet_v112/conv41/batchnorm41/gamma/read
v/cg/resnet_v15/conv18/batchnorm18/moving_variance
v/cg/resnet_v113/conv43/batchnorm43/gamma
tower_0/v/cg/resnet_v17/conv26/batchnorm26/FusedBatchNormV3
1608143244725612	12.25
1608143244725613	0.0009765625
1608143244725614	0.0009765625
1608143244725615	0.0009765625
1608143244725616	0.0009765625
1608143244726437	-0.0009765625
1608143244726478	-0.0009765625
1608143244813426	-12.25
1608143244813716	-0.0009765625
1608143244813716	-0.0009765625
v/cg/affine0/weights/read
tower_0/v/gradients/AddN_12
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244803193	1.0
1608143244803200	1.0
1608143244803217	0.00244140625
1608143244803334	-0.00244140625
1608143244803337	-1.0
1608143244805439	-1.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v113/conv46/batchnorm46/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/truediv_recip
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv48/batchnorm48/beta/ApplyGradientDescent
v/cg/resnet_v11/conv7/batchnorm7/gamma/read
v/cg/resnet_v113/conv43/batchnorm43/beta
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg_1/sub_1
v/cg/resnet_v11/conv7/batchnorm7/gamma
tower_0/v/cg/resnet_v115/conv51/Relu
v/cg/resnet_v16/conv22/batchnorm22/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv31/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v15/conv18/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244779641	7.820556640625
1608143244779648	4.0
1608143244779675	9.00048828125
1608143244779693	0.00439453125
1608143244779777	-7.820556640625
1608143244779780	-0.00439453125
1608143244779780	-4.0
1608143244780342	-9.00048828125
tower_0/v/gradients/AddN_6
tower_0/v/gradients/tower_0/v/cg/resnet_v16/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv1/batchnorm1/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v111/conv37/batchnorm37/FusedBatchNormV3
1608143244732502	12.25
1608143244732503	0.0009765625
1608143244732504	0.0009765625
1608143244732504	0.0009765625
1608143244732505	0.0009765625
1608143244733163	-0.0009765625
1608143244733204	-0.0009765625
1608143244790298	-12.25
1608143244790466	-0.0009765625
1608143244790466	-0.0009765625
tower_0/v/resnet50_synthetic_labels/shape
v/cg/resnet_v15/conv20/batchnorm20/moving_variance/read
tower_0/v/cg/resnet_v112/add
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv24/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D
1608143244708264	49.0
1608143244708271	0.015625
1608143244708340	0.01806640625
1608143244708437	-0.01806640625
1608143244708442	-0.015625
1608143244880357	-49.0
v/cg/resnet_v15/conv18/batchnorm18/moving_variance/read
v/cg/conv0/conv2d/kernel/read
v/cg/resnet_v13/conv14/batchnorm14/beta/read
v/cg/resnet_v15/conv19/batchnorm19/moving_mean/read
v/cg/resnet_v115/conv50/conv2d/kernel/read
tower_0/v/cg/resnet_v115/conv50/batchnorm50/FusedBatchNormV3
1608143244753647	6.125
1608143244753648	0.001953125
1608143244753649	0.001953125
1608143244753650	0.001953125
1608143244753651	0.001953125
1608143244755444	-0.001953125
1608143244755482	-0.001953125
1608143244765633	-6.125
1608143244766352	-0.001953125
1608143244766353	-0.001953125
tower_0/v/gradients/AddN_23
v/cg/resnet_v10/conv2/batchnorm2/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244850436	0.7548828125
1608143244850443	1.0
1608143244850457	147.0078125
1608143244851410	-147.0078125
1608143244851412	-1.0
1608143244851796	-0.7548828125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v113/conv46/batchnorm46/moving_variance/read
v/cg/resnet_v10/conv4/batchnorm4/gamma/read
tower_0/v/gradients/AddN_55
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg
v/cg/resnet_v14/conv16/batchnorm16/moving_mean
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg_1/mul
v/cg/resnet_v18/conv30/batchnorm30/moving_mean/read
v/cg/resnet_v115/conv50/batchnorm50/beta/read
tower_0/v/cg/resnet_v10/add
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv30/conv2d/kernel/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_37
1608143244698946	0.000244140625
1608143244698948	0.000244140625
1608143244698998	-0.000244140625
1608143244706882	-0.000244140625
v/cg/resnet_v13/conv12/batchnorm12/gamma
v/cg/resnet_v16/conv22/conv2d/kernel
v/cg/resnet_v12/conv9/conv2d/kernel
v/cg/resnet_v112/conv41/batchnorm41/gamma
tower_0/v/cg/resnet_v13/conv12/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/batchnorm48/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244769489	6.1328125
1608143244769489	0.001953125
1608143244769490	0.001953125
1608143244769491	0.000244140625
1608143244769520	0.000244140625
1608143244769598	-0.000244140625
1608143244769599	-0.000244140625
1608143244770613	-6.1328125
1608143244770663	-0.001953125
1608143244771371	-0.001953125
tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D
1608143244721022	24.5
1608143244721027	0.5625
1608143244721094	112.5
1608143244721196	-112.5
1608143244721200	-0.5625
1608143244831778	-24.5
tower_0/v/cg/conv0/Pad/paddings
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv27/batchnorm27/gamma/ApplyGradientDescent
v/cg/resnet_v16/conv21/batchnorm21/beta/read
v/cg/resnet_v11/conv5/batchnorm5/gamma
v/cg/resnet_v19/conv32/batchnorm32/gamma
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg/sub_1
v/cg/resnet_v13/conv11/conv2d/kernel/read
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg/sub_1
learning_rate/PiecewiseConstant/LessEqual_1
1608143244695820	0.000244140625
1608143244702609	-0.000244140625
v/cg/resnet_v112/conv41/batchnorm41/moving_mean/read
v/cg/resnet_v14/conv16/batchnorm16/moving_variance/read
tower_0/v/cg/resnet_v10/conv2/Relu
tower_0/v/cg/resnet_v111/add
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv5/batchnorm5/gamma/ApplyGradientDescent
v/cg/resnet_v18/conv29/batchnorm29/moving_variance/read
v/cg/resnet_v18/conv29/batchnorm29/gamma/read
tower_0/v/l2_loss/L2Loss_28
1608143244698391	0.000244140625
1608143244698393	0.000244140625
1608143244698447	-0.000244140625
1608143244706874	-0.000244140625
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg
v/cg/resnet_v17/conv25/batchnorm25/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244832255	0.56298828125
1608143244832261	1.0
1608143244832276	112.5
1608143244833461	-112.5
1608143244833464	-1.0
1608143244834338	-0.56298828125
v/cg/resnet_v112/conv40/batchnorm40/gamma
v/cg/resnet_v15/conv19/batchnorm19/gamma/read
tower_0/v/l2_loss/L2Loss_54
1608143244705690	0.000244140625
1608143244706896	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244872476	53.818115234375
1608143244872482	0.0625
1608143244872507	49.0
1608143244872520	0.020263671875
1608143244873301	-53.818115234375
1608143244873303	-0.020263671875
1608143244873304	-0.0625
1608143244882775	-49.0
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv22/batchnorm22/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv20/batchnorm20/beta/ApplyGradientDescent
v/cg/resnet_v115/conv51/batchnorm51/moving_mean/read
ConstantFoldingCtrl/learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Switch_1
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/affine0/weights/ApplyGradientDescent
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg
v/cg/resnet_v13/conv11/batchnorm11/moving_mean
v/cg/resnet_v10/conv1/batchnorm1/gamma/read
learning_rate/PiecewiseConstant/case/cond/pred_id
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg_1/sub_1
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/Switch/Switch
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v14/conv16/conv2d/kernel
tower_0/v/l2_loss/L2Loss_19
1608143244703455	0.000244140625
1608143244703457	0.000244140625
1608143244703512	-0.000244140625
1608143244706865	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244813840	19.501953125
1608143244813847	2.25
1608143244813872	12.25
1608143244813889	81.0
1608143244814246	-19.501953125
1608143244814249	-81.0
1608143244814251	-2.25
1608143244820215	-12.25
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244880683	0.015625
1608143244880689	0.015625
1608143244880703	0.0029296875
1608143244881606	-0.0029296875
1608143244881608	-0.015625
1608143244882816	-0.015625
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244827670	0.25
1608143244827678	0.25
1608143244827692	0.00439453125
1608143244830876	-0.00439453125
1608143244830878	-0.25
1608143244831109	-0.25
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244835277	0.25
1608143244835283	0.25048828125
1608143244835297	0.00390625
1608143244836241	-0.00390625
1608143244836243	-0.25048828125
1608143244836531	-0.25
v/cg/resnet_v12/conv9/batchnorm9/beta/read
v/cg/resnet_v13/conv14/batchnorm14/moving_variance
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_8_grad/mul
1608143244703914	0.0625
1608143244861263	-0.0625
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244824918	1.0
1608143244824924	1.0
1608143244824940	112.5
1608143244825573	-112.5
1608143244825576	-1.0
1608143244826708	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_22_grad/mul
1608143244703786	0.5625
1608143244826204	-0.5625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv12/batchnorm12/beta/ApplyGradientDescent
v/cg/resnet_v13/conv13/batchnorm13/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v114/Relu
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/num_present
tower_0/v/cg/resnet_v110/conv34/Relu
v/cg/resnet_v13/conv13/batchnorm13/beta
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg
tower_0/v/gradients/AddN_59
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv42/batchnorm42/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v15/Relu
v/cg/resnet_v110/conv34/conv2d/kernel
v/cg/resnet_v10/conv2/batchnorm2/gamma
v/cg/resnet_v13/conv14/batchnorm14/moving_variance/read
v/cg/resnet_v14/conv17/batchnorm17/moving_variance/read
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv35/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/Relu_grad/ReluGrad
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg_1
tower_0/v/l2_loss/L2Loss_14
1608143244705573	0.000244140625
1608143244705575	0.000244140625
1608143244705620	-0.000244140625
1608143244706862	-0.000244140625
v/cg/resnet_v14/conv15/conv2d/kernel/read
v/cg/resnet_v14/conv15/batchnorm15/moving_variance
v/cg/resnet_v112/conv42/batchnorm42/beta/read
v/cg/resnet_v112/conv42/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v11/conv6/batchnorm6/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv39/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244797290	1.0
1608143244797297	1.0
1608143244797314	0.00244140625
1608143244797432	-0.00244140625
1608143244797435	-1.0
1608143244797773	-1.0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_43_grad/mul
1608143244697754	8.0
1608143244780108	-8.0
tower_0/v/cg/resnet_v13/conv13/batchnorm13/FusedBatchNormV3
1608143244717466	24.5
1608143244717467	0.00048828125
1608143244717468	0.00048828125
1608143244717469	0.00048828125
1608143244717470	0.00048828125
1608143244718242	-0.00048828125
1608143244718285	-0.00048828125
1608143244848651	-24.5
1608143244849067	-0.00048828125
1608143244849068	-0.00048828125
v/cg/resnet_v10/conv1/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244842889	0.25
1608143244842895	0.25048828125
1608143244842908	0.00439453125
1608143244843890	-0.00439453125
1608143244843892	-0.25048828125
1608143244844224	-0.25
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg_1
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/batchnorm36/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244792486	49.00390625
1608143244792487	0.00390625
1608143244792488	0.00439453125
1608143244792488	0.000244140625
1608143244792512	0.000244140625
1608143244792675	-0.000244140625
1608143244792676	-0.000244140625
1608143244793036	-49.00390625
1608143244793084	-0.00390625
1608143244793876	-0.00439453125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv47/batchnorm47/beta/ApplyGradientDescent
v/cg/resnet_v115/conv52/batchnorm52/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/batchnorm7/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244861334	196.0
1608143244861335	0.001220703125
1608143244861336	0.0009765625
1608143244861336	0.000244140625
1608143244861358	0.000244140625
1608143244861428	-0.000244140625
1608143244861428	-0.000244140625
1608143244863508	-196.0
1608143244863543	-0.001220703125
1608143244863574	-0.0009765625
v/cg/resnet_v115/conv50/batchnorm50/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv4/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv2/batchnorm2/beta/ApplyGradientDescent
v/cg/resnet_v10/conv1/batchnorm1/beta
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_36_grad/mul
1608143244699682	1.0
1608143244793951	-1.0
tower_0/v/cg/resnet_v112/Relu
v/cg/resnet_v13/conv12/batchnorm12/moving_variance/read
tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D
1608143244730448	12.25
1608143244730454	1.0
1608143244730500	0.001953125
1608143244730571	-0.001953125
1608143244730574	-1.0
1608143244796269	-12.25
v/cg/resnet_v114/conv47/batchnorm47/gamma
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg
v/cg/resnet_v17/conv26/batchnorm26/gamma/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244812024	1.0
1608143244812031	1.0
1608143244812046	0.00390625
1608143244813204	-0.00390625
1608143244813206	-1.0
1608143244813824	-1.0
tower_0/v/cg/conv0/Relu
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244782964	12.25
1608143244782970	4.0
1608143244782999	12.25
1608143244783023	81.0
1608143244783272	-12.25
1608143244783274	-81.0
1608143244783276	-4.0
1608143244785819	-12.25
v/cg/resnet_v11/conv7/batchnorm7/moving_mean
v/cg/resnet_v110/conv36/batchnorm36/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv1/batchnorm1/gamma/ApplyGradientDescent
tower_0/v/gradients/AddN_4
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg_1/mul
v/cg/resnet_v111/conv37/batchnorm37/moving_variance/read
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg/mul
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv18/conv2d/kernel/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v19/conv32/batchnorm32/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244857260	0.25
1608143244857266	0.25048828125
1608143244857280	0.00537109375
1608143244858915	-0.00537109375
1608143244858917	-0.25048828125
1608143244859206	-0.25
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/batchnorm29/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244804345	12.25
1608143244804346	0.0009765625
1608143244804346	0.001220703125
1608143244804347	0.000244140625
1608143244804381	0.000244140625
1608143244804472	-0.000244140625
1608143244804473	-0.000244140625
1608143244806106	-12.25
1608143244806154	-0.0009765625
1608143244806189	-0.001220703125
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244836741	31.751953125
1608143244836746	0.25
1608143244837295	24.5
1608143244837321	0.006591796875
1608143244837629	-31.751953125
1608143244837631	-0.006591796875
1608143244837633	-0.25
1608143244838815	-24.5
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v112/conv40/Relu
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_7_grad/mul
1608143244702519	0.0625
1608143244863837	-0.0625
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv25/batchnorm25/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg/mul
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv31/batchnorm31/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv48/batchnorm48/FusedBatchNormV3
1608143244749899	6.1328125
1608143244749900	0.001953125
1608143244749901	0.001953125
1608143244749902	0.001953125
1608143244749903	0.001953125
1608143244751372	-0.001953125
1608143244751410	-0.001953125
1608143244769428	-6.1328125
1608143244769595	-0.001953125
1608143244769597	-0.001953125
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244796337	49.0
1608143244796343	1.0
1608143244796387	49.0
1608143244796404	0.00390625
1608143244796481	-49.0
1608143244796484	-0.00390625
1608143244796484	-1.0
1608143244796787	-49.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv9/batchnorm9/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/batchnorm38/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244788761	12.25
1608143244788762	0.0009765625
1608143244788762	0.001220703125
1608143244788763	0.000244140625
1608143244788870	0.000244140625
1608143244788963	-0.000244140625
1608143244788964	-0.000244140625
1608143244790165	-12.25
1608143244790219	-0.0009765625
1608143244790258	-0.001220703125
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg_1/sub_1
tower_0/v/gradients/AddN_43
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg/sub_1
v/cg/resnet_v111/conv37/batchnorm37/beta
v/cg/resnet_v110/conv34/batchnorm34/moving_variance
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_18_grad/mul
1608143244706079	0.25
1608143244836465	-0.25
learning_rate/PiecewiseConstant/case/num_true_conds
v/cg/resnet_v17/conv26/batchnorm26/gamma
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg
tower_0/v/cg/resnet_v19/conv31/Relu
v/cg/resnet_v115/conv50/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v110/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/l2_loss/L2Loss_46
1608143244701666	0.000244140625
1608143244701680	0.0087890625
1608143244701746	-0.0087890625
1608143244706889	-0.000244140625
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg_1
tower_0/v/cg/resnet_v10/conv3/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv10/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v114/conv47/batchnorm47/moving_mean/read
tower_0/v/cg/resnet_v11/conv5/Relu
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg
tower_0/v/gradients/AddN_50
v/cg/resnet_v16/conv23/batchnorm23/moving_variance
v/cg/resnet_v13/conv11/batchnorm11/moving_variance/read
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg_1/mul
v/cg/resnet_v111/conv38/batchnorm38/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/batchnorm22/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244824002	24.5
1608143244824003	0.00048828125
1608143244824004	0.00048828125
1608143244824004	0.000244140625
1608143244824025	0.000244140625
1608143244824101	-0.000244140625
1608143244824102	-0.000244140625
1608143244825583	-24.5
1608143244825859	-0.00048828125
1608143244825892	-0.00048828125
tower_0/v/cg/mpool0/MaxPool
1608143244708072	49.0
1608143244882773	-49.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv34/batchnorm34/beta/ApplyGradientDescent
tower_0/v/gradients/AddN_10
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v18/conv30/batchnorm30/gamma/read
tower_0/v/cg/resnet_v18/conv28/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv29/batchnorm29/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v19/conv33/batchnorm33/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244853972	49.0
1608143244853978	0.0625
1608143244854002	49.0
1608143244854016	0.020263671875
1608143244854930	-49.0
1608143244854932	-0.020263671875
1608143244854934	-0.0625
1608143244856629	-49.0
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg/mul
v/cg/resnet_v17/conv24/batchnorm24/moving_mean/read
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg_1
v/cg/resnet_v112/conv40/batchnorm40/moving_mean
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/cond/Switch/Switch
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv16/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/ShapeN-matshapes-0
edge_526_learning_rate/Less@@MemcpyDtoH
v/cg/resnet_v111/conv37/conv2d/kernel
tower_0/v/l2_loss/L2Loss_6
1608143244705450	0.000244140625
1608143244705452	0.000244140625
1608143244705502	-0.000244140625
1608143244706897	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv35/batchnorm35/gamma/ApplyGradientDescent
v/cg/resnet_v18/conv28/batchnorm28/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv16/batchnorm16/gamma/ApplyGradientDescent
v/cg/resnet_v11/conv7/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244874549	0.0625
1608143244874555	0.0625
1608143244874568	0.0029296875
1608143244875754	-0.0029296875
1608143244875757	-0.0625
1608143244877605	-0.0625
tower_0/v/cg/resnet_v13/conv14/batchnorm14/FusedBatchNormV3
1608143244718088	98.0
1608143244718089	0.001953125
1608143244718091	0.001953125
1608143244718092	0.001953125
1608143244718092	0.001953125
1608143244718331	-98.0
1608143244718770	-0.001953125
1608143244718805	-0.001953125
1608143244845150	-0.001953125
1608143244845151	-0.001953125
v/cg/resnet_v19/conv32/batchnorm32/moving_mean/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_39_grad/mul
1608143244699812	1.0
1608143244788748	-1.0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_23_grad/mul
1608143244698335	0.25
1608143244823991	-0.25
v/cg/resnet_v10/conv3/batchnorm3/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v115/Relu_grad/ReluGrad
v/cg/resnet_v19/conv33/batchnorm33/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244840751	0.56298828125
1608143244840757	1.0
1608143244840772	112.5
1608143244841065	-112.5
1608143244841068	-1.0
1608143244841926	-0.56298828125
v/cg/resnet_v11/conv7/conv2d/kernel
v/cg/resnet_v113/conv44/conv2d/kernel/read
v/cg/resnet_v18/conv29/conv2d/kernel/read
v/cg/resnet_v115/conv51/batchnorm51/moving_variance/read
v/cg/resnet_v10/conv4/batchnorm4/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv11/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v110/conv35/conv2d/kernel/read
v/cg/resnet_v19/conv33/conv2d/kernel/read
tower_0/v/cg/conv0/batchnorm0/FusedBatchNormV3
1608143244707645	196.0
1608143244707647	0.000244140625
1608143244707648	0.000244140625
1608143244707649	0.000244140625
1608143244707650	0.000244140625
1608143244708738	-0.000244140625
1608143244708786	-0.000244140625
1608143244882861	-196.0
1608143244882961	-0.000244140625
1608143244882963	-0.000244140625
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v19/add
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg_1/sub_1
v/cg/resnet_v114/conv49/batchnorm49/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv43/batchnorm43/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v11/conv6/conv2d/kernel
v/cg/resnet_v114/conv48/batchnorm48/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv40/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv45/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v13/conv14/batchnorm14/moving_mean/read
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg/sub_1
learning_rate/Cast_1
tower_0/v/gradients/tower_0/v/cg/resnet_v10/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg_1
v/cg/resnet_v13/conv13/batchnorm13/moving_mean/read
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v12/Relu
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244770452	9.00048828125
1608143244770460	12.0009765625
1608143244770478	131.619384765625
1608143244770596	-131.619384765625
1608143244770599	-12.0009765625
1608143244772002	-9.00048828125
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v114/conv48/conv2d/kernel
tower_0/v/cg/resnet_v16/conv22/Relu
learning_rate/truediv
v/cg/resnet_v113/conv44/batchnorm44/beta/read
v/cg/resnet_v112/conv42/batchnorm42/moving_mean/read
v/cg/resnet_v113/conv45/conv2d/kernel/read
v/cg/resnet_v10/conv2/batchnorm2/moving_mean/read
tower_0/v/cg/resnet_v115/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv7/batchnorm7/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/Relu_grad/ReluGrad
v/cg/resnet_v114/conv49/batchnorm49/moving_variance
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg
v/cg/resnet_v14/conv16/batchnorm16/gamma/read
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v115/conv50/batchnorm50/moving_mean/read
v/cg/resnet_v113/conv46/batchnorm46/moving_mean/read
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg/mul
v/cg/resnet_v11/conv6/conv2d/kernel/read
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/value
v/cg/resnet_v113/conv46/batchnorm46/gamma/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_46_grad/mul
1608143244701768	4.0
1608143244780184	-4.0
tower_0/v/cg/resnet_v17/add
tower_0/v/cg/conv0/Pad
1608143244706607	38.7451171875
1608143244883174	-38.7451171875
v/cg/resnet_v18/conv28/batchnorm28/moving_variance
tower_0/v/cg/resnet_v19/Relu
tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D
1608143244727905	49.0
1608143244727910	1.0
1608143244727966	0.001220703125
1608143244728039	-0.001220703125
1608143244728043	-1.0
1608143244802985	-49.0
v/cg/resnet_v16/conv23/conv2d/kernel
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg/mul
tower_0/v/cg/resnet_v113/Relu
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/batchnorm46/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244778950	24.5
1608143244778952	0.0078125
1608143244778952	0.0078125
1608143244778953	0.000244140625
1608143244778981	0.000244140625
1608143244779052	-0.000244140625
1608143244779053	-0.000244140625
1608143244779978	-24.5
1608143244780023	-0.0078125
1608143244780066	-0.0078125
v/cg/resnet_v113/conv45/conv2d/kernel
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg/mul
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg_1/mul
v/cg/resnet_v17/conv27/batchnorm27/gamma
v/cg/resnet_v13/conv11/batchnorm11/moving_variance
v/cg/resnet_v11/conv5/batchnorm5/beta/read
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg_1/mul
tower_0/v/l2_loss/L2Loss_4
1608143244704857	0.000244140625
1608143244704859	0.000244140625
1608143244704907	-0.000244140625
1608143244706884	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/l2_loss/L2Loss_45
1608143244698519	0.000244140625
1608143244698533	0.0087890625
1608143244698593	-0.0087890625
1608143244706889	-0.000244140625
tower_0/v/cg/resnet_v15/conv18/batchnorm18/FusedBatchNormV3
1608143244720763	24.5
1608143244720764	0.00048828125
1608143244720765	0.00048828125
1608143244720766	0.00048828125
1608143244720767	0.00048828125
1608143244721502	-0.00048828125
1608143244721545	-0.00048828125
1608143244833810	-24.5
1608143244834289	-0.00048828125
1608143244834290	-0.00048828125
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/Relu_grad/ReluGrad
v/cg/resnet_v112/conv41/conv2d/kernel/read
v/cg/resnet_v115/conv51/batchnorm51/moving_variance
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv42/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v17/conv25/batchnorm25/moving_variance
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg/sub_1
v/cg/resnet_v17/conv24/batchnorm24/beta
tower_0/v/gradients/AddN_38
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv48/batchnorm48/gamma/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_29
1608143244703044	0.000244140625
1608143244703057	0.0087890625
1608143244703112	-0.0087890625
1608143244706875	-0.000244140625
tower_0/v/l2_loss/L2Loss_49
1608143244701967	0.000244140625
1608143244701983	0.0087890625
1608143244702049	-0.0087890625
1608143244706892	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv15/batchnorm15/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg_1
tower_0/v/cg/resnet_v17/conv25/batchnorm25/FusedBatchNormV3
1608143244724803	12.25
1608143244724804	0.0009765625
1608143244724805	0.0009765625
1608143244724806	0.0009765625
1608143244724807	0.0009765625
1608143244725748	-0.0009765625
1608143244725790	-0.0009765625
1608143244819263	-12.25
1608143244820217	-0.0009765625
1608143244820220	-0.0009765625
learning_rate/PiecewiseConstant/case/cond/Switch_1
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244821304	0.5
1608143244821311	0.5
1608143244821327	0.00439453125
1608143244821440	-0.00439453125
1608143244821442	-0.5
1608143244821663	-0.5
v/cg/resnet_v12/conv9/batchnorm9/beta
v/cg/resnet_v11/conv5/batchnorm5/moving_mean/read
v/cg/resnet_v16/conv23/batchnorm23/moving_mean/read
tower_0/v/l2_loss/L2Loss_22
1608143244703710	0.000244140625
1608143244703712	0.000244140625
1608143244703766	-0.000244140625
1608143244706868	-0.000244140625
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg_1/mul
v/cg/resnet_v112/conv42/batchnorm42/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv14/batchnorm14/beta/ApplyGradientDescent
v/cg/resnet_v19/conv32/batchnorm32/beta/read
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv19/batchnorm19/gamma/ApplyGradientDescent
tower_0/v/cg/affine0/xw_plus_b/MatMul
1608143244758798	0.244384765625
1608143244761714	-0.244384765625
tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D
1608143244716202	36.742431640625
1608143244716208	0.125
1608143244716263	0.004638671875
1608143244716337	-0.004638671875
1608143244716341	-0.125
1608143244851727	-36.742431640625
tower_0/v/gradients/AddN_16
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v113/conv45/batchnorm45/beta/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv7/batchnorm7/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v115/conv52/batchnorm52/gamma
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v15/conv18/batchnorm18/moving_mean/read
learning_rate/Const_4
tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D
1608143244756029	24.5
1608143244756034	4.0
1608143244756248	0.00048828125
1608143244756403	-0.00048828125
1608143244756407	-4.0
1608143244762796	-24.5
tower_0/v/cg/resnet_v111/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244764281	6.125
1608143244764289	9.0
1608143244764319	7.820556640625
1608143244764340	72.0
1608143244764506	-6.125
1608143244764509	-72.0
1608143244764511	-9.0
1608143244766349	-7.820556640625
tower_0/v/cg/conv0/conv2d/Conv2D
1608143244707236	196.0
1608143244707248	0.035888671875
1608143244707345	0.072021484375
1608143244707451	-0.072021484375
1608143244707455	-0.035888671875
1608143244882961	-196.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv37/batchnorm37/beta/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg_1/sub_1
tower_0/v/gradients/AddN_58
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_14_grad/mul
1608143244705640	0.25
1608143244848678	-0.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv24/batchnorm24/beta/ApplyGradientDescent
v/cg/resnet_v18/conv29/batchnorm29/moving_variance
v/cg/resnet_v110/conv35/batchnorm35/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv14/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv30/batchnorm30/gamma/ApplyGradientDescent
v/cg/resnet_v14/conv16/batchnorm16/gamma
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v15/conv19/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv27/batchnorm27/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg/sub_1
tower_0/v/gpu_cached_inputs
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244807280	49.0
1608143244807286	1.0
1608143244808199	49.0
1608143244808214	0.00439453125
1608143244808293	-49.0
1608143244808295	-0.00439453125
1608143244808296	-1.0
1608143244808668	-49.0
v/cg/conv0/batchnorm0/gamma/read
learning_rate/PiecewiseConstant/LessEqual_2
1608143244696239	0.000244140625
1608143244703230	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244846436	0.25
1608143244846442	0.25048828125
1608143244846456	0.00244140625
1608143244848317	-0.00244140625
1608143244848319	-0.25048828125
1608143244849394	-0.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv25/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv36/batchnorm36/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/batchnorm15/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244841469	24.5
1608143244841469	0.00048828125
1608143244841470	0.000732421875
1608143244841470	0.000244140625
1608143244841812	0.000244140625
1608143244841882	-0.000244140625
1608143244841882	-0.000244140625
1608143244843899	-24.5
1608143244843935	-0.00048828125
1608143244843966	-0.000732421875
tower_0/v/gradients/AddN_22
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244796509	1.0
1608143244796517	1.0
1608143244796533	0.00390625
1608143244796653	-0.00390625
1608143244796656	-1.0
1608143244796986	-1.0
tower_0/v/cg/resnet_v11/conv5/batchnorm5/FusedBatchNormV3
1608143244711649	49.0
1608143244711651	0.000244140625
1608143244711651	0.000244140625
1608143244711652	0.000244140625
1608143244711653	0.000244140625
1608143244712653	-0.000244140625
1608143244712694	-0.000244140625
1608143244869854	-49.0
1608143244869995	-0.000244140625
1608143244869996	-0.000244140625
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244780627	9.000244140625
1608143244780635	12.0009765625
1608143244780654	72.0
1608143244780777	-72.0
1608143244780780	-12.0009765625
1608143244781164	-9.000244140625
v/cg/resnet_v16/conv22/conv2d/kernel/read
v/cg/resnet_v19/conv31/conv2d/kernel
v/cg/resnet_v12/conv8/batchnorm8/moving_variance/read
v/cg/resnet_v14/conv17/batchnorm17/gamma/read
tower_0/v/mul/x
tower_0/v/gradients/AddN_36
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv50/batchnorm50/beta/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_35
1608143244700338	0.000244140625
1608143244700351	0.0087890625
1608143244701381	-0.0087890625
1608143244706880	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv52/batchnorm52/gamma/ApplyGradientDescent
v/cg/resnet_v16/conv21/batchnorm21/gamma
v/cg/resnet_v114/conv48/batchnorm48/gamma/read
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v15/conv19/batchnorm19/FusedBatchNormV3
1608143244721340	24.5
1608143244721341	0.00048828125
1608143244721342	0.00048828125
1608143244721343	0.00048828125
1608143244721344	0.00048828125
1608143244722124	-0.00048828125
1608143244722167	-0.00048828125
1608143244831637	-24.5
1608143244831778	-0.00048828125
1608143244831779	-0.00048828125
tower_0/v/gradients/AddN_61
v/cg/resnet_v19/conv31/conv2d/kernel/read
tower_0/v/mul
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_35_grad/mul
1608143244701451	2.25
1608143244795343	-2.25
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/batchnorm2/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244880270	49.0
1608143244880271	0.000244140625
1608143244880271	0.000244140625
1608143244880272	0.000244140625
1608143244880290	0.000244140625
1608143244880365	-0.000244140625
1608143244880366	-0.000244140625
1608143244881615	-49.0
1608143244881806	-0.000244140625
1608143244881996	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244766470	24.5
1608143244766478	4.00048828125
1608143244766508	24.5
1608143244766529	0.00390625
1608143244766618	-24.5
1608143244766622	-0.00390625
1608143244766623	-4.00048828125
1608143244767554	-24.5
v/cg/resnet_v13/conv12/conv2d/kernel
tower_0/v/l2_loss/AddN
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D
1608143244731542	49.0
1608143244731548	1.0
1608143244731596	0.001220703125
1608143244731666	-0.001220703125
1608143244731669	-1.0
1608143244792671	-49.0
v/cg/resnet_v15/conv18/batchnorm18/beta
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg_1
tower_0/v/resnet50_synthetic_labels/max
tower_0/v/cg/resnet_v12/conv9/batchnorm9/FusedBatchNormV3
1608143244714830	49.0
1608143244714831	0.000244140625
1608143244714832	0.000244140625
1608143244714833	0.000244140625
1608143244714834	0.000244140625
1608143244715661	-0.000244140625
1608143244715702	-0.000244140625
1608143244856247	-49.0
1608143244856631	-0.000244140625
1608143244856633	-0.000244140625
v/cg/resnet_v111/conv39/batchnorm39/beta
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/batchnorm17/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244836545	98.00390625
1608143244836546	0.001953125
1608143244836546	0.00244140625
1608143244836547	0.000244140625
1608143244836634	0.000244140625
1608143244836724	-0.000244140625
1608143244836725	-0.000244140625
1608143244838487	-98.00390625
1608143244838555	-0.001953125
1608143244838584	-0.00244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv23/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v13/conv11/batchnorm11/FusedBatchNormV3
1608143244716505	98.0
1608143244716506	0.001953125
1608143244716507	0.001953125
1608143244716508	0.001953125
1608143244716509	0.001953125
1608143244717411	-0.001953125
1608143244717451	-0.001953125
1608143244844114	-98.0
1608143244844929	-0.001953125
1608143244844930	-0.001953125
v/cg/resnet_v112/conv40/batchnorm40/gamma/read
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg
v/cg/resnet_v12/conv8/conv2d/kernel
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_31_grad/mul
1608143244697946	1.0
1608143244801841	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v14/conv15/batchnorm15/moving_variance/read
v/cg/resnet_v10/conv2/batchnorm2/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv11/batchnorm11/beta/ApplyGradientDescent
v/cg/resnet_v13/conv13/batchnorm13/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/batchnorm30/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244802537	49.00390625
1608143244802538	0.00390625
1608143244802539	0.00439453125
1608143244802539	0.000244140625
1608143244802625	0.000244140625
1608143244802989	-0.000244140625
1608143244802990	-0.000244140625
1608143244803346	-49.00390625
1608143244803388	-0.00390625
1608143244803425	-0.00439453125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv22/batchnorm22/gamma/ApplyGradientDescent
v/cg/resnet_v10/conv1/batchnorm1/moving_variance/read
v/cg/resnet_v12/conv10/batchnorm10/gamma
v/cg/resnet_v10/conv4/batchnorm4/moving_mean/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v18/conv30/batchnorm30/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244800826	1.0
1608143244800834	1.0
1608143244800850	0.00390625
1608143244800972	-0.00390625
1608143244800974	-1.0
1608143244802527	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v13/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244764550	9.0
1608143244764560	9.0
1608143244764581	72.0
1608143244765476	-72.0
1608143244765481	-9.0
1608143244766450	-9.0
v/cg/resnet_v16/conv21/batchnorm21/beta
v/cg/resnet_v113/conv43/batchnorm43/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv26/batchnorm26/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv28/batchnorm28/FusedBatchNormV3
1608143244727013	12.25
1608143244727014	0.0009765625
1608143244727015	0.0009765625
1608143244727016	0.0009765625
1608143244727016	0.0009765625
1608143244727693	-0.0009765625
1608143244727736	-0.0009765625
1608143244806224	-12.25
1608143244807217	-0.0009765625
1608143244807218	-0.0009765625
tower_0/v/cg/resnet_v14/conv16/batchnorm16/FusedBatchNormV3
1608143244719385	24.501953125
1608143244719387	0.00048828125
1608143244719388	0.00048828125
1608143244719389	0.00048828125
1608143244719389	0.00048828125
1608143244720176	-0.00048828125
1608143244720211	-0.00048828125
1608143244838618	-24.501953125
1608143244838818	-0.00048828125
1608143244838818	-0.00048828125
tower_0/v/l2_loss/L2Loss_44
1608143244699871	0.000244140625
1608143244699884	0.0087890625
1608143244699942	-0.0087890625
1608143244706888	-0.000244140625
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg_1
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/ShapeN-matshapes-0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244849410	24.5
1608143244849416	0.7548828125
1608143244849439	24.5
1608143244849453	147.0078125
1608143244850407	-24.5
1608143244850410	-147.0078125
1608143244850410	-0.7548828125
1608143244851725	-24.5
learning_rate/PiecewiseConstant/Greater
1608143244692465	0.000244140625
1608143244706566	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv32/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv16/batchnorm16/beta/ApplyGradientDescent
v/cg/resnet_v114/conv47/batchnorm47/beta
v/cg/resnet_v10/conv3/batchnorm3/moving_variance
tower_0/v/gradients/AddN_3
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg_1/mul
tower_0/v/l2_loss/L2Loss
1608143244704740	0.000244140625
1608143244704742	0.000244140625
1608143244704788	-0.000244140625
1608143244798366	-0.000244140625
tower_0/v/cg/resnet_v14/conv15/Relu
tower_0/v/gradients/AddN
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv41/batchnorm41/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v18/add
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/batchnorm3/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244876928	49.0
1608143244876928	0.000244140625
1608143244876929	0.000244140625
1608143244876930	0.000244140625
1608143244876948	0.000244140625
1608143244877567	-0.000244140625
1608143244877568	-0.000244140625
1608143244879263	-49.0
1608143244879304	-0.000244140625
1608143244879334	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244781849	12.25
1608143244781856	1.0
1608143244781887	12.25
1608143244781905	0.00341796875
1608143244781979	-12.25
1608143244781982	-0.00341796875
1608143244781983	-1.0
1608143244782465	-12.25
v/cg/resnet_v114/conv49/batchnorm49/gamma/read
v/cg/resnet_v113/conv45/batchnorm45/moving_mean
tower_0/v/cg/resnet_v18/conv30/batchnorm30/FusedBatchNormV3
1608143244728183	49.0
1608143244728185	0.00390625
1608143244728186	0.00390625
1608143244728186	0.00390625
1608143244728187	0.00390625
1608143244728876	-0.00390625
1608143244728914	-0.00390625
1608143244801907	-49.0
1608143244802986	-0.00390625
1608143244802987	-0.00390625
tower_0/v/l2_loss/L2Loss_17
1608143244702624	0.000244140625
1608143244702626	0.000244140625
1608143244702682	-0.000244140625
1608143244706864	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244826718	98.0
1608143244826723	0.25
1608143244826752	98.0
1608143244826768	0.006591796875
1608143244827642	-98.0
1608143244827645	-0.006591796875
1608143244827646	-0.25
1608143244831011	-98.0
tower_0/v/cg/resnet_v115/add
v/cg/resnet_v110/conv36/batchnorm36/gamma
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv29/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D
1608143244732227	12.25
1608143244732232	1.0
1608143244732285	0.001953125
1608143244732353	-0.001953125
1608143244732355	-1.0
1608143244790465	-12.25
tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D
1608143244725254	12.25
1608143244725260	2.25
1608143244725308	81.0
1608143244725409	-81.0
1608143244725413	-2.25
1608143244813714	-12.25
tower_0/v/cg/resnet_v16/conv22/batchnorm22/FusedBatchNormV3
1608143244723267	24.5
1608143244723268	0.00048828125
1608143244723269	0.00048828125
1608143244723270	0.00048828125
1608143244723271	0.00048828125
1608143244724039	-0.00048828125
1608143244724079	-0.00048828125
1608143244823957	-24.5
1608143244824099	-0.00048828125
1608143244824100	-0.00048828125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv51/batchnorm51/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg
edge_274_global_step/read@@MemcpyHtoD
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_33_grad/mul
1608143244698893	1.0
1608143244797602	-1.0
v/cg/resnet_v13/conv13/batchnorm13/gamma/read
tower_0/v/gradients/AddN_8
learning_rate/PiecewiseConstant/case/cond/cond/Switch/Switch
tower_0/v/gradients/AddN_46
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv35/batchnorm35/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv51/batchnorm51/beta/ApplyGradientDescent
v/cg/resnet_v16/conv22/batchnorm22/moving_mean
tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D
1608143244729152	12.25
1608143244729157	2.25
1608143244729203	81.0
1608143244729305	-81.0
1608143244729309	-2.25
1608143244797725	-12.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv47/batchnorm47/gamma/ApplyGradientDescent
v/cg/resnet_v111/conv38/batchnorm38/gamma/read
v/cg/resnet_v12/conv9/batchnorm9/moving_variance
tower_0/v/gradients/AddN_20
v/cg/resnet_v110/conv34/batchnorm34/moving_mean
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg/mul
v/cg/resnet_v113/conv43/batchnorm43/moving_variance
v/cg/resnet_v17/conv25/batchnorm25/beta/read
v/cg/resnet_v110/conv36/batchnorm36/moving_variance/read
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/batchnorm26/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244813606	12.25
1608143244813607	0.0009765625
1608143244813608	0.001220703125
1608143244813608	0.000244140625
1608143244813635	0.000244140625
1608143244813718	-0.000244140625
1608143244813718	-0.000244140625
1608143244819154	-12.25
1608143244819193	-0.0009765625
1608143244819228	-0.001220703125
tower_0/v/cg/resnet_v112/conv41/batchnorm41/FusedBatchNormV3
1608143244736113	12.25
1608143244736115	0.0009765625
1608143244736116	0.0009765625
1608143244736116	0.0009765625
1608143244736117	0.0009765625
1608143244739875	-0.0009765625
1608143244739910	-0.0009765625
1608143244782303	-12.25
1608143244782468	-0.0009765625
1608143244782469	-0.0009765625
v/cg/resnet_v12/conv9/batchnorm9/gamma
v/cg/resnet_v114/conv48/batchnorm48/gamma
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244768403	7.804931640625
1608143244768412	4.0
1608143244768432	0.00390625
1608143244769272	-0.00390625
1608143244769275	-4.0
1608143244770190	-7.804931640625
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg_1/mul
v/cg/resnet_v10/conv1/batchnorm1/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv21/batchnorm21/beta/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v112/conv40/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv17/batchnorm17/beta/ApplyGradientDescent
v/cg/resnet_v110/conv36/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/Relu_grad/ReluGrad
v/cg/resnet_v11/conv5/batchnorm5/gamma/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v114/conv49/conv2d/kernel
v/cg/resnet_v112/conv41/batchnorm41/beta/read
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg_1/mul
v/cg/resnet_v111/conv37/batchnorm37/moving_mean/read
tower_0/v/cg/resnet_v114/conv47/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/batchnorm35/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244793962	12.25
1608143244793963	0.0009765625
1608143244793963	0.001220703125
1608143244793964	0.000244140625
1608143244793986	0.000244140625
1608143244794077	-0.000244140625
1608143244794077	-0.000244140625
1608143244795186	-12.25
1608143244795237	-0.0009765625
1608143244795273	-0.001220703125
v/cg/resnet_v115/conv52/batchnorm52/moving_variance/read
tower_0/v/gradients/AddN_26
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/control_dependency
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v14/conv17/batchnorm17/gamma
v/cg/resnet_v14/conv17/conv2d/kernel/read
v/cg/resnet_v113/conv43/batchnorm43/beta/read
v/cg/resnet_v17/conv26/batchnorm26/moving_variance
tower_0/v/gradients/AddN_70
v/cg/resnet_v18/conv28/conv2d/kernel
v/cg/resnet_v114/conv47/batchnorm47/beta/read
v/cg/resnet_v16/conv22/batchnorm22/moving_mean/read
v/cg/resnet_v115/conv50/batchnorm50/moving_variance/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v17/conv27/batchnorm27/beta/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v15/conv20/batchnorm20/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v113/conv44/batchnorm44/moving_mean
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg_1/mul
v/cg/resnet_v111/conv39/conv2d/kernel/read
tower_0/v/cg/resnet_v113/conv44/Relu
v/cg/resnet_v18/conv28/batchnorm28/moving_mean/read
v/cg/resnet_v18/conv28/batchnorm28/beta
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244787661	12.25
1608143244787667	1.0
1608143244787699	12.25
1608143244787716	0.00341796875
1608143244787802	-12.25
1608143244787805	-0.00341796875
1608143244787806	-1.0
1608143244788957	-12.25
learning_rate/PiecewiseConstant/case/Cast
1608143244707085	0.000244140625
1608143244710835	-0.000244140625
tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D
1608143244715196	196.0
1608143244715202	0.0625
1608143244715255	0.01806640625
1608143244715335	-0.01806640625
1608143244715339	-0.0625
1608143244853953	-196.0
v/cg/resnet_v111/conv38/batchnorm38/moving_mean/read
v/cg/resnet_v113/conv46/batchnorm46/beta/read
tower_0/v/cg/resnet_v12/conv8/batchnorm8/FusedBatchNormV3
1608143244713954	49.0
1608143244713956	0.000244140625
1608143244713957	0.000244140625
1608143244713958	0.000244140625
1608143244713958	0.000244140625
1608143244714992	-0.000244140625
1608143244715043	-0.000244140625
1608143244859028	-49.0
1608143244859160	-0.000244140625
1608143244859162	-0.000244140625
v/cg/resnet_v12/conv10/conv2d/kernel
tower_0/v/gradients/AddN_30
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv7/conv2d/kernel/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg/mul
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg/mul
v/cg/resnet_v12/conv10/batchnorm10/gamma/read
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg
tower_0/v/cg/resnet_v113/conv43/batchnorm43/FusedBatchNormV3
1608143244741173	24.5
1608143244741174	0.0078125
1608143244741176	0.0078125
1608143244741176	0.0078125
1608143244741177	0.0078125
1608143244743915	-0.0078125
1608143244743955	-0.0078125
1608143244778725	-24.5
1608143244778916	-0.0078125
1608143244778917	-0.0078125
learning_rate/Const_8
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_24_grad/mul
1608143244702862	2.0
1608143244813384	-2.0
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg_1
tower_0/v/gradients/AddN_62
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244786200	49.0
1608143244786207	1.0
1608143244786235	49.0
1608143244786253	0.00390625
1608143244786444	-49.0
1608143244786447	-0.00390625
1608143244786448	-1.0
1608143244786768	-49.0
v/cg/resnet_v114/conv49/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/batchnorm9/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244856541	49.0
1608143244856542	0.000244140625
1608143244856542	0.000244140625
1608143244856543	0.000244140625
1608143244856563	0.000244140625
1608143244856634	-0.000244140625
1608143244856634	-0.000244140625
1608143244858924	-49.0
1608143244858966	-0.000244140625
1608143244859000	-0.000244140625
v/cg/resnet_v114/conv47/conv2d/kernel/read
v/cg/resnet_v11/conv5/batchnorm5/moving_variance/read
v/cg/resnet_v112/conv41/batchnorm41/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244874345	53.818115234375
1608143244874350	0.0625
1608143244874371	49.0
1608143244874384	0.020263671875
1608143244874524	-53.818115234375
1608143244874527	-0.020263671875
1608143244874528	-0.0625
1608143244877562	-49.0
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/batchnorm44/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244780976	7.820556640625
1608143244780976	0.001953125
1608143244780977	0.001953125
1608143244780978	0.000244140625
1608143244781047	0.000244140625
1608143244781117	-0.000244140625
1608143244781117	-0.000244140625
1608143244781505	-7.820556640625
1608143244781550	-0.001953125
1608143244781583	-0.001953125
tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D
1608143244736968	49.0
1608143244736974	1.0
1608143244738566	0.001220703125
1608143244738636	-0.001220703125
1608143244738639	-1.0
1608143244781823	-49.0
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv27/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v16/Relu
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg_1/mul
v/cg/resnet_v17/conv24/batchnorm24/beta/read
v/cg/resnet_v115/conv50/batchnorm50/gamma
v/cg/resnet_v16/conv23/batchnorm23/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244841935	98.0
1608143244841941	0.25
1608143244842787	98.0
1608143244842801	0.006591796875
1608143244842865	-98.0
1608143244842867	-0.006591796875
1608143244842868	-0.25
1608143244844049	-98.0
v/cg/resnet_v114/conv48/conv2d/kernel/read
tower_0/v/cg/resnet_v114/conv47/batchnorm47/FusedBatchNormV3
1608143244747930	6.125
1608143244747931	0.001953125
1608143244747932	0.001953125
1608143244747932	0.001953125
1608143244747933	0.001953125
1608143244750066	-0.001953125
1608143244750175	-0.001953125
1608143244771413	-6.125
1608143244771945	-0.001953125
1608143244771946	-0.001953125
tower_0/v/gradients/AddN_35
v/cg/resnet_v112/conv42/batchnorm42/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244781348	2.0
1608143244781356	2.0
1608143244781375	0.00390625
1608143244781494	-0.00390625
1608143244781496	-2.0
1608143244781710	-2.0
tower_0/v/gradients/AddN_54
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg/sub
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg/mul
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg_1/sub_1
learning_rate/PiecewiseConstant/case/cond/cond/Switch_1
v/cg/resnet_v115/conv52/batchnorm52/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Reshape/shape
v/cg/resnet_v15/conv19/batchnorm19/beta/read
tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D
1608143244719068	24.5
1608143244719074	0.5625
1608143244719123	112.5
1608143244719238	-112.5
1608143244719242	-0.5625
1608143244838817	-24.5
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/batchnorm40/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244785702	12.25
1608143244785703	0.0009765625
1608143244785710	0.001220703125
1608143244785710	0.000244140625
1608143244785736	0.000244140625
1608143244785825	-0.000244140625
1608143244785825	-0.000244140625
1608143244786641	-12.25
1608143244786693	-0.0009765625
1608143244786728	-0.001220703125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg_1
tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D
1608143244717807	98.0
1608143244717813	0.25
1608143244717862	0.004638671875
1608143244717935	-0.004638671875
1608143244717939	-0.25
1608143244845150	-98.0
append_apply_gradient_ops/GradientDescent/update_v/cg/conv0/batchnorm0/gamma/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_9
1608143244705211	0.000244140625
1608143244705213	0.000244140625
1608143244705259	-0.000244140625
1608143244706899	-0.000244140625
tower_0/v/cg/resnet_v113/add
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v18/conv30/batchnorm30/moving_variance/read
tower_0/v/l2_loss/L2Loss_52
1608143244702285	0.000244140625
1608143244702297	0.0087890625
1608143244702359	-0.0087890625
1608143244706895	-0.000244140625
tower_0/v/gradients/AddN_69
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D
1608143244708477	196.0
1608143244708483	0.0625
1608143244708540	0.01806640625
1608143244708620	-0.01806640625
1608143244708624	-0.0625
1608143244872294	-196.0
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244856960	49.0
1608143244856965	0.25
1608143244856992	49.0
1608143244857006	85.046875
1608143244857233	-49.0
1608143244857235	-85.046875
1608143244857237	-0.25
1608143244859158	-49.0
v/cg/resnet_v115/conv51/batchnorm51/beta/read
tower_0/v/gradients/AddN_42
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg/mul
learning_rate/PiecewiseConstant/case/cond/Merge
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg_1/sub_1
v/cg/resnet_v18/conv30/conv2d/kernel/read
v/cg/resnet_v114/conv48/batchnorm48/moving_variance/read
v/cg/resnet_v17/conv26/batchnorm26/moving_mean/read
learning_rate/Less/y
v/cg/resnet_v13/conv12/batchnorm12/beta
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v14/conv16/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv51/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v13/add
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg/sub_1
v/cg/resnet_v113/conv44/batchnorm44/moving_variance/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv12/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244808320	1.0
1608143244808327	1.0
1608143244808343	0.00439453125
1608143244808465	-0.00439453125
1608143244808467	-1.0
1608143244809465	-1.0
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv4/batchnorm4/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg_1
tower_0/v/cg/resnet_v19/conv33/batchnorm33/FusedBatchNormV3
1608143244730006	49.0
1608143244730007	0.00390625
1608143244730008	0.00390625
1608143244730009	0.00390625
1608143244730010	0.00390625
1608143244730655	-0.00390625
1608143244730695	-0.00390625
1608143244796951	-49.0
1608143244797105	-0.00390625
1608143244797105	-0.00390625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_29_grad/mul
1608143244703139	2.25
1608143244807100	-2.25
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/batchnorm23/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244821679	98.001953125
1608143244821679	0.001953125
1608143244821680	0.001953125
1608143244821681	0.000244140625
1608143244821765	0.000244140625
1608143244821925	-0.000244140625
1608143244821925	-0.000244140625
1608143244823847	-98.001953125
1608143244823886	-0.001953125
1608143244823921	-0.001953125
tower_0/v/cg/resnet_v12/conv10/batchnorm10/FusedBatchNormV3
1608143244715488	196.0
1608143244715489	0.0009765625
1608143244715490	0.001220703125
1608143244715491	0.0009765625
1608143244715492	0.0009765625
1608143244716439	-0.0009765625
1608143244716484	-0.001220703125
1608143244853773	-196.0
1608143244853954	-0.0009765625
1608143244853955	-0.0009765625
v/cg/resnet_v12/conv10/batchnorm10/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/affine0/xw_plus_b/MatMul_grad/MatMul_1
1608143244761674	7.8203125
1608143244762469	-7.8203125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv22/conv2d/kernel/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v114/conv48/batchnorm48/beta
v/cg/resnet_v12/conv10/batchnorm10/moving_mean
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg/mul
learning_rate/PiecewiseConstant/Greater_2
1608143244695910	0.000244140625
1608143244707075	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv17/conv2d/kernel/ApplyGradientDescent
learning_rate/PiecewiseConstant/LessEqual
1608143244692713	0.000244140625
1608143244706564	-0.000244140625
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv39/batchnorm39/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv6/batchnorm6/beta/ApplyGradientDescent
v/cg/resnet_v19/conv32/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv31/batchnorm31/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv33/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v15/conv20/batchnorm20/gamma
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg_1/sub_1
tower_0/v/gradients/AddN_67
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_34_grad/mul
1608143244698078	1.0
1608143244796851	-1.0
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg/mul
v/cg/resnet_v111/conv37/conv2d/kernel/read
tower_0/v/l2_loss/L2Loss_48
1608143244700193	0.000244140625
1608143244700206	0.0087890625
1608143244700263	-0.0087890625
1608143244706891	-0.000244140625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_47_grad/mul
1608143244700140	4.0
1608143244773313	-4.0
v/cg/resnet_v13/conv12/batchnorm12/moving_mean/read
v/cg/resnet_v19/conv32/conv2d/kernel
tower_0/v/cg/resnet_v11/conv7/batchnorm7/FusedBatchNormV3
1608143244713172	196.0
1608143244713174	0.0009765625
1608143244713174	0.001220703125
1608143244713175	0.0009765625
1608143244713177	0.0009765625
1608143244713895	-0.0009765625
1608143244713940	-0.001220703125
1608143244861294	-196.0
1608143244861425	-0.0009765625
1608143244861426	-0.0009765625
v/cg/resnet_v10/conv3/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244786474	1.0
1608143244786482	1.0
1608143244786499	0.00390625
1608143244786628	-0.00390625
1608143244786631	-1.0
1608143244787461	-1.0
learning_rate/cond/Switch_1
tower_0/v/cg/resnet_v17/conv24/batchnorm24/FusedBatchNormV3
1608143244724918	49.0
1608143244724919	0.00390625
1608143244724921	0.00390625
1608143244724922	0.00390625
1608143244724923	0.00390625
1608143244725824	-0.00390625
1608143244725874	-0.00390625
1608143244809379	-49.0
1608143244809655	-0.00390625
1608143244809656	-0.00390625
tower_0/v/l2_loss/L2Loss_12
1608143244704971	0.000244140625
1608143244704973	0.000244140625
1608143244705017	-0.000244140625
1608143244706860	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv23/batchnorm23/gamma/ApplyGradientDescent
v/cg/resnet_v113/conv44/batchnorm44/beta
tower_0/v/l2_loss/L2Loss_3
1608143244704295	0.000244140625
1608143244704297	0.000244140625
1608143244704346	-0.000244140625
1608143244706875	-0.000244140625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_32_grad/mul
1608143244699299	2.25
1608143244799416	-2.25
v/cg/resnet_v17/conv25/batchnorm25/beta
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v114/conv49/batchnorm49/beta
edge_544_learning_rate/PiecewiseConstant/case/Cast@@MemcpyDtoH
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Tile/multiples
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv29/batchnorm29/beta/ApplyGradientDescent
train_ops_group
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/affine0/xw_plus_b_grad/BiasAddGrad
1608143244761391	0.00390625
1608143244761955	-0.00390625
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg_1
v/cg/resnet_v16/conv21/batchnorm21/gamma/read
v/cg/resnet_v12/conv9/batchnorm9/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv44/batchnorm44/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg_1
v/cg/resnet_v115/conv52/conv2d/kernel/read
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg_1/mul
v/cg/resnet_v114/conv47/batchnorm47/gamma/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v115/conv50/Relu
v/cg/resnet_v111/conv39/batchnorm39/beta/read
v/cg/resnet_v12/conv8/batchnorm8/moving_variance
tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D
1608143244754083	6.125
1608143244754089	9.0
1608143244754141	72.0
1608143244755006	-72.0
1608143244755010	-9.0
1608143244764032	-6.125
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg_1/sub_1
v/cg/resnet_v17/conv25/batchnorm25/moving_variance/read
v/cg/resnet_v115/conv51/conv2d/kernel
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg_1
v/cg/resnet_v112/conv42/batchnorm42/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv2/batchnorm2/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv3/batchnorm3/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_54_grad/mul
1608143244705737	0.00390625
1608143244761805	-0.00390625
v/cg/resnet_v18/conv30/batchnorm30/moving_variance
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244780439	8.000244140625
1608143244780446	9.000244140625
1608143244780474	9.00048828125
1608143244780494	72.0
1608143244780592	-8.000244140625
1608143244780595	-72.0
1608143244780596	-9.000244140625
1608143244781111	-9.00048828125
v/cg/resnet_v112/conv42/batchnorm42/gamma/read
tower_0/v/gradients/AddN_24
v/cg/resnet_v11/conv5/conv2d/kernel
v/cg/resnet_v18/conv28/conv2d/kernel/read
v/cg/resnet_v10/conv2/batchnorm2/moving_mean
v/cg/resnet_v12/conv8/batchnorm8/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv52/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg/mul
v/cg/resnet_v16/conv23/batchnorm23/moving_mean
v/cg/resnet_v19/conv31/batchnorm31/beta
tower_0/v/gradients/AddN_17
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv40/batchnorm40/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg_1/sub_1
v/cg/resnet_v113/conv46/batchnorm46/gamma
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg_1/sub_1
v/cg/resnet_v13/conv11/conv2d/kernel
tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D
1608143244720489	24.5
1608143244720495	0.25
1608143244720553	0.004638671875
1608143244720627	-0.004638671875
1608143244720631	-0.25
1608143244834289	-24.5
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244873325	0.0625
1608143244873331	0.0625
1608143244873345	0.0029296875
1608143244874244	-0.0029296875
1608143244874247	-0.0625
1608143244876918	-0.0625
v/cg/resnet_v110/conv34/conv2d/kernel/read
learning_rate/PiecewiseConstant/Greater_3
1608143244696294	0.000244140625
1608143244707215	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/batchnorm11/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244844237	98.0009765625
1608143244844237	0.001953125
1608143244844238	0.001953125
1608143244844239	0.000244140625
1608143244844257	0.000244140625
1608143244844932	-0.000244140625
1608143244844932	-0.000244140625
1608143244846179	-98.0009765625
1608143244846221	-0.001953125
1608143244846293	-0.001953125
tower_0/v/cg/spatial_mean0/reduction_indices
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg_1/sub_1
v/cg/resnet_v10/conv3/batchnorm3/moving_mean/read
v/cg/resnet_v14/conv15/batchnorm15/moving_mean
tower_0/v/gradients/AddN_53
v/cg/resnet_v15/conv18/batchnorm18/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244834349	98.0
1608143244834355	0.25
1608143244834383	98.0
1608143244834397	0.006591796875
1608143244835249	-98.0
1608143244835251	-0.006591796875
1608143244835253	-0.25
1608143244836394	-98.0
v/cg/resnet_v18/conv29/batchnorm29/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv18/batchnorm18/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/batchnorm14/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244844953	98.0
1608143244844954	0.00244140625
1608143244844955	0.001953125
1608143244844955	0.000244140625
1608143244844991	0.000244140625
1608143244845152	-0.000244140625
1608143244845153	-0.000244140625
1608143244848326	-98.0
1608143244848374	-0.00244140625
1608143244848411	-0.001953125
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244859432	0.062744140625
1608143244859438	0.0625
1608143244859452	0.0029296875
1608143244861123	-0.0029296875
1608143244861126	-0.0625
1608143244861326	-0.062744140625
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/l2_loss/L2Loss_16
1608143244703586	0.000244140625
1608143244703588	0.000244140625
1608143244703637	-0.000244140625
1608143244706863	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/batchnorm28/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244807115	12.25
1608143244807115	0.0009765625
1608143244807116	0.001220703125
1608143244807116	0.000244140625
1608143244807138	0.000244140625
1608143244807219	-0.000244140625
1608143244807219	-0.000244140625
1608143244808475	-12.25
1608143244808523	-0.0009765625
1608143244808580	-0.001220703125
tower_0/v/cg/resnet_v14/conv15/batchnorm15/FusedBatchNormV3
1608143244718824	24.5
1608143244718825	0.00048828125
1608143244718826	0.00048828125
1608143244718827	0.00048828125
1608143244718828	0.00048828125
1608143244719537	-0.00048828125
1608143244719582	-0.00048828125
1608143244841429	-24.5
1608143244841880	-0.00048828125
1608143244841881	-0.00048828125
v/cg/resnet_v11/conv6/batchnorm6/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244861585	0.0625
1608143244861591	0.0625
1608143244861605	0.0029296875
1608143244863499	-0.0029296875
1608143244863501	-0.0625
1608143244864235	-0.0625
v/cg/resnet_v115/conv50/batchnorm50/beta
v/cg/resnet_v13/conv11/batchnorm11/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/batchnorm5/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244869899	49.0
1608143244869899	0.000244140625
1608143244869900	0.000244140625
1608143244869901	0.000244140625
1608143244869927	0.000244140625
1608143244869998	-0.000244140625
1608143244869998	-0.000244140625
1608143244871936	-49.0
1608143244871972	-0.000244140625
1608143244872004	-0.000244140625
v/cg/resnet_v17/conv27/batchnorm27/moving_variance/read
v/cg/resnet_v17/conv27/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_19_grad/mul
1608143244703530	0.5625
1608143244833839	-0.5625
v/cg/resnet_v10/conv1/batchnorm1/moving_variance
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/batchnorm27/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244809680	49.0
1608143244809681	0.00390625
1608143244809682	0.00390625
1608143244809682	0.000244140625
1608143244810217	0.000244140625
1608143244810379	-0.000244140625
1608143244810380	-0.000244140625
1608143244813215	-49.0
1608143244813257	-0.00390625
1608143244813298	-0.00390625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_4_grad/mul
1608143244704925	0.0625
1608143244876403	-0.0625
v/cg/resnet_v113/conv44/conv2d/kernel
tower_0/v/gradients/AddN_21
v/cg/resnet_v13/conv14/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244797125	12.25
1608143244797132	1.0
1608143244797161	19.501953125
1608143244797185	0.00341796875
1608143244797261	-12.25
1608143244797264	-0.00341796875
1608143244797265	-1.0
1608143244797723	-19.501953125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv34/batchnorm34/gamma/ApplyGradientDescent
tower_0/v/gradients/AddN_32
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/batchnorm51/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244763769	6.125
1608143244763770	0.001953125
1608143244763771	0.001953125
1608143244763772	0.000244140625
1608143244763953	0.000244140625
1608143244764036	-0.000244140625
1608143244764037	-0.000244140625
1608143244765490	-6.125
1608143244765549	-0.001953125
1608143244765587	-0.001953125
v/cg/resnet_v111/conv37/batchnorm37/gamma
v/cg/conv0/batchnorm0/beta/read
learning_rate/Const_7
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv32/batchnorm32/beta/ApplyGradientDescent
v/cg/resnet_v111/conv37/batchnorm37/gamma/read
tower_0/v/l2_loss/L2Loss_50
1608143244702133	0.000244140625
1608143244702147	0.0087890625
1608143244702204	-0.0087890625
1608143244706893	-0.000244140625
train_ops_group/NoOp_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/conv0/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/Relu_grad/ReluGrad
v/cg/resnet_v19/conv31/batchnorm31/moving_variance/read
learning_rate/Less
1608143244692611	0.000244140625
1608143244692703	-0.000244140625
edge_655_learning_rate/PiecewiseConstant/Greater@@MemcpyDtoH
learning_rate/PiecewiseConstant/and_1
v/cg/resnet_v12/conv8/batchnorm8/beta/read
v/cg/resnet_v110/conv35/batchnorm35/gamma
tower_0/v/l2_loss/L2Loss_8
1608143244703839	0.000244140625
1608143244703841	0.000244140625
1608143244703894	-0.000244140625
1608143244706899	-0.000244140625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_12_grad/mul
1608143244705042	0.125
1608143244853743	-0.125
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_20_grad/mul
1608143244702990	0.25
1608143244831668	-0.25
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv32/batchnorm32/gamma/ApplyGradientDescent
v/cg/resnet_v112/conv40/batchnorm40/beta
tower_0/v/cg/resnet_v11/add
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv46/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v18/conv30/batchnorm30/beta
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v19/conv31/batchnorm31/FusedBatchNormV3
1608143244728927	12.25
1608143244728928	0.0009765625
1608143244728929	0.0009765625
1608143244728930	0.0009765625
1608143244728931	0.0009765625
1608143244729578	-0.0009765625
1608143244729620	-0.0009765625
1608143244799384	-12.25
1608143244800541	-0.0009765625
1608143244800541	-0.0009765625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v13/conv13/batchnorm13/moving_variance
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg_1/sub_1
tower_0/v/l2_loss/L2Loss_5
1608143244704462	0.000244140625
1608143244704465	0.000244140625
1608143244704514	-0.000244140625
1608143244706892	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/batchnorm6/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244863847	49.0
1608143244863848	0.000244140625
1608143244863848	0.000244140625
1608143244863849	0.000244140625
1608143244863868	0.000244140625
1608143244864192	-0.000244140625
1608143244864192	-0.000244140625
1608143244867943	-49.0
1608143244867984	-0.000244140625
1608143244868014	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v13/conv12/batchnorm12/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv10/batchnorm10/gamma/ApplyGradientDescent
v/cg/resnet_v115/conv51/batchnorm51/moving_mean
v/cg/resnet_v10/conv1/batchnorm1/moving_mean/read
tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D
1608143244726010	49.0
1608143244726017	1.0
1608143244726072	0.001220703125
1608143244726148	-0.001220703125
1608143244726152	-1.0
1608143244810377	-49.0
tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D
1608143244729754	49.0
1608143244729759	1.0
1608143244729805	0.001220703125
1608143244729873	-0.001220703125
1608143244729877	-1.0
1608143244797103	-49.0
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v11/Relu_grad/ReluGrad
v/cg/resnet_v10/conv2/batchnorm2/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg/sub_1
v/cg/affine0/biases
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244864788	0.25
1608143244864794	0.140625
1608143244864808	0.00537109375
1608143244867934	-0.00537109375
1608143244867936	-0.140625
1608143244870040	-0.25
tower_0/v/gradients/tower_0/v/cg/resnet_v112/Relu_grad/ReluGrad
v/cg/resnet_v113/conv43/batchnorm43/moving_mean
tower_0/v/cg/resnet_v10/conv2/batchnorm2/FusedBatchNormV3
1608143244708800	49.0
1608143244708807	0.000244140625
1608143244708808	0.000244140625
1608143244708809	0.000244140625
1608143244708810	0.000244140625
1608143244710238	-0.000244140625
1608143244710280	-0.000244140625
1608143244880226	-49.0
1608143244880358	-0.000244140625
1608143244880358	-0.000244140625
learning_rate/Cast_4
1608143244692859	0.000244140625
1608143244884350	-0.000244140625
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv30/batchnorm30/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv34/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/AddN_51
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg
v/cg/resnet_v15/conv18/conv2d/kernel
edge_659_learning_rate/PiecewiseConstant/and@@MemcpyDtoH
tower_0/v/gradients/AddN_2
tower_0/v/gradients/AddN_33
learning_rate/PiecewiseConstant/case/LessEqual
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/batchnorm8/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244859072	49.0
1608143244859073	0.000244140625
1608143244859073	0.000244140625
1608143244859074	0.000244140625
1608143244859092	0.000244140625
1608143244859163	-0.000244140625
1608143244859163	-0.000244140625
1608143244861133	-49.0
1608143244861173	-0.000244140625
1608143244861201	-0.000244140625
v/cg/resnet_v19/conv31/batchnorm31/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/batchnorm18/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244833853	24.5
1608143244833854	0.00048828125
1608143244833854	0.000732421875
1608143244833855	0.000244140625
1608143244834206	0.000244140625
1608143244834291	-0.000244140625
1608143244834292	-0.000244140625
1608143244836250	-24.5
1608143244836313	-0.00048828125
1608143244836345	-0.000732421875
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv6/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/AddN_47
v/cg/resnet_v16/conv22/batchnorm22/beta
v/cg/resnet_v11/conv5/batchnorm5/beta
v/cg/resnet_v110/conv36/batchnorm36/moving_mean
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg_1
v/cg/resnet_v10/conv4/conv2d/kernel/read
tower_0/v/l2_loss/L2Loss_32
1608143244699202	0.000244140625
1608143244699216	0.0087890625
1608143244699274	-0.0087890625
1608143244706878	-0.000244140625
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg_1/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244797789	19.501953125
1608143244797795	4.0
1608143244797821	12.25
1608143244797837	81.0
1608143244798077	-19.501953125
1608143244798080	-81.0
1608143244798082	-4.0
1608143244800538	-12.25
v/cg/resnet_v110/conv36/conv2d/kernel/read
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/xentropy/xentropy
1608143244759117	0.000244140625
1608143244759119	0.000244140625
1608143244761250	-0.000244140625
1608143244761380	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/Relu_grad/ReluGrad
v/cg/resnet_v10/conv4/batchnorm4/moving_variance/read
v/cg/resnet_v111/conv38/batchnorm38/gamma
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv28/batchnorm28/beta/ApplyGradientDescent
v/cg/resnet_v15/conv20/batchnorm20/beta
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg_1
learning_rate/cond/Switch_2
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_42_grad/mul
1608143244699149	1.0
1608143244782338	-1.0
append_apply_gradient_ops/GradientDescent/update_v/cg/conv0/batchnorm0/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v111/conv38/Relu
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/l2_loss/L2Loss_53
1608143244704584	0.000244140625
1608143244704598	0.0087890625
1608143244704669	-0.0087890625
1608143244706896	-0.000244140625
v/cg/resnet_v115/conv51/batchnorm51/gamma
tower_0/v/gradients/AddN_31
v/cg/resnet_v10/conv3/batchnorm3/beta
v/cg/resnet_v12/conv10/conv2d/kernel/read
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg_1/mul
learning_rate/cond/Merge
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244810398	98.0
1608143244810405	2.25
1608143244810623	98.0
1608143244810720	-98.0
1608143244810722	-2.25
1608143244845148	-98.0
v/cg/resnet_v10/conv4/batchnorm4/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv38/conv2d/kernel/ApplyGradientDescent
learning_rate/Const_5
tower_0/v/cg/resnet_v11/conv6/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv45/batchnorm45/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_53_grad/mul
1608143244704689	7.8203125
1608143244761860	-7.8203125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv5/conv2d/kernel/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_1
1608143244703967	0.000244140625
1608143244703969	0.000244140625
1608143244704017	-0.000244140625
1608143244706857	-0.000244140625
v/cg/resnet_v112/conv42/batchnorm42/beta
v/cg/resnet_v19/conv33/batchnorm33/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v12/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg/sub_1
tower_0/v/resnet50_synthetic_labels
1608143244697111	0.000244140625
1608143244761260	-0.000244140625
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg_1
tower_0/v/cg/resnet_v10/conv1/batchnorm1/FusedBatchNormV3
1608143244708943	196.0
1608143244708944	0.0009765625
1608143244708945	0.0009765625
1608143244708946	0.0009765625
1608143244708947	0.0009765625
1608143244710325	-0.0009765625
1608143244710371	-0.0009765625
1608143244872117	-196.0
1608143244872295	-0.0009765625
1608143244872296	-0.0009765625
v/cg/resnet_v10/conv1/batchnorm1/beta/read
v/cg/resnet_v115/conv51/batchnorm51/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/batchnorm16/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244838719	24.501953125
1608143244838720	0.00048828125
1608143244838720	0.00048828125
1608143244838721	0.000244140625
1608143244838745	0.000244140625
1608143244838820	-0.000244140625
1608143244838820	-0.000244140625
1608143244841079	-24.501953125
1608143244841359	-0.00048828125
1608143244841394	-0.00048828125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/Conv2DBackpropInput
1608143244851807	196.0
1608143244851812	0.125
1608143244851839	245.0078125
1608143244852572	-196.0
1608143244852574	-0.125
1608143244853713	-245.0078125
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244831394	0.25
1608143244831407	0.25048828125
1608143244831421	0.00244140625
1608143244831522	-0.00244140625
1608143244831524	-0.25048828125
1608143244831821	-0.25
v/cg/resnet_v15/conv20/batchnorm20/moving_mean/read
v/cg/resnet_v110/conv34/batchnorm34/gamma/read
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv2/conv2d/kernel/ApplyGradientDescent
v/cg/conv0/batchnorm0/moving_variance
v/cg/resnet_v112/conv40/batchnorm40/beta/read
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/Sum
1608143244761340	0.000244140625
1608143244761903	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/batchnorm31/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608143244799431	12.25
1608143244799431	0.0009765625
1608143244799432	0.001220703125
1608143244799432	0.000244140625
1608143244800417	0.000244140625
1608143244800543	-0.000244140625
1608143244800543	-0.000244140625
1608143244800983	-12.25
1608143244801034	-0.0009765625
1608143244801675	-0.001220703125
v/cg/resnet_v13/conv13/conv2d/kernel/read
tower_0/v/cg/resnet_v10/conv4/batchnorm4/FusedBatchNormV3
1608143244710815	196.0
1608143244710818	0.0009765625
1608143244710822	0.0009765625
1608143244710823	0.0009765625
1608143244710824	0.0009765625
1608143244711099	-196.0
1608143244711595	-0.0009765625
1608143244711631	-0.0009765625
1608143244872459	-0.0009765625
1608143244872459	-0.0009765625
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg_1/sub_1
tower_0/v/gradients/AddN_52
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_21_grad/mul
1608143244705155	0.25
1608143244831042	-0.25
v/cg/resnet_v111/conv39/batchnorm39/moving_variance
v/cg/resnet_v113/conv45/batchnorm45/beta
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg
v/cg/resnet_v14/conv15/batchnorm15/moving_mean/read
v/cg/resnet_v114/conv47/batchnorm47/moving_mean
v/cg/resnet_v15/conv18/batchnorm18/moving_mean
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg_1
v/cg/resnet_v10/conv3/batchnorm3/gamma
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg_1
v/cg/resnet_v111/conv37/batchnorm37/moving_mean
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg/mul
v/cg/resnet_v10/conv4/batchnorm4/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/Relu_grad/ReluGrad
v/cg/resnet_v19/conv33/conv2d/kernel
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_41_grad/mul
1608143244701616	2.25
1608143244785689	-2.25
v/cg/resnet_v19/conv32/batchnorm32/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv6/batchnorm6/gamma/ApplyGradientDescent
v/cg/resnet_v19/conv33/batchnorm33/gamma/read
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg/mul
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg_1
learning_rate/PiecewiseConstant/LessEqual_3
1608143244692811	0.000244140625
1608143244703271	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v114/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608143244772224	7.820556640625
1608143244772232	4.0
1608143244772250	0.00439453125
1608143244773111	-0.00439453125
1608143244773113	-4.0
1608143244778782	-7.820556640625
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg_1
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg/mul
v/cg/resnet_v113/conv44/batchnorm44/moving_mean/read
v/cg/resnet_v112/conv42/conv2d/kernel
tower_0/v/cg/resnet_v16/conv21/batchnorm21/FusedBatchNormV3
1608143244722694	24.5
1608143244722695	0.00048828125
1608143244722696	0.00048828125
1608143244722697	0.00048828125
1608143244722698	0.00048828125
1608143244723418	-0.00048828125
1608143244723461	-0.00048828125
1608143244826168	-24.5
1608143244826659	-0.00048828125
1608143244826659	-0.00048828125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv46/batchnorm46/beta/ApplyGradientDescent
v/cg/resnet_v113/conv43/conv2d/kernel/read
