v/cg/resnet_v15/conv18/conv2d/kernel/read
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg_1/mul
v/cg/conv0/batchnorm0/beta/read
v/cg/resnet_v10/conv4/batchnorm4/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv3/conv2d/kernel/ApplyGradientDescent
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/Switch_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv41/batchnorm41/gamma/ApplyGradientDescent
v/cg/resnet_v11/conv6/batchnorm6/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv31/batchnorm31/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg/mul
tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D
1608170648853757	24.5
1608170648853763	0.5625
1608170648853807	112.5
1608170648853916	-112.5
1608170648853920	-0.5625
1608170648956355	-24.5
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv43/batchnorm43/gamma/ApplyGradientDescent
v/cg/resnet_v13/conv12/conv2d/kernel
v/cg/resnet_v19/conv33/conv2d/kernel
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v13/conv13/Relu
v/cg/resnet_v10/conv3/batchnorm3/beta/read
tower_0/v/l2_loss/L2Loss_29
1608170648831222	0.000244140625
1608170648831238	0.0087890625
1608170648831331	-0.0087890625
1608170648837168	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v10/conv3/batchnorm3/FusedBatchNormV3
1608170648840027	49.0
1608170648840028	0.000244140625
1608170648840029	0.000244140625
1608170648840030	0.000244140625
1608170648840031	0.000244140625
1608170648841120	-0.000244140625
1608170648841175	-0.000244140625
1608170649009000	-49.0
1608170649009645	-0.000244140625
1608170649009646	-0.000244140625
tower_0/v/cg/resnet_v14/conv16/Relu
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg
learning_rate/Less
1608170648827886	0.000244140625
1608170648837039	-0.000244140625
v/cg/resnet_v113/conv46/batchnorm46/moving_mean/read
tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D
1608170648845735	196.0
1608170648845743	0.0625
1608170648845791	0.01806640625
1608170648845860	-0.01806640625
1608170648845863	-0.0625
1608170648986449	-196.0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_54_grad/mul
1608170648833688	0.00390625
1608170648892557	-0.00390625
append_apply_gradient_ops/GradientDescent/update_v/cg/conv0/batchnorm0/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg
learning_rate/Cast
v/cg/resnet_v13/conv11/batchnorm11/moving_variance/read
v/cg/resnet_v13/conv14/batchnorm14/beta/read
tower_0/v/l2_loss/L2Loss_9
1608170648834658	0.000244140625
1608170648834660	0.000244140625
1608170648834703	-0.000244140625
1608170648837214	-0.000244140625
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv40/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D
1608170648858625	49.0
1608170648858631	1.0
1608170648858671	0.001953125
1608170648858737	-0.001953125
1608170648858739	-1.0
1608170648933694	-49.0
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg_1/mul
v/cg/resnet_v112/conv41/batchnorm41/moving_mean/read
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/value
v/cg/conv0/batchnorm0/moving_mean/read
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg_1/mul
tower_0/v/l2_loss/L2Loss_2
1608170648833952	0.000244140625
1608170648837147	-0.000244140625
tower_0/v/cg/resnet_v17/conv26/batchnorm26/FusedBatchNormV3
1608170648856574	12.25
1608170648856575	0.0009765625
1608170648856575	0.0009765625
1608170648856576	0.0009765625
1608170648856577	0.0009765625
1608170648857254	-0.0009765625
1608170648857293	-0.0009765625
1608170648945360	-12.25
1608170648945713	-0.0009765625
1608170648945714	-0.0009765625
v/cg/resnet_v11/conv5/batchnorm5/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648954158	0.25
1608170648954164	0.25
1608170648954177	0.00244140625
1608170648955120	-0.00244140625
1608170648955122	-0.25
1608170648956412	-0.25
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648929532	2.25048828125
1608170648929539	2.251220703125
1608170648929554	81.0
1608170648929997	-81.0
1608170648929999	-2.251220703125
1608170648931221	-2.25048828125
ConstantFoldingCtrl/learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Switch_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg_1/mul
v/cg/resnet_v12/conv10/batchnorm10/gamma
v/cg/resnet_v16/conv23/batchnorm23/beta
v/cg/resnet_v113/conv45/batchnorm45/beta/read
tower_0/v/l2_loss/L2Loss_14
1608170648835373	0.000244140625
1608170648835375	0.000244140625
1608170648835421	-0.000244140625
1608170648837138	-0.000244140625
v/cg/resnet_v18/conv28/conv2d/kernel/read
v/cg/resnet_v14/conv16/conv2d/kernel
v/cg/resnet_v114/conv48/batchnorm48/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648914068	4.0
1608170648914075	4.00048828125
1608170648914092	81.0
1608170648914513	-81.0
1608170648914516	-4.00048828125
1608170648916954	-4.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv8/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648910439	49.0
1608170648910445	2.0
1608170648910467	49.0
1608170648910564	-49.0
1608170648910566	-2.0
1608170648911483	-49.0
v/cg/resnet_v112/conv42/batchnorm42/moving_variance/read
v/cg/resnet_v115/conv52/batchnorm52/gamma/read
tower_0/v/gradients/AddN_36
tower_0/v/cg/resnet_v10/conv1/batchnorm1/FusedBatchNormV3
1608170648838836	196.0
1608170648838837	0.0009765625
1608170648838839	0.0009765625
1608170648838840	0.0009765625
1608170648838842	0.0009765625
1608170648840280	-0.0009765625
1608170648840318	-0.0009765625
1608170649004690	-196.0
1608170649004813	-0.0009765625
1608170649004814	-0.0009765625
tower_0/v/cg/resnet_v110/conv34/batchnorm34/FusedBatchNormV3
1608170648861328	12.25
1608170648861329	0.0009765625
1608170648861329	0.0009765625
1608170648861330	0.0009765625
1608170648861331	0.0009765625
1608170648861988	-0.0009765625
1608170648862028	-0.0009765625
1608170648926643	-12.25
1608170648926804	-0.0009765625
1608170648926811	-0.0009765625
v/cg/resnet_v17/conv24/batchnorm24/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv38/batchnorm38/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv33/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/batchnorm38/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648919678	13.000732421875
1608170648919678	0.0009765625
1608170648919679	0.0009765625
1608170648919680	0.000244140625
1608170648919798	0.000244140625
1608170648919881	-0.000244140625
1608170648919882	-0.000244140625
1608170648921097	-13.000732421875
1608170648921138	-0.0009765625
1608170648921179	-0.0009765625
v/cg/resnet_v18/conv29/batchnorm29/gamma
tower_0/v/cg/resnet_v112/conv41/Relu
v/cg/resnet_v114/conv49/batchnorm49/moving_variance/read
tower_0/v/mul
v/cg/resnet_v114/conv48/batchnorm48/moving_variance
tower_0/v/l2_loss/L2Loss_20
1608170648830178	0.000244140625
1608170648830181	0.000244140625
1608170648830243	-0.000244140625
1608170648837161	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648966277	98.0
1608170648966282	0.25
1608170648966302	98.0
1608170648966315	0.006591796875
1608170648966728	-98.0
1608170648966730	-0.006591796875
1608170648966731	-0.25
1608170648968720	-98.0
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/batchnorm7/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648993858	196.0
1608170648993859	0.0009765625
1608170648993859	0.0009765625
1608170648993860	0.000244140625
1608170648993891	0.000244140625
1608170648993966	-0.000244140625
1608170648993966	-0.000244140625
1608170648995177	-196.0
1608170648996103	-0.0009765625
1608170648996134	-0.0009765625
v/cg/resnet_v16/conv21/batchnorm21/beta/read
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D
1608170648844053	49.0
1608170648844059	0.0625
1608170648844110	0.01806640625
1608170648844183	-0.01806640625
1608170648844186	-0.0625
1608170648991752	-49.0
v/cg/resnet_v114/conv47/batchnorm47/gamma
v/cg/resnet_v13/conv14/batchnorm14/gamma/read
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg_1/sub_1
average_loss/Mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv25/batchnorm25/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg_1/sub_1
v/cg/resnet_v16/conv22/batchnorm22/beta
v/cg/resnet_v18/conv28/conv2d/kernel
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv24/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v111/conv38/batchnorm38/moving_mean/read
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_3_grad/mul
1608170648833603	0.140625
1608170649012921	-0.140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv37/batchnorm37/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv24/batchnorm24/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v16/conv23/batchnorm23/gamma
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv50/batchnorm50/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg
v/cg/resnet_v13/conv12/conv2d/kernel/read
v/cg/resnet_v19/conv31/batchnorm31/gamma/read
tower_0/v/l2_loss/L2Loss_40
1608170648835622	0.000244140625
1608170648835624	0.000244140625
1608170648835670	-0.000244140625
1608170648837178	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v111/conv38/batchnorm38/gamma/read
train_ops_group
learning_rate/Const_4
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170649010499	0.140625
1608170649010505	0.140625
1608170649010519	0.00537109375
1608170649011921	-0.00537109375
1608170649011923	-0.140625
1608170649013070	-0.140625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_34_grad/mul
1608170648835791	1.0
1608170648928271	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648898848	7.82080078125
1608170648898854	4.00048828125
1608170648898880	9.00048828125
1608170648898895	0.00390625
1608170648899030	-7.82080078125
1608170648899032	-0.00390625
1608170648899033	-4.00048828125
1608170648900860	-9.00048828125
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648951558	98.0
1608170648951563	0.5
1608170648951584	134.765625
1608170648951680	-98.0
1608170648951682	-0.5
1608170648953723	-134.765625
v/cg/resnet_v110/conv34/batchnorm34/beta
v/cg/resnet_v114/conv47/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648927905	1.0
1608170648927912	1.0
1608170648927926	0.0029296875
1608170648928080	-0.0029296875
1608170648928082	-1.0
1608170648928408	-1.0
v/cg/resnet_v11/conv5/conv2d/kernel
tower_0/v/l2_loss/L2Loss_50
1608170648833829	0.000244140625
1608170648833840	0.0087890625
1608170648833892	-0.0087890625
1608170648837204	-0.000244140625
tower_0/v/cg/resnet_v10/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv14/batchnorm14/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg/mul
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg_1
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg_1
tower_0/v/cg/resnet_v10/add
v/cg/resnet_v113/conv46/batchnorm46/beta
tower_0/v/gradients/AddN_27
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv18/batchnorm18/gamma/ApplyGradientDescent
learning_rate/PiecewiseConstant/case/cond/pred_id
tower_0/v/cg/resnet_v15/conv20/batchnorm20/FusedBatchNormV3
1608170648852749	98.0
1608170648852750	0.001953125
1608170648852751	0.001953125
1608170648852753	0.001953125
1608170648852754	0.001953125
1608170648853433	-0.001953125
1608170648853476	-0.001953125
1608170648961175	-98.0
1608170648961306	-0.001953125
1608170648961306	-0.001953125
v/cg/resnet_v17/conv24/batchnorm24/moving_variance
v/cg/resnet_v17/conv26/batchnorm26/beta/read
tower_0/v/gradients/AddN_47
tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D
1608170648854462	98.0
1608170648854468	0.25
1608170648854511	0.004638671875
1608170648854580	-0.004638671875
1608170648854583	-0.25
1608170648953988	-98.0
tower_0/v/gradients/AddN_19
tower_0/v/l2_loss/L2Loss_23
1608170648830693	0.000244140625
1608170648830695	0.000244140625
1608170648830763	-0.000244140625
1608170648837164	-0.000244140625
v/cg/resnet_v16/conv22/batchnorm22/beta/read
v/cg/resnet_v14/conv15/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv26/batchnorm26/beta/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v114/conv49/batchnorm49/FusedBatchNormV3
1608170648881805	24.5
1608170648881806	0.0078125
1608170648881809	0.0078125
1608170648881811	0.0078125
1608170648881812	0.0078125
1608170648884220	-0.0078125
1608170648884258	-0.0078125
1608170648898477	-24.5
1608170648898821	-0.0078125
1608170648898821	-0.0078125
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_19_grad/mul
1608170648831952	0.5625
1608170648965702	-0.5625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/Relu_grad/ReluGrad
v/cg/resnet_v110/conv36/batchnorm36/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v115/Relu_grad/ReluGrad
v/cg/resnet_v13/conv14/conv2d/kernel
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg
v/cg/resnet_v17/conv25/batchnorm25/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648929310	12.25
1608170648929315	2.25048828125
1608170648929337	14.0009765625
1608170648929350	182.25
1608170648929494	-12.25
1608170648929496	-182.25
1608170648929497	-2.25048828125
1608170648931157	-14.0009765625
v/cg/resnet_v113/conv46/batchnorm46/gamma/read
v/cg/resnet_v110/conv36/batchnorm36/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv15/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648902892	4.00048828125
1608170648902899	4.00048828125
1608170648902914	0.00390625
1608170648903768	-0.00390625
1608170648903770	-4.00048828125
1608170648908319	-4.00048828125
v/cg/resnet_v13/conv12/batchnorm12/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/l2_loss/L2Loss
1608170648833728	0.000244140625
1608170648833729	0.000244140625
1608170648833774	-0.000244140625
1608170648930087	-0.000244140625
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg_1/mul
v/cg/resnet_v19/conv32/batchnorm32/moving_mean
learning_rate/PiecewiseConstant/case/preds_c
1608170648825208	0.000244140625
1608170648825667	-0.000244140625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_10_grad/mul
1608170648834358	0.0625
1608170648988861	-0.0625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_21_grad/mul
1608170648832190	0.25
1608170648961141	-0.25
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170649004961	62.7001953125
1608170649004966	0.0625
1608170649004990	49.0
1608170649005002	0.020263671875
1608170649005793	-62.7001953125
1608170649005795	-0.020263671875
1608170649005796	-0.0625
1608170649015483	-49.0
learning_rate/cond/Merge
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_28_grad/mul
1608170648831149	1.0
1608170648940338	-1.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv35/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v115/conv51/Relu
tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D
1608170648862168	49.0
1608170648862172	1.0
1608170648862219	0.001220703125
1608170648862289	-0.001220703125
1608170648862292	-1.0
1608170648923647	-49.0
tower_0/v/gradients/AddN_32
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv31/batchnorm31/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_30_grad/mul
1608170648830619	1.0
1608170648935080	-1.0
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v19/Relu_grad/ReluGrad
v/cg/resnet_v14/conv16/batchnorm16/moving_variance
learning_rate/PiecewiseConstant/Greater
1608170648824647	0.000244140625
1608170648825397	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv36/batchnorm36/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv51/batchnorm51/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v112/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv15/batchnorm15/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg
v/cg/resnet_v17/conv25/batchnorm25/moving_mean/read
tower_0/v/cg/resnet_v12/conv8/Relu
v/cg/resnet_v13/conv13/conv2d/kernel
tower_0/v/cg/resnet_v19/add
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648917279	1.0
1608170648917286	1.0
1608170648917302	0.00390625
1608170648917421	-0.00390625
1608170648917423	-1.0
1608170648918444	-1.0
learning_rate/PiecewiseConstant/case/cond/cond/cond/Switch_1
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv10/batchnorm10/gamma/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_1
1608170648834410	0.000244140625
1608170648834412	0.000244140625
1608170648834460	-0.000244140625
1608170648837119	-0.000244140625
tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D
1608170648861074	12.25
1608170648861079	1.0
1608170648861126	0.001953125
1608170648861189	-0.001953125
1608170648861191	-1.0
1608170648926803	-12.25
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648984204	196.0
1608170648984210	0.125
1608170648984230	269.5078125
1608170648984443	-196.0
1608170648984445	-0.125
1608170648986226	-269.5078125
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg_1
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv3/batchnorm3/beta/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/truediv_recip
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648942735	14.0009765625
1608170648942741	1.0
1608170648942766	12.25
1608170648942779	0.00439453125
1608170648942901	-14.0009765625
1608170648942903	-0.00439453125
1608170648942903	-1.0
1608170648945709	-12.25
tower_0/v/gradients/AddN_56
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/l2_loss/L2Loss_38
1608170648832697	0.000244140625
1608170648832717	0.0087890625
1608170648832787	-0.0087890625
1608170648837176	-0.000244140625
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg_1
v/cg/resnet_v15/conv19/batchnorm19/moving_variance
tower_0/v/gradients/AddN_2
tower_0/v/gradients/AddN_13
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv14/batchnorm14/beta/ApplyGradientDescent
v/cg/resnet_v110/conv36/batchnorm36/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv4/batchnorm4/gamma/ApplyGradientDescent
tower_0/v/resnet50_synthetic_labels/shape
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648956430	24.5
1608170648956437	1.0
1608170648956458	24.5
1608170648956471	112.5
1608170648956550	-24.5
1608170648956552	-112.5
1608170648956553	-1.0
1608170648958143	-24.5
v/cg/resnet_v10/conv3/batchnorm3/moving_variance/read
v/cg/resnet_v11/conv5/batchnorm5/gamma/read
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg_1/sub_1
edge_655_learning_rate/PiecewiseConstant/Greater@@MemcpyDtoH
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg_1
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg_1/sub_1
v/cg/resnet_v14/conv15/batchnorm15/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v16/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648971321	0.5625
1608170648971327	1.0
1608170648971339	112.5
1608170648973263	-112.5
1608170648973265	-1.0
1608170648974010	-0.5625
v/cg/resnet_v16/conv21/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/Relu_grad/ReluGrad
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg_1/sub_1
v/cg/resnet_v15/conv18/conv2d/kernel
v/cg/affine0/biases
tower_0/v/cg/resnet_v114/conv47/batchnorm47/FusedBatchNormV3
1608170648878453	6.125
1608170648878454	0.001953125
1608170648878455	0.001953125
1608170648878456	0.001953125
1608170648878457	0.001953125
1608170648880629	-0.001953125
1608170648880748	-0.001953125
1608170648902096	-6.125
1608170648902618	-0.001953125
1608170648902619	-0.001953125
v/cg/resnet_v18/conv28/batchnorm28/moving_variance
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/num_present
v/cg/resnet_v17/conv27/batchnorm27/moving_mean
v/cg/resnet_v12/conv8/batchnorm8/moving_mean/read
tower_0/v/l2_loss/L2Loss_34
1608170648835730	0.000244140625
1608170648835732	0.000244140625
1608170648835775	-0.000244140625
1608170648837173	-0.000244140625
_SOURCE
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg
tower_0/v/cg/spatial_mean0
1608170648889391	0.5
1608170648892426	-0.5
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_47_grad/mul
1608170648829628	4.0
1608170648903978	-4.0
tower_0/v/cg/resnet_v110/Relu
v/cg/resnet_v17/conv25/conv2d/kernel
learning_rate/PiecewiseConstant/LessEqual
1608170648823477	0.000244140625
1608170648825395	-0.000244140625
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg_1/sub_1
v/cg/resnet_v113/conv45/batchnorm45/moving_mean/read
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/average_loss/Mean/input_const_axis
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg
v/cg/resnet_v110/conv35/batchnorm35/moving_mean
v/cg/resnet_v16/conv21/conv2d/kernel
v/cg/resnet_v13/conv11/batchnorm11/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/AddN_64
v/cg/resnet_v115/conv51/conv2d/kernel
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/conv0/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v110/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648923685	13.000732421875
1608170648923690	1.0
1608170648923754	12.25
1608170648923776	0.00341796875
1608170648923930	-13.000732421875
1608170648923932	-0.00341796875
1608170648923933	-1.0
1608170648925250	-12.25
tower_0/v/gradients/AddN_8
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_33_grad/mul
1608170648836208	1.0
1608170648929140	-1.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/affine0/xw_plus_b/MatMul_grad/MatMul
1608170648892299	0.5
1608170648892769	-0.5
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v11/conv5/batchnorm5/gamma
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v19/conv31/batchnorm31/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/batchnorm51/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648894638	6.125
1608170648894639	0.001953125
1608170648894640	0.001953125
1608170648894640	0.000244140625
1608170648894664	0.000244140625
1608170648894931	-0.000244140625
1608170648894931	-0.000244140625
1608170648896164	-6.125
1608170648896213	-0.001953125
1608170648896250	-0.001953125
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/batchnorm40/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648915054	12.25
1608170648915055	0.0009765625
1608170648915055	0.0009765625
1608170648915056	0.000244140625
1608170648915141	0.000244140625
1608170648915222	-0.000244140625
1608170648915223	-0.000244140625
1608170648917431	-12.25
1608170648917475	-0.0009765625
1608170648917543	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv48/batchnorm48/gamma/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_47
1608170648829486	0.000244140625
1608170648829503	0.0087890625
1608170648829578	-0.0087890625
1608170648837184	-0.000244140625
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg_1
v/cg/resnet_v13/conv14/batchnorm14/gamma
v/cg/resnet_v113/conv46/conv2d/kernel/read
v/cg/resnet_v112/conv42/conv2d/kernel/read
v/cg/resnet_v111/conv37/batchnorm37/moving_mean/read
tower_0/v/cg/resnet_v110/conv34/Relu
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg/mul
v/cg/resnet_v19/conv31/batchnorm31/gamma
v/cg/resnet_v10/conv3/batchnorm3/moving_mean
tower_0/v/cg/affine0/xw_plus_b
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv9/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg/mul
tower_0/v/l2_loss/L2Loss_27
1608170648831696	0.000244140625
1608170648831700	0.000244140625
1608170648831776	-0.000244140625
1608170648837167	-0.000244140625
tower_0/v/l2_loss/L2Loss_43
1608170648836390	0.000244140625
1608170648836401	0.0087890625
1608170648836458	-0.0087890625
1608170648837181	-0.000244140625
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg_1
edge_274_global_step/read@@MemcpyHtoD
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v115/conv51/batchnorm51/moving_variance/read
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D
1608170648851250	24.5
1608170648851256	0.25
1608170648851302	0.004638671875
1608170648851371	-0.004638671875
1608170648851374	-0.25
1608170648966014	-24.5
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648909268	4.00048828125
1608170648909275	4.00048828125
1608170648909289	0.00390625
1608170648909393	-0.00390625
1608170648909395	-4.00048828125
1608170648909777	-4.00048828125
v/cg/resnet_v111/conv38/conv2d/kernel/read
v/cg/resnet_v15/conv20/batchnorm20/moving_mean/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v13/conv14/batchnorm14/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv30/batchnorm30/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v111/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg_1/mul
learning_rate/Const_6
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_51_grad/mul
1608170648834122	9.0
1608170648896320	-9.0
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg
tower_0/v/gradients/AddN_10
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v110/conv36/batchnorm36/moving_mean
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/conv0/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv17/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v16/conv22/batchnorm22/moving_variance
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D
1608170648872002	6.125
1608170648872007	9.0
1608170648872697	72.0
1608170648873325	-72.0
1608170648873328	-9.0
1608170648909725	-6.125
tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D
1608170648859780	12.25
1608170648859785	2.25
1608170648859830	81.0
1608170648859928	-81.0
1608170648859931	-2.25
1608170648929251	-12.25
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg_1/mul
v/cg/resnet_v16/conv21/batchnorm21/gamma
v/cg/resnet_v11/conv5/batchnorm5/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648921441	49.0
1608170648921450	1.0
1608170648921473	49.0
1608170648921487	0.004150390625
1608170648922323	-49.0
1608170648922325	-0.004150390625
1608170648922326	-1.0
1608170648922623	-49.0
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648899059	4.00048828125
1608170648899066	7.82080078125
1608170648899081	0.00390625
1608170648899992	-0.00390625
1608170648899994	-7.82080078125
1608170648900970	-4.00048828125
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg_1/sub_1
v/cg/resnet_v11/conv6/batchnorm6/moving_variance/read
tower_0/v/gradients/AddN_24
tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D
1608170648844666	49.0
1608170648844672	0.140625
1608170648844732	85.046875
1608170648845135	-85.046875
1608170648845138	-0.140625
1608170648989223	-49.0
v/cg/resnet_v114/conv49/conv2d/kernel/read
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv19/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v17/conv24/batchnorm24/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv5/batchnorm5/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v113/conv44/batchnorm44/FusedBatchNormV3
1608170648871592	6.125
1608170648871593	0.001953125
1608170648871594	0.001953125
1608170648871595	0.001953125
1608170648871595	0.001953125
1608170648874469	-0.001953125
1608170648874505	-0.001953125
1608170648910208	-6.125
1608170648910381	-0.001953125
1608170648910382	-0.001953125
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_50_grad/mul
1608170648833908	4.0
1608170648898261	-4.0
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/batchnorm28/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648937792	12.25
1608170648937793	0.0009765625
1608170648937794	0.0009765625
1608170648937794	0.000244140625
1608170648937928	0.000244140625
1608170648938041	-0.000244140625
1608170648938041	-0.000244140625
1608170648940194	-12.25
1608170648940236	-0.0009765625
1608170648940268	-0.0009765625
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/batchnorm41/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648912895	12.25
1608170648912896	0.0009765625
1608170648912896	0.0009765625
1608170648912897	0.000244140625
1608170648912921	0.000244140625
1608170648913710	-0.000244140625
1608170648913711	-0.000244140625
1608170648914529	-12.25
1608170648914575	-0.0009765625
1608170648914614	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv11/batchnorm11/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648938115	49.0
1608170648938120	1.0
1608170648938143	49.0
1608170648938157	0.00341796875
1608170648938979	-49.0
1608170648938981	-0.00341796875
1608170648938982	-1.0
1608170648940304	-49.0
v/cg/resnet_v113/conv43/batchnorm43/moving_variance/read
v/cg/resnet_v16/conv21/batchnorm21/moving_mean/read
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg_1/sub_1
v/cg/resnet_v18/conv29/conv2d/kernel/read
v/cg/resnet_v16/conv23/batchnorm23/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v18/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v17/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648981502	24.505859375
1608170648981507	0.5625
1608170648981532	24.5
1608170648981545	122.5
1608170648981971	-24.505859375
1608170648981972	-122.5
1608170648981973	-0.5625
1608170648984145	-24.5
v/cg/resnet_v12/conv10/batchnorm10/moving_mean/read
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/batchnorm43/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648908333	24.5
1608170648908335	0.0078125
1608170648908336	0.0078125
1608170648908337	0.000244140625
1608170648908358	0.000244140625
1608170648908460	-0.000244140625
1608170648908461	-0.000244140625
1608170648909026	-24.5
1608170648909071	-0.0078125
1608170648909109	-0.0078125
v/cg/resnet_v112/conv40/conv2d/kernel/read
v/cg/resnet_v18/conv28/batchnorm28/gamma/read
tower_0/v/cg/resnet_v18/conv29/Relu
v/cg/resnet_v19/conv31/conv2d/kernel/read
v/cg/resnet_v13/conv12/batchnorm12/gamma
v/cg/resnet_v18/conv30/batchnorm30/moving_variance/read
v/cg/resnet_v13/conv13/batchnorm13/moving_variance/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv50/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v115/add
v/cg/resnet_v112/conv41/conv2d/kernel
v/cg/resnet_v17/conv27/batchnorm27/moving_mean/read
v/cg/resnet_v16/conv21/batchnorm21/moving_mean
v/cg/resnet_v112/conv40/conv2d/kernel
append_apply_gradient_ops/GradientDescent/update_v/cg/affine0/biases/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv35/batchnorm35/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv46/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg_1/sub_1
v/cg/resnet_v18/conv29/batchnorm29/moving_mean
tower_0/v/cg/resnet_v111/conv37/batchnorm37/FusedBatchNormV3
1608170648863121	12.25
1608170648863122	0.0009765625
1608170648863123	0.0009765625
1608170648863124	0.0009765625
1608170648863125	0.0009765625
1608170648863816	-0.0009765625
1608170648863858	-0.0009765625
1608170648921214	-12.25
1608170648921368	-0.0009765625
1608170648921368	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv26/batchnorm26/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv26/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/AddN_25
v/cg/resnet_v112/conv41/batchnorm41/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/batchnorm24/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648940438	49.0
1608170648940439	0.00439453125
1608170648940440	0.005859375
1608170648940440	0.000244140625
1608170648940508	0.000244140625
1608170648940664	-0.000244140625
1608170648940665	-0.000244140625
1608170648942617	-49.0
1608170648942663	-0.00439453125
1608170648942720	-0.005859375
v/cg/resnet_v11/conv7/conv2d/kernel
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v11/conv7/batchnorm7/beta/read
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv27/batchnorm27/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg_1
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg/mul
v/cg/resnet_v15/conv20/conv2d/kernel
tower_0/v/cg/resnet_v16/conv22/batchnorm22/FusedBatchNormV3
1608170648854086	24.5
1608170648854087	0.00048828125
1608170648854088	0.00048828125
1608170648854089	0.00048828125
1608170648854090	0.00048828125
1608170648854896	-0.00048828125
1608170648854932	-0.00048828125
1608170648955879	-24.5
1608170648956356	-0.00048828125
1608170648956356	-0.00048828125
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg_1/mul
v/cg/resnet_v12/conv10/batchnorm10/moving_variance
v/cg/resnet_v110/conv34/batchnorm34/moving_mean
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg/mul
v/cg/resnet_v11/conv5/batchnorm5/moving_variance/read
v/cg/resnet_v17/conv26/batchnorm26/moving_variance/read
v/cg/resnet_v114/conv47/batchnorm47/beta
tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D
1608170648853215	24.5
1608170648853221	0.25
1608170648853266	0.004638671875
1608170648853340	-0.004638671875
1608170648853344	-0.25
1608170648958144	-24.5
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_11_grad/mul
1608170648833138	0.5
1608170648980856	-0.5
append_apply_gradient_ops/GradientDescent/update_v/cg/conv0/batchnorm0/gamma/ApplyGradientDescent
v/cg/conv0/batchnorm0/gamma/read
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv15/batchnorm15/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg_1/sub_1
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/cond/Switch/Switch
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/batchnorm9/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648988872	49.0
1608170648988872	0.000244140625
1608170648988873	0.000244140625
1608170648988878	0.000244140625
1608170648988896	0.000244140625
1608170648989227	-0.000244140625
1608170648989227	-0.000244140625
1608170648990658	-49.0
1608170648990699	-0.000244140625
1608170648990732	-0.000244140625
tower_0/v/gradients/AddN_12
tower_0/v/cg/resnet_v19/conv32/batchnorm32/FusedBatchNormV3
1608170648860068	12.25
1608170648860070	0.0009765625
1608170648860070	0.0009765625
1608170648860072	0.0009765625
1608170648860073	0.0009765625
1608170648860789	-0.0009765625
1608170648860830	-0.0009765625
1608170648929104	-12.25
1608170648929252	-0.0009765625
1608170648929253	-0.0009765625
v/cg/resnet_v112/conv40/batchnorm40/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv2/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648925335	12.25
1608170648925342	2.251220703125
1608170648925365	13.000732421875
1608170648925379	182.25
1608170648925543	-12.25
1608170648925545	-182.25
1608170648925546	-2.251220703125
1608170648926802	-13.000732421875
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648918584	12.25
1608170648918590	1.0
1608170648918622	12.25
1608170648918636	0.00341796875
1608170648918707	-12.25
1608170648918710	-0.00341796875
1608170648918711	-1.0
1608170648919877	-12.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv43/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v13/conv14/batchnorm14/FusedBatchNormV3
1608170648848771	98.0
1608170648848772	0.001953125
1608170648848773	0.001953125
1608170648848774	0.001953125
1608170648848775	0.001953125
1608170648849023	-98.0
1608170648849494	-0.001953125
1608170648849534	-0.001953125
1608170648976931	-0.001953125
1608170648976937	-0.001953125
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v10/conv2/batchnorm2/moving_mean/read
v/cg/resnet_v11/conv6/batchnorm6/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v12/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_5_grad/mul
1608170648833026	0.0625
1608170649004659	-0.0625
tower_0/v/gradients/AddN_65
v/cg/resnet_v13/conv12/batchnorm12/beta
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v111/conv37/batchnorm37/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648931265	49.0
1608170648931270	1.0
1608170648932219	49.0
1608170648932233	0.00439453125
1608170648932309	-49.0
1608170648932311	-0.00439453125
1608170648932311	-1.0
1608170648932633	-49.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv47/conv2d/kernel/ApplyGradientDescent
edge_659_learning_rate/PiecewiseConstant/and@@MemcpyDtoH
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv12/batchnorm12/gamma/ApplyGradientDescent
v/cg/resnet_v113/conv46/batchnorm46/beta/read
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg_1/mul
v/cg/resnet_v15/conv18/batchnorm18/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/batchnorm46/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648908479	24.5
1608170648908481	0.0078125
1608170648908482	0.0078125
1608170648908483	0.000244140625
1608170648908506	0.000244140625
1608170648908571	-0.000244140625
1608170648908571	-0.000244140625
1608170648909402	-24.5
1608170648909447	-0.0078125
1608170648909477	-0.0078125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/l2_loss/L2Loss_11
1608170648833073	0.000244140625
1608170648833074	0.000244140625
1608170648833121	-0.000244140625
1608170648837130	-0.000244140625
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg/sub_1
learning_rate/Cast_1
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648919950	12.25
1608170648919955	4.0
1608170648919978	12.25
1608170648919991	182.25
1608170648920108	-12.25
1608170648920110	-182.25
1608170648920111	-4.0
1608170648921365	-12.25
v/cg/resnet_v115/conv52/batchnorm52/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648951708	0.5
1608170648951714	0.5
1608170648951728	0.00439453125
1608170648952525	-0.00439453125
1608170648952526	-0.5
1608170648953822	-0.5
v/cg/resnet_v110/conv35/batchnorm35/moving_mean/read
v/cg/resnet_v10/conv2/batchnorm2/beta/read
tower_0/v/l2_loss/L2Loss_42
1608170648828693	0.000244140625
1608170648828698	0.000244140625
1608170648828789	-0.000244140625
1608170648837181	-0.000244140625
v/cg/resnet_v112/conv40/batchnorm40/moving_variance/read
v/cg/resnet_v110/conv36/batchnorm36/beta
v/cg/resnet_v111/conv39/batchnorm39/moving_mean
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg/mul
v/cg/resnet_v19/conv32/batchnorm32/beta/read
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg
tower_0/v/cg/resnet_v17/conv27/batchnorm27/FusedBatchNormV3
1608170648857133	49.0
1608170648857133	0.005859375
1608170648857134	0.00390625
1608170648857136	0.00390625
1608170648857137	0.00390625
1608170648857336	-49.0
1608170648857734	-0.005859375
1608170648857767	-0.00390625
1608170648941379	-0.00390625
1608170648941380	-0.00390625
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/batchnorm52/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648893191	24.5078125
1608170648893192	0.0078125
1608170648893193	0.0078125
1608170648893193	0.000244140625
1608170648893278	0.000244140625
1608170648893367	-0.000244140625
1608170648893368	-0.000244140625
1608170648893833	-24.5078125
1608170648893878	-0.0078125
1608170648894352	-0.0078125
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_53_grad/mul
1608170648833492	7.8203125
1608170648892606	-7.8203125
v/cg/resnet_v114/conv47/batchnorm47/moving_mean/read
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg_1
tower_0/v/l2_loss/L2Loss_10
1608170648834293	0.000244140625
1608170648834294	0.000244140625
1608170648834339	-0.000244140625
1608170648837121	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_9_grad/mul
1608170648834719	0.140625
1608170648991656	-0.140625
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg_1/mul
v/cg/resnet_v114/conv48/batchnorm48/moving_mean
tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D
1608170648864678	12.25
1608170648864684	1.0
1608170648864725	0.001953125
1608170648864790	-0.001953125
1608170648864792	-1.0
1608170648915220	-12.25
tower_0/v/cg/resnet_v15/conv18/Relu
learning_rate/PiecewiseConstant/case/cond/cond/Switch_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/conv0/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648981997	0.5625
1608170648982004	1.0
1608170648982016	122.5
1608170648983898	-122.5
1608170648983899	-1.0
1608170648984191	-0.5625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv45/batchnorm45/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v114/Relu
tower_0/v/cg/resnet_v15/Relu
tower_0/v/l2_loss/L2Loss_49
1608170648835488	0.000244140625
1608170648835500	0.0087890625
1608170648835555	-0.0087890625
1608170648837186	-0.000244140625
v/cg/resnet_v16/conv21/batchnorm21/beta
v/cg/resnet_v111/conv37/batchnorm37/moving_variance
v/cg/resnet_v114/conv47/conv2d/kernel
v/cg/resnet_v10/conv4/batchnorm4/gamma
tower_0/v/gradients/tower_0/v/cg/mpool0/MaxPool_grad/MaxPoolGrad
1608170649015404	196.0
1608170649015674	-196.0
v/cg/resnet_v113/conv43/batchnorm43/beta
v/cg/affine0/biases/read
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv4/batchnorm4/beta/ApplyGradientDescent
v/cg/resnet_v17/conv26/batchnorm26/moving_mean
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv10/batchnorm10/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv25/batchnorm25/FusedBatchNormV3
1608170648855773	12.25
1608170648855774	0.0009765625
1608170648855775	0.0009765625
1608170648855776	0.0009765625
1608170648855777	0.0009765625
1608170648856720	-0.0009765625
1608170648856752	-0.0009765625
1608170648948931	-12.25
1608170648951494	-0.0009765625
1608170648951494	-0.0009765625
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648897149	24.5
1608170648897154	4.00048828125
1608170648897179	24.5
1608170648897195	0.00390625
1608170648897279	-24.5
1608170648897281	-0.00390625
1608170648897282	-4.00048828125
1608170648898226	-24.5
tower_0/v/gradients/tower_0/v/cg/resnet_v11/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg/mul
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg
v/cg/resnet_v19/conv32/batchnorm32/gamma/read
tower_0/v/cg/resnet_v13/conv12/Relu
tower_0/v/cg/resnet_v14/conv16/batchnorm16/FusedBatchNormV3
1608170648850079	24.501953125
1608170648850081	0.00048828125
1608170648850081	0.00048828125
1608170648850082	0.00048828125
1608170648850083	0.00048828125
1608170648850936	-0.00048828125
1608170648850982	-0.00048828125
1608170648970968	-24.501953125
1608170648971115	-0.00048828125
1608170648971116	-0.00048828125
v/cg/resnet_v13/conv11/batchnorm11/moving_mean/read
tower_0/v/cg/resnet_v13/conv12/batchnorm12/FusedBatchNormV3
1608170648847183	24.5
1608170648847185	0.00048828125
1608170648847187	0.00048828125
1608170648847188	0.00048828125
1608170648847190	0.00048828125
1608170648848290	-0.00048828125
1608170648848338	-0.00048828125
1608170648984010	-24.5
1608170648984147	-0.00048828125
1608170648984148	-0.00048828125
tower_0/v/gradients/AddN_70
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/l2_loss/L2Loss_18
1608170648835000	0.000244140625
1608170648835001	0.000244140625
1608170648835044	-0.000244140625
1608170648837145	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/batchnorm47/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648902317	9.0
1608170648902318	0.001953125
1608170648902318	0.001953125
1608170648902319	0.000244140625
1608170648902344	0.000244140625
1608170648902620	-0.000244140625
1608170648902621	-0.000244140625
1608170648903778	-9.0
1608170648903834	-0.001953125
1608170648903885	-0.001953125
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg/mul
v/cg/resnet_v15/conv19/batchnorm19/moving_mean/read
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v15/conv19/batchnorm19/beta/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v115/conv52/batchnorm52/moving_variance
v/cg/resnet_v15/conv19/batchnorm19/moving_mean
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg_1
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg_1/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D
1608170648861560	12.25
1608170648861570	2.25
1608170648861611	81.0
1608170648861711	-81.0
1608170648861714	-2.25
1608170648925252	-12.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv42/batchnorm42/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D
1608170648860387	49.0
1608170648860392	1.0
1608170648860435	0.001220703125
1608170648860503	-0.001220703125
1608170648860506	-1.0
1608170648928613	-49.0
v/cg/resnet_v13/conv14/conv2d/kernel/read
v/cg/resnet_v17/conv24/batchnorm24/gamma
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v14/conv17/batchnorm17/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170649006940	62.7001953125
1608170649006945	0.0625
1608170649006965	49.0
1608170649006979	0.020263671875
1608170649007113	-62.7001953125
1608170649007114	-0.020263671875
1608170649007115	-0.0625
1608170649009642	-49.0
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/batchnorm10/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648986361	196.0
1608170648986362	0.0009765625
1608170648986362	0.0009765625
1608170648986363	0.000244140625
1608170648986380	0.000244140625
1608170648986454	-0.000244140625
1608170648986454	-0.000244140625
1608170648988538	-196.0
1608170648988575	-0.0009765625
1608170648988609	-0.0009765625
tower_0/v/gradients/tower_0/v/cg/affine0/xw_plus_b/MatMul_grad/MatMul_1
1608170648892384	7.8203125
1608170648892811	-7.8203125
v/cg/resnet_v17/conv26/batchnorm26/moving_mean/read
v/cg/resnet_v14/conv15/batchnorm15/moving_mean
v/cg/resnet_v15/conv19/batchnorm19/moving_variance/read
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg_1
v/cg/resnet_v18/conv28/batchnorm28/gamma
v/cg/resnet_v14/conv17/conv2d/kernel
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg
v/cg/resnet_v14/conv17/batchnorm17/moving_mean/read
average_loss/Mean/_568
learning_rate/mul
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg_1
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg_1
tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D
1608170648857536	12.25
1608170648857541	1.0
1608170648857587	0.001953125
1608170648857651	-0.001953125
1608170648857654	-1.0
1608170648938034	-12.25
v/cg/resnet_v14/conv17/batchnorm17/beta/read
v/cg/resnet_v15/conv18/batchnorm18/moving_variance/read
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg_1
v/cg/resnet_v15/conv20/batchnorm20/moving_variance
tower_0/v/cg/resnet_v11/conv6/Relu
v/cg/resnet_v13/conv12/batchnorm12/moving_mean
tower_0/v/cg/resnet_v114/conv48/batchnorm48/FusedBatchNormV3
1608170648880458	6.125
1608170648880459	0.001953125
1608170648880460	0.001953125
1608170648880461	0.001953125
1608170648880462	0.001953125
1608170648881991	-0.001953125
1608170648882030	-0.001953125
1608170648900117	-6.125
1608170648900862	-0.001953125
1608170648900864	-0.001953125
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg
learning_rate/PiecewiseConstant/case/cond/cond/cond/Switch/Switch
tower_0/v/l2_loss/L2Loss_46
1608170648836525	0.000244140625
1608170648836537	0.0087890625
1608170648836590	-0.0087890625
1608170648837183	-0.000244140625
tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D
1608170648851799	24.5
1608170648851805	0.5625
1608170648851850	112.5
1608170648851955	-112.5
1608170648851959	-0.5625
1608170648963439	-24.5
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_43_grad/mul
1608170648836479	8.0
1608170648909514	-8.0
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v111/conv38/Relu
tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D
1608170648863364	12.25
1608170648863370	2.25
1608170648863411	81.0
1608170648863516	-81.0
1608170648863519	-2.25
1608170648919878	-12.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv28/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648954015	24.5
1608170648954021	0.25
1608170648954050	24.5
1608170648954064	0.006591796875
1608170648954129	-24.5
1608170648954130	-0.006591796875
1608170648954132	-0.25
1608170648956353	-24.5
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v114/conv47/batchnorm47/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/batchnorm25/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648948976	12.25
1608170648948977	0.0009765625
1608170648948978	0.0009765625
1608170648948978	0.000244140625
1608170648951331	0.000244140625
1608170648951496	-0.000244140625
1608170648951496	-0.000244140625
1608170648952533	-12.25
1608170648953635	-0.0009765625
1608170648953689	-0.0009765625
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg_1
tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D
1608170648879094	6.125
1608170648879100	9.0
1608170648879148	72.0
1608170648879526	-72.0
1608170648879529	-9.0
1608170648900861	-6.125
tower_0/v/gradients/tower_0/v/cg/conv0/batchnorm0/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170649015567	245.0
1608170649015568	0.000244140625
1608170649015568	0.000244140625
1608170649015569	0.000244140625
1608170649015608	0.000244140625
1608170649015678	-0.000244140625
1608170649015678	-0.000244140625
1608170649015908	-245.0
1608170649015948	-0.000244140625
1608170649017024	-0.000244140625
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg/mul
v/cg/resnet_v112/conv42/conv2d/kernel
v/cg/resnet_v17/conv27/conv2d/kernel
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv8/batchnorm8/gamma/ApplyGradientDescent
v/cg/resnet_v10/conv1/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/ExpandDims
v/cg/resnet_v17/conv27/batchnorm27/gamma
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_20_grad/mul
1608170648830278	0.25
1608170648963318	-0.25
tower_0/v/l2_loss/L2Loss_4
1608170648834896	0.000244140625
1608170648834898	0.000244140625
1608170648834942	-0.000244140625
1608170648837177	-0.000244140625
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg
v/cg/resnet_v17/conv25/conv2d/kernel/read
tower_0/v/l2_loss/L2Loss_41
1608170648832234	0.000244140625
1608170648832247	0.0087890625
1608170648832304	-0.0087890625
1608170648837179	-0.000244140625
v/cg/resnet_v14/conv16/batchnorm16/beta
tower_0/v/l2_loss/L2Loss_45
1608170648829280	0.000244140625
1608170648829292	0.0087890625
1608170648829363	-0.0087890625
1608170648837183	-0.000244140625
v/cg/resnet_v111/conv39/batchnorm39/moving_mean/read
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv29/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/batchnorm34/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648926700	12.25
1608170648926700	0.0009765625
1608170648926701	0.0009765625
1608170648926702	0.000244140625
1608170648926722	0.000244140625
1608170648926813	-0.000244140625
1608170648926813	-0.000244140625
1608170648928089	-12.25
1608170648928142	-0.0009765625
1608170648928180	-0.0009765625
v/cg/resnet_v115/conv50/batchnorm50/beta
learning_rate/Const_8
v/cg/resnet_v114/conv49/batchnorm49/gamma
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v113/conv43/batchnorm43/FusedBatchNormV3
1608170648871701	24.5
1608170648871703	0.0078125
1608170648871704	0.0078125
1608170648871705	0.0078125
1608170648871707	0.0078125
1608170648874546	-0.0078125
1608170648875275	-0.0078125
1608170648908266	-24.5
1608170648908457	-0.0078125
1608170648908458	-0.0078125
v/cg/resnet_v15/conv19/batchnorm19/beta
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v10/conv1/batchnorm1/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/batchnorm22/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648956000	24.5
1608170648956001	0.000732421875
1608170648956001	0.00048828125
1608170648956002	0.000244140625
1608170648956282	0.000244140625
1608170648956358	-0.000244140625
1608170648956358	-0.000244140625
1608170648957373	-24.5
1608170648957411	-0.000732421875
1608170648957445	-0.00048828125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v14/conv16/batchnorm16/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg_1
v/cg/resnet_v15/conv20/batchnorm20/beta
v/cg/resnet_v12/conv9/batchnorm9/moving_mean/read
tower_0/v/l2_loss/L2Loss_17
1608170648836035	0.000244140625
1608170648836036	0.000244140625
1608170648836079	-0.000244140625
1608170648837141	-0.000244140625
v/cg/resnet_v12/conv8/batchnorm8/beta/read
tower_0/v/gradients/AddN_23
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg_1/sub_1
v/cg/resnet_v16/conv22/batchnorm22/moving_mean/read
tower_0/v/gradients/AddN_50
tower_0/v/cg/resnet_v18/conv28/Relu
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg_1/mul
v/cg/resnet_v115/conv52/conv2d/kernel
v/cg/resnet_v113/conv45/batchnorm45/gamma/read
v/cg/resnet_v12/conv10/batchnorm10/gamma/read
tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D
1608170648884710	6.125
1608170648884714	9.0
1608170648884756	72.0
1608170648885635	-72.0
1608170648885638	-9.0
1608170648894927	-6.125
tower_0/v/cg/resnet_v13/conv11/batchnorm11/FusedBatchNormV3
1608170648847056	98.0
1608170648847057	0.001953125
1608170648847058	0.001953125
1608170648847060	0.001953125
1608170648847062	0.001953125
1608170648848057	-0.001953125
1608170648848100	-0.001953125
1608170648976492	-98.0
1608170648976657	-0.001953125
1608170648976657	-0.001953125
tower_0/v/cg/resnet_v17/conv24/batchnorm24/FusedBatchNormV3
1608170648855664	49.0
1608170648855666	0.00390625
1608170648855667	0.00390625
1608170648855668	0.00390625
1608170648855669	0.00390625
1608170648856518	-0.00390625
1608170648856560	-0.00390625
1608170648940383	-49.0
1608170648940662	-0.00390625
1608170648940663	-0.00390625
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v10/conv1/batchnorm1/moving_variance
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170649010201	69.326171875
1608170649010206	0.140625
1608170649010227	49.0
1608170649010239	147.0
1608170649010468	-69.326171875
1608170649010470	-147.0
1608170649010470	-0.140625
1608170649013020	-49.0
tower_0/v/l2_loss/L2Loss_39
1608170648836257	0.000244140625
1608170648836259	0.000244140625
1608170648836305	-0.000244140625
1608170648837177	-0.000244140625
v/cg/resnet_v13/conv11/batchnorm11/moving_mean
tower_0/v/cg/resnet_v11/conv5/Relu
v/cg/resnet_v14/conv17/batchnorm17/moving_variance
v/cg/resnet_v10/conv4/conv2d/kernel
tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D
1608170648855413	12.25
1608170648855419	0.5
1608170648855463	0.001220703125
1608170648855530	-0.001220703125
1608170648855533	-0.5
1608170648951493	-12.25
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg/mul
edge_526_learning_rate/Less@@MemcpyDtoH
v/cg/resnet_v10/conv2/batchnorm2/moving_variance/read
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg_1/mul
v/cg/resnet_v17/conv27/batchnorm27/moving_variance/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv52/batchnorm52/beta/ApplyGradientDescent
v/cg/resnet_v114/conv47/batchnorm47/gamma/read
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/batchnorm35/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648925129	12.25
1608170648925130	0.0009765625
1608170648925130	0.0009765625
1608170648925131	0.000244140625
1608170648925166	0.000244140625
1608170648925255	-0.000244140625
1608170648925256	-0.000244140625
1608170648926505	-12.25
1608170648926553	-0.0009765625
1608170648926594	-0.0009765625
v/cg/resnet_v12/conv8/batchnorm8/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648901154	9.00048828125
1608170648901162	9.0
1608170648901177	122.611572265625
1608170648901286	-122.611572265625
1608170648901288	-9.0
1608170648902668	-9.00048828125
v/cg/resnet_v17/conv26/batchnorm26/gamma/read
v/cg/resnet_v115/conv50/conv2d/kernel
v/cg/resnet_v12/conv9/batchnorm9/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170649005829	0.0625
1608170649005837	0.0625
1608170649005852	0.0029296875
1608170649006840	-0.0029296875
1608170649006842	-0.0625
1608170649009056	-0.0625
v/cg/resnet_v112/conv41/batchnorm41/moving_variance
v/cg/resnet_v112/conv41/batchnorm41/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv5/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv17/batchnorm17/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv38/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/AddN_30
v/cg/resnet_v13/conv14/batchnorm14/moving_variance
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg_1
tower_0/v/cg/conv0/Relu
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg/mul
v/cg/resnet_v12/conv10/batchnorm10/beta
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg_1/sub_1
learning_rate/PiecewiseConstant/Greater_3
1608170648824813	0.000244140625
1608170648825646	-0.000244140625
v/cg/resnet_v112/conv40/batchnorm40/gamma/read
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv22/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v112/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/l2_loss/L2Loss_51
1608170648834037	0.000244140625
1608170648834048	0.0087890625
1608170648834103	-0.0087890625
1608170648837205	-0.000244140625
v/cg/resnet_v16/conv22/batchnorm22/gamma
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg
v/cg/resnet_v114/conv49/batchnorm49/beta
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg/sub_1
tower_0/v/gpu_cached_inputs
v/cg/resnet_v19/conv32/batchnorm32/moving_variance/read
tower_0/v/l2_loss/L2Loss_33
1608170648836143	0.000244140625
1608170648836145	0.000244140625
1608170648836188	-0.000244140625
1608170648837172	-0.000244140625
tower_0/v/cg/resnet_v13/Relu
v/cg/resnet_v110/conv34/batchnorm34/gamma
v/cg/resnet_v113/conv46/batchnorm46/gamma
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg_1
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg
v/cg/resnet_v12/conv8/conv2d/kernel
v/cg/resnet_v114/conv48/batchnorm48/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648909788	7.82080078125
1608170648909794	9.0
1608170648909816	9.00048828125
1608170648909830	98.00390625
1608170648909918	-7.82080078125
1608170648909920	-98.00390625
1608170648909921	-9.0
1608170648910378	-9.00048828125
v/cg/resnet_v112/conv40/batchnorm40/beta
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_1_grad/mul
1608170648834478	0.0625
1608170649008970	-0.0625
v/cg/resnet_v114/conv48/batchnorm48/gamma
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg_1/sub_1
tower_0/v/l2_loss/L2Loss_15
1608170648835254	0.000244140625
1608170648835257	0.000244140625
1608170648835303	-0.000244140625
1608170648837139	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv13/batchnorm13/beta/ApplyGradientDescent
tower_0/v/gradients/AddN_61
v/cg/resnet_v113/conv43/conv2d/kernel/read
tower_0/v/gradients/AddN_22
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648936143	12.25
1608170648936148	2.25048828125
1608170648936171	14.0009765625
1608170648936185	182.25
1608170648937255	-12.25
1608170648937256	-182.25
1608170648937258	-2.25048828125
1608170648938032	-14.0009765625
tower_0/v/l2_loss/L2Loss_16
1608170648832572	0.000244140625
1608170648832574	0.000244140625
1608170648832630	-0.000244140625
1608170648837140	-0.000244140625
v/cg/resnet_v112/conv41/batchnorm41/beta/read
v/cg/resnet_v13/conv13/batchnorm13/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv11/batchnorm11/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/AddN_18
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648958739	0.25
1608170648958745	0.25
1608170648958757	0.00439453125
1608170648960135	-0.00439453125
1608170648960137	-0.25
1608170648961209	-0.25
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648909122	7.82080078125
1608170648909128	4.00048828125
1608170648909150	9.00048828125
1608170648909169	0.00390625
1608170648909243	-7.82080078125
1608170648909245	-0.00390625
1608170648909246	-4.00048828125
1608170648909724	-9.00048828125
tower_0/v/cg/resnet_v110/add
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg/sub_1
v/cg/resnet_v16/conv22/batchnorm22/gamma/read
v/cg/resnet_v112/conv41/batchnorm41/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/batchnorm26/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648945522	14.0009765625
1608170648945523	0.0009765625
1608170648945524	0.0009765625
1608170648945524	0.000244140625
1608170648945573	0.000244140625
1608170648945715	-0.000244140625
1608170648945716	-0.000244140625
1608170648946552	-14.0009765625
1608170648948864	-0.0009765625
1608170648948901	-0.0009765625
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648986473	49.0
1608170648986479	0.0625
1608170648986511	49.0
1608170648986528	0.020263671875
1608170648986618	-49.0
1608170648986620	-0.020263671875
1608170648986621	-0.0625
1608170648989222	-49.0
v/cg/resnet_v18/conv30/batchnorm30/beta/read
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648976957	196.0
1608170648976962	0.5
1608170648977387	196.0
1608170648977619	-196.0
1608170648977621	-0.5
1608170649004933	-196.0
tower_0/v/transpose/perm
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648956574	1.0
1608170648956582	1.0
1608170648956599	112.5
1608170648957365	-112.5
1608170648957367	-1.0
1608170648958362	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v10/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Tile/multiples
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170649013372	0.015625
1608170649013380	0.015625
1608170649013392	0.0029296875
1608170649014115	-0.0029296875
1608170649014117	-0.015625
1608170649015529	-0.015625
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg
tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D
1608170648886693	24.5
1608170648886700	4.0
1608170648886897	0.00048828125
1608170648887072	-0.00048828125
1608170648887075	-4.0
1608170648893363	-24.5
v/cg/resnet_v10/conv4/batchnorm4/beta
v/cg/resnet_v15/conv18/batchnorm18/gamma/read
v/cg/resnet_v112/conv40/batchnorm40/beta/read
learning_rate/Cast_4
1608170648824108	0.000244140625
1608170649017086	-0.000244140625
v/cg/resnet_v113/conv43/batchnorm43/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v111/conv38/batchnorm38/FusedBatchNormV3
1608170648863680	12.25
1608170648863681	0.0009765625
1608170648863682	0.0009765625
1608170648863683	0.0009765625
1608170648863684	0.0009765625
1608170648864400	-0.0009765625
1608170648864436	-0.0009765625
1608170648919618	-12.25
1608170648919879	-0.0009765625
1608170648919880	-0.0009765625
v/cg/resnet_v113/conv44/batchnorm44/beta
v/cg/resnet_v18/conv30/conv2d/kernel
v/cg/resnet_v111/conv37/conv2d/kernel
v/cg/resnet_v13/conv11/batchnorm11/gamma/read
main_fetch_group/_564
tower_0/v/gradients/AddN_42
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv31/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v19/conv33/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv28/batchnorm28/gamma/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_26
1608170648829968	0.000244140625
1608170648829992	0.0087890625
1608170648830071	-0.0087890625
1608170648837166	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/batchnorm48/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648900169	6.125
1608170648900170	0.001953125
1608170648900171	0.001953125
1608170648900171	0.000244140625
1608170648900196	0.000244140625
1608170648900865	-0.000244140625
1608170648900866	-0.000244140625
1608170648901296	-6.125
1608170648902028	-0.001953125
1608170648902060	-0.001953125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v18/conv29/conv2d/kernel
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv9/batchnorm9/beta/ApplyGradientDescent
v/cg/resnet_v10/conv2/batchnorm2/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D
1608170648867316	49.0
1608170648867322	1.0
1608170648868921	0.001220703125
1608170648868993	-0.001220703125
1608170648868996	-1.0
1608170648911741	-49.0
v/cg/resnet_v115/conv52/batchnorm52/gamma
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Assert/Switch_1
tower_0/v/gradients/AddN_1
tower_0/v/l2_loss/L2Loss_22
1608170648830878	0.000244140625
1608170648830880	0.000244140625
1608170648830939	-0.000244140625
1608170648837163	-0.000244140625
v/cg/resnet_v113/conv46/batchnorm46/moving_variance/read
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg/mul
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_26_grad/mul
1608170648830099	2.25
1608170648948966	-2.25
v/cg/resnet_v18/conv30/batchnorm30/beta
tower_0/v/cg/resnet_v18/add
tower_0/v/cg/conv0/Pad/paddings
v/cg/resnet_v114/conv49/batchnorm49/moving_mean
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv7/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg
edge_560_learning_rate/PiecewiseConstant/case/preds_c@@MemcpyDtoH
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg
tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D
1608170648856199	12.25
1608170648856205	2.25
1608170648856247	81.0
1608170648856345	-81.0
1608170648856348	-2.25
1608170648945712	-12.25
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648922353	1.0
1608170648922362	1.0
1608170648922376	0.0029296875
1608170648922492	-0.0029296875
1608170648922495	-1.0
1608170648923528	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648977649	0.5
1608170648977655	0.5625
1608170648977671	0.00244140625
1608170648978561	-0.00244140625
1608170648978564	-0.5625
1608170648980947	-0.5
tower_0/v/gradients/AddN_5
v/cg/resnet_v115/conv51/batchnorm51/gamma
v/cg/resnet_v10/conv2/conv2d/kernel/read
tower_0/v/cg/resnet_v19/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648932335	1.0
1608170648932342	1.0
1608170648932355	0.00439453125
1608170648932476	-0.00439453125
1608170648932478	-1.0
1608170648933468	-1.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv36/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/conv0/conv2d/Conv2D
1608170648837268	196.0
1608170648837285	0.035888671875
1608170648837411	0.072021484375
1608170648837557	-0.072021484375
1608170648837561	-0.035888671875
1608170649015676	-196.0
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/batchnorm5/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170649000671	49.0
1608170649000672	0.000244140625
1608170649000673	0.000244140625
1608170649000673	0.000244140625
1608170649002488	0.000244140625
1608170649002571	-0.000244140625
1608170649002572	-0.000244140625
1608170649004538	-49.0
1608170649004573	-0.000244140625
1608170649004603	-0.000244140625
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg_1
v/cg/resnet_v113/conv46/conv2d/kernel
v/cg/resnet_v16/conv21/batchnorm21/moving_variance/read
v/cg/resnet_v110/conv36/batchnorm36/gamma
v/cg/resnet_v115/conv52/batchnorm52/moving_mean
edge_667_learning_rate/PiecewiseConstant/and_2@@MemcpyDtoH
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg
v/cg/resnet_v113/conv45/conv2d/kernel
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg/mul
v/cg/resnet_v16/conv21/batchnorm21/moving_variance
v/cg/resnet_v11/conv6/batchnorm6/gamma/read
v/cg/resnet_v12/conv9/batchnorm9/beta
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/ShapeN-matshapes-0
learning_rate/PiecewiseConstant/case/n_true_conds
tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D
1608170648838237	49.0
1608170648838243	0.015625
1608170648838290	0.01806640625
1608170648838361	-0.01806640625
1608170648838364	-0.015625
1608170649013021	-49.0
v/cg/resnet_v13/conv13/batchnorm13/moving_mean
v/cg/resnet_v13/conv11/conv2d/kernel
v/cg/resnet_v114/conv48/batchnorm48/moving_mean/read
tower_0/v/gradients/AddN_51
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg_1/sub_1
v/cg/resnet_v17/conv25/batchnorm25/moving_mean
v/cg/resnet_v114/conv48/conv2d/kernel
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/batchnorm32/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648929156	12.25
1608170648929157	0.0009765625
1608170648929158	0.0009765625
1608170648929158	0.000244140625
1608170648929177	0.000244140625
1608170648929254	-0.000244140625
1608170648929255	-0.000244140625
1608170648930005	-12.25
1608170648930064	-0.0009765625
1608170648930098	-0.0009765625
tower_0/v/gradients/tower_0/v/cg/resnet_v114/Relu_grad/ReluGrad
tower_0/v/gradients/AddN_52
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv2/batchnorm2/gamma/ApplyGradientDescent
v/cg/resnet_v13/conv13/batchnorm13/beta/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_41_grad/mul
1608170648832327	2.25
1608170648915036	-2.25
v/cg/resnet_v115/conv50/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v16/conv21/batchnorm21/gamma/read
v/cg/resnet_v18/conv28/batchnorm28/moving_variance/read
v/cg/resnet_v10/conv3/batchnorm3/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv18/batchnorm18/beta/ApplyGradientDescent
v/cg/resnet_v10/conv4/batchnorm4/moving_variance
tower_0/v/cg/resnet_v19/conv33/batchnorm33/FusedBatchNormV3
1608170648860658	49.0
1608170648860659	0.005859375
1608170648860660	0.00390625
1608170648860661	0.00390625
1608170648860662	0.00390625
1608170648861273	-0.005859375
1608170648861308	-0.00390625
1608170648928318	-49.0
1608170648928614	-0.00390625
1608170648928614	-0.00390625
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg/mul
v/cg/resnet_v115/conv52/batchnorm52/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648923967	1.0
1608170648923976	1.00048828125
1608170648923991	0.00244140625
1608170648924110	-0.00244140625
1608170648924112	-1.00048828125
1608170648925306	-1.0
v/cg/resnet_v114/conv49/batchnorm49/gamma/read
v/cg/resnet_v17/conv27/batchnorm27/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv47/batchnorm47/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/batchnorm39/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648918460	49.00390625
1608170648918461	0.004150390625
1608170648918462	0.005859375
1608170648918462	0.000244140625
1608170648918482	0.000244140625
1608170648918562	-0.000244140625
1608170648918563	-0.000244140625
1608170648918878	-49.00390625
1608170648918926	-0.004150390625
1608170648918955	-0.005859375
tower_0/v/gradients/AddN_57
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/ShapeN-matshapes-1
learning_rate/PiecewiseConstant/LessEqual_1
1608170648824269	0.000244140625
1608170648824960	-0.000244140625
v/cg/resnet_v14/conv15/batchnorm15/moving_variance
v/cg/resnet_v14/conv17/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v18/conv30/batchnorm30/moving_mean
v/cg/resnet_v111/conv38/conv2d/kernel
learning_rate/PiecewiseConstant/and_1
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg/mul
v/cg/resnet_v111/conv39/batchnorm39/moving_variance/read
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/xentropy/xentropy
1608170648889813	0.000244140625
1608170648889815	0.000244140625
1608170648891936	-0.000244140625
1608170648892201	-0.000244140625
average_loss/Mean/input
v/cg/conv0/conv2d/kernel/read
v/cg/conv0/batchnorm0/moving_variance
v/cg/resnet_v10/conv1/batchnorm1/gamma/read
tower_0/v/cg/conv0/batchnorm0/FusedBatchNormV3
1608170648837662	196.0
1608170648837664	0.000244140625
1608170648837665	0.000244140625
1608170648837665	0.000244140625
1608170648837666	0.000244140625
1608170648838645	-0.000244140625
1608170648838684	-0.000244140625
1608170649015559	-196.0
1608170649015676	-0.000244140625
1608170649015677	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170649007138	0.0625
1608170649007144	0.0625
1608170649007157	0.0029296875
1608170649008393	-0.0029296875
1608170649008395	-0.0625
1608170649010185	-0.0625
v/cg/resnet_v12/conv8/conv2d/kernel/read
tower_0/v/cg/resnet_v115/conv50/Relu
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg/mul
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg_1/sub_1
v/cg/resnet_v14/conv15/batchnorm15/gamma/read
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg_1/mul
v/cg/resnet_v112/conv41/batchnorm41/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648941586	2.25048828125
1608170648941592	2.25048828125
1608170648941609	0.00244140625
1608170648942607	-0.00244140625
1608170648942610	-2.25048828125
1608170648945472	-2.25048828125
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv46/batchnorm46/gamma/ApplyGradientDescent
v/cg/resnet_v11/conv5/batchnorm5/moving_variance
tower_0/v/gradients/AddN_31
tower_0/v/cg/resnet_v12/Relu
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/ShapeN-matshapes-0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v114/conv47/batchnorm47/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/Relu_grad/ReluGrad
v/cg/resnet_v115/conv50/batchnorm50/moving_variance/read
tower_0/v/cg/resnet_v16/conv23/batchnorm23/FusedBatchNormV3
1608170648854728	98.0
1608170648854729	0.001953125
1608170648854730	0.001953125
1608170648854731	0.001953125
1608170648854732	0.001953125
1608170648855603	-0.001953125
1608170648855644	-0.001953125
1608170648953784	-98.0
1608170648953989	-0.001953125
1608170648953990	-0.001953125
v/cg/resnet_v18/conv28/batchnorm28/moving_mean
v/cg/resnet_v17/conv24/batchnorm24/moving_variance/read
learning_rate/PiecewiseConstant/case/cond/cond/Switch/Switch
tower_0/v/gradients/AddN_68
tower_0/v/cg/resnet_v11/conv5/batchnorm5/FusedBatchNormV3
1608170648841794	49.0
1608170648841795	0.000244140625
1608170648841796	0.000244140625
1608170648841797	0.000244140625
1608170648841798	0.000244140625
1608170648842901	-0.000244140625
1608170648842947	-0.000244140625
1608170649000629	-49.0
1608170649002569	-0.000244140625
1608170649002570	-0.000244140625
edge_544_learning_rate/PiecewiseConstant/case/Cast@@MemcpyDtoH
v/cg/resnet_v110/conv34/batchnorm34/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/batchnorm31/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648931057	12.25
1608170648931057	0.0009765625
1608170648931058	0.0009765625
1608170648931058	0.000244140625
1608170648931078	0.000244140625
1608170648931161	-0.000244140625
1608170648931161	-0.000244140625
1608170648932485	-12.25
1608170648932526	-0.0009765625
1608170648932560	-0.0009765625
v/cg/affine0/weights
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv19/batchnorm19/gamma/ApplyGradientDescent
v/cg/resnet_v13/conv12/batchnorm12/gamma/read
tower_0/v/cg/conv0/Pad
1608170648836673	38.7451171875
1608170649015908	-38.7451171875
v/cg/resnet_v13/conv13/batchnorm13/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/batchnorm11/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648976539	98.001953125
1608170648976540	0.001953125
1608170648976541	0.00244140625
1608170648976541	0.000244140625
1608170648976587	0.000244140625
1608170648976658	-0.000244140625
1608170648976659	-0.000244140625
1608170648978570	-98.001953125
1608170648978605	-0.001953125
1608170648978645	-0.00244140625
tower_0/v/gradients/AddN_48
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv39/batchnorm39/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv3/batchnorm3/gamma/ApplyGradientDescent
v/cg/resnet_v19/conv32/batchnorm32/gamma
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv16/batchnorm16/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D
1608170648870557	6.125
1608170648870564	2.0
1608170648870615	0.00048828125
1608170648871138	-0.00048828125
1608170648871141	-2.0
1608170648910380	-6.125
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v112/conv40/batchnorm40/FusedBatchNormV3
1608170648864947	12.25
1608170648864948	0.0009765625
1608170648864948	0.0009765625
1608170648864949	0.0009765625
1608170648864950	0.0009765625
1608170648867146	-0.0009765625
1608170648867181	-0.0009765625
1608170648914655	-12.25
1608170648915220	-0.0009765625
1608170648915221	-0.0009765625
v/cg/resnet_v114/conv48/batchnorm48/gamma/read
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg_1/sub_1
v/cg/resnet_v112/conv40/batchnorm40/moving_mean
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg_1
v/cg/resnet_v115/conv51/batchnorm51/moving_variance
tower_0/v/gradients/AddN_11
v/cg/resnet_v115/conv52/batchnorm52/beta
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg_1/mul
learning_rate/Const_7
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv20/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v11/conv5/batchnorm5/moving_mean
v/cg/resnet_v11/conv5/conv2d/kernel/read
learning_rate/PiecewiseConstant/Greater_2
1608170648824331	0.000244140625
1608170648825406	-0.000244140625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_48_grad/mul
1608170648829221	9.0
1608170648902306	-9.0
tower_0/v/gradients/AddN_55
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv21/batchnorm21/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_13_grad/mul
1608170648835993	0.5625
1608170648984044	-0.5625
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648926889	49.0
1608170648926894	1.0
1608170648927656	49.0
1608170648927671	0.004150390625
1608170648927873	-49.0
1608170648927875	-0.004150390625
1608170648927876	-1.0
1608170648928230	-49.0
tower_0/v/cg/resnet_v113/conv45/batchnorm45/FusedBatchNormV3
1608170648874336	6.125
1608170648874337	0.001953125
1608170648874338	0.001953125
1608170648874339	0.001953125
1608170648874341	0.001953125
1608170648876567	-0.001953125
1608170648876603	-0.001953125
1608170648909552	-6.125
1608170648909727	-0.001953125
1608170648909727	-0.001953125
v/cg/resnet_v18/conv28/batchnorm28/moving_mean/read
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg_1
v/cg/resnet_v110/conv34/batchnorm34/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv34/batchnorm34/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg/mul
v/cg/resnet_v15/conv20/batchnorm20/beta/read
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg/sub_1
v/cg/resnet_v113/conv45/conv2d/kernel/read
v/cg/resnet_v13/conv12/batchnorm12/moving_variance/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv16/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v19/conv31/conv2d/kernel
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg/sub_1
tower_0/v/gradients/AddN_43
v/cg/resnet_v17/conv26/batchnorm26/moving_variance
tower_0/v/l2_loss/L2Loss_12
1608170648829755	0.000244140625
1608170648829760	0.000244140625
1608170648829831	-0.000244140625
1608170648837131	-0.000244140625
v/cg/resnet_v11/conv7/batchnorm7/gamma/read
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv44/batchnorm44/gamma/ApplyGradientDescent
learning_rate/Less/y
v/cg/resnet_v16/conv23/batchnorm23/beta/read
learning_rate/PiecewiseConstant/Greater_1
1608170648824882	0.000244140625
1608170648825404	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/AddN_38
tower_0/v/cg/resnet_v16/conv22/Relu
v/cg/resnet_v111/conv38/batchnorm38/moving_variance
v/cg/resnet_v14/conv17/batchnorm17/gamma
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv2/batchnorm2/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv8/batchnorm8/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv34/conv2d/kernel/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_19
1608170648831878	0.000244140625
1608170648831880	0.000244140625
1608170648831932	-0.000244140625
1608170648837146	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_7_grad/mul
1608170648833256	0.0625
1608170648996203	-0.0625
v/cg/resnet_v12/conv10/batchnorm10/moving_mean
v/cg/resnet_v18/conv30/batchnorm30/moving_mean/read
v/cg/resnet_v112/conv42/batchnorm42/beta
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg/sub_1
learning_rate/PiecewiseConstant/and
v/cg/resnet_v113/conv44/batchnorm44/moving_mean
v/cg/affine0/weights/read
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Tile
1608170648892718	24.5
1608170648908566	-24.5
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv41/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/AddN_9
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg/mul
v/cg/resnet_v112/conv42/batchnorm42/beta/read
v/cg/resnet_v112/conv41/batchnorm41/gamma/read
tower_0/v/cg/resnet_v16/conv21/batchnorm21/FusedBatchNormV3
1608170648853496	24.5
1608170648853497	0.00048828125
1608170648853498	0.00048828125
1608170648853499	0.00048828125
1608170648853500	0.00048828125
1608170648854258	-0.00048828125
1608170648854303	-0.00048828125
1608170648958007	-24.5
1608170648958145	-0.00048828125
1608170648958153	-0.00048828125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv33/batchnorm33/beta/ApplyGradientDescent
v/cg/resnet_v111/conv37/batchnorm37/beta/read
tower_0/v/cg/resnet_v114/conv48/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648893461	7.81298828125
1608170648893476	4.0
1608170648893506	6.125
1608170648893532	0.00390625
1608170648893626	-7.81298828125
1608170648893629	-0.00390625
1608170648893629	-4.0
1608170648894925	-6.125
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v10/conv4/batchnorm4/moving_variance/read
tower_0/v/cg/resnet_v111/add
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv30/batchnorm30/beta/ApplyGradientDescent
v/cg/conv0/batchnorm0/moving_variance/read
tower_0/v/l2_loss/L2Loss_31
1608170648832002	0.000244140625
1608170648832004	0.000244140625
1608170648832053	-0.000244140625
1608170648837171	-0.000244140625
tower_0/v/cg/resnet_v12/conv10/batchnorm10/FusedBatchNormV3
1608170648846032	196.0
1608170648846033	0.0009765625
1608170648846035	0.0009765625
1608170648846038	0.0009765625
1608170648846040	0.0009765625
1608170648846995	-0.0009765625
1608170648847038	-0.0009765625
1608170648986311	-196.0
1608170648986450	-0.0009765625
1608170648986451	-0.0009765625
tower_0/v/cg/resnet_v15/conv18/batchnorm18/FusedBatchNormV3
1608170648851524	24.5
1608170648851525	0.00048828125
1608170648851526	0.00048828125
1608170648851527	0.00048828125
1608170648851528	0.00048828125
1608170648852260	-0.00048828125
1608170648852303	-0.00048828125
1608170648965672	-24.5
1608170648966015	-0.00048828125
1608170648966015	-0.00048828125
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv7/batchnorm7/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v112/conv42/batchnorm42/FusedBatchNormV3
1608170648869491	49.0
1608170648869492	0.005859375
1608170648869492	0.00390625
1608170648869493	0.00390625
1608170648869495	0.00390625
1608170648871527	-0.005859375
1608170648871578	-0.00390625
1608170648911584	-49.0
1608170648911742	-0.00390625
1608170648911743	-0.00390625
v/cg/resnet_v112/conv40/batchnorm40/moving_mean/read
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg/mul
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg_1/sub_1
v/cg/resnet_v15/conv20/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v110/conv35/batchnorm35/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648893658	7.81298828125
1608170648893669	4.0
1608170648893690	0.00390625
1608170648893823	-0.00390625
1608170648893825	-4.0
1608170648894982	-7.81298828125
v/cg/resnet_v115/conv51/batchnorm51/beta
tower_0/v/gradients/AddN_58
tower_0/v/gradients/tower_0/v/cg/resnet_v14/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_15_grad/mul
1608170648835325	0.25
1608170648976462	-0.25
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v15/conv20/batchnorm20/moving_variance/read
v/cg/resnet_v15/conv20/batchnorm20/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv49/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v111/conv39/batchnorm39/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/batchnorm33/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648928434	49.00390625
1608170648928435	0.004150390625
1608170648928435	0.005859375
1608170648928436	0.000244140625
1608170648928511	0.000244140625
1608170648928617	-0.000244140625
1608170648928617	-0.000244140625
1608170648928984	-49.00390625
1608170648929029	-0.004150390625
1608170648929066	-0.005859375
learning_rate/Const_5
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/batchnorm30/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648933479	49.0078125
1608170648933479	0.00439453125
1608170648933482	0.00390625
1608170648933483	0.000244140625
1608170648933556	0.000244140625
1608170648933697	-0.000244140625
1608170648933698	-0.000244140625
1608170648934901	-49.0078125
1608170648934948	-0.00439453125
1608170648934981	-0.00390625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648961475	0.25
1608170648961481	0.25
1608170648961494	0.00244140625
1608170648962560	-0.00244140625
1608170648962562	-0.25
1608170648963487	-0.25
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648911765	12.25
1608170648911772	1.0
1608170648911798	12.25
1608170648911815	0.00341796875
1608170648912536	-12.25
1608170648912538	-0.00341796875
1608170648912540	-1.0
1608170648913705	-12.25
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648996775	49.0
1608170648996780	0.25
1608170648996802	49.0
1608170648996814	85.046875
1608170648997042	-49.0
1608170648997044	-85.046875
1608170648997046	-0.25
1608170649002566	-49.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v13/conv13/batchnorm13/moving_variance
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Switch
tower_0/v/gradients/tower_0/v/cg/conv0/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170649015694	0.035888671875
1608170649015701	0.035888671875
1608170649015714	0.0341796875
1608170649015900	-0.0341796875
1608170649015902	-0.035888671875
1608170649017087	-0.035888671875
tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D
1608170648859303	12.25
1608170648859308	1.0
1608170648859349	0.001953125
1608170648859414	-0.001953125
1608170648859417	-1.0
1608170648931158	-12.25
v/cg/resnet_v114/conv48/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/batchnorm20/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648961220	98.001953125
1608170648961220	0.001953125
1608170648961221	0.001953125
1608170648961222	0.000244140625
1608170648961239	0.000244140625
1608170648961308	-0.000244140625
1608170648961309	-0.000244140625
1608170648962569	-98.001953125
1608170648963221	-0.001953125
1608170648963255	-0.001953125
v/cg/resnet_v18/conv30/batchnorm30/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/Relu_grad/ReluGrad
v/cg/resnet_v110/conv35/conv2d/kernel/read
tower_0/v/gradients/AddN_4
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv44/batchnorm44/beta/ApplyGradientDescent
v/cg/resnet_v111/conv37/batchnorm37/moving_variance/read
learning_rate/truediv
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg_1/mul
learning_rate/PiecewiseConstant/case/num_true_conds
v/cg/resnet_v17/conv25/batchnorm25/beta
tower_0/v/l2_loss/L2Loss_25
1608170648830347	0.000244140625
1608170648830351	0.000244140625
1608170648830404	-0.000244140625
1608170648837166	-0.000244140625
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg/sub_1
v/cg/resnet_v110/conv34/batchnorm34/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/affine0/xw_plus_b_grad/BiasAddGrad
1608170648892217	0.00390625
1608170648892706	-0.00390625
tower_0/v/add
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648986657	0.0625
1608170648986663	0.0625
1608170648986677	0.0029296875
1608170648988530	-0.0029296875
1608170648988532	-0.0625
1608170648989277	-0.0625
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg/mul
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg_1/mul
v/cg/resnet_v115/conv50/batchnorm50/gamma
v/cg/resnet_v18/conv29/batchnorm29/moving_variance
tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D
1608170648848501	98.0
1608170648848508	0.25
1608170648848554	0.004638671875
1608170648848621	-0.004638671875
1608170648848624	-0.25
1608170648976931	-98.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv20/batchnorm20/gamma/ApplyGradientDescent
v/cg/resnet_v19/conv33/batchnorm33/gamma/read
v/cg/resnet_v110/conv34/batchnorm34/beta/read
tower_0/v/cg/resnet_v113/conv46/batchnorm46/FusedBatchNormV3
1608170648875902	24.5
1608170648875904	0.0078125
1608170648875904	0.0078125
1608170648875905	0.0078125
1608170648875906	0.0078125
1608170648876752	-24.5
1608170648877928	-0.0078125
1608170648878439	-0.0078125
1608170648908569	-0.0078125
1608170648908569	-0.0078125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/batchnorm36/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648923549	49.00390625
1608170648923549	0.004150390625
1608170648923550	0.005859375
1608170648923551	0.000244140625
1608170648923571	0.000244140625
1608170648923650	-0.000244140625
1608170648923651	-0.000244140625
1608170648924119	-49.00390625
1608170648924173	-0.004150390625
1608170648924210	-0.005859375
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent
tower_0/v/cg/resnet_v11/add
v/cg/resnet_v111/conv39/conv2d/kernel/read
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg/mul
v/cg/resnet_v12/conv9/conv2d/kernel/read
tower_0/v/cg/resnet_v110/conv35/batchnorm35/FusedBatchNormV3
1608170648861852	12.25
1608170648861854	0.0009765625
1608170648861854	0.0009765625
1608170648861855	0.0009765625
1608170648861856	0.0009765625
1608170648862548	-0.0009765625
1608170648862591	-0.0009765625
1608170648925062	-12.25
1608170648925253	-0.0009765625
1608170648925254	-0.0009765625
v/cg/resnet_v113/conv43/conv2d/kernel
v/cg/resnet_v14/conv17/batchnorm17/gamma/read
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg_1/sub_1
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/Sum
1608170648892028	0.000244140625
1608170648892645	-0.000244140625
v/cg/resnet_v111/conv37/batchnorm37/gamma
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv29/batchnorm29/beta/ApplyGradientDescent
tower_0/v/gradients/AddN_17
tower_0/v/cg/resnet_v17/conv25/Relu
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg/sub_1
v/cg/resnet_v15/conv19/batchnorm19/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648895230	9.0
1608170648895239	9.0
1608170648895255	72.0
1608170648896154	-72.0
1608170648896156	-9.0
1608170648897135	-9.0
tower_0/v/l2_loss/L2Loss_21
1608170648832122	0.000244140625
1608170648832124	0.000244140625
1608170648832171	-0.000244140625
1608170648837162	-0.000244140625
v/cg/resnet_v14/conv16/batchnorm16/moving_mean
v/cg/resnet_v112/conv42/batchnorm42/moving_mean/read
tower_0/v/l2_loss/L2Loss_3
1608170648833537	0.000244140625
1608170648833539	0.000244140625
1608170648833582	-0.000244140625
1608170648837169	-0.000244140625
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg_1/mul
edge_663_learning_rate/PiecewiseConstant/and_1@@MemcpyDtoH
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg/sub_1
v/cg/resnet_v11/conv7/batchnorm7/moving_mean
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v16/add
v/cg/resnet_v15/conv18/batchnorm18/moving_mean
tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D
1608170648850448	98.0
1608170648850455	0.25
1608170648850503	0.004638671875
1608170648850579	-0.004638671875
1608170648850582	-0.25
1608170648968905	-98.0
tower_0/v/gradients/AddN_62
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_29_grad/mul
1608170648831382	2.25
1608170648937777	-2.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv17/batchnorm17/beta/ApplyGradientDescent
v/cg/resnet_v11/conv6/conv2d/kernel/read
v/cg/resnet_v10/conv3/conv2d/kernel
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_44_grad/mul
1608170648832514	2.0
1608170648911530	-2.0
v/cg/resnet_v111/conv38/batchnorm38/moving_variance/read
tower_0/v/cg/resnet_v110/conv36/batchnorm36/FusedBatchNormV3
1608170648862423	49.0
1608170648862425	0.005859375
1608170648862425	0.00390625
1608170648862426	0.00390625
1608170648862427	0.00390625
1608170648863064	-0.005859375
1608170648863106	-0.00390625
1608170648922712	-49.0
1608170648923648	-0.00390625
1608170648923648	-0.00390625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_23_grad/mul
1608170648830793	0.25
1608170648955985	-0.25
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/Switch/Switch
v/cg/resnet_v17/conv25/batchnorm25/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648978859	0.25
1608170648978864	0.25
1608170648978876	0.00439453125
1608170648979897	-0.00439453125
1608170648979898	-0.25
1608170648981494	-0.25
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg_1/mul
v/cg/resnet_v11/conv7/batchnorm7/gamma
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg/mul
v/cg/resnet_v11/conv6/batchnorm6/gamma
v/cg/resnet_v113/conv44/batchnorm44/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648916970	49.0
1608170648916976	1.0
1608170648917008	49.0
1608170648917025	0.00390625
1608170648917252	-49.0
1608170648917254	-0.00390625
1608170648917255	-1.0
1608170648917644	-49.0
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648963649	0.5625
1608170648963655	1.0
1608170648963668	112.5
1608170648964676	-112.5
1608170648964678	-1.0
1608170648966261	-0.5625
tower_0/v/cg/resnet_v19/conv31/batchnorm31/FusedBatchNormV3
1608170648859557	12.25
1608170648859558	0.0009765625
1608170648859559	0.0009765625
1608170648859560	0.0009765625
1608170648859561	0.0009765625
1608170648860202	-0.0009765625
1608170648860236	-0.0009765625
1608170648930144	-12.25
1608170648931159	-0.0009765625
1608170648931159	-0.0009765625
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg/mul
tower_0/v/cg/resnet_v11/conv7/batchnorm7/FusedBatchNormV3
1608170648843431	196.0
1608170648843432	0.0009765625
1608170648843433	0.0009765625
1608170648843434	0.0009765625
1608170648843435	0.0009765625
1608170648844278	-0.0009765625
1608170648844322	-0.0009765625
1608170648993819	-196.0
1608170648993964	-0.0009765625
1608170648993965	-0.0009765625
tower_0/v/cg/resnet_v15/conv19/batchnorm19/FusedBatchNormV3
1608170648852111	24.5
1608170648852112	0.00048828125
1608170648852113	0.00048828125
1608170648852114	0.00048828125
1608170648852115	0.00048828125
1608170648852911	-0.00048828125
1608170648852947	-0.00048828125
1608170648963284	-24.5
1608170648963439	-0.00048828125
1608170648963440	-0.00048828125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv48/batchnorm48/beta/ApplyGradientDescent
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/Const_1
v/cg/resnet_v17/conv26/batchnorm26/gamma
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv39/batchnorm39/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg_1
v/cg/resnet_v14/conv16/batchnorm16/moving_mean/read
v/cg/resnet_v17/conv25/batchnorm25/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648902688	24.5
1608170648902694	4.00048828125
1608170648902719	24.5
1608170648902733	0.00390625
1608170648902863	-24.5
1608170648902865	-0.00390625
1608170648902865	-4.00048828125
1608170648903939	-24.5
v/cg/resnet_v18/conv30/batchnorm30/gamma/read
tower_0/v/gradients/AddN_7
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv1/batchnorm1/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg/sub
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg/sub_1
v/cg/resnet_v115/conv51/batchnorm51/gamma/read
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Reshape/shape
v/cg/resnet_v19/conv33/batchnorm33/moving_variance
tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D
1608170648846564	98.0
1608170648846570	0.5
1608170648846622	0.004638671875
1608170648846698	-0.004638671875
1608170648846701	-0.5
1608170648976655	-98.0
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648942937	1.0
1608170648942943	1.0
1608170648942956	0.00439453125
1608170648944068	-0.00439453125
1608170648944069	-1.0
1608170648945793	-1.0
tower_0/v/cg/resnet_v19/conv31/Relu
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg_1
v/cg/resnet_v14/conv16/batchnorm16/beta/read
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg
v/cg/resnet_v111/conv37/conv2d/kernel/read
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg/mul
tower_0/v/mul/x
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v18/conv29/batchnorm29/moving_variance/read
v/cg/resnet_v113/conv43/batchnorm43/moving_mean
v/cg/resnet_v10/conv4/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv1/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v19/conv33/batchnorm33/moving_variance/read
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg/mul
v/cg/resnet_v113/conv45/batchnorm45/moving_mean
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/ShapeN-matshapes-1
gpu_compute_stage_ops_group
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv49/batchnorm49/beta/ApplyGradientDescent
v/cg/resnet_v16/conv22/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648918738	1.0
1608170648918745	1.0
1608170648918759	0.00244140625
1608170648918869	-0.00244140625
1608170648918871	-1.0
1608170648919931	-1.0
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_22_grad/mul
1608170648830984	0.5625
1608170648958046	-0.5625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv28/batchnorm28/beta/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v15/conv18/batchnorm18/moving_mean/read
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/AddN_54
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/Mul
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg_1
learning_rate/PiecewiseConstant/LessEqual_2
1608170648824021	0.000244140625
1608170648824509	-0.000244140625
tower_0/v/cg/spatial_mean0/reduction_indices
tower_0/v/transpose
1608170648832863	36.75
1608170648836755	-36.75
v/cg/resnet_v18/conv30/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_49_grad/mul
1608170648835576	4.0
1608170648900153	-4.0
tower_0/v/gradients/tower_0/v/cg/resnet_v17/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648928681	13.000732421875
1608170648928689	1.0
1608170648928718	12.25
1608170648928732	0.00341796875
1608170648928802	-13.000732421875
1608170648928804	-0.00341796875
1608170648928805	-1.0
1608170648929249	-12.25
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/Relu_grad/ReluGrad
v/cg/resnet_v19/conv32/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/batchnorm29/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648935089	12.25390625
1608170648935090	0.0009765625
1608170648935091	0.0009765625
1608170648935091	0.000244140625
1608170648935114	0.000244140625
1608170648935192	-0.000244140625
1608170648935192	-0.000244140625
1608170648937514	-12.25390625
1608170648937668	-0.0009765625
1608170648937703	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv48/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv33/batchnorm33/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv47/batchnorm47/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D
1608170648855221	49.0
1608170648855227	2.0
1608170648855276	0.001220703125
1608170648855346	-0.001220703125
1608170648855349	-2.0
1608170648940661	-49.0
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648937284	2.25048828125
1608170648937290	2.25048828125
1608170648937310	81.0
1608170648937505	-81.0
1608170648937508	-2.25048828125
1608170648938097	-2.25048828125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v11/conv6/batchnorm6/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv12/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v113/conv43/batchnorm43/beta/read
v/cg/conv0/batchnorm0/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648941405	98.0
1608170648941410	2.25048828125
1608170648941436	98.0
1608170648941557	-98.0
1608170648941559	-2.25048828125
1608170648976929	-98.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv50/batchnorm50/beta/ApplyGradientDescent
v/cg/resnet_v112/conv42/batchnorm42/gamma
v/cg/conv0/batchnorm0/gamma
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv52/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v19/conv33/batchnorm33/beta/read
tower_0/v/cg/affine0/xw_plus_b/MatMul
1608170648889499	0.244384765625
1608170648892427	-0.244384765625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_38_grad/mul
1608170648832806	2.25
1608170648921251	-2.25
tower_0/v/resnet50_synthetic_labels
1608170648827435	0.000244140625
1608170648891944	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv21/batchnorm21/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v113/conv44/Relu
v/cg/resnet_v12/conv9/batchnorm9/beta/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg/mul
v/cg/resnet_v16/conv22/batchnorm22/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648974415	0.25
1608170648974421	0.25
1608170648974433	0.00439453125
1608170648976312	-0.00439453125
1608170648976313	-0.25
1608170648976526	-0.25
v/cg/resnet_v110/conv35/batchnorm35/beta
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v10/conv3/batchnorm3/moving_mean/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_18_grad/mul
1608170648835064	0.25
1608170648968745	-0.25
v/cg/resnet_v112/conv42/batchnorm42/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv35/batchnorm35/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_52_grad/mul
1608170648834608	4.0
1608170648894619	-4.0
tower_0/v/cg/resnet_v12/add
tower_0/v/cg/resnet_v17/add
tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D
1608170648880870	24.5
1608170648880874	4.0
1608170648881002	0.00048828125
1608170648881516	-0.00048828125
1608170648881519	-4.0
1608170648898820	-24.5
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_12_grad/mul
1608170648829863	0.125
1608170648986261	-0.125
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/batchnorm14/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648976677	98.0
1608170648976678	0.001953125
1608170648976679	0.001953125
1608170648976679	0.000244140625
1608170648976703	0.000244140625
1608170648976938	-0.000244140625
1608170648976938	-0.000244140625
1608170648979904	-98.0
1608170648979940	-0.001953125
1608170648979970	-0.001953125
tower_0/v/cg/resnet_v15/conv19/Relu
tower_0/v/l2_loss/L2Loss_8
1608170648833296	0.000244140625
1608170648833298	0.000244140625
1608170648833344	-0.000244140625
1608170648837213	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v113/conv45/batchnorm45/moving_variance
tower_0/v/l2_loss/L2Loss_6
1608170648834170	0.000244140625
1608170648834171	0.000244140625
1608170648834219	-0.000244140625
1608170648837211	-0.000244140625
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg_1/sub_1
v/cg/resnet_v19/conv31/batchnorm31/moving_mean
v/cg/resnet_v113/conv45/batchnorm45/moving_variance/read
v/cg/resnet_v112/conv40/batchnorm40/gamma
v/cg/resnet_v13/conv14/batchnorm14/moving_mean
tower_0/v/cg/resnet_v114/conv47/Relu
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg/sub_1
v/cg/resnet_v113/conv43/batchnorm43/moving_mean/read
v/cg/resnet_v16/conv23/batchnorm23/moving_variance
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv14/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v12/conv9/batchnorm9/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648989834	0.25
1608170648989841	0.25
1608170648989860	0.00537109375
1608170648990650	-0.00537109375
1608170648990652	-0.25
1608170648991802	-0.25
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg/mul
v/cg/resnet_v15/conv20/batchnorm20/gamma
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_4_grad/mul
1608170648834960	0.0625
1608170649009029	-0.0625
tower_0/v/cg/resnet_v10/conv2/Relu
tower_0/v/cg/resnet_v13/conv13/batchnorm13/FusedBatchNormV3
1608170648848120	24.5
1608170648848121	0.00048828125
1608170648848123	0.00048828125
1608170648848125	0.00048828125
1608170648848126	0.00048828125
1608170648848931	-0.00048828125
1608170648848974	-0.00048828125
1608170648980888	-24.5
1608170648981253	-0.00048828125
1608170648981253	-0.00048828125
v/cg/resnet_v110/conv35/batchnorm35/gamma
v/cg/resnet_v15/conv19/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/batchnorm17/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648968821	98.00390625
1608170648968822	0.001953125
1608170648968823	0.00244140625
1608170648968823	0.000244140625
1608170648968840	0.000244140625
1608170648968908	-0.000244140625
1608170648968908	-0.000244140625
1608170648970865	-98.00390625
1608170648970903	-0.001953125
1608170648970937	-0.00244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648897306	4.00048828125
1608170648897313	7.82080078125
1608170648897329	0.00390625
1608170648897450	-0.00390625
1608170648897452	-7.82080078125
1608170648898516	-4.00048828125
tower_0/v/cg/resnet_v16/conv21/Relu
v/cg/resnet_v14/conv15/batchnorm15/moving_variance/read
v/cg/resnet_v111/conv38/batchnorm38/moving_mean
v/cg/resnet_v10/conv1/batchnorm1/beta/read
tower_0/v/cg/resnet_v111/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv52/batchnorm52/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_2_grad/mul
1608170648833995	0.015625
1608170649015391	-0.015625
learning_rate/PiecewiseConstant/and_2
v/cg/resnet_v112/conv42/batchnorm42/gamma/read
tower_0/v/cg/mpool0/MaxPool
1608170648838062	49.0
1608170649015482	-49.0
tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D
1608170648871183	24.5
1608170648871188	8.0
1608170648871379	0.00048828125
1608170648871442	-0.00048828125
1608170648871444	-8.0
1608170648908455	-24.5
tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D
1608170648843119	196.0
1608170648843125	0.0625
1608170648843177	0.01806640625
1608170648843247	-0.01806640625
1608170648843250	-0.0625
1608170648993963	-196.0
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg
v/cg/resnet_v111/conv37/batchnorm37/moving_mean
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg_1
tower_0/v/cg/resnet_v13/add
v/cg/resnet_v10/conv3/batchnorm3/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv13/batchnorm13/gamma/ApplyGradientDescent
learning_rate/cond/Switch_2
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv38/batchnorm38/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv22/batchnorm22/gamma/ApplyGradientDescent
v/cg/resnet_v12/conv10/batchnorm10/moving_variance/read
append_apply_gradient_ops/GradientDescent/update_v/cg/affine0/weights/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/Relu_grad/ReluGrad
v/cg/resnet_v12/conv10/batchnorm10/beta/read
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv40/batchnorm40/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v12/conv10/conv2d/kernel
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv30/conv2d/kernel/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_35
1608170648835112	0.000244140625
1608170648835124	0.0087890625
1608170648835180	-0.0087890625
1608170648837174	-0.000244140625
tower_0/v/cg/resnet_v115/conv52/batchnorm52/FusedBatchNormV3
1608170648887209	24.5
1608170648887210	0.0078125
1608170648887211	0.0078125
1608170648887212	0.0078125
1608170648887212	0.0078125
1608170648889338	-0.0078125
1608170648889374	-0.0078125
1608170648893163	-24.5
1608170648893364	-0.0078125
1608170648893365	-0.0078125
tower_0/v/cg/resnet_v115/Relu
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648908867	9.0
1608170648908875	9.00048828125
1608170648908892	0.00390625
1608170648909016	-0.00390625
1608170648909019	-9.00048828125
1608170648909618	-9.0
v/cg/resnet_v19/conv33/batchnorm33/moving_mean/read
tower_0/v/cg/resnet_v14/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/batchnorm44/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648910256	7.82080078125
1608170648910257	0.001953125
1608170648910257	0.001953125
1608170648910258	0.000244140625
1608170648910320	0.000244140625
1608170648910383	-0.000244140625
1608170648910384	-0.000244140625
1608170648910734	-7.82080078125
1608170648910773	-0.001953125
1608170648911449	-0.001953125
v/cg/resnet_v18/conv30/batchnorm30/gamma
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/cond/Switch_1
v/cg/resnet_v11/conv7/batchnorm7/moving_mean/read
v/cg/resnet_v11/conv5/batchnorm5/moving_mean/read
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg/mul
tower_0/v/gradients/AddN_69
v/cg/resnet_v110/conv35/batchnorm35/beta/read
v/cg/resnet_v19/conv33/batchnorm33/gamma
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_35_grad/mul
1608170648835200	2.25
1608170648926680	-2.25
tower_0/v/cg/resnet_v14/add
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv51/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648913788	12.25
1608170648913795	4.0
1608170648913819	12.25
1608170648913835	257.296875
1608170648914040	-12.25
1608170648914042	-257.296875
1608170648914043	-4.0
1608170648915218	-12.25
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg_1/sub_1
v/cg/resnet_v113/conv43/batchnorm43/gamma/read
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg_1
tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D
1608170648839212	49.0
1608170648839219	0.140625
1608170648839273	85.046875
1608170648839775	-85.046875
1608170648839779	-0.140625
1608170649009644	-49.0
v/cg/resnet_v113/conv44/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648971169	24.5
1608170648971174	0.5625
1608170648971204	24.501953125
1608170648971217	112.5
1608170648971292	-24.5
1608170648971293	-112.5
1608170648971295	-0.5625
1608170648973957	-24.501953125
v/cg/resnet_v17/conv25/batchnorm25/beta/read
tower_0/v/cg/resnet_v110/conv35/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648933718	14.0009765625
1608170648933724	1.0
1608170648933755	12.25
1608170648933769	0.00341796875
1608170648934726	-14.0009765625
1608170648934728	-0.00341796875
1608170648934730	-1.0
1608170648935187	-12.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv7/batchnorm7/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/batchnorm8/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648991667	49.0
1608170648991668	0.000244140625
1608170648991668	0.000244140625
1608170648991669	0.000244140625
1608170648991687	0.000244140625
1608170648991757	-0.000244140625
1608170648991757	-0.000244140625
1608170648992966	-49.0
1608170648993072	-0.000244140625
1608170648993724	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648991969	0.06298828125
1608170648991975	0.0625
1608170648991987	0.00439453125
1608170648992957	-0.00439453125
1608170648992959	-0.0625
1608170648993849	-0.06298828125
tower_0/v/cg/resnet_v10/conv2/batchnorm2/FusedBatchNormV3
1608170648838697	49.0
1608170648838698	0.000244140625
1608170648838699	0.000244140625
1608170648838700	0.000244140625
1608170648838701	0.000244140625
1608170648840192	-0.000244140625
1608170648840237	-0.000244140625
1608170649012031	-49.0
1608170649013022	-0.000244140625
1608170649013026	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv49/batchnorm49/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv46/batchnorm46/beta/ApplyGradientDescent
learning_rate/PiecewiseConstant/case/LessEqual
v/cg/resnet_v13/conv12/batchnorm12/beta/read
v/cg/resnet_v112/conv42/batchnorm42/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv43/batchnorm43/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv3/Relu
v/cg/resnet_v115/conv50/batchnorm50/beta/read
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv36/batchnorm36/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg_1
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg
v/cg/resnet_v14/conv15/batchnorm15/gamma
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg
tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D
1608170648838395	196.0
1608170648838400	0.0625
1608170648838448	0.01806640625
1608170648838520	-0.01806640625
1608170648838523	-0.0625
1608170649004812	-196.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v115/conv52/conv2d/kernel/read
v/cg/resnet_v15/conv19/batchnorm19/gamma
tower_0/v/gradients/AddN_33
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_16_grad/mul
1608170648832650	0.5625
1608170648973614	-0.5625
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/batchnorm16/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648971007	24.5
1608170648971008	0.000732421875
1608170648971009	0.00048828125
1608170648971009	0.000244140625
1608170648971036	0.000244140625
1608170648971117	-0.000244140625
1608170648971117	-0.000244140625
1608170648973272	-24.5
1608170648973313	-0.000732421875
1608170648973339	-0.00048828125
tower_0/v/cg/resnet_v18/conv30/batchnorm30/FusedBatchNormV3
1608170648858877	49.0
1608170648858879	0.00390625
1608170648858879	0.00390625
1608170648858880	0.00390625
1608170648858881	0.00390625
1608170648859502	-0.00390625
1608170648859544	-0.00390625
1608170648932844	-49.0
1608170648933695	-0.00390625
1608170648933695	-0.00390625
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg/sub_1
v/cg/resnet_v115/conv51/conv2d/kernel/read
tower_0/v/cg/resnet_v12/conv9/Relu
v/cg/resnet_v10/conv2/batchnorm2/gamma
tower_0/v/cg/resnet_v18/conv28/batchnorm28/FusedBatchNormV3
1608170648857790	12.25
1608170648857791	0.0009765625
1608170648857792	0.0009765625
1608170648857792	0.0009765625
1608170648857793	0.0009765625
1608170648858430	-0.0009765625
1608170648858463	-0.0009765625
1608170648937739	-12.25
1608170648938035	-0.0009765625
1608170648938039	-0.0009765625
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_17_grad/mul
1608170648836095	0.25
1608170648970994	-0.25
v/cg/resnet_v10/conv1/batchnorm1/moving_mean
main_fetch_group
v/cg/resnet_v13/conv11/batchnorm11/gamma
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_36_grad/mul
1608170648828998	1.0
1608170648925115	-1.0
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg
learning_rate/Cast_2
tower_0/v/l2_loss/L2Loss_48
1608170648829049	0.000244140625
1608170648829091	0.0087890625
1608170648829194	-0.0087890625
1608170648837185	-0.000244140625
v/cg/resnet_v13/conv14/batchnorm14/moving_variance/read
v/cg/resnet_v10/conv1/batchnorm1/gamma
v/cg/resnet_v111/conv39/batchnorm39/gamma
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v113/conv45/Relu
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v14/conv15/batchnorm15/FusedBatchNormV3
1608170648849547	24.5
1608170648849548	0.00048828125
1608170648849549	0.00048828125
1608170648849550	0.00048828125
1608170648849550	0.00048828125
1608170648850232	-0.00048828125
1608170648850277	-0.00048828125
1608170648973579	-24.5
1608170648973959	-0.00048828125
1608170648973959	-0.00048828125
v/cg/resnet_v18/conv29/batchnorm29/beta
tower_0/v/gradients/AddN_53
v/cg/resnet_v17/conv27/batchnorm27/beta/read
v/cg/resnet_v12/conv10/conv2d/kernel/read
v/cg/resnet_v14/conv16/conv2d/kernel/read
v/cg/resnet_v110/conv34/batchnorm34/moving_mean/read
tower_0/v/cg/resnet_v112/conv41/batchnorm41/FusedBatchNormV3
1608170648866447	12.25
1608170648866449	0.0009765625
1608170648866449	0.0009765625
1608170648866450	0.0009765625
1608170648866451	0.0009765625
1608170648870263	-0.0009765625
1608170648870303	-0.0009765625
1608170648912845	-12.25
1608170648913708	-0.0009765625
1608170648913709	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv21/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v16/conv23/batchnorm23/moving_mean/read
tower_0/v/gradients/AddN
v/cg/resnet_v111/conv39/batchnorm39/beta/read
v/cg/resnet_v16/conv23/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/batchnorm18/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648965712	24.5
1608170648965713	0.000732421875
1608170648965713	0.00048828125
1608170648965714	0.000244140625
1608170648965944	0.000244140625
1608170648966017	-0.000244140625
1608170648966017	-0.000244140625
1608170648967740	-24.5
1608170648967777	-0.000732421875
1608170648968687	-0.00048828125
tower_0/v/cg/resnet_v17/conv26/Relu
v/cg/resnet_v12/conv9/batchnorm9/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648920141	4.0
1608170648920148	4.00048828125
1608170648920162	81.0
1608170648921086	-81.0
1608170648921089	-4.00048828125
1608170648921424	-4.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv10/conv2d/kernel/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_52
1608170648834522	0.000244140625
1608170648834533	0.0087890625
1608170648834588	-0.0087890625
1608170648837205	-0.000244140625
learning_rate/PiecewiseConstant/LessEqual_3
1608170648825082	0.000244140625
1608170648825173	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648939014	1.0
1608170648939021	1.0
1608170648939034	0.00341796875
1608170648940185	-0.00341796875
1608170648940187	-1.0
1608170648940425	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/batchnorm23/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648953837	98.001953125
1608170648953837	0.001953125
1608170648953838	0.001953125
1608170648953839	0.000244140625
1608170648953857	0.000244140625
1608170648953991	-0.000244140625
1608170648953992	-0.000244140625
1608170648955128	-98.001953125
1608170648955195	-0.001953125
1608170648955260	-0.001953125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v13/conv12/batchnorm12/moving_mean/read
v/cg/resnet_v12/conv8/batchnorm8/moving_variance
tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D
1608170648847610	24.5
1608170648847616	0.5625
1608170648847666	112.5
1608170648847857	-112.5
1608170648847860	-0.5625
1608170648981252	-24.5
tower_0/v/cg/resnet_v12/conv8/batchnorm8/FusedBatchNormV3
1608170648844342	49.0
1608170648844344	0.000244140625
1608170648844344	0.000244140625
1608170648844345	0.000244140625
1608170648844346	0.000244140625
1608170648845509	-0.000244140625
1608170648845563	-0.000244140625
1608170648991623	-49.0
1608170648991753	-0.000244140625
1608170648991755	-0.000244140625
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/batchnorm13/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648980963	24.5
1608170648980963	0.000732421875
1608170648980964	0.00048828125
1608170648980965	0.000244140625
1608170648981181	0.000244140625
1608170648981255	-0.000244140625
1608170648981255	-0.000244140625
1608170648983905	-24.5
1608170648983950	-0.000732421875
1608170648983980	-0.00048828125
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/batchnorm21/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648958056	24.5
1608170648958057	0.000732421875
1608170648958057	0.00048828125
1608170648958058	0.000244140625
1608170648958076	0.000244140625
1608170648958155	-0.000244140625
1608170648958155	-0.000244140625
1608170648960144	-24.5
1608170648960179	-0.000732421875
1608170648960211	-0.00048828125
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/Relu_grad/ReluGrad
v/cg/resnet_v113/conv44/conv2d/kernel
v/cg/resnet_v115/conv52/batchnorm52/moving_mean/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_14_grad/mul
1608170648835442	0.25
1608170648980918	-0.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv25/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v12/conv8/batchnorm8/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648984472	0.125
1608170648984479	0.125
1608170648984492	0.00390625
1608170648986094	-0.00390625
1608170648986095	-0.125
1608170648986349	-0.125
tower_0/v/l2_loss/L2Loss_13
1608170648835932	0.000244140625
1608170648835934	0.000244140625
1608170648835977	-0.000244140625
1608170648837133	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/ShapeN-matshapes-1
learning_rate/Cast_3
v/cg/resnet_v113/conv44/batchnorm44/gamma/read
v/cg/resnet_v12/conv8/batchnorm8/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/batchnorm49/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648898527	24.5078125
1608170648898527	0.0078125
1608170648898528	0.0078125
1608170648898529	0.000244140625
1608170648898550	0.000244140625
1608170648898823	-0.000244140625
1608170648898824	-0.000244140625
1608170648900001	-24.5078125
1608170648900048	-0.0078125
1608170648900085	-0.0078125
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_grad/mul
1608170648833790	0.035888671875
1608170649017056	-0.035888671875
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_37_grad/mul
1608170648835890	1.0
1608170648922666	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648934755	1.0
1608170648934762	1.00048828125
1608170648934776	0.00244140625
1608170648934892	-0.00244140625
1608170648934895	-1.00048828125
1608170648936129	-1.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv6/batchnorm6/gamma/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_7
1608170648833188	0.000244140625
1608170648833189	0.000244140625
1608170648833237	-0.000244140625
1608170648837212	-0.000244140625
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v11/conv6/batchnorm6/beta/read
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648993985	49.0
1608170648993990	0.06298828125
1608170648994017	49.0
1608170648994030	0.020263671875
1608170648994117	-49.0
1608170648994119	-0.020263671875
1608170648994120	-0.06298828125
1608170648996509	-49.0
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg_1/mul
v/cg/resnet_v10/conv2/batchnorm2/gamma/read
tower_0/v/l2_loss/AddN
v/cg/resnet_v10/conv1/conv2d/kernel
v/cg/resnet_v19/conv31/batchnorm31/moving_variance/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv27/batchnorm27/beta/ApplyGradientDescent
tower_0/v/gradients/AddN_3
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv6/batchnorm6/beta/ApplyGradientDescent
v/cg/resnet_v12/conv9/batchnorm9/gamma/read
tower_0/v/cg/resnet_v114/add
v/cg/resnet_v10/conv3/batchnorm3/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg/sub_1
v/cg/resnet_v14/conv17/batchnorm17/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/batchnorm1/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170649004727	196.0
1608170649004728	0.0009765625
1608170649004728	0.0009765625
1608170649004729	0.000244140625
1608170649004746	0.000244140625
1608170649004815	-0.000244140625
1608170649004815	-0.000244140625
1608170649006848	-196.0
1608170649006893	-0.0009765625
1608170649006930	-0.0009765625
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg_1
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_27_grad/mul
1608170648831826	1.0
1608170648945417	-1.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg/sub_1
tower_0/v/gradients/AddN_6
v/cg/resnet_v110/conv35/batchnorm35/moving_variance
v/cg/resnet_v110/conv36/conv2d/kernel
tower_0/v/cg/resnet_v10/conv4/batchnorm4/FusedBatchNormV3
1608170648840835	196.0
1608170648840836	0.0009765625
1608170648840837	0.0009765625
1608170648840838	0.0009765625
1608170648840839	0.0009765625
1608170648841255	-196.0
1608170648841734	-0.0009765625
1608170648841769	-0.0009765625
1608170649004935	-0.0009765625
1608170649004936	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv45/batchnorm45/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D
1608170648876973	6.125
1608170648876979	4.0
1608170648877018	0.00048828125
1608170648877847	-0.00048828125
1608170648877850	-4.0
1608170648902617	-6.125
tower_0/v/gradients/AddN_37
tower_0/v/gradients/AddN_63
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/batchnorm45/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648909638	6.125
1608170648909639	0.001953125
1608170648909640	0.001953125
1608170648909641	0.000244140625
1608170648909661	0.000244140625
1608170648909729	-0.000244140625
1608170648909729	-0.000244140625
1608170648910088	-6.125
1608170648910133	-0.001953125
1608170648910167	-0.001953125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_46_grad/mul
1608170648836612	4.0
1608170648909582	-4.0
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg/mul
v/cg/resnet_v11/conv7/batchnorm7/moving_variance/read
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg_1/mul
v/cg/resnet_v10/conv2/conv2d/kernel
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg
v/cg/resnet_v17/conv24/batchnorm24/moving_mean/read
tower_0/v/gradients/AddN_59
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv5/batchnorm5/beta/ApplyGradientDescent
v/cg/resnet_v18/conv29/batchnorm29/beta/read
v/cg/resnet_v18/conv28/batchnorm28/beta/read
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg/sub_1
v/cg/resnet_v17/conv26/conv2d/kernel/read
v/cg/resnet_v115/conv50/batchnorm50/moving_mean/read
tower_0/v/gradients/tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/mul
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648928841	1.0
1608170648928847	1.0
1608170648928861	0.00244140625
1608170648928975	-0.00244140625
1608170648928977	-1.0
1608170648929299	-1.0
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg/sub_1
v/cg/resnet_v110/conv34/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/batchnorm37/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648921267	13.000732421875
1608170648921268	0.0009765625
1608170648921269	0.0009765625
1608170648921270	0.000244140625
1608170648921289	0.000244140625
1608170648921370	-0.000244140625
1608170648921370	-0.000244140625
1608170648922502	-13.000732421875
1608170648922548	-0.0009765625
1608170648922591	-0.0009765625
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg/mul
v/cg/conv0/batchnorm0/moving_mean
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv27/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/Relu_grad/ReluGrad
v/cg/resnet_v114/conv49/batchnorm49/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/batchnorm4/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170649004834	196.0
1608170649004835	0.0009765625
1608170649004835	0.00146484375
1608170649004836	0.000244140625
1608170649004864	0.000244140625
1608170649004937	-0.000244140625
1608170649004937	-0.000244140625
1608170649008401	-196.0
1608170649008437	-0.0009765625
1608170649008463	-0.00146484375
tower_0/v/l2_loss/L2Loss_24
1608170648831472	0.000244140625
1608170648831486	0.0087890625
1608170648831559	-0.0087890625
1608170648837165	-0.000244140625
tower_0/v/gradients/AddN_28
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg/mul
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170649002762	0.0625
1608170649002768	0.0625
1608170649002779	0.00439453125
1608170649004529	-0.00439453125
1608170649004531	-0.0625
1608170649004717	-0.0625
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg/sub_1
tower_0/v/l2_loss/L2Loss_28
1608170648831042	0.000244140625
1608170648831044	0.000244140625
1608170648831111	-0.000244140625
1608170648837168	-0.000244140625
v/cg/resnet_v19/conv33/batchnorm33/beta
v/cg/resnet_v10/conv2/batchnorm2/moving_mean
tower_0/v/cg/resnet_v18/Relu
tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D
1608170648865173	12.25
1608170648865177	2.25
1608170648865227	81.0
1608170648866303	-81.0
1608170648866306	-2.25
1608170648913707	-12.25
tower_0/v/gradients/AddN_26
v/cg/resnet_v13/conv11/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648908595	49.0
1608170648908602	9.0
1608170648908629	49.0
1608170648908836	-49.0
1608170648908839	-9.0
1608170648941376	-49.0
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648969286	0.25
1608170648969292	0.25
1608170648969305	0.00244140625
1608170648970857	-0.00244140625
1608170648970859	-0.25
1608170648971159	-0.25
tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D
1608170648858001	12.25
1608170648858006	2.25
1608170648858050	81.0
1608170648858152	-81.0
1608170648858155	-2.25
1608170648935189	-12.25
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_45_grad/mul
1608170648829392	9.0
1608170648910244	-9.0
v/cg/resnet_v19/conv32/batchnorm32/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv29/batchnorm29/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648963501	24.5
1608170648963506	0.5625
1608170648963527	24.5
1608170648963540	112.5
1608170648963621	-24.5
1608170648963623	-112.5
1608170648963624	-0.5625
1608170648966013	-24.5
tower_0/v/gradients/AddN_39
v/cg/resnet_v110/conv35/conv2d/kernel
v/cg/resnet_v19/conv32/batchnorm32/beta
tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D
1608170648849268	24.5
1608170648849274	0.25
1608170648849327	0.004638671875
1608170648849401	-0.004638671875
1608170648849404	-0.25
1608170648973958	-24.5
v/cg/resnet_v19/conv33/batchnorm33/moving_mean
v/cg/resnet_v11/conv7/batchnorm7/beta
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg_1
tower_0/v/cg/resnet_v111/conv37/Relu
v/cg/resnet_v115/conv51/batchnorm51/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170649002629	196.0
1608170649002634	0.0625
1608170649002661	196.0
1608170649002674	0.020263671875
1608170649002735	-196.0
1608170649002737	-0.020263671875
1608170649002738	-0.0625
1608170649004629	-196.0
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648900983	6.125
1608170648900989	9.00048828125
1608170648901014	7.82080078125
1608170648901029	131.611572265625
1608170648901120	-6.125
1608170648901122	-131.611572265625
1608170648901123	-9.00048828125
1608170648902616	-7.82080078125
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_32_grad/mul
1608170648834852	2.25
1608170648931036	-2.25
v/cg/resnet_v15/conv18/batchnorm18/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv12/batchnorm12/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg_1
v/cg/resnet_v110/conv34/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_8_grad/mul
1608170648833362	0.0625
1608170648993789	-0.0625
tower_0/v/gradients/tower_0/v/cg/resnet_v113/Relu_grad/ReluGrad
v/cg/resnet_v110/conv35/batchnorm35/gamma/read
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v115/conv51/batchnorm51/FusedBatchNormV3
1608170648885968	6.125
1608170648885970	0.001953125
1608170648885970	0.001953125
1608170648885972	0.001953125
1608170648885973	0.001953125
1608170648887336	-0.001953125
1608170648887368	-0.001953125
1608170648894388	-6.125
1608170648894927	-0.001953125
1608170648894929	-0.001953125
v/cg/resnet_v19/conv31/batchnorm31/beta/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv32/batchnorm32/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg/mul
tower_0/v/l2_loss/L2Loss_53
1608170648833407	0.000244140625
1608170648833419	0.0087890625
1608170648833471	-0.0087890625
1608170648837209	-0.000244140625
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Reshape
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648945835	12.25
1608170648945842	2.25048828125
1608170648945871	12.25
1608170648945905	182.25
1608170648946095	-12.25
1608170648946097	-182.25
1608170648946098	-2.25048828125
1608170648951492	-12.25
learning_rate/PiecewiseConstant/case/Cast
1608170648825439	0.000244140625
1608170648825729	-0.000244140625
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg/mul
v/cg/resnet_v11/conv6/conv2d/kernel
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg
tower_0/v/resnet50_synthetic_labels/min
v/cg/resnet_v11/conv7/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/batchnorm2/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170649012933	69.47119140625
1608170649012934	0.000244140625
1608170649012934	0.000244140625
1608170649012935	0.000244140625
1608170649012953	0.000244140625
1608170649013027	-0.000244140625
1608170649013028	-0.000244140625
1608170649014123	-69.47119140625
1608170649014333	-0.000244140625
1608170649014530	-0.000244140625
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg
v/cg/resnet_v110/conv36/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv42/batchnorm42/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv32/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv29/batchnorm29/FusedBatchNormV3
1608170648858300	12.25390625
1608170648858301	0.0009765625
1608170648858302	0.0009765625
1608170648858303	0.0009765625
1608170648858304	0.0009765625
1608170648859007	-0.0009765625
1608170648859042	-0.0009765625
1608170648935017	-12.25390625
1608170648935190	-0.0009765625
1608170648935191	-0.0009765625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv22/batchnorm22/beta/ApplyGradientDescent
v/cg/resnet_v14/conv17/batchnorm17/moving_mean
tower_0/v/gradients/AddN_34
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv42/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/truediv
v/cg/resnet_v112/conv41/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648961336	24.5
1608170648961341	0.25
1608170648961369	24.5
1608170648961381	0.006591796875
1608170648961447	-24.5
1608170648961449	-0.006591796875
1608170648961450	-0.25
1608170648963437	-24.5
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648946129	2.25048828125
1608170648946135	2.25048828125
1608170648946149	122.5
1608170648946545	-122.5
1608170648946546	-2.25048828125
1608170648951540	-2.25048828125
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg_1/sub_1
v/cg/resnet_v17/conv27/batchnorm27/beta
tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D
1608170648852462	98.0
1608170648852472	0.25
1608170648852518	0.004638671875
1608170648852587	-0.004638671875
1608170648852590	-0.25
1608170648961305	-98.0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv37/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv51/batchnorm51/gamma/ApplyGradientDescent
v/cg/resnet_v11/conv7/batchnorm7/moving_variance
v/cg/resnet_v110/conv36/batchnorm36/beta/read
edge_641_learning_rate/PiecewiseConstant/LessEqual@@MemcpyDtoH
v/cg/resnet_v113/conv46/batchnorm46/moving_variance
tower_0/v/gradients/AddN_49
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v115/conv50/batchnorm50/gamma/read
tower_0/v/l2_loss/L2Loss_5
1608170648832946	0.000244140625
1608170648832959	0.000244140625
1608170648833007	-0.000244140625
1608170648837199	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648997071	0.25
1608170648997078	0.140625
1608170648997093	0.00537109375
1608170648997863	-0.00537109375
1608170648997865	-0.140625
1608170649002619	-0.25
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv34/batchnorm34/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648912568	1.0
1608170648912576	1.00048828125
1608170648912593	0.00244140625
1608170648912710	-0.00244140625
1608170648912713	-1.00048828125
1608170648913763	-1.0
tower_0/v/l2_loss/L2Loss_37
1608170648835831	0.000244140625
1608170648835832	0.000244140625
1608170648835875	-0.000244140625
1608170648837175	-0.000244140625
v/cg/resnet_v113/conv44/batchnorm44/beta/read
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv6/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v112/add
v/cg/resnet_v111/conv39/batchnorm39/moving_variance
v/cg/resnet_v113/conv44/batchnorm44/moving_variance
tower_0/v/cg/resnet_v11/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648909953	9.0
1608170648909960	12.00048828125
1608170648909974	98.00390625
1608170648910079	-98.00390625
1608170648910081	-12.00048828125
1608170648910425	-9.0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_25_grad/mul
1608170648830438	0.5
1608170648953754	-0.5
v/cg/resnet_v11/conv6/batchnorm6/moving_mean
v/cg/resnet_v13/conv13/batchnorm13/gamma
tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D
1608170648862864	12.25
1608170648862872	1.0
1608170648862913	0.001953125
1608170648862976	-0.001953125
1608170648862978	-1.0
1608170648921367	-12.25
v/cg/resnet_v13/conv11/batchnorm11/beta/read
tower_0/v/gradients/AddN_20
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg
v/cg/resnet_v19/conv32/conv2d/kernel/read
v/cg/resnet_v10/conv4/batchnorm4/beta/read
tower_0/v/gradients/AddN_46
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_31_grad/mul
1608170648832072	1.0
1608170648932736	-1.0
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/batchnorm6/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648996214	49.0
1608170648996215	0.000244140625
1608170648996216	0.000244140625
1608170648996216	0.000244140625
1608170648996441	0.000244140625
1608170648996514	-0.000244140625
1608170648996514	-0.000244140625
1608170648997871	-49.0
1608170649000562	-0.000244140625
1608170649000597	-0.000244140625
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg/mul
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v111/conv39/batchnorm39/FusedBatchNormV3
1608170648864259	49.0
1608170648864260	0.005859375
1608170648864261	0.00390625
1608170648864262	0.00390625
1608170648864264	0.00390625
1608170648864881	-0.005859375
1608170648864932	-0.00390625
1608170648918406	-49.0
1608170648918560	-0.00390625
1608170648918560	-0.00390625
v/cg/resnet_v115/conv50/batchnorm50/moving_variance
tower_0/v/l2_loss/L2Loss_32
1608170648834769	0.000244140625
1608170648834781	0.0087890625
1608170648834832	-0.0087890625
1608170648837171	-0.000244140625
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg/sub_1
v/cg/resnet_v19/conv32/batchnorm32/moving_mean/read
tower_0/v/cg/resnet_v11/conv6/batchnorm6/FusedBatchNormV3
1608170648842724	49.0
1608170648842725	0.000244140625
1608170648842728	0.000244140625
1608170648842728	0.000244140625
1608170648842729	0.000244140625
1608170648843619	-0.000244140625
1608170648843675	-0.000244140625
1608170648996168	-49.0
1608170648996511	-0.000244140625
1608170648996512	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv23/batchnorm23/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv39/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/batchnorm19/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648963332	24.5
1608170648963332	0.000732421875
1608170648963333	0.00048828125
1608170648963333	0.000244140625
1608170648963351	0.000244140625
1608170648963441	-0.000244140625
1608170648963442	-0.000244140625
1608170648964685	-24.5
1608170648965613	-0.000732421875
1608170648965641	-0.00048828125
v/cg/resnet_v10/conv3/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/batchnorm27/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648940685	49.0
1608170648940686	0.00390625
1608170648940686	0.00390625
1608170648940687	0.000244140625
1608170648940714	0.000244140625
1608170648941381	-0.000244140625
1608170648941381	-0.000244140625
1608170648944075	-49.0
1608170648944146	-0.00390625
1608170648944203	-0.00390625
v/cg/resnet_v115/conv51/batchnorm51/moving_mean
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/batchnorm42/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648911627	49.00390625
1608170648911628	0.004150390625
1608170648911628	0.005859375
1608170648911629	0.000244140625
1608170648911650	0.000244140625
1608170648911745	-0.000244140625
1608170648911745	-0.000244140625
1608170648912720	-49.00390625
1608170648912771	-0.004150390625
1608170648912802	-0.005859375
v/cg/resnet_v12/conv8/batchnorm8/gamma/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_42_grad/mul
1608170648828813	1.0
1608170648912884	-1.0
v/cg/resnet_v15/conv18/batchnorm18/beta/read
v/cg/resnet_v10/conv4/batchnorm4/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648978657	24.5
1608170648978662	0.25
1608170648978685	24.5
1608170648978698	0.006591796875
1608170648978836	-24.5
1608170648978838	-0.006591796875
1608170648978839	-0.25
1608170648981250	-24.5
tower_0/v/gradients/AddN_45
tower_0/v/l2_loss/L2Loss_30
1608170648830515	0.000244140625
1608170648830518	0.000244140625
1608170648830588	-0.000244140625
1608170648837170	-0.000244140625
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/batchnorm3/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170649009068	49.0
1608170649009068	0.000244140625
1608170649009069	0.000244140625
1608170649009069	0.000244140625
1608170649009578	0.000244140625
1608170649009647	-0.000244140625
1608170649009647	-0.000244140625
1608170649011929	-49.0
1608170649011967	-0.000244140625
1608170649011999	-0.000244140625
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv11/conv2d/kernel/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v111/conv38/batchnorm38/gamma
tower_0/v/gradients/AddN_66
v/cg/resnet_v16/conv22/batchnorm22/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/batchnorm15/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648973624	24.5
1608170648973625	0.000732421875
1608170648973625	0.00048828125
1608170648973626	0.000244140625
1608170648973888	0.000244140625
1608170648973961	-0.000244140625
1608170648973961	-0.000244140625
1608170648976319	-24.5
1608170648976356	-0.000732421875
1608170648976398	-0.00048828125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v114/conv49/batchnorm49/beta/read
tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D
1608170648840508	196.0
1608170648840515	0.0625
1608170648840569	0.01806640625
1608170648840646	-0.01806640625
1608170648840650	-0.0625
1608170649004935	-196.0
tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D
1608170648846794	36.740478515625
1608170648846799	0.125
1608170648846849	0.004638671875
1608170648846917	-0.004638671875
1608170648846919	-0.125
1608170648984147	-36.740478515625
tower_0/v/gradients/AddN_40
tower_0/v/l2_loss/L2Loss_44
1608170648832415	0.000244140625
1608170648832428	0.0087890625
1608170648832495	-0.0087890625
1608170648837182	-0.000244140625
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg_1/mul
v/cg/resnet_v18/conv28/batchnorm28/beta
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v13/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648894996	6.125
1608170648895003	9.0
1608170648895032	7.82080078125
1608170648895050	72.0
1608170648895200	-6.125
1608170648895203	-72.0
1608170648895204	-9.0
1608170648897025	-7.82080078125
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg
tower_0/v/gradients/AddN_41
tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D
1608170648875609	24.5
1608170648875613	4.0
1608170648875655	0.00048828125
1608170648875726	-0.00048828125
1608170648875729	-4.0
1608170648908568	-24.5
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg_1
v/cg/resnet_v16/conv23/batchnorm23/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv45/conv2d/kernel/ApplyGradientDescent
tower_0/v/gpu_cached_inputs/read
v/cg/resnet_v111/conv37/batchnorm37/gamma/read
v/cg/resnet_v14/conv16/batchnorm16/gamma/read
tower_0/v/gradients/AddN_29
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv41/batchnorm41/beta/ApplyGradientDescent
v/cg/resnet_v14/conv16/batchnorm16/gamma
v/cg/resnet_v12/conv9/batchnorm9/moving_variance/read
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv44/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv13/conv2d/kernel/ApplyGradientDescent
train_ops_group/NoOp_1
tower_0/v/gradients/AddN_44
v/cg/resnet_v10/conv1/batchnorm1/moving_variance/read
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_39_grad/mul
1608170648836324	1.0
1608170648919660	-1.0
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg/sub_1
tower_0/v/l2_loss/L2Loss_54
1608170648833647	0.000244140625
1608170648837210	-0.000244140625
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg_1/sub_1
learning_rate/cond/Switch_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv4/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D
1608170648842083	49.0
1608170648842090	0.140625
1608170648842145	85.046875
1608170648842540	-85.046875
1608170648842543	-0.140625
1608170648996511	-49.0
v/cg/resnet_v19/conv31/batchnorm31/beta
v/cg/resnet_v113/conv44/batchnorm44/moving_variance/read
tower_0/v/gradients/AddN_14
tower_0/v/cg/resnet_v115/conv50/batchnorm50/FusedBatchNormV3
1608170648884272	6.125
1608170648884273	0.001953125
1608170648884274	0.001953125
1608170648884275	0.001953125
1608170648884275	0.001953125
1608170648886087	-0.001953125
1608170648886122	-0.001953125
1608170648896288	-6.125
1608170648897028	-0.001953125
1608170648897028	-0.001953125
tower_0/v/cg/resnet_v112/conv40/Relu
v/cg/resnet_v17/conv26/conv2d/kernel
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv37/batchnorm37/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v16/Relu
v/cg/resnet_v14/conv15/conv2d/kernel
tower_0/v/gradients/AddN_60
v/cg/resnet_v15/conv20/batchnorm20/moving_mean
v/cg/resnet_v10/conv4/batchnorm4/moving_mean
tower_0/v/cg/resnet_v113/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648989296	49.0
1608170648989301	0.25
1608170648989321	49.0
1608170648989333	85.046875
1608170648989806	-49.0
1608170648989808	-85.046875
1608170648989810	-0.25
1608170648991750	-49.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv23/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/Relu_grad/ReluGrad
v/cg/conv0/conv2d/kernel
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg/sub_1
v/cg/resnet_v17/conv27/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg/mul
v/cg/resnet_v113/conv46/batchnorm46/moving_mean
tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D
1608170648864007	49.0
1608170648864012	1.0
1608170648864052	0.001220703125
1608170648864118	-0.001220703125
1608170648864121	-1.0
1608170648918559	-49.0
tower_0/v/l2_loss/L2Loss_36
1608170648828914	0.000244140625
1608170648828916	0.000244140625
1608170648828978	-0.000244140625
1608170648837175	-0.000244140625
v/cg/resnet_v17/conv24/conv2d/kernel
tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D
1608170648849784	24.5
1608170648849790	0.5625
1608170648849834	112.5
1608170648849937	-112.5
1608170648849941	-0.5625
1608170648971114	-24.5
v/cg/resnet_v15/conv18/batchnorm18/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648925591	2.251220703125
1608170648925598	4.0
1608170648925613	81.0
1608170648926496	-81.0
1608170648926498	-4.0
1608170648926866	-2.251220703125
tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D
1608170648856877	49.0
1608170648856884	1.0
1608170648856925	0.001220703125
1608170648856991	-0.001220703125
1608170648856994	-1.0
1608170648941379	-49.0
v/cg/resnet_v110/conv36/batchnorm36/moving_variance/read
v/cg/resnet_v114/conv47/batchnorm47/moving_mean
v/cg/resnet_v13/conv13/batchnorm13/gamma/read
v/cg/resnet_v114/conv47/batchnorm47/moving_variance
v/cg/resnet_v115/conv50/batchnorm50/moving_mean
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D
1608170648883073	6.125
1608170648883078	4.0
1608170648883117	0.00048828125
1608170648883663	-0.00048828125
1608170648883666	-4.0
1608170648897027	-6.125
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv23/batchnorm23/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648958378	98.0
1608170648958384	0.25
1608170648958406	98.0
1608170648958418	0.006591796875
1608170648958714	-98.0
1608170648958715	-0.006591796875
1608170648958717	-0.25
1608170648961111	-98.0
v/cg/resnet_v17/conv24/batchnorm24/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/batchnorm50/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648896336	9.00048828125
1608170648896337	0.001953125
1608170648896337	0.001953125
1608170648896338	0.000244140625
1608170648896359	0.000244140625
1608170648897030	-0.000244140625
1608170648897030	-0.000244140625
1608170648897459	-9.00048828125
1608170648897502	-0.001953125
1608170648898188	-0.001953125
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg
v/cg/resnet_v13/conv13/conv2d/kernel/read
v/cg/resnet_v12/conv8/batchnorm8/beta
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_6_grad/mul
1608170648834241	0.140625
1608170649000655	-0.140625
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648968936	24.5
1608170648968941	0.25
1608170648968965	24.5
1608170648968977	0.006591796875
1608170648969259	-24.5
1608170648969260	-0.006591796875
1608170648969262	-0.25
1608170648971113	-24.5
v/cg/resnet_v12/conv9/conv2d/kernel
v/cg/resnet_v18/conv29/batchnorm29/moving_mean/read
tower_0/v/cg/resnet_v12/conv9/batchnorm9/FusedBatchNormV3
1608170648845329	49.0
1608170648845330	0.000244140625
1608170648845333	0.000244140625
1608170648845334	0.000244140625
1608170648845334	0.000244140625
1608170648846196	-0.000244140625
1608170648846240	-0.000244140625
1608170648988638	-49.0
1608170648989224	-0.000244140625
1608170648989225	-0.000244140625
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg
v/cg/resnet_v16/conv23/conv2d/kernel/read
v/cg/resnet_v15/conv19/conv2d/kernel
tower_0/v/cg/resnet_v14/conv17/batchnorm17/FusedBatchNormV3
1608170648850738	98.0
1608170648850741	0.001953125
1608170648850744	0.001953125
1608170648850746	0.001953125
1608170648850747	0.001953125
1608170648851469	-0.001953125
1608170648851510	-0.001953125
1608170648968780	-98.0
1608170648968906	-0.001953125
1608170648968906	-0.001953125
v/cg/resnet_v10/conv2/batchnorm2/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv25/batchnorm25/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg_1
v/cg/resnet_v113/conv43/batchnorm43/gamma
v/cg/resnet_v16/conv22/conv2d/kernel/read
tower_0/v/cg/resnet_v14/conv15/Relu
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648966754	0.25
1608170648966760	0.25
1608170648966773	0.00341796875
1608170648967733	-0.00341796875
1608170648967735	-0.25
1608170648968811	-0.25
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv19/batchnorm19/beta/ApplyGradientDescent
v/cg/resnet_v17/conv24/batchnorm24/moving_mean
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg_1
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg/mul
tower_0/v/cg/resnet_v113/add
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg
v/cg/resnet_v16/conv23/batchnorm23/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v15/Relu_grad/ReluGrad
learning_rate/PiecewiseConstant/case/cond/Switch_1
tower_0/v/resnet50_synthetic_labels/max
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/batchnorm12/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608170648984060	24.81591796875
1608170648984061	0.000732421875
1608170648984061	0.00048828125
1608170648984062	0.000244140625
1608170648984080	0.000244140625
1608170648984149	-0.000244140625
1608170648984149	-0.000244140625
1608170648986101	-24.81591796875
1608170648986149	-0.000732421875
1608170648986183	-0.00048828125
v/cg/resnet_v13/conv14/batchnorm14/beta
tower_0/v/cg/resnet_v114/conv49/batchnorm49/Const
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv16/batchnorm16/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v113/conv45/batchnorm45/gamma
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv18/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v13/conv11/batchnorm11/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648974023	98.0
1608170648974028	0.25
1608170648974049	98.0
1608170648974061	0.006591796875
1608170648974387	-98.0
1608170648974389	-0.006591796875
1608170648974390	-0.25
1608170648976432	-98.0
v/cg/resnet_v10/conv3/batchnorm3/moving_variance
v/cg/resnet_v14/conv15/batchnorm15/beta
v/cg/resnet_v10/conv1/batchnorm1/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170649013082	49.0
1608170649013087	0.015625
1608170649013110	49.0
1608170649013124	0.020263671875
1608170649013341	-49.0
1608170649013343	-0.020263671875
1608170649013344	-0.015625
1608170649014724	-49.0
tower_0/v/gradients/AddN_35
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/Conv2DBackpropInput
1608170648991815	196.0
1608170648991820	0.06298828125
1608170648991841	196.0
1608170648991854	0.020263671875
1608170648991940	-196.0
1608170648991942	-0.020263671875
1608170648991943	-0.06298828125
1608170648993757	-196.0
v/cg/resnet_v114/conv49/batchnorm49/moving_mean/read
v/cg/resnet_v111/conv38/batchnorm38/beta/read
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D
1608170648841517	49.0
1608170648841523	0.0625
1608170648841573	0.01806640625
1608170648841649	-0.01806640625
1608170648841652	-0.0625
1608170649002568	-49.0
v/cg/resnet_v111/conv39/conv2d/kernel
v/cg/resnet_v113/conv44/batchnorm44/moving_mean/read
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg_1/mul
v/cg/resnet_v18/conv29/batchnorm29/gamma/read
v/cg/resnet_v111/conv38/batchnorm38/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv1/batchnorm1/gamma/ApplyGradientDescent
tower_0/v/gradients/AddN_16
tower_0/v/gradients/AddN_21
v/cg/resnet_v17/conv26/batchnorm26/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv24/batchnorm24/beta/ApplyGradientDescent
v/cg/resnet_v17/conv25/batchnorm25/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648910594	2.0
1608170648910601	2.0
1608170648910616	0.004150390625
1608170648910726	-0.004150390625
1608170648910728	-2.0
1608170648911615	-2.0
v/cg/resnet_v14/conv15/batchnorm15/moving_mean/read
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg_1
v/cg/resnet_v114/conv49/conv2d/kernel
learning_rate/PiecewiseConstant/case/cond/Merge
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608170648994144	0.06298828125
1608170648994150	0.0625
1608170648994163	0.0029296875
1608170648995170	-0.0029296875
1608170648995172	-0.0625
1608170648996761	-0.06298828125
tower_0/v/gradients/AddN_15
tower_0/v/cg/resnet_v19/conv32/Relu
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg/sub_1
v/cg/resnet_v17/conv27/batchnorm27/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/Relu_grad/ReluGrad
v/cg/resnet_v113/conv45/batchnorm45/beta
tower_0/v/gradients/AddN_67
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_24_grad/mul
1608170648831604	2.0
1608170648945275	-2.0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv20/batchnorm20/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v15/add
v/cg/resnet_v114/conv48/batchnorm48/moving_variance/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_40_grad/mul
1608170648835687	1.0
1608170648918310	-1.0
v/cg/resnet_v19/conv31/batchnorm31/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv9/batchnorm9/gamma/ApplyGradientDescent
v/cg/resnet_v115/conv51/batchnorm51/beta/read
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg_1
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv32/batchnorm32/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv40/batchnorm40/beta/ApplyGradientDescent
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Merge
v/cg/resnet_v111/conv39/batchnorm39/beta
v/cg/resnet_v17/conv24/conv2d/kernel/read
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/control_dependency
