v/cg/resnet_v16/conv23/batchnorm23/beta/read
tower_0/v/cg/resnet_v110/conv34/batchnorm34/FusedBatchNormV3
1608571026475884	12845056
1608571026475885	1024
1608571026475886	1024
1608571026475887	1024
1608571026475888	1024
1608571026476585	-1024
1608571026476631	-1024
1608571026540730	-12845056
1608571026540881	-1024
1608571026540882	-1024
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v11/conv5/batchnorm5/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026607443	65536
1608571026607449	65536
1608571026607461	3072
1608571026608459	-3072
1608571026608461	-65536
1608571026610053	-65536
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv49/batchnorm49/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_17_grad/mul
1608571026448281	262144
1608571026584436	-262144
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026545060	51380224
1608571026545066	1049088
1608571026545138	51380224
1608571026545152	4352
1608571026546091	-51380224
1608571026546093	-4352
1608571026546094	-1049088
1608571026546428	-51380224
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv25/batchnorm25/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D
1608571026471224	51380224
1608571026471229	1048576
1608571026471268	1280
1608571026471328	-1280
1608571026471331	-1048576
1608571026555074	-51380224
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg
v/cg/resnet_v12/conv8/batchnorm8/beta/read
v/cg/resnet_v14/conv16/batchnorm16/gamma
v/cg/resnet_v15/conv18/conv2d/kernel/read
tower_0/v/cg/resnet_v17/conv24/batchnorm24/FusedBatchNormV3
1608571026469988	51380224
1608571026469990	4096
1608571026469990	4096
1608571026469991	4096
1608571026469992	4096
1608571026470843	-4096
1608571026470890	-4096
1608571026554120	-51380224
1608571026554369	-4096
1608571026554369	-4096
v/cg/resnet_v111/conv37/batchnorm37/moving_variance
v/cg/resnet_v114/conv48/batchnorm48/moving_variance
v/cg/resnet_v10/conv1/conv2d/kernel/read
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg/mul
v/cg/resnet_v110/conv34/batchnorm34/moving_variance/read
v/cg/resnet_v15/conv20/batchnorm20/moving_mean/read
tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D
1608571026468791	102760448
1608571026468796	262144
1608571026468837	4864
1608571026468898	-4864
1608571026468901	-262144
1608571026567303	-102760448
v/cg/resnet_v16/conv22/batchnorm22/gamma/read
v/cg/resnet_v10/conv2/batchnorm2/gamma
v/cg/resnet_v114/conv47/conv2d/kernel
tower_0/v/cg/resnet_v13/conv12/batchnorm12/FusedBatchNormV3
1608571026461665	25690112
1608571026461666	512
1608571026461667	512
1608571026461668	512
1608571026461669	512
1608571026462667	-512
1608571026462717	-512
1608571026597378	-25690112
1608571026597534	-512
1608571026597535	-512
v/cg/resnet_v10/conv1/batchnorm1/moving_mean/read
v/cg/resnet_v115/conv52/batchnorm52/beta/read
tower_0/v/cg/resnet_v11/conv5/batchnorm5/FusedBatchNormV3
1608571026456924	51380224
1608571026456926	256
1608571026456926	256
1608571026456927	256
1608571026456928	256
1608571026457870	-256
1608571026457931	-256
1608571026613939	-51380224
1608571026615903	-256
1608571026615904	-256
v/cg/resnet_v112/conv41/batchnorm41/beta
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_43_grad/mul
1608571026451162	8388608
1608571026524991	-8388608
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D
1608571026467627	25690112
1608571026467633	262144
1608571026467672	4864
1608571026467732	-4864
1608571026467735	-262144
1608571026571463	-25690112
tower_0/v/cg/resnet_v14/conv17/batchnorm17/FusedBatchNormV3
1608571026465178	102760448
1608571026465179	2048
1608571026465180	2048
1608571026465181	2048
1608571026465181	2048
1608571026465877	-2048
1608571026465925	-2048
1608571026582187	-102760448
1608571026582322	-2048
1608571026582323	-2048
v/cg/resnet_v15/conv19/batchnorm19/gamma
tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D
1608571026479693	12845056
1608571026479697	2359296
1608571026479740	84934656
1608571026481213	-84934656
1608571026481216	-2359296
1608571026527629	-12845056
tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D
1608571026468150	25690112
1608571026468155	589824
1608571026468196	117964800
1608571026468287	-117964800
1608571026468291	-589824
1608571026569676	-25690112
v/cg/resnet_v18/conv28/batchnorm28/gamma/read
v/cg/resnet_v17/conv25/batchnorm25/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv7/batchnorm7/gamma/ApplyGradientDescent
learning_rate/PiecewiseConstant/case/cond/pred_id
tower_0/v/cg/resnet_v112/conv41/batchnorm41/FusedBatchNormV3
1608571026481355	12845056
1608571026481356	1024
1608571026481357	1024
1608571026481358	1024
1608571026481358	1024
1608571026485156	-1024
1608571026485197	-1024
1608571026527467	-12845056
1608571026527629	-1024
1608571026527634	-1024
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg
v/cg/resnet_v114/conv49/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv16/batchnorm16/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v10/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg_1/mul
v/cg/resnet_v110/conv35/batchnorm35/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/batchnorm34/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026540787	12845056
1608571026540788	1024
1608571026540788	1024
1608571026540789	256
1608571026540807	256
1608571026540884	-256
1608571026540884	-256
1608571026541998	-12845056
1608571026542119	-1024
1608571026542157	-1024
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg/mul
v/cg/resnet_v18/conv29/conv2d/kernel
tower_0/v/cg/affine0/xw_plus_b/MatMul
1608571026504318	256256
1608571026507176	-256256
tower_0/v/gradients/AddN_24
v/cg/resnet_v16/conv21/batchnorm21/moving_variance/read
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg_1/sub_1
v/cg/resnet_v15/conv18/batchnorm18/moving_mean
v/cg/resnet_v15/conv19/conv2d/kernel/read
tower_0/v/cg/resnet_v13/conv11/batchnorm11/FusedBatchNormV3
1608571026461540	102760448
1608571026461541	2048
1608571026461542	2048
1608571026461543	2048
1608571026461544	2048
1608571026462447	-2048
1608571026462491	-2048
1608571026589916	-102760448
1608571026590065	-2048
1608571026590070	-2048
tower_0/v/gradients/AddN_32
tower_0/v/cg/resnet_v18/conv28/Relu
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/AddN_42
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv19/batchnorm19/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg_1
tower_0/v/cg/resnet_v11/add
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv26/batchnorm26/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_39_grad/mul
1608571026450013	1048576
1608571026534180	-1048576
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg_1/sub_1
v/cg/resnet_v11/conv5/batchnorm5/moving_variance
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv17/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v111/conv39/batchnorm39/beta/read
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg_1/sub_1
v/cg/resnet_v13/conv11/batchnorm11/moving_mean
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv33/batchnorm33/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v111/conv39/batchnorm39/FusedBatchNormV3
1608571026478825	51380224
1608571026478826	6144
1608571026478827	4096
1608571026478828	4096
1608571026478829	4096
1608571026479432	-6144
1608571026479476	-4096
1608571026532207	-51380224
1608571026533057	-4096
1608571026533057	-4096
v/cg/resnet_v111/conv37/batchnorm37/moving_mean/read
tower_0/v/gradients/AddN_65
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg/sub_1
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/num_present
v/cg/resnet_v112/conv42/batchnorm42/gamma/read
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v17/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026546122	1049088
1608571026546129	1048576
1608571026546142	4352
1608571026546242	-4352
1608571026546244	-1048576
1608571026547255	-1049088
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv52/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v113/conv45/batchnorm45/beta/read
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/batchnorm11/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026589969	102762496
1608571026589970	2048
1608571026589970	2304
1608571026589971	256
1608571026589996	256
1608571026590071	-256
1608571026590072	-256
1608571026591885	-102762496
1608571026591925	-2048
1608571026591969	-2304
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv51/batchnorm51/beta/ApplyGradientDescent
v/cg/resnet_v14/conv17/batchnorm17/beta
tower_0/v/cg/conv0/batchnorm0/FusedBatchNormV3
1608571026452709	205520896
1608571026452710	256
1608571026452711	256
1608571026452712	256
1608571026452713	256
1608571026453903	-256
1608571026453945	-256
1608571026628908	-205520896
1608571026629003	-256
1608571026629004	-256
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg_1/sub_1
learning_rate/PiecewiseConstant/case/n_true_conds
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/batchnorm47/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026517040	9437696
1608571026517041	2048
1608571026517041	2048
1608571026517042	256
1608571026517066	256
1608571026517336	-256
1608571026517336	-256
1608571026518493	-9437696
1608571026518551	-2048
1608571026518603	-2048
v/cg/resnet_v15/conv20/batchnorm20/gamma/read
v/cg/resnet_v10/conv3/conv2d/kernel
tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D
1608571026453623	51380224
1608571026453628	16384
1608571026453673	18944
1608571026453738	-18944
1608571026453741	-16384
1608571026626387	-51380224
tower_0/v/gradients/AddN_10
v/cg/resnet_v12/conv9/batchnorm9/moving_variance/read
tower_0/v/gradients/AddN_40
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg_1/mul
v/cg/resnet_v10/conv4/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026559345	2359296
1608571026559351	4194816
1608571026559364	128450560
1608571026559819	-128450560
1608571026559821	-4194816
1608571026564947	-2359296
v/cg/resnet_v113/conv44/batchnorm44/moving_mean/read
tower_0/v/cg/resnet_v111/conv37/Relu
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg
tower_0/v/gradients/AddN_9
learning_rate/Cast_4
1608571026436988	256
1608571026630433	-256
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026523932	51380224
1608571026523938	9437440
1608571026523966	51380224
1608571026524241	-51380224
1608571026524244	-9437440
1608571026555071	-51380224
v/cg/resnet_v18/conv30/batchnorm30/gamma
v/cg/resnet_v12/conv8/batchnorm8/moving_mean/read
tower_0/v/cg/resnet_v112/conv40/batchnorm40/FusedBatchNormV3
1608571026479491	12845056
1608571026479492	1024
1608571026479492	1024
1608571026479493	1024
1608571026479494	1024
1608571026482058	-1024
1608571026482094	-1024
1608571026529281	-12845056
1608571026531161	-1024
1608571026531162	-1024
tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D
1608571026464881	102760448
1608571026464886	262144
1608571026464932	4864
1608571026464994	-4864
1608571026464997	-262144
1608571026582321	-102760448
v/cg/resnet_v113/conv43/batchnorm43/moving_variance
v/cg/resnet_v10/conv2/batchnorm2/gamma/read
v/cg/resnet_v13/conv13/batchnorm13/moving_variance/read
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg/sub_1
v/cg/resnet_v17/conv27/conv2d/kernel/read
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv29/batchnorm29/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg_1
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg
v/cg/resnet_v16/conv23/batchnorm23/moving_variance
v/cg/conv0/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/batchnorm40/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026529348	12845056
1608571026529349	1024
1608571026529349	1024
1608571026529350	256
1608571026531067	256
1608571026531164	-256
1608571026531164	-256
1608571026531995	-12845056
1608571026532053	-1024
1608571026532086	-1024
tower_0/v/cg/resnet_v114/add
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv35/batchnorm35/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v16/add
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg/mul
v/cg/resnet_v16/conv21/batchnorm21/beta/read
v/cg/resnet_v13/conv11/batchnorm11/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026616876	65536
1608571026616882	65536
1608571026616895	3072
1608571026617854	-3072
1608571026617856	-65536
1608571026618087	-65536
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv6/batchnorm6/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v112/add
tower_0/v/l2_loss/L2Loss_31
1608571026448474	256
1608571026448475	256
1608571026448523	-256
1608571026452144	-256
v/cg/resnet_v111/conv37/conv2d/kernel
v/cg/resnet_v16/conv22/batchnorm22/beta/read
v/cg/resnet_v110/conv36/batchnorm36/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/batchnorm45/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026525118	8200192
1608571026525119	2048
1608571026525120	2048
1608571026525120	256
1608571026525139	256
1608571026525199	-256
1608571026525200	-256
1608571026525540	-8200192
1608571026525590	-2048
1608571026525623	-2048
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv41/batchnorm41/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026543230	14944256
1608571026543236	4194816
1608571026543257	12845056
1608571026543271	191102976
1608571026543351	-14944256
1608571026543353	-191102976
1608571026543355	-4194816
1608571026544972	-12845056
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v13/conv14/batchnorm14/FusedBatchNormV3
1608571026463170	102760448
1608571026463171	2048
1608571026463172	2048
1608571026463173	2048
1608571026463174	2048
1608571026463436	-102760448
1608571026463909	-2048
1608571026463954	-2048
1608571026590357	-2048
1608571026590358	-2048
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/batchnorm33/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026542334	51384320
1608571026542335	4352
1608571026542335	6144
1608571026542336	256
1608571026542402	256
1608571026542560	-256
1608571026542560	-256
1608571026542864	-51384320
1608571026542912	-4352
1608571026542941	-6144
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg/sub_1
learning_rate/PiecewiseConstant/case/LessEqual
v/cg/resnet_v115/conv51/batchnorm51/beta/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_21_grad/mul
1608571026447758	262144
1608571026574463	-262144
tower_0/v/gradients/AddN_14
tower_0/v/gradients/AddN_7
v/cg/resnet_v13/conv12/batchnorm12/moving_mean/read
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026534665	3146496
1608571026534671	4194816
1608571026534685	84934656
1608571026534776	-84934656
1608571026534778	-4194816
1608571026535922	-3146496
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v18/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv27/batchnorm27/gamma/ApplyGradientDescent
v/cg/resnet_v16/conv22/batchnorm22/beta
tower_0/v/cg/resnet_v13/Relu
v/cg/resnet_v113/conv45/batchnorm45/moving_mean
v/cg/resnet_v11/conv5/batchnorm5/moving_variance/read
tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D
1608571026477958	12845056
1608571026477963	2359296
1608571026478000	84934656
1608571026478087	-84934656
1608571026478090	-2359296
1608571026534414	-12845056
v/cg/resnet_v18/conv29/batchnorm29/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv46/batchnorm46/gamma/ApplyGradientDescent
v/cg/resnet_v115/conv50/batchnorm50/moving_variance/read
tower_0/v/l2_loss/L2Loss_30
1608571026450217	256
1608571026450219	256
1608571026450264	-256
1608571026452144	-256
v/cg/resnet_v16/conv23/batchnorm23/moving_variance/read
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv1/batchnorm1/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_53_grad/mul
1608571026445501	8200192
1608571026507388	-8200192
tower_0/v/cg/resnet_v115/conv50/batchnorm50/FusedBatchNormV3
1608571026499036	6422528
1608571026499037	2048
1608571026499038	2048
1608571026499039	2048
1608571026499039	2048
1608571026500870	-2048
1608571026500924	-2048
1608571026511034	-6422528
1608571026511751	-2048
1608571026511752	-2048
v/cg/resnet_v16/conv23/conv2d/kernel/read
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/batchnorm19/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026576818	25690112
1608571026576818	512
1608571026576819	512
1608571026576820	256
1608571026576840	256
1608571026576913	-256
1608571026576913	-256
1608571026578084	-25690112
1608571026579014	-512
1608571026579054	-512
v/cg/resnet_v17/conv24/batchnorm24/moving_mean/read
tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D
1608571026477471	12845056
1608571026477476	1048576
1608571026477513	2048
1608571026477570	-2048
1608571026477572	-1048576
1608571026535867	-12845056
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026551066	4194816
1608571026551072	4194816
1608571026551086	84934656
1608571026551291	-84934656
1608571026551293	-4194816
1608571026551877	-4194816
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv23/batchnorm23/beta/ApplyGradientDescent
v/cg/resnet_v115/conv50/batchnorm50/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026525267	9437440
1608571026525272	9437696
1608571026525295	6422528
1608571026525309	75497472
1608571026525385	-9437440
1608571026525388	-75497472
1608571026525389	-9437696
1608571026525816	-6422528
tower_0/v/cg/resnet_v17/conv27/batchnorm27/FusedBatchNormV3
1608571026471473	51380224
1608571026471474	6144
1608571026471475	4096
1608571026471476	4096
1608571026471476	4096
1608571026471679	-51380224
1608571026472129	-6144
1608571026472176	-4096
1608571026555074	-4096
1608571026555075	-4096
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv2/batchnorm2/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg
v/cg/resnet_v113/conv45/conv2d/kernel
tower_0/v/cg/resnet_v10/conv3/batchnorm3/FusedBatchNormV3
1608571026455343	51380224
1608571026455344	256
1608571026455345	256
1608571026455346	256
1608571026455347	256
1608571026456256	-256
1608571026456293	-256
1608571026622352	-51380224
1608571026623542	-256
1608571026623543	-256
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026626719	16384
1608571026626725	16384
1608571026626737	3072
1608571026627649	-3072
1608571026627651	-16384
1608571026628875	-16384
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/batchnorm1/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026618107	205520896
1608571026618108	1024
1608571026618108	1024
1608571026618109	256
1608571026618126	256
1608571026618234	-256
1608571026618235	-256
1608571026620190	-205520896
1608571026620234	-1024
1608571026620275	-1024
v/cg/resnet_v113/conv43/batchnorm43/moving_mean/read
v/cg/resnet_v13/conv13/conv2d/kernel
tower_0/v/gradients/AddN_66
v/cg/resnet_v13/conv12/batchnorm12/moving_variance
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv48/batchnorm48/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026567463	262144
1608571026567469	262144
1608571026567482	2560
1608571026568443	-2560
1608571026568446	-262144
1608571026569733	-262144
v/cg/resnet_v111/conv39/batchnorm39/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v12/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026517408	25698304
1608571026517413	4194816
1608571026517436	25690112
1608571026517450	4096
1608571026517571	-25698304
1608571026517573	-4096
1608571026517574	-4194816
1608571026518662	-25690112
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_41_grad/mul
1608571026450590	2359296
1608571026529323	-2359296
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/batchnorm5/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026615809	51380224
1608571026615810	256
1608571026615810	256
1608571026615811	256
1608571026615829	256
1608571026615906	-256
1608571026615906	-256
1608571026617862	-51380224
1608571026617912	-256
1608571026617941	-256
tower_0/v/gradients/AddN_18
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg_1/sub_1
v/cg/resnet_v111/conv39/batchnorm39/moving_variance
v/cg/resnet_v17/conv25/batchnorm25/moving_variance/read
v/cg/resnet_v11/conv7/batchnorm7/gamma/read
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv28/batchnorm28/gamma/ApplyGradientDescent
v/cg/resnet_v18/conv28/batchnorm28/beta/read
v/cg/resnet_v13/conv14/batchnorm14/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv8/batchnorm8/gamma/ApplyGradientDescent
v/cg/resnet_v110/conv35/batchnorm35/moving_variance/read
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg_1/mul
v/cg/resnet_v19/conv32/conv2d/kernel
v/cg/resnet_v114/conv47/conv2d/kernel/read
v/cg/resnet_v17/conv24/batchnorm24/moving_variance
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026624508	147456
1608571026624514	147456
1608571026624526	5632
1608571026625248	-5632
1608571026625250	-147456
1608571026626450	-147456
tower_0/v/l2_loss/L2Loss_21
1608571026447692	256
1608571026447693	256
1608571026447733	-256
1608571026452125	-256
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/batchnorm20/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026574575	102762496
1608571026574576	2048
1608571026574577	2048
1608571026574577	256
1608571026574595	256
1608571026574669	-256
1608571026574669	-256
1608571026575864	-102762496
1608571026576617	-2048
1608571026576721	-2048
tower_0/v/cg/resnet_v19/conv31/Relu
v/cg/resnet_v114/conv47/batchnorm47/moving_mean/read
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v17/Relu
v/cg/resnet_v19/conv31/batchnorm31/beta
v/cg/resnet_v113/conv44/batchnorm44/beta/read
tower_0/v/cg/resnet_v111/Relu
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg_1/mul
v/cg/resnet_v15/conv20/batchnorm20/moving_mean
tower_0/v/cg/resnet_v114/conv47/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026528324	12845056
1608571026528330	4194816
1608571026528357	16778240
1608571026528385	231256064
1608571026528621	-12845056
1608571026528623	-231256064
1608571026528624	-4194816
1608571026531159	-16778240
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg_1
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v115/conv51/batchnorm51/FusedBatchNormV3
1608571026500729	6422528
1608571026500730	2048
1608571026500731	2048
1608571026500732	2048
1608571026500732	2048
1608571026502103	-2048
1608571026502147	-2048
1608571026509137	-6422528
1608571026509437	-2048
1608571026509438	-2048
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v14/conv16/batchnorm16/moving_variance
v/cg/resnet_v113/conv43/conv2d/kernel/read
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Switch
v/cg/resnet_v111/conv38/batchnorm38/moving_variance/read
v/cg/resnet_v17/conv25/conv2d/kernel
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg_1/mul
tower_0/v/cg/mpool0/MaxPool
1608571026453225	51380224
1608571026628835	-51380224
tower_0/v/gradients/AddN_1
v/cg/resnet_v15/conv19/batchnorm19/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026512040	4194816
1608571026512046	8200192
1608571026512061	4096
1608571026512170	-4096
1608571026512173	-8200192
1608571026513237	-4194816
v/cg/resnet_v111/conv38/conv2d/kernel
tower_0/v/gradients/AddN_25
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg_1
v/cg/resnet_v15/conv19/batchnorm19/moving_variance/read
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg_1/sub_1
tower_0/v/gradients/AddN_28
tower_0/v/cg/resnet_v11/Relu
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026605281	65536
1608571026605287	65536
1608571026605300	3072
1608571026606328	-3072
1608571026606331	-65536
1608571026607177	-65536
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D
1608571026499483	6422528
1608571026499487	9437184
1608571026499523	75497472
1608571026500411	-75497472
1608571026500414	-9437184
1608571026509437	-6422528
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg/sub_1
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Assert/Switch_1
tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D
1608571026490443	25690112
1608571026490447	4194304
1608571026490484	512
1608571026490545	-512
1608571026490548	-4194304
1608571026523883	-25690112
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v12/conv9/batchnorm9/FusedBatchNormV3
1608571026459914	51380224
1608571026459915	256
1608571026459916	256
1608571026459917	256
1608571026459918	256
1608571026460717	-256
1608571026460763	-256
1608571026601936	-51380224
1608571026602515	-256
1608571026602516	-256
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg_1
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg_1/sub_1
v/cg/resnet_v113/conv46/batchnorm46/gamma
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg
v/cg/resnet_v13/conv11/batchnorm11/gamma
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/AddN_17
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_29_grad/mul
1608571026444771	2359296
1608571026551567	-2359296
edge_544_learning_rate/PiecewiseConstant/case/Cast@@MemcpyDtoH
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v112/conv40/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/affine0/biases/ApplyGradientDescent
v/cg/resnet_v112/conv41/batchnorm41/moving_variance
v/cg/resnet_v10/conv3/batchnorm3/gamma
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg_1/sub_1
v/cg/resnet_v14/conv15/batchnorm15/moving_variance
tower_0/v/gradients/tower_0/v/cg/affine0/xw_plus_b/MatMul_grad/MatMul_1
1608571026507140	8200192
1608571026507624	-8200192
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_3_grad/mul
1608571026444207	147456
1608571026626274	-147456
tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D
1608571026478567	51380224
1608571026478572	1048576
1608571026478609	1280
1608571026478665	-1280
1608571026478668	-1048576
1608571026533056	-51380224
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026602584	51380224
1608571026602589	262144
1608571026602614	71114240
1608571026602627	89178112
1608571026603068	-51380224
1608571026603070	-89178112
1608571026603072	-262144
1608571026605070	-71114240
v/cg/resnet_v16/conv21/conv2d/kernel/read
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg_1/sub_1
v/cg/resnet_v13/conv13/conv2d/kernel/read
v/cg/conv0/batchnorm0/moving_mean/read
tower_0/v/cg/resnet_v115/conv50/Relu
v/cg/resnet_v115/conv52/batchnorm52/moving_mean
v/cg/resnet_v110/conv34/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026552797	1049088
1608571026552803	1048576
1608571026552816	4352
1608571026553898	-4352
1608571026553900	-1048576
1608571026554160	-1049088
v/cg/resnet_v13/conv14/batchnorm14/beta/read
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv16/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v17/conv26/batchnorm26/moving_mean/read
tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D
1608571026475616	12845056
1608571026475621	1048576
1608571026475664	2048
1608571026475723	-2048
1608571026475725	-1048576
1608571026540881	-12845056
v/cg/resnet_v112/conv42/batchnorm42/moving_variance
tower_0/v/l2_loss/L2Loss_28
1608571026448102	256
1608571026448103	256
1608571026448144	-256
1608571026452138	-256
tower_0/v/cg/conv0/conv2d/Conv2D
1608571026452234	205520896
1608571026452251	37632
1608571026452417	75520
1608571026452581	-75520
1608571026452587	-37632
1608571026629003	-205520896
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v17/conv26/batchnorm26/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/Relu_grad/ReluGrad
v/cg/resnet_v113/conv43/batchnorm43/gamma
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_2_grad/mul
1608571026445735	16384
1608571026628740	-16384
v/cg/resnet_v10/conv1/conv2d/kernel
learning_rate/cond/Switch_1
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg/mul
v/cg/resnet_v18/conv30/batchnorm30/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026567329	25690112
1608571026567335	262144
1608571026567358	28054528
1608571026567371	6912
1608571026567433	-25690112
1608571026567435	-6912
1608571026567437	-262144
1608571026569675	-28054528
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv48/conv2d/kernel/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v14/Relu
v/cg/resnet_v113/conv45/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg_1/sub_1
v/cg/resnet_v18/conv30/conv2d/kernel
ConstantFolding/average_loss/Mean/input_const_axis
v/cg/resnet_v110/conv34/batchnorm34/gamma/read
tower_0/v/resnet50_synthetic_labels/shape
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v111/add
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv31/batchnorm31/beta/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v12/conv8/batchnorm8/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026605150	205520896
1608571026605156	65536
1608571026605179	205520896
1608571026605192	21248
1608571026605251	-205520896
1608571026605253	-21248
1608571026605254	-65536
1608571026607062	-205520896
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_28_grad/mul
1608571026448171	1048576
1608571026554085	-1048576
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v12/conv8/batchnorm8/moving_variance
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026543394	4194816
1608571026543400	4194816
1608571026543414	84934656
1608571026543668	-84934656
1608571026543671	-4194816
1608571026545041	-4194816
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/batchnorm46/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026523799	25690112
1608571026523800	8192
1608571026523801	8192
1608571026523801	256
1608571026523824	256
1608571026523886	-256
1608571026523886	-256
1608571026524859	-25690112
1608571026524909	-8192
1608571026524957	-8192
v/cg/resnet_v10/conv2/batchnorm2/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv42/batchnorm42/beta/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D
1608571026493927	6422528
1608571026493931	9437184
1608571026493971	75497472
1608571026494348	-75497472
1608571026494351	-9437184
1608571026514967	-6422528
tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D
1608571026472458	12845056
1608571026472463	2359296
1608571026472503	84934656
1608571026472596	-84934656
1608571026472599	-2359296
1608571026548963	-12845056
v/cg/resnet_v11/conv5/batchnorm5/beta
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg_1
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026538201	1048576
1608571026538207	1048576
1608571026538220	2560
1608571026538447	-2560
1608571026538450	-1048576
1608571026539586	-1048576
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026603095	262144
1608571026603101	262144
1608571026603114	5632
1608571026603927	-5632
1608571026603929	-262144
1608571026605126	-262144
v/cg/resnet_v19/conv31/batchnorm31/moving_mean/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_23_grad/mul
1608571026448422	262144
1608571026569313	-262144
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg_1/sub_1
v/cg/resnet_v10/conv1/batchnorm1/moving_variance
tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D
1608571026465660	25690112
1608571026465665	262144
1608571026465704	4864
1608571026465764	-4864
1608571026465767	-262144
1608571026579420	-25690112
tower_0/v/cg/resnet_v15/conv18/Relu
tower_0/v/cg/resnet_v10/Relu
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v13/conv12/batchnorm12/gamma/read
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg
v/cg/resnet_v11/conv7/batchnorm7/beta
v/cg/resnet_v19/conv31/batchnorm31/beta/read
v/cg/resnet_v18/conv29/batchnorm29/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/Relu_grad/ReluGrad
v/cg/resnet_v10/conv1/batchnorm1/moving_variance/read
tower_0/v/gradients/tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/ExpandDims
v/cg/resnet_v114/conv49/batchnorm49/moving_mean
_SOURCE
v/cg/resnet_v17/conv27/batchnorm27/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026513766	4194816
1608571026513773	8200192
1608571026513787	4096
1608571026514660	-4096
1608571026514662	-8200192
1608571026515583	-4194816
v/cg/resnet_v115/conv52/conv2d/kernel/read
v/cg/resnet_v10/conv4/batchnorm4/gamma/read
v/cg/resnet_v16/conv22/conv2d/kernel/read
v/cg/resnet_v14/conv17/conv2d/kernel/read
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv32/batchnorm32/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026591084	589824
1608571026591090	589824
1608571026591103	2560
1608571026591876	-2560
1608571026591878	-589824
1608571026594290	-589824
tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D
1608571026474330	12845056
1608571026474334	2359296
1608571026474378	84934656
1608571026474467	-84934656
1608571026474470	-2359296
1608571026543156	-12845056
v/cg/resnet_v115/conv50/batchnorm50/moving_variance
v/cg/resnet_v112/conv41/batchnorm41/gamma
v/cg/resnet_v12/conv10/batchnorm10/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v110/Relu_grad/ReluGrad
v/cg/resnet_v11/conv6/batchnorm6/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v112/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv49/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/batchnorm18/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026579144	25690112
1608571026579145	512
1608571026579146	512
1608571026579146	256
1608571026579347	256
1608571026579426	-256
1608571026579426	-256
1608571026581142	-25690112
1608571026581192	-512
1608571026582087	-512
learning_rate/PiecewiseConstant/Greater_2
1608571026438002	256
1608571026439192	-256
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/AddN_37
v/cg/resnet_v114/conv48/batchnorm48/beta
v/cg/resnet_v14/conv16/conv2d/kernel
v/cg/resnet_v115/conv50/conv2d/kernel/read
tower_0/v/l2_loss/L2Loss_5
1608571026446777	256
1608571026446779	256
1608571026446823	-256
1608571026452163	-256
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_32_grad/mul
1608571026450443	2359296
1608571026544006	-2359296
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv51/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg
v/cg/resnet_v15/conv20/batchnorm20/moving_variance/read
tower_0/v/gradients/AddN_38
v/cg/resnet_v11/conv5/conv2d/kernel
tower_0/v/gradients/AddN_27
append_apply_gradient_ops/GradientDescent/update_v/cg/conv0/batchnorm0/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v15/conv19/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv11/batchnorm11/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v115/conv52/batchnorm52/FusedBatchNormV3
1608571026501988	25690112
1608571026501988	12288
1608571026501989	8192
1608571026501990	8192
1608571026501991	8192
1608571026504094	-12288
1608571026504127	-8192
1608571026507920	-25690112
1608571026508113	-8192
1608571026508114	-8192
tower_0/v/l2_loss/L2Loss_47
1608571026450658	256
1608571026450669	9216
1608571026450722	-9216
1608571026452161	-256
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_18_grad/mul
1608571026445855	262144
1608571026582153	-262144
learning_rate/PiecewiseConstant/LessEqual
1608571026438241	256
1608571026439188	-256
v/cg/resnet_v11/conv5/batchnorm5/beta/read
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg_1
edge_526_learning_rate/Less@@MemcpyDtoH
tower_0/v/l2_loss/L2Loss_34
1608571026450814	256
1608571026450816	256
1608571026450857	-256
1608571026452149	-256
v/cg/resnet_v115/conv52/batchnorm52/moving_variance/read
learning_rate/cond/Switch_2
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/Relu_grad/ReluGrad
tower_0/v/l2_loss/L2Loss_25
1608571026447970	256
1608571026447971	256
1608571026448017	-256
1608571026452129	-256
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026599793	71048448
1608571026599798	65536
1608571026599822	51380224
1608571026599835	21248
1608571026599902	-71048448
1608571026599905	-21248
1608571026599906	-65536
1608571026602512	-51380224
v/cg/resnet_v16/conv22/batchnorm22/moving_mean
v/cg/conv0/batchnorm0/beta/read
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv52/batchnorm52/beta/ApplyGradientDescent
v/cg/resnet_v115/conv52/batchnorm52/gamma
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv14/batchnorm14/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/batchnorm12/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026597441	25690112
1608571026597441	512
1608571026597442	512
1608571026597442	256
1608571026597463	256
1608571026597538	-256
1608571026597538	-256
1608571026599426	-25690112
1608571026599475	-512
1608571026599515	-512
learning_rate/Const_4
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/Relu_grad/ReluGrad
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/Mul
tower_0/v/l2_loss/L2Loss_33
1608571026448880	256
1608571026448882	256
1608571026448925	-256
1608571026452148	-256
v/cg/resnet_v10/conv4/batchnorm4/gamma
v/cg/resnet_v12/conv8/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v115/Relu_grad/ReluGrad
v/cg/resnet_v10/conv4/batchnorm4/moving_mean/read
v/cg/resnet_v14/conv16/batchnorm16/moving_mean/read
v/cg/resnet_v14/conv16/batchnorm16/beta/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/AddN_29
tower_0/v/cg/resnet_v10/conv3/Relu
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg_1/mul
tower_0/v/gradients/AddN_48
v/cg/resnet_v10/conv2/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/conv0/batchnorm0/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026628920	256901120
1608571026628921	256
1608571026628921	256
1608571026628922	256
1608571026628939	256
1608571026629010	-256
1608571026629010	-256
1608571026629220	-256901120
1608571026630301	-256
1608571026630343	-256
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/batchnorm41/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026527532	12845056
1608571026527533	1024
1608571026527533	1024
1608571026527534	256
1608571026527554	256
1608571026527638	-256
1608571026527638	-256
1608571026529142	-12845056
1608571026529200	-1024
1608571026529240	-1024
tower_0/v/cg/resnet_v114/conv49/batchnorm49/Const
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026509959	9437184
1608571026509966	9437184
1608571026509982	75497472
1608571026510887	-75497472
1608571026510890	-9437184
1608571026511858	-9437184
tower_0/v/l2_loss/L2Loss_23
1608571026448337	256
1608571026448338	256
1608571026448392	-256
1608571026452127	-256
v/cg/resnet_v112/conv42/batchnorm42/moving_mean
tower_0/v/l2_loss/L2Loss_1
1608571026445556	256
1608571026445558	256
1608571026445598	-256
1608571026452114	-256
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv20/batchnorm20/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D
1608571026459384	51380224
1608571026459390	147456
1608571026459436	89178112
1608571026459719	-89178112
1608571026459723	-147456
1608571026602514	-51380224
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_48_grad/mul
1608571026448692	9437184
1608571026517022	-9437184
tower_0/v/cg/resnet_v11/conv7/batchnorm7/FusedBatchNormV3
1608571026458386	205520896
1608571026458387	1024
1608571026458388	1024
1608571026458389	1024
1608571026458390	1024
1608571026459058	-1024
1608571026459096	-1024
1608571026607144	-205520896
1608571026607284	-1024
1608571026607284	-1024
learning_rate/PiecewiseConstant/case/cond/cond/cond/Switch/Switch
v/cg/resnet_v111/conv37/batchnorm37/moving_variance/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv15/batchnorm15/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_36_grad/mul
1608571026449611	1048576
1608571026539411	-1048576
v/cg/resnet_v17/conv27/batchnorm27/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv13/conv2d/kernel/ApplyGradientDescent
tower_0/v/transpose/perm
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/batchnorm24/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026554177	51380224
1608571026554178	4352
1608571026554178	6144
1608571026554179	256
1608571026554210	256
1608571026554372	-256
1608571026554373	-256
1608571026556305	-51380224
1608571026556353	-4352
1608571026556402	-6144
tower_0/v/gradients/tower_0/v/cg/conv0/Relu_grad/ReluGrad
tower_0/v/l2_loss/L2Loss_15
1608571026448742	256
1608571026448744	256
1608571026448788	-256
1608571026452120	-256
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg_1
tower_0/v/cg/resnet_v12/Relu
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v19/conv31/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026597598	205520896
1608571026597607	261632
1608571026597627	282599424
1608571026597786	-205520896
1608571026597788	-261632
1608571026599552	-282599424
v/cg/resnet_v19/conv33/batchnorm33/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/Relu_grad/ReluGrad
v/cg/resnet_v115/conv50/batchnorm50/beta/read
v/cg/resnet_v14/conv16/batchnorm16/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv34/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v17/conv27/batchnorm27/gamma
v/cg/resnet_v16/conv22/batchnorm22/moving_variance/read
v/cg/resnet_v18/conv29/conv2d/kernel/read
v/cg/resnet_v110/conv35/batchnorm35/moving_variance
v/cg/resnet_v17/conv24/batchnorm24/gamma/read
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/cond/Switch/Switch
tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D
1608571026482221	51380224
1608571026482226	1048576
1608571026483835	1280
1608571026483893	-1280
1608571026483896	-1048576
1608571026526532	-51380224
tower_0/v/gradients/tower_0/v/cg/resnet_v111/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv26/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv9/Relu
v/cg/resnet_v18/conv30/batchnorm30/moving_variance
tower_0/v/gradients/AddN_31
v/cg/resnet_v10/conv3/batchnorm3/moving_mean
v/cg/resnet_v114/conv48/batchnorm48/moving_variance/read
tower_0/v/cg/resnet_v110/conv35/Relu
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg/mul
v/cg/resnet_v18/conv28/batchnorm28/beta
v/cg/resnet_v110/conv36/batchnorm36/moving_variance/read
v/cg/resnet_v18/conv28/batchnorm28/moving_variance/read
v/cg/resnet_v114/conv48/batchnorm48/gamma
v/cg/resnet_v14/conv15/conv2d/kernel/read
edge_641_learning_rate/PiecewiseConstant/LessEqual@@MemcpyDtoH
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv13/batchnorm13/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_37_grad/mul
1608571026449087	1048576
1608571026537049	-1048576
tower_0/v/gradients/tower_0/v/cg/resnet_v16/Relu_grad/ReluGrad
tower_0/v/l2_loss/L2Loss_38
1608571026450928	256
1608571026450940	9216
1608571026450993	-9216
1608571026452154	-256
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv33/batchnorm33/gamma/ApplyGradientDescent
v/cg/resnet_v19/conv32/batchnorm32/beta
v/cg/resnet_v19/conv33/batchnorm33/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv9/batchnorm9/gamma/ApplyGradientDescent
v/cg/resnet_v12/conv8/batchnorm8/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v17/conv25/Relu
tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D
1608571026471919	12845056
1608571026471924	1048576
1608571026471968	2048
1608571026472029	-2048
1608571026472032	-1048576
1608571026551816	-12845056
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_14_grad/mul
1608571026446474	262144
1608571026594258	-262144
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv31/batchnorm31/gamma/ApplyGradientDescent
v/cg/resnet_v12/conv9/batchnorm9/moving_variance
train_ops_group/NoOp_1
v/cg/resnet_v19/conv32/batchnorm32/gamma/read
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Tile
1608571026507536	25690112
1608571026523881	-25690112
v/cg/resnet_v111/conv39/conv2d/kernel
tower_0/v/l2_loss/L2Loss_4
1608571026444283	256
1608571026444285	256
1608571026444332	-256
1608571026452156	-256
learning_rate/PiecewiseConstant/Greater_1
1608571026438778	256
1608571026439486	-256
v/cg/resnet_v13/conv14/conv2d/kernel
v/cg/resnet_v17/conv26/batchnorm26/gamma/read
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg/mul
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg_1/sub_1
v/cg/resnet_v115/conv50/conv2d/kernel
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg/sub_1
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/Const_1
v/cg/resnet_v114/conv49/conv2d/kernel
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026574704	25690112
1608571026574709	262144
1608571026574732	28054528
1608571026574747	6912
1608571026574808	-25690112
1608571026574810	-6912
1608571026574811	-262144
1608571026576906	-28054528
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026526569	16778240
1608571026526575	1048576
1608571026526600	12845056
1608571026526614	3584
1608571026527085	-16778240
1608571026527088	-3584
1608571026527089	-1048576
1608571026527627	-12845056
tower_0/v/gradients/AddN_52
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026618392	51380224
1608571026618398	65536
1608571026618486	74169088
1608571026618504	21248
1608571026619226	-51380224
1608571026619228	-21248
1608571026619229	-65536
1608571026628836	-74169088
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026536728	1048576
1608571026536734	1048576
1608571026536748	4096
1608571026536873	-4096
1608571026536886	-1048576
1608571026537125	-1048576
v/cg/resnet_v110/conv34/batchnorm34/moving_variance
v/cg/resnet_v12/conv9/batchnorm9/moving_mean/read
tower_0/v/l2_loss/L2Loss_11
1608571026446268	256
1608571026446270	256
1608571026446310	-256
1608571026452117	-256
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg/mul
v/cg/resnet_v11/conv6/batchnorm6/beta/read
v/cg/resnet_v18/conv30/batchnorm30/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv39/batchnorm39/gamma/ApplyGradientDescent
v/cg/resnet_v111/conv38/batchnorm38/moving_mean
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v115/conv51/batchnorm51/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026517604	4194816
1608571026517610	4194816
1608571026517624	4096
1608571026518484	-4096
1608571026518486	-4194816
1608571026523642	-4194816
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/Relu_grad/ReluGrad
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/truediv_recip
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv12/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg/mul
v/cg/resnet_v19/conv32/batchnorm32/moving_variance/read
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026556422	12845056
1608571026556427	1049088
1608571026556448	23858432
1608571026556461	4352
1608571026556523	-12845056
1608571026556526	-4352
1608571026556526	-1049088
1608571026559085	-23858432
tower_0/v/gradients/AddN_6
v/cg/resnet_v112/conv42/conv2d/kernel/read
v/cg/resnet_v13/conv13/batchnorm13/moving_mean/read
learning_rate/truediv
v/cg/resnet_v111/conv37/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026623618	51380224
1608571026623623	147456
1608571026623644	51380224
1608571026623656	102760448
1608571026624483	-51380224
1608571026624485	-102760448
1608571026624486	-147456
1608571026626385	-51380224
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv14/batchnorm14/gamma/ApplyGradientDescent
v/cg/resnet_v13/conv13/batchnorm13/gamma
tower_0/v/cg/resnet_v15/conv19/batchnorm19/FusedBatchNormV3
1608571026466514	25690112
1608571026466515	512
1608571026466516	512
1608571026466517	512
1608571026466517	512
1608571026467293	-512
1608571026467335	-512
1608571026576767	-25690112
1608571026576908	-512
1608571026576909	-512
v/cg/resnet_v19/conv33/batchnorm33/beta/read
tower_0/v/gradients/AddN_3
v/cg/resnet_v16/conv21/batchnorm21/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/batchnorm8/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026604978	51380224
1608571026604979	256
1608571026604979	256
1608571026604980	256
1608571026604997	256
1608571026605076	-256
1608571026605077	-256
1608571026606337	-51380224
1608571026606988	-256
1608571026607029	-256
v/cg/resnet_v14/conv15/batchnorm15/gamma
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg_1
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv45/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v114/conv48/batchnorm48/moving_mean
v/cg/conv0/batchnorm0/gamma
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg/sub_1
v/cg/resnet_v114/conv48/conv2d/kernel
v/cg/resnet_v18/conv29/batchnorm29/moving_variance
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg
v/cg/resnet_v16/conv23/batchnorm23/gamma/read
v/cg/resnet_v110/conv35/batchnorm35/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/batchnorm28/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026551591	23858432
1608571026551591	1024
1608571026551592	1024
1608571026551592	256
1608571026551707	256
1608571026551823	-256
1608571026551824	-256
1608571026553907	-23858432
1608571026553953	-1024
1608571026554005	-1024
learning_rate/Const_8
v/cg/resnet_v112/conv40/batchnorm40/moving_mean/read
train_ops_group
v/cg/resnet_v114/conv49/batchnorm49/moving_variance/read
v/cg/resnet_v110/conv34/batchnorm34/gamma
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv41/batchnorm41/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/Relu_grad/ReluGrad
v/cg/resnet_v13/conv14/batchnorm14/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026524287	9437440
1608571026524294	9437696
1608571026524315	4096
1608571026524443	-4096
1608571026524445	-9437696
1608571026525099	-9437440
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg_1/mul
v/cg/resnet_v112/conv40/batchnorm40/gamma/read
tower_0/v/gradients/AddN_68
v/cg/resnet_v110/conv34/batchnorm34/beta/read
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg_1/sub_1
v/cg/resnet_v16/conv21/batchnorm21/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv10/batchnorm10/beta/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_37
1608571026449019	256
1608571026449021	256
1608571026449061	-256
1608571026452153	-256
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_27_grad/mul
1608571026449488	1048576
1608571026558859	-1048576
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv18/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v114/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026527117	1048576
1608571026527123	1049088
1608571026527138	2560
1608571026527329	-2560
1608571026527331	-1049088
1608571026528305	-1048576
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026548554	1048576
1608571026548560	1048576
1608571026548574	2560
1608571026548686	-2560
1608571026548688	-1048576
1608571026549025	-1048576
tower_0/v/gradients/tower_0/v/cg/resnet_v15/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v19/add
tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D
1608571026455734	205520896
1608571026455744	65536
1608571026455788	18944
1608571026455853	-18944
1608571026455856	-65536
1608571026618357	-205520896
tower_0/v/cg/resnet_v114/conv47/conv2d/Conv2D
1608571026491792	6422528
1608571026491797	4194304
1608571026491832	512
1608571026492686	-512
1608571026492689	-4194304
1608571026517332	-6422528
v/cg/resnet_v15/conv19/batchnorm19/moving_variance
v/cg/resnet_v13/conv11/conv2d/kernel/read
tower_0/v/cg/resnet_v18/conv29/Relu
tower_0/v/cg/resnet_v11/conv6/batchnorm6/FusedBatchNormV3
1608571026457716	51380224
1608571026457717	256
1608571026457718	256
1608571026457719	256
1608571026457720	256
1608571026458539	-256
1608571026458586	-256
1608571026609489	-51380224
1608571026609810	-256
1608571026609815	-256
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv27/batchnorm27/beta/ApplyGradientDescent
v/cg/resnet_v16/conv21/conv2d/kernel
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv5/conv2d/kernel/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026539764	3146496
1608571026539770	4194816
1608571026539783	84934656
1608571026540597	-84934656
1608571026540600	-4194816
1608571026540951	-3146496
v/cg/resnet_v111/conv39/batchnorm39/beta
learning_rate/Cast_2
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v19/conv32/batchnorm32/moving_variance
v/cg/resnet_v112/conv42/batchnorm42/beta/read
v/cg/resnet_v15/conv18/batchnorm18/beta
tower_0/v/transpose
1608571026446528	38535168
1608571026451753	-38535168
v/cg/resnet_v17/conv26/batchnorm26/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026533254	1048576
1608571026533260	1049088
1608571026533274	2560
1608571026533375	-2560
1608571026533378	-1049088
1608571026534477	-1048576
learning_rate/Cast_3
v/cg/resnet_v16/conv22/batchnorm22/moving_mean/read
v/cg/resnet_v14/conv16/batchnorm16/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv20/batchnorm20/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D
1608571026497827	6422528
1608571026497831	4194304
1608571026497868	512
1608571026498412	-512
1608571026498415	-4194304
1608571026511750	-6422528
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg/mul
v/cg/resnet_v14/conv17/batchnorm17/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv23/conv2d/kernel/ApplyGradientDescent
learning_rate/PiecewiseConstant/case/cond/cond/cond/Switch_1
v/cg/resnet_v17/conv24/batchnorm24/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/Relu_grad/ReluGrad
v/cg/resnet_v19/conv31/batchnorm31/gamma
v/cg/resnet_v13/conv12/batchnorm12/moving_variance/read
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg_1
v/cg/resnet_v115/conv50/batchnorm50/beta
v/cg/resnet_v17/conv24/conv2d/kernel/read
v/cg/resnet_v11/conv6/batchnorm6/moving_mean
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg_1/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg_1
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/batchnorm14/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026590092	102760448
1608571026590093	2048
1608571026590093	2048
1608571026590094	256
1608571026590115	256
1608571026590360	-256
1608571026590361	-256
1608571026593231	-102760448
1608571026593272	-2048
1608571026593313	-2048
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg/mul
v/cg/resnet_v115/conv52/batchnorm52/beta
v/cg/resnet_v13/conv14/batchnorm14/gamma/read
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg_1/mul
tower_0/v/l2_loss/L2Loss_53
1608571026445407	256
1608571026445419	9216
1608571026445473	-9216
1608571026452167	-256
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg_1
v/cg/resnet_v14/conv17/conv2d/kernel
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v12/conv8/batchnorm8/beta
learning_rate/cond/Merge
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg_1/mul
v/cg/resnet_v12/conv9/batchnorm9/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/batchnorm30/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026547276	51388416
1608571026547276	4352
1608571026547277	4096
1608571026547278	256
1608571026547346	256
1608571026547485	-256
1608571026547485	-256
1608571026548694	-51388416
1608571026548745	-4352
1608571026548778	-4096
v/cg/resnet_v10/conv3/batchnorm3/beta
v/cg/resnet_v16/conv23/conv2d/kernel
v/cg/resnet_v11/conv6/batchnorm6/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv29/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg/mul
v/cg/resnet_v11/conv6/conv2d/kernel
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg_1/mul
v/cg/resnet_v112/conv40/batchnorm40/moving_mean
v/cg/resnet_v11/conv6/batchnorm6/moving_variance
tower_0/v/cg/resnet_v110/add
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/Relu_grad/ReluGrad
tower_0/v/gradients/AddN_26
v/cg/resnet_v111/conv37/batchnorm37/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026555106	102760448
1608571026555111	2359296
1608571026555140	102760448
1608571026555244	-102760448
1608571026555246	-2359296
1608571026590354	-102760448
v/cg/resnet_v113/conv44/batchnorm44/gamma/read
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg_1
v/cg/resnet_v115/conv52/batchnorm52/moving_variance
v/cg/resnet_v110/conv36/conv2d/kernel
v/cg/resnet_v112/conv41/batchnorm41/moving_mean
tower_0/v/l2_loss/L2Loss_17
1608571026448213	256
1608571026448215	256
1608571026448261	-256
1608571026452122	-256
tower_0/v/cg/resnet_v16/Relu
tower_0/v/gradients/AddN_54
v/cg/resnet_v15/conv18/conv2d/kernel
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/batchnorm36/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026537144	51384320
1608571026537145	4352
1608571026537146	6144
1608571026537146	256
1608571026537938	256
1608571026538011	-256
1608571026538012	-256
1608571026538456	-51384320
1608571026538498	-4352
1608571026538536	-6144
tower_0/v/cg/resnet_v12/conv8/Relu
v/cg/resnet_v16/conv23/batchnorm23/beta
tower_0/v/gradients/AddN_13
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/batchnorm23/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026567192	102762496
1608571026567193	2048
1608571026567194	2048
1608571026567195	256
1608571026567212	256
1608571026567309	-256
1608571026567310	-256
1608571026568452	-102762496
1608571026568513	-2048
1608571026568578	-2048
tower_0/v/gradients/AddN_39
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv18/batchnorm18/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_13_grad/mul
1608571026446096	589824
1608571026597415	-589824
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v113/conv45/batchnorm45/gamma
v/cg/resnet_v13/conv12/batchnorm12/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026610351	262144
1608571026610357	147456
1608571026610369	5632
1608571026611129	-5632
1608571026611131	-147456
1608571026615957	-262144
v/cg/resnet_v112/conv41/batchnorm41/gamma/read
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg
tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D
1608571026469718	12845056
1608571026469722	524288
1608571026469764	1280
1608571026469822	-1280
1608571026469824	-524288
1608571026564876	-12845056
v/cg/resnet_v114/conv47/batchnorm47/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026511876	25690112
1608571026511882	4194816
1608571026511908	25690112
1608571026511922	4096
1608571026511995	-25690112
1608571026511998	-4096
1608571026511999	-4194816
1608571026512958	-25690112
v/cg/resnet_v10/conv4/conv2d/kernel
tower_0/v/gradients/AddN_12
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv39/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/AddN_45
v/cg/resnet_v110/conv34/batchnorm34/beta
tower_0/v/l2_loss/L2Loss_14
1608571026446400	256
1608571026446402	256
1608571026446448	-256
1608571026452120	-256
main_fetch_group/_564
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026574843	262144
1608571026574849	327680
1608571026574862	2560
1608571026575855	-2560
1608571026575858	-327680
1608571026576960	-262144
tower_0/v/cg/resnet_v17/conv26/Relu
v/cg/resnet_v12/conv9/conv2d/kernel
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv20/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v113/conv43/batchnorm43/beta
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg
tower_0/v/l2_loss/L2Loss_6
1608571026446898	256
1608571026446900	256
1608571026446939	-256
1608571026452168	-256
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv50/batchnorm50/gamma/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_52
1608571026447283	256
1608571026447295	9216
1608571026447352	-9216
1608571026452166	-256
edge_659_learning_rate/PiecewiseConstant/and@@MemcpyDtoH
v/cg/resnet_v112/conv40/batchnorm40/moving_variance
v/cg/resnet_v16/conv22/conv2d/kernel
tower_0/v/cg/resnet_v16/conv23/batchnorm23/FusedBatchNormV3
1608571026469086	102760448
1608571026469087	2048
1608571026469087	2048
1608571026469088	2048
1608571026469089	2048
1608571026469922	-2048
1608571026469967	-2048
1608571026567137	-102760448
1608571026567304	-2048
1608571026567305	-2048
v/cg/resnet_v17/conv24/batchnorm24/moving_mean
v/cg/resnet_v14/conv17/batchnorm17/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv12/batchnorm12/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv48/batchnorm48/beta/ApplyGradientDescent
v/cg/resnet_v113/conv44/conv2d/kernel
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv34/batchnorm34/beta/ApplyGradientDescent
v/cg/resnet_v12/conv8/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv33/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v12/conv8/batchnorm8/gamma
v/cg/resnet_v18/conv30/conv2d/kernel/read
tower_0/v/cg/resnet_v115/add
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_33_grad/mul
1608571026448949	1048576
1608571026543032	-1048576
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_47_grad/mul
1608571026450748	4194304
1608571026518695	-4194304
v/cg/resnet_v113/conv46/conv2d/kernel
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv46/batchnorm46/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/batchnorm27/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026554399	51380224
1608571026554400	4096
1608571026554401	4096
1608571026554401	256
1608571026554423	256
1608571026555076	-256
1608571026555077	-256
1608571026557676	-51380224
1608571026557715	-4096
1608571026557762	-4096
tower_0/v/cg/resnet_v18/conv30/batchnorm30/FusedBatchNormV3
1608571026473379	51380224
1608571026473381	4096
1608571026473382	4096
1608571026473382	4096
1608571026473383	4096
1608571026474045	-4096
1608571026474094	-4096
1608571026546640	-51380224
1608571026547482	-4096
1608571026547482	-4096
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/batchnorm52/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026507950	25698304
1608571026507951	12288
1608571026507952	8192
1608571026507953	256
1608571026508029	256
1608571026508119	-256
1608571026508120	-256
1608571026508631	-25698304
1608571026508689	-12288
1608571026509097	-8192
tower_0/v/gradients/AddN_63
v/cg/resnet_v14/conv16/batchnorm16/moving_mean
v/cg/resnet_v11/conv5/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/batchnorm35/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026539438	12845056
1608571026539439	1024
1608571026539440	1024
1608571026539440	256
1608571026539462	256
1608571026539535	-256
1608571026539536	-256
1608571026540611	-12845056
1608571026540656	-1024
1608571026540700	-1024
v/cg/resnet_v10/conv3/batchnorm3/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/batchnorm7/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026607195	205520896
1608571026607196	1024
1608571026607197	1024
1608571026607197	256
1608571026607219	256
1608571026607288	-256
1608571026607288	-256
1608571026608467	-205520896
1608571026609404	-1024
1608571026609446	-1024
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/batchnorm22/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026569332	25690112
1608571026569333	512
1608571026569334	512
1608571026569334	256
1608571026569608	256
1608571026569684	-256
1608571026569685	-256
1608571026570675	-25690112
1608571026570719	-512
1608571026570760	-512
v/cg/resnet_v110/conv34/batchnorm34/moving_mean
v/cg/resnet_v111/conv38/batchnorm38/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/l2_loss/L2Loss_8
1608571026447025	256
1608571026447027	256
1608571026447071	-256
1608571026452170	-256
tower_0/v/gradients/tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/mul
v/cg/resnet_v15/conv18/batchnorm18/moving_mean/read
v/cg/resnet_v17/conv24/batchnorm24/gamma
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/batchnorm48/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026514874	6430720
1608571026514874	2048
1608571026514875	2048
1608571026514875	256
1608571026514895	256
1608571026514975	-256
1608571026514976	-256
1608571026515981	-6430720
1608571026516032	-2048
1608571026516760	-2048
v/cg/resnet_v18/conv30/batchnorm30/beta
v/cg/resnet_v11/conv6/batchnorm6/gamma/read
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv40/batchnorm40/beta/ApplyGradientDescent
v/cg/resnet_v13/conv12/batchnorm12/beta
tower_0/v/l2_loss/L2Loss_18
1608571026445776	256
1608571026445779	256
1608571026445820	-256
1608571026452123	-256
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv27/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v15/conv18/batchnorm18/moving_variance/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_7_grad/mul
1608571026447517	65536
1608571026609529	-65536
v/cg/resnet_v13/conv13/batchnorm13/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/Relu_grad/ReluGrad
v/cg/resnet_v10/conv2/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv35/batchnorm35/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg_1/mul
v/cg/resnet_v112/conv40/conv2d/kernel
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg/mul
v/cg/affine0/biases
tower_0/v/cg/resnet_v111/conv37/batchnorm37/FusedBatchNormV3
1608571026477729	12845056
1608571026477730	1024
1608571026477730	1024
1608571026477731	1024
1608571026477732	1024
1608571026478383	-1024
1608571026478433	-1024
1608571026535709	-12845056
1608571026535868	-1024
1608571026535868	-1024
v/cg/resnet_v15/conv18/batchnorm18/moving_variance
v/cg/resnet_v14/conv15/batchnorm15/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv52/batchnorm52/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv47/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv22/batchnorm22/gamma/ApplyGradientDescent
v/cg/resnet_v10/conv2/batchnorm2/beta/read
v/cg/resnet_v17/conv25/batchnorm25/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/Relu_grad/ReluGrad
v/cg/resnet_v112/conv40/batchnorm40/moving_variance/read
tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D
1608571026466197	25690112
1608571026466202	589824
1608571026466242	117964800
1608571026466332	-117964800
1608571026466335	-589824
1608571026576907	-25690112
tower_0/v/cg/resnet_v110/conv36/batchnorm36/FusedBatchNormV3
1608571026477041	51380224
1608571026477042	6144
1608571026477043	4096
1608571026477044	4096
1608571026477044	4096
1608571026477667	-6144
1608571026477710	-4096
1608571026537086	-51380224
1608571026538008	-4096
1608571026538009	-4096
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/l2_loss/L2Loss_20
1608571026444827	256
1608571026444832	256
1608571026444879	-256
1608571026452125	-256
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv12/batchnorm12/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026580162	262144
1608571026580168	262144
1608571026580180	4096
1608571026581133	-4096
1608571026581135	-262144
1608571026582215	-262144
learning_rate/PiecewiseConstant/and_2
v/cg/resnet_v113/conv45/batchnorm45/moving_variance
v/cg/resnet_v10/conv2/batchnorm2/moving_variance/read
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026556554	1049088
1608571026556560	1049088
1608571026556572	4352
1608571026557668	-4352
1608571026557670	-1049088
1608571026559136	-1049088
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv51/batchnorm51/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026569750	28054528
1608571026569755	589824
1608571026569779	25690112
1608571026569793	117964800
1608571026569861	-28054528
1608571026569863	-117964800
1608571026569865	-589824
1608571026571461	-25690112
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv38/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v110/conv36/batchnorm36/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv21/batchnorm21/gamma/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_3
1608571026444145	256
1608571026444146	256
1608571026444189	-256
1608571026452143	-256
tower_0/v/gpu_cached_inputs/read
tower_0/v/cg/resnet_v17/add
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v17/conv26/batchnorm26/FusedBatchNormV3
1608571026470911	12845056
1608571026470912	1024
1608571026470912	1024
1608571026470914	1024
1608571026470914	1024
1608571026471595	-1024
1608571026471638	-1024
1608571026558812	-12845056
1608571026559088	-1024
1608571026559089	-1024
learning_rate/PiecewiseConstant/case/num_true_conds
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/AddN_33
v/cg/resnet_v113/conv44/batchnorm44/beta
tower_0/v/mul/x
tower_0/v/l2_loss/L2Loss_7
1608571026447442	256
1608571026447444	256
1608571026447487	-256
1608571026452169	-256
v/cg/resnet_v13/conv13/batchnorm13/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv6/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v13/conv14/batchnorm14/moving_variance/read
tower_0/v/cg/resnet_v18/conv28/batchnorm28/FusedBatchNormV3
1608571026472202	12845056
1608571026472203	1024
1608571026472204	1024
1608571026472204	1024
1608571026472205	1024
1608571026472905	-1024
1608571026472942	-1024
1608571026551533	-12845056
1608571026551817	-1024
1608571026551818	-1024
v/cg/resnet_v19/conv32/batchnorm32/moving_mean
v/cg/resnet_v12/conv10/batchnorm10/moving_variance/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_22_grad/mul
1608571026445043	589824
1608571026571356	-589824
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_9_grad/mul
1608571026447230	147456
1608571026604959	-147456
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv30/conv2d/kernel/ApplyGradientDescent
tower_0/v/l2_loss/L2Loss_9
1608571026447148	256
1608571026447150	256
1608571026447189	-256
1608571026452170	-256
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/Relu_grad/ReluGrad
v/cg/resnet_v17/conv25/conv2d/kernel/read
tower_0/v/gradients/AddN_62
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/Relu_grad/ReluGrad
v/cg/resnet_v113/conv44/batchnorm44/moving_variance/read
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv44/batchnorm44/beta/ApplyGradientDescent
v/cg/resnet_v113/conv46/batchnorm46/moving_variance/read
v/cg/resnet_v113/conv45/batchnorm45/gamma/read
v/cg/resnet_v112/conv40/conv2d/kernel/read
v/cg/resnet_v10/conv1/batchnorm1/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/batchnorm29/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026548869	12849152
1608571026548870	1024
1608571026548870	1024
1608571026548871	256
1608571026548889	256
1608571026548972	-256
1608571026548973	-256
1608571026551300	-12849152
1608571026551445	-1024
1608571026551483	-1024
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v113/conv43/batchnorm43/FusedBatchNormV3
1608571026486492	25690112
1608571026486493	8192
1608571026486494	8192
1608571026486495	8192
1608571026486496	8192
1608571026489210	-8192
1608571026489249	-8192
1608571026523590	-25690112
1608571026523752	-8192
1608571026523757	-8192
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg/sub_1
v/cg/resnet_v113/conv43/batchnorm43/moving_variance/read
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_34_grad/mul
1608571026450882	1048576
1608571026542247	-1048576
tower_0/v/cg/resnet_v15/conv18/batchnorm18/AssignMovingAvg_1
v/cg/resnet_v14/conv17/batchnorm17/moving_mean
tower_0/v/cg/resnet_v19/conv32/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/batchnorm32/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026543062	12845056
1608571026543062	1024
1608571026543063	1024
1608571026543063	256
1608571026543085	256
1608571026543160	-256
1608571026543160	-256
1608571026543677	-12845056
1608571026543876	-1024
1608571026543930	-1024
v/cg/resnet_v18/conv29/batchnorm29/moving_variance/read
tower_0/v/resnet50_synthetic_labels/max
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv5/batchnorm5/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/truediv
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv42/batchnorm42/gamma/ApplyGradientDescent
v/cg/resnet_v15/conv19/batchnorm19/moving_mean
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv31/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v19/Relu
v/cg/resnet_v10/conv3/batchnorm3/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv30/batchnorm30/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_grad/mul
1608571026444078	37632
1608571026630391	-37632
tower_0/v/cg/resnet_v16/conv22/Relu
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv38/batchnorm38/gamma/ApplyGradientDescent
v/cg/resnet_v12/conv10/batchnorm10/beta
v/cg/resnet_v113/conv46/batchnorm46/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/batchnorm37/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026535776	12845056
1608571026535776	1024
1608571026535777	1024
1608571026535777	256
1608571026535797	256
1608571026535871	-256
1608571026535871	-256
1608571026536894	-12845056
1608571026536941	-1024
1608571026536978	-1024
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_12_grad/mul
1608571026445968	131072
1608571026599585	-131072
v/cg/resnet_v19/conv32/batchnorm32/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv32/batchnorm32/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv49/batchnorm49/FusedBatchNormV3
1608571026496561	25690112
1608571026496562	8192
1608571026496563	8192
1608571026496564	8192
1608571026496564	8192
1608571026498978	-8192
1608571026499016	-8192
1608571026513192	-25690112
1608571026513527	-8192
1608571026513528	-8192
v/cg/resnet_v110/conv34/conv2d/kernel/read
tower_0/v/l2_loss/L2Loss_19
1608571026445266	256
1608571026445268	256
1608571026445309	-256
1608571026452123	-256
tower_0/v/cg/resnet_v18/conv30/batchnorm30/AssignMovingAvg_1
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v14/conv15/conv2d/kernel
average_loss/Mean/_568
v/cg/resnet_v113/conv43/batchnorm43/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv4/batchnorm4/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv48/Relu
learning_rate/PiecewiseConstant/LessEqual_3
1608571026436439	256
1608571026437658	-256
v/cg/resnet_v110/conv36/batchnorm36/gamma
tower_0/v/l2_loss/L2Loss_49
1608571026451366	256
1608571026451377	9216
1608571026451430	-9216
1608571026452163	-256
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv22/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/batchnorm39/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026532268	51384320
1608571026532269	4352
1608571026532269	6144
1608571026532270	256
1608571026532913	256
1608571026533065	-256
1608571026533066	-256
1608571026533385	-51384320
1608571026533437	-4352
1608571026533481	-6144
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/value
tower_0/v/l2_loss/L2Loss_36
1608571026449541	256
1608571026449543	256
1608571026449584	-256
1608571026452153	-256
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026610072	51380224
1608571026610077	262144
1608571026610101	75588096
1608571026610114	89178112
1608571026610318	-51380224
1608571026610321	-89178112
1608571026610322	-262144
1608571026615901	-75588096
tower_0/v/gradients/AddN_49
tower_0/v/gradients/AddN_70
v/cg/resnet_v114/conv48/batchnorm48/gamma/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v17/conv25/batchnorm25/FusedBatchNormV3
1608571026470097	12845056
1608571026470098	1024
1608571026470098	1024
1608571026470099	1024
1608571026470100	1024
1608571026471049	-1024
1608571026471085	-1024
1608571026562315	-12845056
1608571026564877	-1024
1608571026564883	-1024
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg_1
tower_0/v/cg/resnet_v112/Relu
tower_0/v/cg/resnet_v12/conv8/batchnorm8/FusedBatchNormV3
1608571026459111	51380224
1608571026459112	256
1608571026459113	256
1608571026459114	256
1608571026459114	256
1608571026460067	-256
1608571026460112	-256
1608571026604924	-51380224
1608571026605072	-256
1608571026605074	-256
tower_0/v/cg/resnet_v10/conv2/Relu
v/cg/resnet_v17/conv26/batchnorm26/gamma
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg_1
v/cg/resnet_v19/conv33/batchnorm33/moving_variance/read
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026565114	524288
1608571026565119	524800
1608571026565132	4352
1608571026565914	-4352
1608571026565916	-524800
1608571026567174	-524288
tower_0/v/gradients/AddN_56
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026525900	51380224
1608571026525906	2097152
1608571026525927	77103104
1608571026526015	-51380224
1608571026526017	-2097152
1608571026526322	-77103104
tower_0/v/gradients/AddN_47
tower_0/v/cg/resnet_v10/conv4/batchnorm4/FusedBatchNormV3
1608571026456016	205520896
1608571026456017	1024
1608571026456018	1024
1608571026456019	1024
1608571026456020	1024
1608571026456351	-205520896
1608571026456854	-1024
1608571026456896	-1024
1608571026618357	-1024
1608571026618358	-1024
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/Relu_grad/ReluGrad
tower_0/v/gradients/AddN_36
tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D
1608571026469557	51380224
1608571026469561	2097152
1608571026469606	1280
1608571026469666	-1280
1608571026469669	-2097152
1608571026554367	-51380224
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg/sub_1
v/cg/resnet_v113/conv46/batchnorm46/beta/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v115/Relu
v/cg/resnet_v19/conv33/batchnorm33/moving_variance
tower_0/v/cg/resnet_v14/conv16/batchnorm16/FusedBatchNormV3
1608571026464540	25692160
1608571026464541	512
1608571026464542	512
1608571026464543	512
1608571026464543	512
1608571026465318	-512
1608571026465374	-512
1608571026584397	-25692160
1608571026584549	-512
1608571026584550	-512
v/cg/resnet_v112/conv42/batchnorm42/moving_variance/read
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v11/conv5/batchnorm5/AssignMovingAvg/mul
v/cg/resnet_v115/conv50/batchnorm50/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026590385	205520896
1608571026590391	589824
1608571026590805	205520896
1608571026591041	-205520896
1608571026591043	-589824
1608571026618354	-205520896
v/cg/resnet_v17/conv26/batchnorm26/beta/read
tower_0/v/l2_loss/L2Loss_40
1608571026451519	256
1608571026451521	256
1608571026451562	-256
1608571026452156	-256
tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D
1608571026457200	51380224
1608571026457205	147456
1608571026457248	89178112
1608571026457538	-89178112
1608571026457542	-147456
1608571026609810	-51380224
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv45/batchnorm45/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_5_grad/mul
1608571026446850	65536
1608571026618015	-65536
v/cg/resnet_v115/conv51/conv2d/kernel/read
tower_0/v/cg/conv0/Pad/paddings
v/cg/resnet_v14/conv15/batchnorm15/beta/read
tower_0/v/gradients/AddN_21
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D
1608571026476791	51380224
1608571026476795	1048576
1608571026476836	1280
1608571026476894	-1280
1608571026476897	-1048576
1608571026538007	-51380224
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026547514	12845056
1608571026547519	1048576
1608571026547544	17303808
1608571026547559	3584
1608571026548519	-12845056
1608571026548522	-3584
1608571026548523	-1048576
1608571026548961	-17303808
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv40/batchnorm40/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026539610	12845056
1608571026539615	3146496
1608571026539637	20186368
1608571026539651	191102976
1608571026539729	-12845056
1608571026539731	-191102976
1608571026539733	-3146496
1608571026540879	-20186368
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026564961	102760448
1608571026564966	524288
1608571026564991	154157056
1608571026565068	-102760448
1608571026565070	-524288
1608571026567065	-154157056
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/conv0/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026629037	37632
1608571026629043	37632
1608571026629057	35840
1608571026629210	-35840
1608571026629212	-37632
1608571026630434	-37632
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg_1
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv34/batchnorm34/gamma/ApplyGradientDescent
v/cg/resnet_v112/conv41/conv2d/kernel/read
tower_0/v/gradients/AddN_67
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg/mul
v/cg/resnet_v10/conv2/batchnorm2/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv8/batchnorm8/beta/ApplyGradientDescent
v/cg/resnet_v18/conv28/conv2d/kernel
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg_1/mul
v/cg/resnet_v111/conv38/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/ShapeN-matshapes-0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv1/batchnorm1/beta/ApplyGradientDescent
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg_1
tower_0/v/l2_loss/L2Loss_29
1608571026444567	256
1608571026444638	9216
1608571026444738	-9216
1608571026452139	-256
v/cg/conv0/batchnorm0/gamma/read
v/cg/resnet_v113/conv43/batchnorm43/moving_mean
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_44_grad/mul
1608571026450165	2097152
1608571026526354	-2097152
v/cg/resnet_v14/conv15/batchnorm15/gamma/read
edge_655_learning_rate/PiecewiseConstant/Greater@@MemcpyDtoH
tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D
1608571026495702	25690112
1608571026495707	4194304
1608571026495792	512
1608571026496295	-512
1608571026496298	-4194304
1608571026513526	-25690112
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv23/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv43/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_45_grad/mul
1608571026449351	9437184
1608571026525703	-9437184
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/Switch/Switch
v/cg/resnet_v17/conv26/batchnorm26/moving_variance/read
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v111/conv38/batchnorm38/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv41/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D
1608571026476127	12845056
1608571026476135	2359296
1608571026476175	84934656
1608571026476264	-84934656
1608571026476267	-2359296
1608571026539532	-12845056
v/cg/resnet_v11/conv7/conv2d/kernel
tower_0/v/cg/resnet_v11/conv7/batchnorm7/AssignMovingAvg_1
v/cg/resnet_v13/conv11/batchnorm11/gamma/read
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/Sum
1608571026506789	256
1608571026507435	-256
v/cg/resnet_v11/conv6/batchnorm6/moving_variance/read
v/cg/resnet_v112/conv41/batchnorm41/moving_variance/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_31_grad/mul
1608571026448554	1048576
1608571026546528	-1048576
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg/sub_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg_1/sub_1
v/cg/resnet_v17/conv25/batchnorm25/moving_mean/read
tower_0/v/cg/resnet_v10/add
v/cg/resnet_v113/conv43/batchnorm43/gamma/read
v/cg/resnet_v110/conv36/conv2d/kernel/read
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv6/batchnorm6/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg_1
v/cg/resnet_v15/conv20/batchnorm20/beta
tower_0/v/cg/resnet_v13/add
v/cg/resnet_v14/conv16/batchnorm16/moving_variance/read
v/cg/resnet_v17/conv24/batchnorm24/moving_variance/read
v/cg/resnet_v114/conv47/batchnorm47/beta
v/cg/resnet_v112/conv41/batchnorm41/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv13/batchnorm13/beta/ApplyGradientDescent
v/cg/resnet_v18/conv28/batchnorm28/moving_mean/read
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv10/batchnorm10/gamma/ApplyGradientDescent
v/cg/resnet_v14/conv15/batchnorm15/moving_variance/read
tower_0/v/cg/resnet_v10/conv1/batchnorm1/FusedBatchNormV3
1608571026453978	205520896
1608571026453980	1024
1608571026453981	1024
1608571026453982	1024
1608571026453982	1024
1608571026455263	-1024
1608571026455307	-1024
1608571026618049	-205520896
1608571026618231	-1024
1608571026618232	-1024
v/cg/resnet_v12/conv10/batchnorm10/beta/read
v/cg/resnet_v113/conv43/conv2d/kernel
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg_1/sub_1
v/cg/resnet_v11/conv7/batchnorm7/moving_mean
tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D
1608571026453457	205520896
1608571026453463	65536
1608571026453506	18944
1608571026453576	-18944
1608571026453580	-65536
1608571026618230	-205520896
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv47/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v17/conv27/batchnorm27/moving_variance/read
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg/mul
v/cg/resnet_v110/conv35/batchnorm35/moving_mean
edge_667_learning_rate/PiecewiseConstant/and_2@@MemcpyDtoH
v/cg/conv0/batchnorm0/moving_variance/read
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg
v/cg/affine0/weights/read
tower_0/v/gradients/tower_0/v/cg/affine0/xw_plus_b/MatMul_grad/MatMul
1608571026507082	524288
1608571026507585	-524288
tower_0/v/cg/resnet_v115/conv51/Relu
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v15/conv18/batchnorm18/FusedBatchNormV3
1608571026465946	25690112
1608571026465948	512
1608571026465948	512
1608571026465949	512
1608571026465950	512
1608571026466650	-512
1608571026466709	-512
1608571026579089	-25690112
1608571026579421	-512
1608571026579421	-512
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026555278	2359296
1608571026555285	2097152
1608571026555299	2560
1608571026556295	-2560
1608571026556298	-2097152
1608571026558907	-2359296
v/cg/resnet_v16/conv21/batchnorm21/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/ShapeN-matshapes-0
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv44/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v17/conv25/batchnorm25/gamma/read
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg/mul
tower_0/v/l2_loss/L2Loss_16
1608571026444438	256
1608571026444440	256
1608571026444482	-256
1608571026452121	-256
v/cg/resnet_v19/conv33/conv2d/kernel
tower_0/v/l2_loss/L2Loss_41
1608571026450501	256
1608571026450512	9216
1608571026450564	-9216
1608571026452157	-256
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv50/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v110/conv36/batchnorm36/moving_mean/read
tower_0/v/cg/resnet_v16/conv21/Relu
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg/mul
v/cg/resnet_v15/conv20/batchnorm20/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv36/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D
1608571026461301	38525184
1608571026461306	131072
1608571026461354	4864
1608571026461414	-4864
1608571026461417	-131072
1608571026597533	-38525184
tower_0/v/cg/resnet_v114/conv47/batchnorm47/FusedBatchNormV3
1608571026493290	6422528
1608571026493292	2048
1608571026493292	2048
1608571026493293	2048
1608571026493294	2048
1608571026495432	-2048
1608571026495548	-2048
1608571026516803	-6422528
1608571026517333	-2048
1608571026517334	-2048
v/cg/resnet_v114/conv48/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv40/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg/sub_1
v/cg/resnet_v114/conv47/batchnorm47/beta/read
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg/sub_1
v/cg/resnet_v10/conv3/batchnorm3/moving_mean/read
tower_0/v/l2_loss/L2Loss_48
1608571026448602	256
1608571026448614	9216
1608571026448663	-9216
1608571026452162	-256
v/cg/resnet_v17/conv27/conv2d/kernel
tower_0/v/cg/resnet_v18/conv29/batchnorm29/FusedBatchNormV3
1608571026472772	12849152
1608571026472774	1024
1608571026472775	1024
1608571026472776	1024
1608571026472776	1024
1608571026473513	-1024
1608571026473559	-1024
1608571026548815	-12849152
1608571026548963	-1024
1608571026548965	-1024
tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D
1608571026473838	12845056
1608571026473844	1048576
1608571026473883	2048
1608571026473943	-2048
1608571026473946	-1048576
1608571026544974	-12845056
tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D
1608571026474942	51380224
1608571026474947	1048576
1608571026474987	1280
1608571026475046	-1280
1608571026475049	-1048576
1608571026542554	-51380224
tower_0/v/gradients/tower_0/v/cg/resnet_v11/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v113/conv44/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v14/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026508444	8192000
1608571026508463	4194304
1608571026508484	4096
1608571026508620	-4096
1608571026508622	-4194304
1608571026509676	-8192000
v/cg/resnet_v14/conv17/batchnorm17/gamma/read
v/cg/resnet_v111/conv37/batchnorm37/gamma
tower_0/v/l2_loss/L2Loss_27
1608571026449413	256
1608571026449414	256
1608571026449456	-256
1608571026452137	-256
v/cg/resnet_v17/conv27/batchnorm27/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/Relu_grad/ReluGrad
tower_0/v/gradients/AddN_44
v/cg/resnet_v19/conv31/batchnorm31/moving_mean
tower_0/v/cg/resnet_v11/conv6/batchnorm6/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026594863	45358336
1608571026594868	589824
1608571026594889	25690112
1608571026594902	179836928
1608571026595294	-45358336
1608571026595296	-179836928
1608571026595297	-589824
1608571026597532	-25690112
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg
tower_0/v/gradients/AddN_69
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg_1
v/cg/resnet_v10/conv2/batchnorm2/moving_variance
v/cg/resnet_v19/conv31/batchnorm31/gamma/read
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026576972	28054528
1608571026576977	589824
1608571026577002	25690112
1608571026577015	117964800
1608571026577085	-28054528
1608571026577087	-117964800
1608571026577088	-589824
1608571026579418	-25690112
tower_0/v/l2_loss/L2Loss_13
1608571026446023	256
1608571026446025	256
1608571026446070	-256
1608571026452119	-256
tower_0/v/cg/resnet_v113/add
tower_0/v/l2_loss/L2Loss_39
1608571026449946	256
1608571026449948	256
1608571026449992	-256
1608571026452155	-256
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv46/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v114/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v16/conv22/batchnorm22/FusedBatchNormV3
1608571026468463	25690112
1608571026468464	512
1608571026468465	512
1608571026468465	512
1608571026468466	512
1608571026469229	-512
1608571026469274	-512
1608571026569201	-25690112
1608571026569677	-512
1608571026569678	-512
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg_1
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg_1
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg_1
tower_0/v/cg/resnet_v12/add
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026592203	262144
1608571026592208	262144
1608571026592220	4352
1608571026593223	-4352
1608571026593225	-262144
1608571026594836	-262144
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg_1/mul
v/cg/resnet_v113/conv44/conv2d/kernel/read
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg
tower_0/v/gradients/AddN_58
v/cg/resnet_v15/conv18/batchnorm18/gamma/read
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg_1/sub_1
v/cg/resnet_v18/conv30/batchnorm30/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026607312	71114240
1608571026607317	65536
1608571026607341	51380224
1608571026607354	21248
1608571026607419	-71114240
1608571026607421	-21248
1608571026607422	-65536
1608571026609808	-51380224
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg/mul
tower_0/v/gradients/AddN_64
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv28/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026551896	51384320
1608571026551901	1049088
1608571026551926	51380224
1608571026551939	4352
1608571026552762	-51384320
1608571026552765	-4352
1608571026552766	-1049088
1608571026554040	-51380224
v/cg/resnet_v12/conv10/conv2d/kernel
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026615977	205520896
1608571026615982	65536
1608571026616002	205520896
1608571026616020	21248
1608571026616844	-205520896
1608571026616846	-21248
1608571026616847	-65536
1608571026617977	-205520896
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg/mul
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg/sub_1
v/cg/resnet_v114/conv49/batchnorm49/gamma
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_49_grad/mul
1608571026451452	4194304
1608571026514851	-4194304
v/cg/resnet_v10/conv4/batchnorm4/moving_variance/read
learning_rate/Cast
v/cg/resnet_v115/conv51/batchnorm51/beta
v/cg/resnet_v15/conv20/batchnorm20/beta/read
v/cg/resnet_v18/conv30/batchnorm30/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/Relu_grad/ReluGrad
tower_0/v/mul
v/cg/resnet_v16/conv21/batchnorm21/beta
tower_0/v/cg/resnet_v14/conv15/Relu
v/cg/resnet_v17/conv24/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026535943	51380224
1608571026535948	1048576
1608571026535975	51380224
1608571026535989	4096
1608571026536689	-51380224
1608571026536691	-4096
1608571026536692	-1048576
1608571026537010	-51380224
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_54_grad/mul
1608571026446204	4096
1608571026507333	-4096
v/cg/resnet_v113/conv45/batchnorm45/moving_mean/read
tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D
1608571026462089	25690112
1608571026462094	589824
1608571026462142	117964800
1608571026462276	-117964800
1608571026462280	-589824
1608571026594587	-25690112
tower_0/v/cg/resnet_v15/Relu
v/cg/resnet_v13/conv14/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/l2_loss/L2Loss_35
1608571026449815	256
1608571026449827	9216
1608571026449875	-9216
1608571026452150	-256
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026620292	51380224
1608571026620297	65536
1608571026620318	51380224
1608571026620329	21248
1608571026620468	-51380224
1608571026620471	-21248
1608571026620472	-65536
1608571026623539	-51380224
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v19/conv32/batchnorm32/gamma
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg
v/cg/resnet_v15/conv20/batchnorm20/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026599936	65536
1608571026599942	65536
1608571026599954	3072
1608571026601811	-3072
1608571026601814	-65536
1608571026602571	-65536
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv1/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026619262	65536
1608571026619268	65536
1608571026619280	3072
1608571026620181	-3072
1608571026620183	-65536
1608571026622893	-65536
v/cg/resnet_v13/conv11/batchnorm11/beta/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D
1608571026470542	12845056
1608571026470546	2359296
1608571026470585	84934656
1608571026470669	-84934656
1608571026470672	-2359296
1608571026559087	-12845056
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv30/batchnorm30/gamma/ApplyGradientDescent
v/cg/resnet_v13/conv12/batchnorm12/moving_mean
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg
tower_0/v/gradients/AddN
tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D
1608571026466865	102760448
1608571026466874	262144
1608571026466914	4864
1608571026466973	-4864
1608571026466976	-262144
1608571026574661	-102760448
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v113/conv46/batchnorm46/FusedBatchNormV3
1608571026490734	25690112
1608571026490735	12288
1608571026490735	8192
1608571026490736	8192
1608571026490737	8192
1608571026491570	-25690112
1608571026492781	-12288
1608571026493274	-8192
1608571026523884	-8192
1608571026523884	-8192
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv22/batchnorm22/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv17/batchnorm17/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg
tower_0/v/cg/resnet_v112/conv42/batchnorm42/AssignMovingAvg_1/sub_1
ConstantFoldingCtrl/learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Switch_1
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg/mul
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg_1/sub_1
average_loss/Mean
tower_0/v/cg/resnet_v112/conv41/Relu
tower_0/v/gradients/AddN_15
v/cg/resnet_v11/conv7/conv2d/kernel/read
tower_0/v/cg/resnet_v17/conv26/batchnorm26/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg_1/mul
v/cg/resnet_v114/conv49/batchnorm49/beta/read
v/cg/resnet_v12/conv10/batchnorm10/moving_mean
tower_0/v/l2_loss/L2Loss_2
1608571026445686	256
1608571026452124	-256
v/cg/resnet_v18/conv29/batchnorm29/beta
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg_1/mul
v/cg/resnet_v113/conv44/batchnorm44/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026528661	4194816
1608571026528667	4194816
1608571026528681	84934656
1608571026529132	-84934656
1608571026529135	-4194816
1608571026531216	-4194816
learning_rate/Cast_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v19/conv31/conv2d/kernel/read
tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D
1608571026479243	12845056
1608571026479248	1048576
1608571026479285	2048
1608571026479342	-2048
1608571026479344	-1048576
1608571026531161	-12845056
append_apply_gradient_ops/GradientDescent/update_v/cg/conv0/batchnorm0/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026524729	4194816
1608571026524735	4194816
1608571026524749	4096
1608571026524851	-4096
1608571026524853	-4194816
1608571026525246	-4194816
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/Switch_1
v/cg/resnet_v13/conv11/batchnorm11/moving_mean/read
v/cg/resnet_v111/conv39/batchnorm39/gamma/read
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg
tower_0/v/gradients/AddN_4
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv3/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv1/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v110/conv35/batchnorm35/AssignMovingAvg_1/mul
v/cg/resnet_v13/conv11/batchnorm11/moving_variance/read
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg/mul
tower_0/v/l2_loss/L2Loss_44
1608571026450072	256
1608571026450083	9216
1608571026450131	-9216
1608571026452159	-256
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v113/conv46/batchnorm46/moving_variance
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/batchnorm42/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026526434	51384320
1608571026526435	4352
1608571026526436	6144
1608571026526436	256
1608571026526454	256
1608571026526536	-256
1608571026526537	-256
1608571026527338	-51384320
1608571026527380	-4352
1608571026527422	-6144
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026582694	262144
1608571026582699	262144
1608571026582712	2560
1608571026584262	-2560
1608571026584264	-262144
1608571026584595	-262144
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg
tower_0/v/cg/resnet_v18/Relu
v/cg/affine0/biases/read
v/cg/resnet_v13/conv13/batchnorm13/gamma/read
v/cg/resnet_v10/conv3/batchnorm3/moving_variance/read
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026587812	262144
1608571026587818	262144
1608571026587830	4352
1608571026589715	-4352
1608571026589716	-262144
1608571026589953	-262144
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv24/batchnorm24/gamma/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/batchnorm6/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026609539	51380224
1608571026609540	256
1608571026609540	256
1608571026609541	256
1608571026609734	256
1608571026609817	-256
1608571026609817	-256
1608571026611137	-51380224
1608571026613865	-256
1608571026613907	-256
tower_0/v/l2_loss/L2Loss_22
1608571026444967	256
1608571026444969	256
1608571026445011	-256
1608571026452126	-256
tower_0/v/gradients/AddN_35
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv43/batchnorm43/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v17/conv25/batchnorm25/gamma
v/cg/resnet_v14/conv17/batchnorm17/moving_variance/read
tower_0/v/l2_loss/L2Loss_32
1608571026450347	256
1608571026450359	9216
1608571026450408	-9216
1608571026452145	-256
tower_0/v/gradients/AddN_2
tower_0/v/add
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv47/batchnorm47/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg_1/sub_1
v/cg/resnet_v17/conv25/batchnorm25/beta
v/cg/resnet_v10/conv4/batchnorm4/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv4/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v11/conv6/Relu
v/cg/resnet_v13/conv14/batchnorm14/moving_mean
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v111/conv39/batchnorm39/AssignMovingAvg_1
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg_1/mul
tower_0/v/gradients/AddN_34
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_52_grad/mul
1608571026447382	4194304
1608571026509175	-4194304
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/ShapeN-matshapes-1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv16/batchnorm16/gamma/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv11/batchnorm11/beta/ApplyGradientDescent
v/cg/resnet_v110/conv35/batchnorm35/gamma/read
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg_1
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg_1
tower_0/v/cg/resnet_v19/conv33/batchnorm33/AssignMovingAvg/mul
tower_0/v/l2_loss/AddN
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_46_grad/mul
1608571026451316	4194304
1608571026525063	-4194304
learning_rate/PiecewiseConstant/case/Cast
1608571026439271	256
1608571026439581	-256
tower_0/v/cg/resnet_v111/conv37/batchnorm37/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v10/conv4/batchnorm4/AssignMovingAvg/sub_1
v/cg/resnet_v113/conv45/batchnorm45/moving_variance/read
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg/mul
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv25/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v10/conv3/conv2d/kernel/read
v/cg/resnet_v111/conv39/batchnorm39/gamma
tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D
1608571026458846	51380224
1608571026458852	65536
1608571026458899	18944
1608571026458964	-18944
1608571026458967	-65536
1608571026605072	-51380224
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv50/batchnorm50/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026511104	9437440
1608571026511105	2048
1608571026511105	2048
1608571026511106	256
1608571026511127	256
1608571026511756	-256
1608571026511757	-256
1608571026512180	-9437440
1608571026512233	-2048
1608571026512912	-2048
v/cg/resnet_v13/conv14/batchnorm14/gamma
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/control_dependency
v/cg/resnet_v13/conv12/batchnorm12/gamma
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v18/conv29/batchnorm29/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026515605	6422528
1608571026515611	9437440
1608571026515690	8200192
1608571026515705	138012928
1608571026515803	-6422528
1608571026515805	-138012928
1608571026515806	-9437440
1608571026517330	-8200192
tower_0/v/l2_loss/L2Loss_12
1608571026445902	256
1608571026445904	256
1608571026445945	-256
1608571026452118	-256
tower_0/v/cg/resnet_v14/conv16/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026559164	14681856
1608571026559169	2359296
1608571026559224	23858432
1608571026559237	191102976
1608571026559314	-14681856
1608571026559316	-191102976
1608571026559318	-2359296
1608571026564874	-23858432
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv8/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg
tower_0/v/cg/conv0/Pad
1608571026451669	40627200
1608571026629219	-40627200
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_26_grad/mul
1608571026449749	2359296
1608571026562356	-2359296
learning_rate/PiecewiseConstant/Greater_3
1608571026437464	256
1608571026439193	-256
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026531236	51380224
1608571026531242	1048576
1608571026531580	51380224
1608571026531595	4096
1608571026531827	-51380224
1608571026531830	-4096
1608571026531831	-1048576
1608571026532125	-51380224
v/cg/resnet_v112/conv42/batchnorm42/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv31/batchnorm31/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026544031	12845056
1608571026544032	1024
1608571026544032	1024
1608571026544033	256
1608571026544897	256
1608571026544977	-256
1608571026544977	-256
1608571026546252	-12845056
1608571026546301	-1024
1608571026546344	-1024
v/cg/resnet_v115/conv50/batchnorm50/moving_mean
v/cg/resnet_v16/conv21/batchnorm21/gamma
v/cg/resnet_v110/conv36/batchnorm36/gamma/read
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D
1608571026454571	51380224
1608571026454577	147456
1608571026454625	89178112
1608571026455045	-89178112
1608571026455049	-147456
1608571026623542	-51380224
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv27/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v111/conv38/Relu
learning_rate/PiecewiseConstant/case/Assert/AssertGuard/Merge
v/cg/resnet_v10/conv4/batchnorm4/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v19/conv31/batchnorm31/FusedBatchNormV3
1608571026474107	12845056
1608571026474108	1024
1608571026474109	1024
1608571026474110	1024
1608571026474110	1024
1608571026474760	-1024
1608571026474797	-1024
1608571026543971	-12845056
1608571026544975	-1024
1608571026544975	-1024
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg/sub_1
learning_rate/PiecewiseConstant/case/cond/cond/Switch_1
v/cg/resnet_v14/conv16/conv2d/kernel/read
edge_663_learning_rate/PiecewiseConstant/and_1@@MemcpyDtoH
tower_0/v/cg/resnet_v11/conv5/Relu
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg/mul
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg
tower_0/v/cg/resnet_v10/conv2/batchnorm2/FusedBatchNormV3
1608571026454118	51380224
1608571026454119	256
1608571026454120	256
1608571026454124	256
1608571026454125	256
1608571026455502	-256
1608571026455558	-256
1608571026626246	-51380224
1608571026626388	-256
1608571026626389	-256
tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D
1608571026487623	6422528
1608571026487628	9437184
1608571026488159	75497472
1608571026488770	-75497472
1608571026488774	-9437184
1608571026525195	-6422528
v/cg/resnet_v110/conv34/batchnorm34/moving_mean/read
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v16/conv21/batchnorm21/FusedBatchNormV3
1608571026467916	25690112
1608571026467917	512
1608571026467918	512
1608571026467918	512
1608571026467919	512
1608571026468605	-512
1608571026468648	-512
1608571026571322	-25690112
1608571026571463	-512
1608571026571464	-512
tower_0/v/l2_loss/L2Loss_24
1608571026445097	256
1608571026445109	9216
1608571026445163	-9216
1608571026452128	-256
tower_0/v/cg/resnet_v113/conv45/Relu
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg
v/cg/resnet_v11/conv7/batchnorm7/moving_variance/read
v/cg/resnet_v18/conv28/batchnorm28/moving_mean
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv7/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v111/conv37/batchnorm37/moving_mean
v/cg/resnet_v10/conv4/batchnorm4/beta
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026584754	589824
1608571026584759	589824
1608571026584772	117964800
1608571026586655	-117964800
1608571026586658	-589824
1608571026587412	-589824
tower_0/v/cg/resnet_v12/conv8/batchnorm8/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg/mul
edge_560_learning_rate/PiecewiseConstant/case/preds_c@@MemcpyDtoH
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_25_grad/mul
1608571026448042	524288
1608571026567100	-524288
append_apply_gradient_ops/GradientDescent/update_v/cg/affine0/weights/ApplyGradientDescent
v/cg/resnet_v16/conv23/batchnorm23/gamma
tower_0/v/gradients/tower_0/v/cg/affine0/xw_plus_b_grad/BiasAddGrad
1608571026506994	4096
1608571026507516	-4096
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_35_grad/mul
1608571026449904	2359296
1608571026540772	-2359296
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg/sub
tower_0/v/cg/resnet_v13/conv12/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026579681	102760448
1608571026579686	262144
1608571026579711	102760448
1608571026579724	6912
1608571026580121	-102760448
1608571026580123	-6912
1608571026580124	-262144
1608571026582124	-102760448
v/cg/resnet_v114/conv48/batchnorm48/beta/read
tower_0/v/cg/resnet_v11/conv5/conv2d/Conv2D
1608571026456612	51380224
1608571026456618	65536
1608571026456661	18944
1608571026456740	-18944
1608571026456744	-65536
1608571026615903	-51380224
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg/sub_1
v/cg/resnet_v111/conv38/batchnorm38/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026509694	6422528
1608571026509701	9437184
1608571026509730	8200192
1608571026509746	75497472
1608571026509923	-6422528
1608571026509926	-75497472
1608571026509927	-9437184
1608571026511749	-8200192
v/cg/conv0/batchnorm0/moving_variance
tower_0/v/cg/spatial_mean0
1608571026504149	524288
1608571026507175	-524288
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg
tower_0/v/cg/resnet_v16/conv23/batchnorm23/AssignMovingAvg
v/cg/resnet_v115/conv52/batchnorm52/gamma/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv15/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv9/conv2d/kernel/ApplyGradientDescent
learning_rate/PiecewiseConstant/LessEqual_1
1608571026437383	256
1608571026438898	-256
tower_0/v/l2_loss/L2Loss_42
1608571026449137	256
1608571026449139	256
1608571026449182	-256
1608571026452158	-256
tower_0/v/gradients/AddN_50
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv47/batchnorm47/beta/ApplyGradientDescent
v/cg/resnet_v110/conv36/batchnorm36/moving_mean
v/cg/resnet_v113/conv44/batchnorm44/moving_variance
tower_0/v/l2_loss/L2Loss_51
1608571026446635	256
1608571026446648	9216
1608571026446703	-9216
1608571026452165	-256
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/Relu_grad/ReluGrad
v/cg/resnet_v115/conv50/batchnorm50/gamma/read
v/cg/resnet_v16/conv22/batchnorm22/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv25/batchnorm25/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v110/conv36/batchnorm36/AssignMovingAvg/mul
v/cg/resnet_v114/conv49/batchnorm49/moving_variance
tower_0/v/cg/resnet_v13/conv12/batchnorm12/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v17/conv24/batchnorm24/AssignMovingAvg/mul
v/cg/resnet_v15/conv19/conv2d/kernel
v/cg/resnet_v112/conv40/batchnorm40/gamma
learning_rate/PiecewiseConstant/LessEqual_2
1608571026438411	256
1608571026438547	-256
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026595331	589824
1608571026595337	589824
1608571026595349	179836928
1608571026597237	-179836928
1608571026597239	-589824
1608571026597584	-589824
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_51_grad/mul
1608571026446724	9437184
1608571026511078	-9437184
average_loss/Mean/input
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/batchnorm51/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026509192	6422528
1608571026509193	2048
1608571026509193	2048
1608571026509194	256
1608571026509373	256
1608571026509443	-256
1608571026509443	-256
1608571026510897	-6422528
1608571026510945	-2048
1608571026510988	-2048
tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D
1608571026501452	25690112
1608571026501456	4194304
1608571026501648	512
1608571026501821	-512
1608571026501824	-4194304
1608571026508112	-25690112
v/cg/resnet_v15/conv19/batchnorm19/beta/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_50_grad/mul
1608571026447908	4194304
1608571026512999	-4194304
tower_0/v/gradients/AddN_57
v/cg/resnet_v12/conv8/batchnorm8/gamma/read
learning_rate/mul
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_1_grad/mul
1608571026445635	65536
1608571026622311	-65536
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv10/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v13/conv14/batchnorm14/moving_variance
v/cg/resnet_v16/conv22/batchnorm22/gamma
v/cg/resnet_v15/conv20/conv2d/kernel/read
tower_0/v/gradients/AddN_23
tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D
1608571026485453	25690112
1608571026485457	8388608
1608571026485508	512
1608571026486028	-512
1608571026486031	-8388608
1608571026523750	-25690112
v/cg/resnet_v14/conv15/batchnorm15/moving_mean/read
edge_274_global_step/read@@MemcpyHtoD
v/cg/resnet_v115/conv51/batchnorm51/moving_mean
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg
v/cg/resnet_v19/conv33/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v114/conv49/batchnorm49/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026597818	261632
1608571026597824	131072
1608571026597837	2560
1608571026599417	-2560
1608571026599420	-131072
1608571026599661	-261632
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_8_grad/mul
1608571026447089	65536
1608571026607096	-65536
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_30_grad/mul
1608571026450290	1048576
1608571026548848	-1048576
tower_0/v/cg/resnet_v19/conv32/batchnorm32/FusedBatchNormV3
1608571026474625	12845056
1608571026474626	1024
1608571026474627	1024
1608571026474627	1024
1608571026474628	1024
1608571026475331	-1024
1608571026475374	-1024
1608571026542990	-12845056
1608571026543158	-1024
1608571026543158	-1024
tower_0/v/cg/resnet_v19/conv33/batchnorm33/FusedBatchNormV3
1608571026475212	51380224
1608571026475213	6144
1608571026475214	4096
1608571026475215	4096
1608571026475215	4096
1608571026475833	-6144
1608571026475870	-4096
1608571026542283	-51380224
1608571026542556	-4096
1608571026542556	-4096
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg_1/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv26/batchnorm26/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026558921	12845056
1608571026558922	1024
1608571026558922	1024
1608571026558923	256
1608571026558940	256
1608571026559092	-256
1608571026559092	-256
1608571026559828	-12845056
1608571026559929	-1024
1608571026562280	-1024
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_20_grad/mul
1608571026444902	262144
1608571026576802	-262144
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv21/batchnorm21/beta/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv37/batchnorm37/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg/mul
learning_rate/Const_6
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_10_grad/mul
1608571026447636	65536
1608571026602153	-65536
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Tile/multiples
v/cg/resnet_v115/conv51/batchnorm51/moving_mean/read
v/cg/resnet_v10/conv3/batchnorm3/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv17/batchnorm17/gamma/ApplyGradientDescent
v/cg/resnet_v13/conv11/conv2d/kernel
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv8/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v114/conv48/batchnorm48/moving_mean/read
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg_1/mul
v/cg/resnet_v16/conv21/batchnorm21/moving_mean/read
tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D
1608571026462866	102760448
1608571026462871	262144
1608571026462913	4864
1608571026462978	-4864
1608571026462981	-262144
1608571026590356	-102760448
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v113/conv46/batchnorm46/beta
tower_0/v/cg/resnet_v114/conv48/batchnorm48/FusedBatchNormV3
1608571026495270	6430720
1608571026495271	2048
1608571026495272	2048
1608571026495273	2048
1608571026495274	2048
1608571026496750	-2048
1608571026496799	-2048
1608571026514814	-6430720
1608571026514968	-2048
1608571026514970	-2048
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026540973	51380224
1608571026540978	1049088
1608571026541003	51380224
1608571026541017	4096
1608571026541773	-51380224
1608571026541776	-4096
1608571026541776	-1049088
1608571026542187	-51380224
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v10/conv1/batchnorm1/gamma
v/cg/resnet_v12/conv10/conv2d/kernel/read
learning_rate/Const_7
tower_0/v/gradients/AddN_16
v/cg/resnet_v110/conv35/conv2d/kernel/read
append_apply_gradient_ops/GradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/AddN_19
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026587437	102760448
1608571026587442	262144
1608571026587462	102760448
1608571026587475	6912
1608571026587785	-102760448
1608571026587787	-6912
1608571026587788	-262144
1608571026589854	-102760448
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv28/batchnorm28/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg/mul
v/cg/resnet_v17/conv26/conv2d/kernel
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/batchnorm44/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026525715	8200192
1608571026525716	2048
1608571026525716	2048
1608571026525717	256
1608571026525765	256
1608571026525822	-256
1608571026525823	-256
1608571026526194	-8200192
1608571026526248	-2048
1608571026526282	-2048
tower_0/v/resnet50_synthetic_labels
1608571026441112	256
1608571026506692	-256
v/cg/resnet_v112/conv42/batchnorm42/moving_mean/read
v/cg/resnet_v11/conv7/batchnorm7/beta/read
v/cg/resnet_v11/conv7/batchnorm7/gamma
tower_0/v/cg/resnet_v113/conv45/batchnorm45/FusedBatchNormV3
1608571026489273	6422528
1608571026489274	2048
1608571026489275	2048
1608571026489276	2048
1608571026489280	2048
1608571026491386	-2048
1608571026491432	-2048
1608571026525033	-6422528
1608571026525196	-2048
1608571026525198	-2048
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026569895	589824
1608571026569901	589824
1608571026569913	117964800
1608571026570666	-117964800
1608571026570669	-589824
1608571026571671	-589824
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/batchnorm16/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026584457	25690112
1608571026584458	512
1608571026584459	512
1608571026584459	256
1608571026584482	256
1608571026584555	-256
1608571026584555	-256
1608571026586664	-25690112
1608571026586710	-512
1608571026586750	-512
v/cg/resnet_v111/conv39/batchnorm39/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v113/Relu_grad/ReluGrad
v/cg/resnet_v15/conv20/conv2d/kernel
tower_0/v/cg/resnet_v13/conv13/batchnorm13/FusedBatchNormV3
1608571026462507	25690112
1608571026462509	512
1608571026462510	512
1608571026462515	512
1608571026462515	512
1608571026463337	-512
1608571026463382	-512
1608571026594228	-25690112
1608571026594588	-512
1608571026594589	-512
v/cg/resnet_v12/conv9/batchnorm9/beta
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v19/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv14/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026592005	25690112
1608571026592010	262144
1608571026592029	45358336
1608571026592044	6912
1608571026592170	-25690112
1608571026592173	-6912
1608571026592174	-262144
1608571026594585	-45358336
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_24_grad/mul
1608571026445205	2097152
1608571026557798	-2097152
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv44/batchnorm44/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v13/conv11/conv2d/Conv2D
1608571026461072	102760448
1608571026461077	524288
1608571026461125	4864
1608571026461188	-4864
1608571026461192	-524288
1608571026590064	-102760448
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv12/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v10/conv1/batchnorm1/AssignMovingAvg/mul
v/cg/resnet_v17/conv26/batchnorm26/beta
v/cg/resnet_v112/conv42/batchnorm42/gamma
tower_0/v/gradients/AddN_43
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/Relu_grad/ReluGrad
append_apply_gradient_ops/GradientDescent/update_v/cg/conv0/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v112/conv40/batchnorm40/AssignMovingAvg_1/sub_1
v/cg/resnet_v19/conv32/conv2d/kernel/read
v/cg/resnet_v11/conv7/batchnorm7/moving_variance
v/cg/resnet_v13/conv13/batchnorm13/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv38/batchnorm38/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v14/conv15/batchnorm15/FusedBatchNormV3
1608571026463968	25690112
1608571026463969	512
1608571026463971	512
1608571026463971	512
1608571026463972	512
1608571026464682	-512
1608571026464719	-512
1608571026586972	-25690112
1608571026587354	-512
1608571026587354	-512
v/cg/resnet_v19/conv31/batchnorm31/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv19/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v13/conv13/batchnorm13/moving_mean
tower_0/v/cg/resnet_v14/conv17/batchnorm17/AssignMovingAvg/sub_1
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg
v/cg/resnet_v18/conv29/batchnorm29/beta/read
v/cg/resnet_v12/conv9/batchnorm9/gamma
tower_0/v/cg/resnet_v13/conv14/batchnorm14/AssignMovingAvg/sub_1
v/cg/resnet_v115/conv51/batchnorm51/moving_variance/read
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv19/batchnorm19/beta/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv24/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v14/conv17/batchnorm17/beta/read
v/cg/resnet_v18/conv29/batchnorm29/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v15/conv18/batchnorm18/gamma/ApplyGradientDescent
v/cg/resnet_v11/conv5/batchnorm5/gamma
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026513565	8200192
1608571026513571	4194816
1608571026513596	9437440
1608571026513610	4096
1608571026513738	-8200192
1608571026513741	-4096
1608571026513741	-4194816
1608571026514966	-9437440
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v13/conv11/batchnorm11/beta
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_16_grad/mul
1608571026444510	589824
1608571026587023	-589824
v/cg/resnet_v111/conv38/batchnorm38/gamma
v/cg/resnet_v19/conv33/batchnorm33/gamma
tower_0/v/xentropy/sparse_softmax_cross_entropy_loss/xentropy/xentropy
1608571026504586	256
1608571026504588	256
1608571026506685	-256
1608571026506964	-256
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg/mul
tower_0/v/cg/resnet_v13/conv13/batchnorm13/AssignMovingAvg_1/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv39/batchnorm39/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026626480	51380224
1608571026626486	16384
1608571026626505	51380224
1608571026626519	21248
1608571026626691	-51380224
1608571026626693	-21248
1608571026626694	-16384
1608571026628704	-51380224
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_42_grad/mul
1608571026449211	1048576
1608571026527507	-1048576
tower_0/v/cg/resnet_v112/conv41/batchnorm41/AssignMovingAvg/mul
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv37/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/batchnorm3/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026622911	51380224
1608571026622912	256
1608571026622913	256
1608571026622913	256
1608571026622935	256
1608571026623545	-256
1608571026623545	-256
1608571026625256	-51380224
1608571026625296	-256
1608571026625328	-256
v/cg/resnet_v17/conv24/batchnorm24/beta/read
v/cg/resnet_v111/conv38/batchnorm38/beta/read
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/batchnorm17/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026582240	102764544
1608571026582240	2048
1608571026582241	2304
1608571026582241	256
1608571026582259	256
1608571026582325	-256
1608571026582326	-256
1608571026584270	-102764544
1608571026584318	-2048
1608571026584350	-2304
tower_0/v/cg/resnet_v18/conv30/conv2d/Conv2D
1608571026473118	51380224
1608571026473124	1048576
1608571026473163	2048
1608571026473224	-2048
1608571026473227	-1048576
1608571026547481	-51380224
v/cg/resnet_v12/conv10/batchnorm10/gamma/read
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg
v/cg/resnet_v110/conv35/batchnorm35/moving_mean/read
tower_0/v/l2_loss/L2Loss_43
1608571026451070	256
1608571026451081	9216
1608571026451130	-9216
1608571026452158	-256
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026572048	262144
1608571026572054	327680
1608571026572067	4352
1608571026573434	-4352
1608571026573435	-327680
1608571026574546	-262144
tower_0/v/cg/resnet_v113/Relu
main_fetch_group
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv26/batchnorm26/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v11/conv7/conv2d/Conv2D
1608571026458101	205520896
1608571026458107	65536
1608571026458148	18944
1608571026458214	-18944
1608571026458217	-65536
1608571026607283	-205520896
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv40/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026531861	1048576
1608571026531867	1049088
1608571026531881	4096
1608571026531986	-4096
1608571026531988	-1049088
1608571026532247	-1048576
v/cg/resnet_v11/conv5/batchnorm5/gamma/read
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg_1
v/cg/resnet_v10/conv1/batchnorm1/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv23/batchnorm23/gamma/ApplyGradientDescent
v/cg/resnet_v19/conv31/batchnorm31/moving_variance/read
tower_0/v/l2_loss/L2Loss_26
1608571026449658	256
1608571026449669	9216
1608571026449722	-9216
1608571026452130	-256
tower_0/v/cg/resnet_v12/conv10/batchnorm10/FusedBatchNormV3
1608571026460570	205520896
1608571026460572	1024
1608571026460572	1024
1608571026460574	1024
1608571026460574	1024
1608571026461471	-1024
1608571026461517	-1024
1608571026599626	-205520896
1608571026599764	-1024
1608571026599765	-1024
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv36/batchnorm36/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v12/conv9/batchnorm9/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv14/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv48/batchnorm48/AssignMovingAvg/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv42/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v111/conv39/batchnorm39/moving_mean
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v19/conv32/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/AddN_55
v/cg/resnet_v113/conv46/batchnorm46/gamma/read
learning_rate/PiecewiseConstant/case/cond/Merge
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv35/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v15/conv20/batchnorm20/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg_1/mul
v/cg/resnet_v13/conv12/conv2d/kernel
v/cg/resnet_v115/conv51/batchnorm51/gamma/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026620494	65536
1608571026620500	65536
1608571026620513	3072
1608571026621708	-3072
1608571026621711	-65536
1608571026623593	-65536
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v115/conv50/batchnorm50/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg
v/cg/resnet_v14/conv15/batchnorm15/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v13/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/batchnorm4/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026618265	205520896
1608571026618266	1024
1608571026618266	1024
1608571026618267	256
1608571026618292	256
1608571026618361	-256
1608571026618361	-256
1608571026621716	-205520896
1608571026621758	-1024
1608571026622279	-1024
tower_0/v/gradients/tower_0/v/cg/mpool0/MaxPool_grad/MaxPoolGrad
1608571026628764	205520896
1608571026629001	-205520896
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v12/conv9/batchnorm9/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg_1
v/cg/resnet_v11/conv6/conv2d/kernel/read
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv7/batchnorm7/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v14/conv16/batchnorm16/AssignMovingAvg_1
v/cg/resnet_v18/conv30/batchnorm30/moving_variance/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv2/conv2d/kernel/ApplyGradientDescent
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv37/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v15/conv18/batchnorm18/gamma
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_38_grad/mul
1608571026451015	2359296
1608571026535753	-2359296
tower_0/v/cg/resnet_v14/conv15/batchnorm15/AssignMovingAvg_1/sub_1
v/cg/resnet_v115/conv51/batchnorm51/moving_variance
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v11/conv5/batchnorm5/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/batchnorm15/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026587041	25690112
1608571026587042	512
1608571026587043	512
1608571026587043	256
1608571026587282	256
1608571026587358	-256
1608571026587359	-256
1608571026589723	-25690112
1608571026589776	-512
1608571026589820	-512
tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/batchnorm25/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026562372	12845056
1608571026562373	1024
1608571026562373	1024
1608571026562374	256
1608571026564729	256
1608571026564884	-256
1608571026564884	-256
1608571026565922	-12845056
1608571026566967	-1024
1608571026567027	-1024
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg_1/mul
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv3/batchnorm3/gamma/ApplyGradientDescent
tower_0/v/cg/resnet_v113/conv43/batchnorm43/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v111/conv38/batchnorm38/FusedBatchNormV3
1608571026478264	12845056
1608571026478265	1024
1608571026478266	1024
1608571026478267	1024
1608571026478267	1024
1608571026478962	-1024
1608571026478998	-1024
1608571026533517	-12845056
1608571026534415	-1024
1608571026534416	-1024
tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv2/batchnorm2/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026626297	51380224
1608571026626297	256
1608571026626298	256
1608571026626298	256
1608571026626316	256
1608571026626390	-256
1608571026626390	-256
1608571026627657	-51380224
1608571026627853	-256
1608571026628034	-256
tower_0/v/cg/resnet_v110/conv35/batchnorm35/FusedBatchNormV3
1608571026476453	12845056
1608571026476455	1024
1608571026476455	1024
1608571026476456	1024
1608571026476457	1024
1608571026477159	-1024
1608571026477200	-1024
1608571026538573	-12845056
1608571026539532	-1024
1608571026539533	-1024
tower_0/v/l2_loss/L2Loss_46
1608571026451221	256
1608571026451232	9216
1608571026451281	-9216
1608571026452161	-256
tower_0/v/cg/resnet_v112/conv42/batchnorm42/FusedBatchNormV3
1608571026484413	51380224
1608571026484418	6144
1608571026484419	4096
1608571026484420	4096
1608571026484421	4096
1608571026486433	-6144
1608571026486467	-4096
1608571026526388	-51380224
1608571026526533	-4096
1608571026526534	-4096
v/cg/resnet_v12/conv9/batchnorm9/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026534495	12845056
1608571026534500	3146496
1608571026534527	17826816
1608571026534541	191102976
1608571026534625	-12845056
1608571026534627	-191102976
1608571026534628	-3146496
1608571026535865	-17826816
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v114/conv49/batchnorm49/beta
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv36/batchnorm36/gamma/ApplyGradientDescent
v/cg/conv0/conv2d/kernel/read
v/cg/resnet_v113/conv45/batchnorm45/beta
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv3/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v113/conv46/batchnorm46/moving_mean
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Reshape/shape
gpu_compute_stage_ops_group
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv32/Relu_grad/ReluGrad
v/cg/conv0/batchnorm0/moving_mean
v/cg/resnet_v10/conv1/batchnorm1/beta
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026515856	9437440
1608571026515863	9437184
1608571026515878	128575744
1608571026515972	-128575744
1608571026515974	-9437184
1608571026517386	-9437440
tower_0/v/cg/resnet_v17/conv25/batchnorm25/AssignMovingAvg/sub_1
learning_rate/PiecewiseConstant/Greater
1608571026438072	256
1608571026439190	-256
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v13/conv11/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v10/conv1/batchnorm1/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v16/conv21/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv46/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026524574	8200192
1608571026524580	4194816
1608571026524613	9437696
1608571026524629	4096
1608571026524695	-8200192
1608571026524697	-4096
1608571026524698	-4194816
1608571026525194	-9437696
v/cg/resnet_v13/conv12/conv2d/kernel/read
v/cg/affine0/weights
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/l2_loss/L2Loss_10
1608571026447570	256
1608571026447572	256
1608571026447616	-256
1608571026452116	-256
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/ShapeN-matshapes-1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v10/conv4/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv4/batchnorm4/gamma/ApplyGradientDescent
v/cg/resnet_v19/conv33/batchnorm33/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv48/Relu_grad/ReluGrad
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_6_grad/mul
1608571026446973	147456
1608571026615788	-147456
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg_1/mul
tower_0/v/gradients/AddN_53
tower_0/v/cg/resnet_v19/conv31/batchnorm31/AssignMovingAvg_1/sub_1
v/cg/resnet_v113/conv46/conv2d/kernel/read
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv10/batchnorm10/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026599678	205520896
1608571026599679	1024
1608571026599679	1024
1608571026599680	256
1608571026599699	256
1608571026599767	-256
1608571026599767	-256
1608571026601820	-205520896
1608571026601866	-1024
1608571026601900	-1024
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg_1/mul
v/cg/resnet_v111/conv39/conv2d/kernel/read
v/cg/resnet_v16/conv23/batchnorm23/moving_mean/read
tower_0/v/cg/resnet_v13/conv13/Relu
v/cg/resnet_v18/conv28/conv2d/kernel/read
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg/sub_1
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v114/conv49/batchnorm49/beta/ApplyGradientDescent
v/cg/resnet_v15/conv19/batchnorm19/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v110/conv35/conv2d/kernel/ApplyGradientDescent
v/cg/resnet_v115/conv52/batchnorm52/moving_mean/read
tower_0/v/cg/resnet_v15/conv19/batchnorm19/AssignMovingAvg_1
v/cg/resnet_v18/conv28/batchnorm28/moving_variance
tower_0/v/cg/resnet_v10/conv2/batchnorm2/AssignMovingAvg/sub_1
tower_0/v/gradients/tower_0/v/cg/spatial_mean0_grad/Reshape
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv19/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026577123	589824
1608571026577129	589824
1608571026577141	117964800
1608571026578074	-117964800
1608571026578077	-589824
1608571026579660	-589824
v/cg/resnet_v115/conv51/conv2d/kernel
tower_0/v/cg/resnet_v18/conv29/batchnorm29/AssignMovingAvg_1/sub_1
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026542737	1049088
1608571026542743	1048576
1608571026542756	2560
1608571026542855	-2560
1608571026542857	-1048576
1608571026543211	-1049088
tower_0/v/gradients/tower_0/v/cg/resnet_v19/conv33/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026542587	12845056
1608571026542593	1049088
1608571026542622	14944256
1608571026542637	3584
1608571026542698	-12845056
1608571026542700	-3584
1608571026542702	-1049088
1608571026543155	-14944256
tower_0/v/gradients/AddN_46
tower_0/v/cg/resnet_v115/conv51/batchnorm51/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026525423	9437440
1608571026525429	9437696
1608571026525443	75497472
1608571026525531	-75497472
1608571026525533	-9437696
1608571026525879	-9437440
v/cg/resnet_v11/conv7/batchnorm7/moving_mean/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv24/conv2d/kernel/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv17/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026582363	25690112
1608571026582368	262144
1608571026582395	28054528
1608571026582409	6912
1608571026582667	-25690112
1608571026582669	-6912
1608571026582670	-262144
1608571026584547	-28054528
v/cg/resnet_v114/conv47/batchnorm47/moving_variance
v/cg/resnet_v17/conv25/batchnorm25/moving_variance
v/cg/resnet_v112/conv40/batchnorm40/beta
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v112/conv42/conv2d/kernel/ApplyGradientDescent
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg_1
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg/sub_1
v/cg/resnet_v111/conv37/batchnorm37/beta
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v17/conv25/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/cg/resnet_v110/conv34/batchnorm34/AssignMovingAvg_1/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/conv0/conv2d/Conv2D_grad/ShapeN-matshapes-1
v/cg/resnet_v12/conv10/batchnorm10/moving_mean/read
tower_0/v/cg/resnet_v14/conv15/conv2d/Conv2D
1608571026463692	25690112
1608571026463697	262144
1608571026463740	4864
1608571026463804	-4864
1608571026463807	-262144
1608571026587353	-25690112
v/cg/resnet_v112/conv41/conv2d/kernel
tower_0/v/cg/resnet_v115/conv52/batchnorm52/AssignMovingAvg_1
v/cg/resnet_v112/conv41/batchnorm41/beta/read
tower_0/v/cg/resnet_v113/conv44/batchnorm44/FusedBatchNormV3
1608571026486605	6422528
1608571026486606	2048
1608571026486607	2048
1608571026486608	2048
1608571026486608	2048
1608571026489397	-2048
1608571026490130	-2048
1608571026525659	-6422528
1608571026525819	-2048
1608571026525820	-2048
tower_0/v/cg/resnet_v12/conv10/conv2d/Conv2D
1608571026460280	205520896
1608571026460285	65536
1608571026460329	18944
1608571026460415	-18944
1608571026460418	-65536
1608571026599763	-205520896
v/cg/resnet_v15/conv18/batchnorm18/beta/read
v/cg/resnet_v11/conv5/batchnorm5/moving_mean/read
tower_0/v/cg/resnet_v110/conv34/Relu
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv15/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v113/conv44/batchnorm44/AssignMovingAvg/mul
tower_0/v/gradients/AddN_5
tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D
1608571026464218	25690112
1608571026464223	589824
1608571026464269	117964800
1608571026464377	-117964800
1608571026464380	-589824
1608571026584548	-25690112
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v112/conv41/Relu_grad/ReluGrad
tower_0/v/cg/resnet_v114/conv47/batchnorm47/AssignMovingAvg_1/sub_1
tower_0/v/gradients/AddN_51
tower_0/v/gradients/AddN_61
tower_0/v/gradients/AddN_59
learning_rate/Less
1608571026443140	256
1608571026452060	-256
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv45/batchnorm45/beta/ApplyGradientDescent
tower_0/v/cg/spatial_mean0/reduction_indices
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v14/conv15/batchnorm15/beta/ApplyGradientDescent
tower_0/v/gradients/AddN_60
v/cg/resnet_v114/conv47/batchnorm47/gamma/read
tower_0/v/l2_loss/L2Loss_54
1608571026446156	256
1608571026452168	-256
v/cg/resnet_v110/conv35/conv2d/kernel
tower_0/v/cg/resnet_v14/add
v/cg/resnet_v19/conv32/batchnorm32/moving_mean/read
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv39/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026533092	17826816
1608571026533098	1048576
1608571026533125	12845056
1608571026533141	3584
1608571026533210	-17826816
1608571026533212	-3584
1608571026533213	-1048576
1608571026534412	-12845056
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv36/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026538034	20186368
1608571026538040	1048576
1608571026538065	12845056
1608571026538083	3584
1608571026538170	-20186368
1608571026538172	-3584
1608571026538174	-1048576
1608571026539530	-12845056
tower_0/v/gradients/tower_0/v/cg/resnet_v111/conv38/batchnorm38/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026534192	12845056
1608571026534193	1024
1608571026534194	1024
1608571026534194	256
1608571026534217	256
1608571026534423	-256
1608571026534423	-256
1608571026534786	-12845056
1608571026535625	-1024
1608571026535670	-1024
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_19_grad/mul
1608571026445356	589824
1608571026579125	-589824
learning_rate/PiecewiseConstant/case/preds_c
1608571026438974	256
1608571026439516	-256
v/cg/resnet_v114/conv47/batchnorm47/gamma
tower_0/v/cg/resnet_v15/add
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv20/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v16/conv23/batchnorm23/moving_mean
tower_0/v/cg/resnet_v19/conv32/batchnorm32/AssignMovingAvg_1/mul
v/cg/resnet_v17/conv26/conv2d/kernel/read
v/cg/resnet_v17/conv27/batchnorm27/moving_mean
tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv52/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026508214	8192000
1608571026508230	4194304
1608571026508260	6422528
1608571026508296	4096
1608571026508400	-8192000
1608571026508403	-4096
1608571026508404	-4194304
1608571026509435	-6422528
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv2/batchnorm2/beta/ApplyGradientDescent
tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026584610	28054528
1608571026584615	589824
1608571026584636	25690112
1608571026584649	117964800
1608571026584718	-28054528
1608571026584721	-117964800
1608571026584722	-589824
1608571026587351	-25690112
tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D
1608571026486075	6422528
1608571026486079	2097152
1608571026486265	512
1608571026486322	-512
1608571026486324	-2097152
1608571026525818	-6422528
v/cg/resnet_v10/conv2/batchnorm2/moving_mean/read
v/cg/resnet_v115/conv52/conv2d/kernel
v/cg/resnet_v114/conv47/batchnorm47/moving_mean
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v17/conv24/batchnorm24/beta/ApplyGradientDescent
tower_0/v/gradients/AddN_8
tower_0/v/gradients/AddN_30
learning_rate/Less/y
tower_0/v/cg/resnet_v16/conv21/batchnorm21/AssignMovingAvg/mul
tower_0/v/l2_loss/L2Loss_45
1608571026449268	256
1608571026449280	9216
1608571026449329	-9216
1608571026452160	-256
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg/sub_1
tower_0/v/gradients/AddN_41
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026571691	102760448
1608571026571697	262144
1608571026571722	102760448
1608571026571735	6912
1608571026572016	-102760448
1608571026572018	-6912
1608571026572019	-262144
1608571026574413	-102760448
tower_0/v/gradients/AddN_22
tower_0/v/cg/resnet_v15/conv20/batchnorm20/FusedBatchNormV3
1608571026467138	102760448
1608571026467139	2048
1608571026467140	2048
1608571026467141	2048
1608571026467142	2048
1608571026467845	-2048
1608571026467896	-2048
1608571026574499	-102760448
1608571026574663	-2048
1608571026574663	-2048
v/cg/resnet_v12/conv9/batchnorm9/gamma/read
tower_0/v/cg/conv0/batchnorm0/AssignMovingAvg_1/sub_1
tower_0/v/cg/resnet_v115/conv50/batchnorm50/AssignMovingAvg/sub_1
v/cg/resnet_v110/conv36/batchnorm36/moving_variance
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv22/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v111/conv37/batchnorm37/gamma/ApplyGradientDescent
v/cg/resnet_v18/conv28/batchnorm28/gamma
tower_0/v/gpu_cached_inputs
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/ShapeN-matshapes-0
tower_0/v/gradients/tower_0/v/cg/resnet_v114/conv49/batchnorm49/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026513267	25706496
1608571026513268	8192
1608571026513269	8192
1608571026513270	256
1608571026513290	256
1608571026513535	-256
1608571026513536	-256
1608571026514670	-25706496
1608571026514725	-8192
1608571026514777	-8192
v/cg/resnet_v12/conv10/batchnorm10/moving_variance
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg_1/sub_1
tower_0/v/gradients/AddN_11
tower_0/v/cg/resnet_v111/conv38/batchnorm38/AssignMovingAvg/sub_1
v/cg/resnet_v19/conv33/batchnorm33/beta
v/cg/resnet_v12/conv9/conv2d/kernel/read
learning_rate/Const_5
v/cg/resnet_v114/conv49/batchnorm49/gamma/read
learning_rate/PiecewiseConstant/and_1
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/gradients/tower_0/v/cg/resnet_v12/conv9/batchnorm9/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026602167	51380224
1608571026602168	256
1608571026602168	256
1608571026602169	256
1608571026602186	256
1608571026602519	-256
1608571026602519	-256
1608571026603936	-51380224
1608571026603981	-256
1608571026604888	-256
tower_0/v/gradients/tower_0/v/cg/resnet_v16/conv21/batchnorm21/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026571379	25690112
1608571026571379	512
1608571026571380	512
1608571026571381	256
1608571026571398	256
1608571026571468	-256
1608571026571469	-256
1608571026573442	-25690112
1608571026573489	-512
1608571026573547	-512
tower_0/v/l2_loss/L2Loss
1608571026443911	256
1608571026443915	256
1608571026444047	-256
1608571026543953	-256
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_15_grad/mul
1608571026448812	262144
1608571026589884	-262144
tower_0/v/cg/resnet_v16/conv22/batchnorm22/AssignMovingAvg_1/mul
tower_0/v/cg/resnet_v18/add
v/cg/resnet_v110/conv35/batchnorm35/gamma
tower_0/v/cg/resnet_v113/conv45/batchnorm45/AssignMovingAvg/mul
tower_0/v/cg/resnet_v10/conv3/batchnorm3/AssignMovingAvg/mul
tower_0/v/gradients/AddN_20
learning_rate/PiecewiseConstant/and
tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/Relu_grad/ReluGrad
v/cg/resnet_v111/conv38/batchnorm38/gamma/read
tower_0/v/gradients/tower_0/v/cg/resnet_v110/conv34/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026541804	1049088
1608571026541810	1048576
1608571026541824	4096
1608571026541989	-4096
1608571026541991	-1048576
1608571026542321	-1049088
v/cg/resnet_v10/conv4/batchnorm4/moving_mean
tower_0/v/cg/resnet_v110/Relu
v/cg/resnet_v11/conv6/batchnorm6/beta
tower_0/v/cg/affine0/xw_plus_b
tower_0/v/l2_loss/L2Loss_50
1608571026447820	256
1608571026447832	9216
1608571026447882	-9216
1608571026452164	-256
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_40_grad/mul
1608571026451599	1048576
1608571026532165	-1048576
v/cg/conv0/batchnorm0/beta
v/cg/resnet_v111/conv37/batchnorm37/beta/read
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v113/conv43/batchnorm43/beta/ApplyGradientDescent
tower_0/v/cg/resnet_v18/conv28/batchnorm28/AssignMovingAvg
v/cg/resnet_v113/conv44/batchnorm44/gamma
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v115/conv51/conv2d/Conv2D_grad/ShapeN-matshapes-1
learning_rate/PiecewiseConstant/case/cond/cond/cond/cond/cond/Switch_1
v/cg/resnet_v17/conv27/batchnorm27/beta/read
tower_0/v/cg/resnet_v17/conv27/batchnorm27/AssignMovingAvg_1
tower_0/v/gradients/tower_0/v/cg/resnet_v18/conv29/conv2d/Conv2D_grad/Conv2DBackpropInput
1608571026549039	12845056
1608571026549044	4194816
1608571026549918	12845056
1608571026549931	191102976
1608571026551035	-12845056
1608571026551037	-191102976
1608571026551039	-4194816
1608571026551815	-12845056
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv29/batchnorm29/gamma/ApplyGradientDescent
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v14/conv16/conv2d/Conv2D_grad/ShapeN-matshapes-0
learning_rate/PiecewiseConstant/case/cond/Switch_1
v/cg/resnet_v14/conv17/batchnorm17/gamma
v/cg/resnet_v112/conv40/batchnorm40/beta/read
tower_0/v/cg/resnet_v13/conv11/batchnorm11/AssignMovingAvg/mul
v/cg/resnet_v112/conv42/conv2d/kernel
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_4_grad/mul
1608571026444380	65536
1608571026622386	-65536
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv43/batchnorm43/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026523659	25690112
1608571026523660	12288
1608571026523661	8192
1608571026523662	256
1608571026523684	256
1608571026523759	-256
1608571026523760	-256
1608571026524453	-25690112
1608571026524511	-12288
1608571026524549	-8192
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv45/conv2d/Conv2D_grad/ShapeN-matshapes-0
v/cg/resnet_v15/conv19/batchnorm19/gamma/read
tower_0/v/cg/resnet_v113/conv46/batchnorm46/AssignMovingAvg_1/mul
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v15/conv18/conv2d/Conv2D_grad/ShapeN-matshapes-1
tower_0/v/resnet50_synthetic_labels/min
tower_0/v/cg/resnet_v12/conv10/batchnorm10/AssignMovingAvg
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v10/conv3/batchnorm3/beta/ApplyGradientDescent
v/cg/resnet_v17/conv27/batchnorm27/moving_mean/read
tower_0/v/gradients/tower_0/v/l2_loss/L2Loss_11_grad/mul
1608571026446337	524288
1608571026594190	-524288
tower_0/v/gradients/tower_0/v/cg/resnet_v13/conv13/batchnorm13/FusedBatchNormV3_grad/FusedBatchNormGradV3
1608571026594312	25690112
1608571026594313	512
1608571026594313	512
1608571026594314	256
1608571026594516	256
1608571026594593	-256
1608571026594593	-256
1608571026597245	-25690112
1608571026597300	-512
1608571026597335	-512
v/cg/resnet_v114/conv49/batchnorm49/moving_mean/read
learning_rate/PiecewiseConstant/case/cond/cond/Switch/Switch
tower_0/v/gradients/tower_0/v/cg/resnet_v113/conv44/conv2d/Conv2D_grad/Conv2DBackpropFilter
1608571026526058	2097152
1608571026526064	2097664
1608571026526081	4352
1608571026526185	-4352
1608571026526187	-2097664
1608571026526419	-2097152
tower_0/v/cg/conv0/Relu
ConstantFolding/tower_0/v/gradients/tower_0/v/cg/resnet_v11/conv6/conv2d/Conv2D_grad/ShapeN-matshapes-0
append_apply_gradient_ops/GradientDescent/update_v/cg/resnet_v18/conv28/conv2d/kernel/ApplyGradientDescent
